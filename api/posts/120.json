{"total":1769,"pageSize":12,"pageCount":148,"data":[{"title":"llamaindex-cli rag","uid":"3c41505139efb74f1661916f145c7f5e","slug":"aigc/langchain/llamaindex-cli rag","date":"2024-03-14T07:45:09.025Z","updated":"2024-03-14T07:45:09.025Z","comments":true,"path":"api/articles/aigc/langchain/llamaindex-cli rag.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" llamaindex-cli rag Llama Index隆重推出了RAG CLI， 一个极其简单的命令行工具，允许您对本地计算机上的任何文件进行 RAG。 倒是一个可以在本地体验RAG的好项目！#知识科普接龙# 索引包括 glob 模式的任何文件， llamaindex-c...","link":"","photos":[],"count_time":{"symbolsCount":504,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"}],"tags":[{"name":"llamaindex-cli","slug":"llamaindex-cli","count":2,"path":"api/tags/llamaindex-cli.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"如何用LangChain对正篇PDF进行润色","uid":"b2e6f88df47e562821a91f15dc8e651f","slug":"aigc/langchain/如何用LangChain对正篇PDF进行润色","date":"2024-03-14T07:45:09.024Z","updated":"2024-03-14T07:45:09.025Z","comments":true,"path":"api/articles/aigc/langchain/如何用LangChain对正篇PDF进行润色.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 如何用LangChain对正篇PDF进行润色 要使用LangChain对正篇PDF进行润色，可以按照以下步骤进行操作： 首先，将正篇PDF文件转换为可编辑的文本格式。可以使用OCR（Optical Character Recognition）软件或在线服务来实现这一步骤。OCR...","link":"","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"宇宙探索编辑部-关于Sora讨论","uid":"8498990ea0518320f72ae9f350cc7d26","slug":"aigc/sora/宇宙探索编辑部-关于Sora讨论","date":"2024-03-14T07:45:09.024Z","updated":"2024-03-14T07:45:09.024Z","comments":true,"path":"api/articles/aigc/sora/宇宙探索编辑部-关于Sora讨论.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 宇宙探索编辑部-关于Sora讨论 很荣幸受 邀请，今天和她以及《宇宙探索编辑部》副导演吕启洋（Ash）一起聊聊了一下当前火爆的话题 Sora，看 Sora 如何改变我们的生活。 我把技术相关的一些问题整理成了文字，希望能够帮助大家更好地理解 Sora。我将问题大约整理成了四类：...","link":"","photos":[],"count_time":{"symbolsCount":"3.9k","symbolsTime":"4 mins."},"categories":[{"name":"笔记","slug":"笔记","count":1,"path":"api/categories/笔记.json"}],"tags":[{"name":"sora","slug":"sora","count":3,"path":"api/tags/sora.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"Sora 和之前 Runway 那些在架构上有啥区别呢","uid":"d513b66cf42e1723c2bda6d425c5b9ed","slug":"aigc/sora/Sora 和之前 Runway 那些在架构上有啥区别呢","date":"2024-03-14T07:45:09.024Z","updated":"2024-03-14T07:45:09.024Z","comments":true,"path":"api/articles/aigc/sora/Sora 和之前 Runway 那些在架构上有啥区别呢.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" Sora 和之前 Runway 那些在架构上有啥区别呢 Sora是基于Diffusion Transformer模型的生成式模型，融合了扩散模型和Transformer架构，能有效处理含噪点的图像输入并逐步预测出更清晰的图像版本。与传统Token预测不同，Sora预测序列中的下...","link":"","photos":[],"count_time":{"symbolsCount":"2.3k","symbolsTime":"2 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"sora","slug":"AIGC/sora","count":1,"path":"api/categories/AIGC/sora.json"}],"tags":[{"name":"sora","slug":"sora","count":3,"path":"api/tags/sora.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"开始构建类似 ChatGPT","uid":"cf3ae125b94c92a05016e1e5aae14eba","slug":"aigc/llm/开始构建类似 ChatGPT","date":"2024-03-14T07:45:09.023Z","updated":"2024-03-14T07:45:09.023Z","comments":true,"path":"api/articles/aigc/llm/开始构建类似 ChatGPT.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 开始构建类似 ChatGPT 教你从零开始构建类似 ChatGPT 的大语言模型。 在 GitHub 上发现一本《Build a Large Language Model (From Scratch)》书籍。 作者将带你从头开始构建一个类似 GPT 语言模型，这过程让你了解如何...","link":"","photos":[],"count_time":{"symbolsCount":479,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"}],"tags":[{"name":"book","slug":"book","count":1,"path":"api/tags/book.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"书生・浦语 2.0（InternLM2）大语言模型正式开源","uid":"ba1b40adefccb80b7453716eb9f031b1","slug":"aigc/llm/书生・浦语 2.0（InternLM2）大语言模型正式开源","date":"2024-03-14T07:45:09.023Z","updated":"2024-03-14T07:45:09.023Z","comments":true,"path":"api/articles/aigc/llm/书生・浦语 2.0（InternLM2）大语言模型正式开源.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 书生・浦语 2.0（InternLM2）大语言模型正式开源 Github：[https://github.com/InternLM/InternLM] HuggingFace：[https://huggingface.co/internlm] ModelScope：[https...","link":"","photos":[],"count_time":{"symbolsCount":194,"symbolsTime":"1 mins."},"categories":[{"name":"InternLM2","slug":"InternLM2","count":1,"path":"api/categories/InternLM2.json"}],"tags":[{"name":"InternLM2","slug":"InternLM2","count":1,"path":"api/tags/InternLM2.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"Mixtral-8x7B中文","uid":"9a40a6a39b959d0093a5b06c499bf410","slug":"aigc/llm/ollama/Mixtral-8x7B中文","date":"2024-03-14T07:45:09.023Z","updated":"2024-03-14T07:45:09.023Z","comments":true,"path":"api/articles/aigc/llm/ollama/Mixtral-8x7B中文.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" Mixtral-8x7B中文 Chinese-Mixtral-8x7B：中文Mixtral-8x7B，基于Mistral发布的模型Mixtral-8x7B进行了中文扩词表增量预训练】‘Chinese-Mixtral-8x7B’ GitHub: github.com/HIT-SC...","link":"","photos":[],"count_time":{"symbolsCount":165,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"Mixtral-8x7B","slug":"AIGC/Mixtral-8x7B","count":1,"path":"api/categories/AIGC/Mixtral-8x7B.json"}],"tags":[{"name":"Mixtral-8x7B","slug":"Mixtral-8x7B","count":1,"path":"api/tags/Mixtral-8x7B.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"模型微调","uid":"80343fe751072d14380c6c808291386e","slug":"aigc/llm/模型微调","date":"2024-03-14T07:45:09.022Z","updated":"2024-03-14T07:45:09.022Z","comments":true,"path":"api/articles/aigc/llm/模型微调.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 模型微调 模型微调和增加检索的区别是什么， 什么场景适用模型进行微调，什么场景更适合适用增加检索RAG进行处理？ 模型微调和增加检索的区别在于它们的目标和方法。 模型微调是指在一个预训练的模型基础上，使用特定的数据集进行再训练，以适应特定的任务或领域。通过微调模型，可以使其更好...","link":"","photos":[],"count_time":{"symbolsCount":561,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"}],"tags":[{"name":"llama","slug":"llama","count":1,"path":"api/tags/llama.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"ChatGLM运行在多块显卡上","uid":"cfb4d1b86fdb40bad53c9ad03918951d","slug":"aigc/llm/chatglm/ChatGLM运行在多块显卡上","date":"2024-03-14T07:45:09.022Z","updated":"2024-03-14T07:45:09.022Z","comments":true,"path":"api/articles/aigc/llm/chatglm/ChatGLM运行在多块显卡上.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" ChatGLM运行在多块显卡上 ChatGLM如何运行在多块显卡上 ChatGLM是一个基于GPT-3的模型，由于GPT-3模型本身的特性，它无法直接在多块显卡上运行。GPT-3是一个非常大的模型，需要大量的计算资源和内存来训练和运行。 然而，可以使用分布式训练和推理技术来在多...","link":"","photos":[],"count_time":{"symbolsCount":489,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"ChatGLM","slug":"AIGC/ChatGLM","count":1,"path":"api/categories/AIGC/ChatGLM.json"}],"tags":[{"name":"ChatGLM","slug":"ChatGLM","count":1,"path":"api/tags/ChatGLM.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"Ubuntu20下安装LangChain","uid":"da3e1a2feb54da7d27a471dfb5b9de32","slug":"aigc/llm/langchain/Ubuntu20下安装LangChain","date":"2024-03-14T07:45:09.022Z","updated":"2024-03-14T07:45:09.022Z","comments":true,"path":"api/articles/aigc/llm/langchain/Ubuntu20下安装LangChain.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" Ubuntu20下安装LangChain Ubuntu20下安装LangChain的具体操作过程是什么 要在Ubuntu 20上安装LangChain，可以按照以下步骤进行操作： 打开终端，使用以下命令更新系统软件包列表： sudo apt update 安装依赖软件包。Lan...","link":"","photos":[],"count_time":{"symbolsCount":694,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"向Langchain提交文件到知识库里","uid":"53a25fe229b631c447bd468734e04066","slug":"aigc/llm/langchain/向Langchain提交文件到知识库里","date":"2024-03-14T07:45:09.022Z","updated":"2024-03-14T07:45:09.022Z","comments":true,"path":"api/articles/aigc/llm/langchain/向Langchain提交文件到知识库里.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 向Langchain提交文件到知识库里 要向Langchain提交文件到知识库里，可以按照以下步骤进行操作： 首先，确保你已经注册并登录了Langchain的平台账户。 在登录后，找到页面上方的导航栏或菜单中的“知识库”选项，并点击进入。 在知识库页面中，你可以浏览已有的文件和...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"langchain","slug":"AIGC/langchain","count":1,"path":"api/categories/AIGC/langchain.json"}],"tags":[{"name":"langchain","slug":"langchain","count":2,"path":"api/tags/langchain.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},{"title":"矢量数据库","uid":"0214cb41e71f0a070ee24d319de60be5","slug":"aigc/矢量数据库","date":"2024-03-14T07:45:09.021Z","updated":"2024-03-14T07:45:09.021Z","comments":true,"path":"api/articles/aigc/矢量数据库.json","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 什么是𝗩𝗲𝗰𝘁𝗼𝗿 𝗗𝗮𝘁𝗮𝗯𝗮𝘀𝗲? 什么是𝗩𝗲𝗰𝘁𝗼𝗿 𝗗𝗮𝘁𝗮𝗯𝗮𝘀𝗲? 随着基础模型的兴起，矢量数据库迅速流行起来。事实上，矢量数据库在大型语言模型上下文之外也很有用。 当谈到机器学习时，我们经常处理向量嵌入。矢量数据库的创建是为了在使用它们时表现特别好： ➡️ 存储。 ...","link":"","photos":[],"count_time":{"symbolsCount":963,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}]}