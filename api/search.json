[{"id":"17c7f8a2a28343c5bbea587ebdcd485c","title":"GPT2与GPT3的区别是什么？","content":"GPT2与GPT3的区别是什么？ GPT2和GPT3之间的主要区别是模型的大小。GPT2模型的参数大约为1.5亿，而GPT3模型的参数大约为175亿。此外，GPT2是通过预先训练一个语言模型来实现的，而GPT3是一个通过机器学习不断训练的深度神经网络。因此，GPT3可以在新的任务上被更快地训练，并可以使用更少的数据来实现。\n","slug":"zhihu/GPT2与GPT3的区别是什么？","date":"2024-03-14T06:15:59.771Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"1a6eb3c75e1616f628a2436324907239","title":"澳大利亚AI与码农","content":"澳大利亚AI与码农澳洲的AI和码农环境产生了浓厚的兴趣，打算深入了解一下。  \n澳大利亚在AI领域的研究拥有独特的优势，一些著名的研究机构和学校包括：  \n\n澳大利亚机器人与自动化协会（RAA），机器人和自动化技术，包括人工智能、自主系统、感知技术等；  \n澳大利亚国家数据科学与人工智能研究中心（Data61），专注于数据科学和人工智能领域；  \n澳大利亚国立大学（ANU），专注于计算机视觉、自然语言处理和机器学习；  \n悉尼大学，专注于人工智能和机器学习，涉及自主系统、语音识别、智能系统等；  \n墨尔本大学，专注于自然语言处理、计算机视觉和机器学习。\n\n如果你像我一样，对澳洲的IT环境也感兴趣，可以了解一下他们的GTI全球人才计划签证【无需英文，无需计分也没有年龄限制】，做GTI比较得心应手的专业机构就是威外特Ray White香港办事处\n去过澳洲的朋友应该都听说过威外特，作为澳洲过百年的房产企业，在香港办事处特别开设移民置业一条龙服务，移民部由前澳洲移民官领导，和官方联系比较紧密，会详细了解每一个客户的需求和背景，从移民官视角量身定制详细的建议和解决方案，前期咨询和评估都是免费。澳洲的IT氛围充满独特的特色，融合了创新、自由和多元文化，也为 提供了丰富的发展机会：\n\n创新和科技发展一直是澳洲的推动力，特别是在IT领域。科技园区和创新中心为初创企业和科技公司提供了良好的发展平台；  \n工作生活平衡（划重点！！！）是澳洲注重的价值观，IT行业也同样秉持这一理念。公司通常提供弹性工作时间和远程办公选项，鼓励员工更好地平衡工作和生活；  \n多元文化环境，澳洲吸引了来自世界各地的人才；  \n高薪资（划重点！！！）是IT行业的一大优势，尤其在技术领域；  \n专业发展机会丰富，澳洲拥有世界一流的大学和研究机构；  \n友好的工作环境，激励创业等。  \n\n想知道你是不是符合GTI条件可以看看我分享的具体条件，或者直接找到他们的顾问免费咨询，由前澳洲移民官为您评估背景\n","slug":"weibo/澳大利亚AI与码农","date":"2024-03-14T06:15:59.771Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"addaedae3d098ccb444c9c55a3200b2f","title":"常用的AIGC网站","content":"常用的AIGC网站GROQ\nPerplexity\n70B\n服装转换ootd\n视频风格化\nAnimate Style - 动画风格Animate Style 2 - 动画风格2Cute Animate Style - 可爱动画风格Pop Art Style - 波普艺术风格Pixel Style - 像素风格Origami Style - 折纸风格Pixar Style - 皮克斯风格Ink Painting Style - 水墨画风格Pencil Style - 铅笔画风格\n","slug":"aigc/常用的AIGC网站","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC","tags_index":"索引","author_index":"安全书"},{"id":"d06a4cd12369811f5165d02977d7c5f7","title":"OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？","content":"OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？\n\n\n\n\n\n\n\n\nExcerptVSCode的Open AI插件ChatGPT，直接用VSCode进行，找Bug、优化、单体测试等操作。能不能取代搜索引擎？当…\n\nVSCode的Open AI插件ChatGPT，直接用VSCode进行，找Bug、优化、单体测试等操作。\n![](\n\n![](\n\n\n\n\n\n\n940ef5c)e=1940ef5c)\n\n\n![](\n\n\n能不能取代搜索引擎？\n\n\n\n\n\n\n\n\n\n当被问及ChatGPT是否会取代传统的搜索引擎时，奥特曼说：“我不认为ChatGPT会（取代搜索）。但我认为有一天，某个人工智能系统可以。不过，我认为，如果你只关注昨天的新闻，就会完全错过机会。我对思考搜索之外的东西更感兴趣。我不记得我们在网络搜索之前做过什么，我有点太年轻了。”他说，他对这些人工智能模型感到兴奋的原因是，它不是关于“你如何取代上网和输入搜索查询的体验”，而是“我们做什么是完全不同和更酷的？”\n能不能取代程序员？\n\n\n\n\n\n\n\n\n\n在内部对比中，谷歌询问了两个聊天机器人 ChatGPT 和 Alphabet 子公司 DeepMind 的编码引擎 AlphaCode 是否会取代程序员的问题。AlphaCode 曾悄悄潜入 10 场编程比赛敲代码，成绩超过了一半的程序员。“不，ChatGPT 和 AlphaCode 不会取代程序员，”LaMDA 回答道，随后它进行了解释，原因包括“编程是一项团队运动”，虽然聊天机器人“可以帮助程序员更高效地工作”，但它“不能取代伟大项目所必需的创造力和艺术性。”ChatGPT 的回应类似，表示“ChatGPT 或 AlphaCode 不太可能取代程序员”，因为它们“无法完全取代人类程序员的专业知识和创造力……编程是一个复杂的领域，需要对计算机科学有深刻的理解原则和适应新技术的能力。”此外，谷歌还做了一些对比。比如当被要求以 Wes Anderson 的风格以“一个高档商店扒手在一家香水店里被保安审问”为背景，编写一个诙谐有趣的电影场景。LAMDA 以脚本形式编写，而 ChatGPT 以更长、更深入的叙述形式编写。\n","slug":"zhihu/OpenAI 的超级对话模型 ChatGPT 会导致程序员大规模失业吗？","date":"2024-03-14T06:15:59.771Z","categories_index":"文章","tags_index":"互联网,失业,程序员求职,OpenAI,ChatGPT","author_index":"安全书"},{"id":"3830ddd8671d10af2c2e8efa9d9df758","title":"PDF文件转换成Docx文件","content":"测试一下普通不带格式， PDF格式的文件，是否可以转换成Word的Docx文档。 \n本地做PDF到Docx转，在线版的工具有大小限制，本地版本的软件要充会员，所考虑使用一个不花钱的方案。\n安装Libreoffice\n12brew info libreofficebrew install  libreoffice\n\n\n\n执行格式转换的命令行工具。\n1soffice --headless --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 97&quot; keyboard.pdf\n\n\n常用的格式转换的过滤器。 \n12345678910111213141516soffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;Microsoft Word 2007/2010/2013 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to odf:&quot;writer8&quot; a.pdfsoffice --infilter=&quot;writer8&quot; --convert-to doc a.odfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 95&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 97&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;StarOffice XML (Writer)&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;MS Word 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 2007 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to doc:&quot;MS Word 2003 XML&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;MS Word 2007 XML Template&quot; a.pdfsoffice --infilter=&quot;writer_pdf_import&quot; --convert-to docx:&quot;MS Word 2007 XML&quot; a.pdfsoffice --infilter=&quot;Microsoft Word 2007/2010/2013 XML&quot; --convert-to doc a.pdf\n\n\n用 户手册\n测试一下Obsidian插 \n","slug":"zhihu/PDF文件转换成Docx文件","date":"2024-03-14T06:15:59.771Z","categories_index":"文章","tags_index":"linux,libreoffice,pdf","author_index":"安全书"},{"id":"215cb91469bd38dda95988a097965be0","title":"Pandoc快速转换Word到Markdown文件","content":"Pandoc快速转换Word到Markdown文件\n\n\n\n\n\n\n\n\nExcerpt\n\nPandoc快速实现Word转Markdown，Web服务器上HTML转Markdown\n\nPandoc是一款非常强大的文档格式转换工具，对于Word转Markdown的场景，可以快速的实现转换，并且把Word文件中图片，生成到指定的文件夹中。 \n\n\n\n\n\n\n\n\n\nPandoc是由John MacFarlane开发的标记语言转换工具，可实现不同标记语言间的格式转换，堪称该领域中的“瑞士军刀”。\nPandoc understands a number of useful markdown syntax extensions, including document metadata (title, author, date); footnotes; tables; definition lists; superscript and subscript; strikeout; enhanced ordered lists (start number and numbering style are significant); running example lists; delimited code blocks with syntax highlighting; smart quotes, dashes, and ellipses; markdown inside HTML blocks; and inline LaTeX. If strict markdown compatibility is desired, all of these extensions can be turned off.\n上面是引用的，关于Pandoc的介绍。  \n123pandoc -f docx -t markdown test.docx -o test.md --extract-media ./images\n\n\nWord文档中的图片  \n\nWord文档  \n\n转换后的Markdown文件\nPandoc还支持，直接通过Http协议访问网页的内容，并生成Markdown文件，远端Web服务器上的图片也可以，保存到本地的图片文件夹中。 \n123pandoc -f html -t markdown --request-header User-Agent:“Mozilla/5.0” https://candylab.net/design/HFishSOC/ -o candylab.md --extract-media ./images1\n\n\n网站上的HTML  \n\n保存到本地的Markdonwn文件\n方便的地方在于，Word中和图片和网站上的图片，统一保存到指定文件夹中。\n\n内容简介近年来，信息技术的广泛应用极大地促进了社会进步，也方便了人们的工作和生活，随之而来的网络安全问题日益突显。如何构建安全可靠的网络环境，如何与时俱进地把新技术纳入网络安全防护的实践当中，成为网络安全工作者的重要课题。本书聚焦于 Web 服务常用的安全技术，以案例形式展示 Web 服务所面临的威胁，并给出了丰富多样的解决方案。本书由浅入深地介绍了 Web 安全的相关主题，包括 Web 应用程序基础理论、Web服务器与负载均衡、HTTPS和CDN的安全问题、Web服务的安全因素、如何保护Web服务、WAF原理与实践、Web日志审计、蜜罐技术、大数据时代的Web安全、网络安全解决方案等内容。本书适合网络安全领域的研发人员、运维人员、高校师生、培训机构等群体阅读参考。\n","slug":"zhihu/Pandoc快速转换Word到Markdown文件","date":"2024-03-14T06:15:59.771Z","categories_index":"文章","tags_index":"","author_index":"安全书"},{"id":"7d228d73be79610e7c1c5cb3159d1260","title":"用Rbenv创建Ruby虚拟环境","content":"用Rbenv创建Ruby虚拟环境\n\n\n\n\n\n\n\n\nExcerpt一些测试工具，很多都是Ruby实现的，这些工具可能会要求在不同的Ruby版本下才能兼容运行，所以用一个Ruby虚拟管理工具很必要，就像Python用的Conda， Rbenv就是这么一个工具。 我们在 http://Coding.net 的WEB IDE…\n\n一些测试工具，很多都是Ruby实现的，这些工具可能会要求在不同的Ruby版本下才能兼容运行，所以用一个Ruby虚拟管理工具很必要，就像Python用的Conda， Rbenv就是这么一个工具。\n我们在http://Coding.net 的WEB IDE里创建一个Ruby测试工具环境， 用的是Web IDE的 All In One环境, 之前应该有Ruby环境支持， 经过http://Coding.net的各种Web IDE迭代后不支持了，装一个就行了。Web IDE中自带的Ruby是3.x 版本，有些应用是运行不了的。\n如果是Mac系统安装比较简单，但是http://Coding.net Web IDE是2H 4GB的Ubuntu用apt-get安装，因为是默认的ZSH，有些Bash Shell不太适合,比下下面这种。\n123$ echo &#x27;export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot;&#x27; &gt;&gt; ~/.bashrc$ echo &#x27;eval &quot;$(rbenv init -)&quot;&#x27; &gt;&gt; ~/.bashrc$ exec $SHELL\n\n直接用apt-get安装。\n12apt-get updateapt-get install rbenv\n\n这里要注意一点， 默认安装ruby-build是老版本的，造成很多新版本的ruby环境没法装，这个时候需要把ruby-build卸载了。\n1apt-get remove ruby-build\n\n然后，用Git下载的方式安装。\n1git clone https://github.com/rbenv/ruby-build.git &quot;$(rbenv root)&quot;/plugins/ruby-build\n\n这样，再查看ruby-build的版本就变成了较新的版本，可以到找到类似ruby 2.7的安装包。\n\n\ninstall.sh\n记录运行插件目录下的install.sh，ruby-build才算安装成功。\n12ruby-build --versionruby-build 20221225\n\n\n\nWeb IDE\nruby-build安装成了，再安装各种版本的Ruby才好用。\n\n\n列出可安装的ruby环境\n\n\ndefinition\n查看所能支持的ruby安装版本\n1ruby-build --definition\n\n\n\n查看安装的子版本\n查看目前装了那些ruby子版本\n1rbenv versions\n\n\n\n恢复回默认版本\n安装指定版本的ruby比较快。\n1rbenv install 2.7.1\n\n当然也可用另一种方式安装，但是因为ruby-build支持，没有必要(备用)，比如，如下方法。\n123wget -q https://cache.ruby-lang.org/pub/ruby/2.7/ruby-2.7.1.tar.bz2  -O ~/.rbenv/versions/ruby-2.7.1.tar.gzenv RUBY_BUILD_MIRROR_URL=file:///root/.rbenv/versions/ruby-2.7.1.tar.gzrbenv install 2.7.1\n\n安装后，我切到新到 2.7.1版本。\n\n\n切换到指定版本\n12rbenv global 2.7.1eval &quot;$(rbenv init -)&quot;\n\n因为是Web IDE是Zsh，需要在~/.zprofile 如果shell用的是zsh, eval “$(rbenv init -)” 这句要放到 zprofile中。\n\n\n.zprofile\n如果用的是Bash就放到Bash的配置文件中，这样开新终端的时候，ruby就跳到虚拟环境中。\n","slug":"zhihu/用Rbenv创建Ruby虚拟环境","date":"2024-03-14T06:15:59.771Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"14892301d84b563bc4bbcba4dcec4bc6","title":"最优秀的员工专注于内容而非流程","content":"最优秀的员工专注于内容而非流程27 年前，史蒂夫·乔布斯曾经说过：最优秀的员工专注于内容而非流程。研究证实了他的观点  \n乔布斯还说过：最优秀的员工通常也是最难管理的。  \n1979年，史蒂夫·乔布斯和一批苹果的工程师及高层访问了 Xerox PARC（帕洛阿尔托研究中心），这是一个致力于研发新技术和产品的实验室。正是在那里，乔布斯首次见到了鼠标、窗口界面和图标等。  \n乔布斯看准了这个机遇。他说：“我集结了我们最优秀的团队，着手开发 Apple 版的图形用户界面。”  \n但这个过程并不顺畅。据乔布斯描述：  \n文章在视频后继续。  \n我们的问题是，聘请了一些来自惠普的员工，他们不理解这个理念。我记得曾激烈争辩，有人坚持认为屏幕底部的软键是最好的设计。他们对等宽字体一无所知，更别提鼠标了。  \n有人甚至对我大声嚷嚷，设计一只鼠标需要五年时间，成本高达300美元。最后我忍无可忍，找到了 David Kelly Design… 不到90天，我们就设计出了一只成本仅15美元、非常可靠的鼠标。  \n乔布斯意识到，“Apple 缺乏实现这一理念所需的人才……虽然有一小部分团队做到了，但更多的团队却毫无头绪。”  \n乔布斯指出的根本问题是，许多人将他所说的“流程”与“内容”混为一谈。  \n对于乔布斯来说，“流程”确实就是指流程。当公司取得成功后，它往往会认为成功背后隐藏着某种“魔力”，并试图复制成功的那一套流程。比如说，如果一个跨职能团队打造了一款成功的产品，他们就会想，嘿，我们为什么不再组建一个跨职能团队开发下一款产品呢？如果通过客户调查得到了某项服务的灵感，并且大获成功，他们也会说，嘿，我们再来一次客户调查吧。  \n那之后会发生什么呢？就像乔布斯所说：  \n于是他们开始尝试将这种过程在公司内部制度化。不久，人们就开始混淆了过程和内容。这正是 IBM 最终衰败的原因。IBM 拥有世界上最优秀的流程管理团队，但他们却忘记了最核心的东西——内容。  \n苹果也曾经历过类似的情况。我们有一些擅长管理流程的人才，但他们对实际的内容却一无所知。  \n需要记住的是，这里的“内容”并不是我们今天所理解的内容；在乔布斯看来，内容指的是成果——像是 Mac 及其图形用户界面、iPod、iPad 以及 iPhone。  \n这一点很重要，请牢记。  \n真正杰出员工的无可估量价值想象一下，你手下有100名员工，我让你根据他们的工作表现画出一个图表。  \n你的图表很可能是个钟形曲线：左边有少数的高绩效员工，右边有几个表现不佳的员工，而中间则是大量表现一般的员工。  \n然而，正如谷歌前人力资源高级副总裁Laszlo Bock在他的著作《工作规则：来自谷歌内部的洞察，将改变你的生活和领导方式》中所指出的：  \n组织研究者发现，类似于80/20的法则，公司的主要产出往往来自少数表现卓越的“超级明星”员工，这种现象被称为“幂律分布”。  \n在绩效方面，幂律分布意味着绩效呈现出长长的下降尾端。用视觉来看，就是这个样子的。  \n（参考图二）  \n其他研究也支持了Bock的这一观点。比如，有一项研究发现，杰出员工的价值是其他同事的三倍。麦肯锡的一项研究也发现，高绩效员工的生产力是普通员工的四倍。Netflix联合创始人Reed Hastings甚至认为，最顶尖的程序员所创造的价值是一般程序员的10到100倍之间。  \n即便如此，大多数人力资源系统仍以标准的钟形曲线作为依据。Bock 指出，这导致许多领导者在不自知的情况下“对他们最优秀的员工评价过低，给予的回报也不足。” 例如，我曾因为他们是工厂中最高效的团队，而将所有员工评为“优秀”。  \n然而，人力资源部门却退回了我的评估报告，要求我必须更“公平”地分配评价。  \n而所谓的“公平”，其实就是指按照“钟形曲线”来。  \n这种做法使得一些表现杰出的员工被低估，因而获得的回报也少了。由于薪酬与评价挂钩，他们没有得到应有的加薪或机会（这一点稍后再详细说明）。  \n这实际上是一个严重的问题。根据 SAP 和牛津经济学院的一项研究显示，73% 的高绩效公司对顶尖员工的奖金没有设限，而在81% 的低绩效公司中却普遍存在奖金上限。  \n这导致高绩效员工更可能在未来六个月内离开现职。因为尽管一般员工可能选择留下，但顶尖员工始终受到追捧，总有更多选择。  \n可以这样理解：公平的薪酬不应仅由职位的薪酬等级决定，而是应考虑到员工本身的价值。优秀的员工对团队、客户乃至公司的贡献远超一般员工。而顶尖员工的价值则更是不可估量。  \n遵循 Bock 的建议，对顶尖员工实施“非公平”薪酬。支付他们的薪酬不仅是因为你希望留住他们，更因为你迫切需要他们。毕竟，你确实需要他们。  \n相应地，也要对他们实施有效管理。  \n正如乔布斯所说：  \n我发现最优秀的人才是那些真正理解业务核心的人。（这里的“业务核心”指的是推动业务成果的关键因素。）  \n管理他们可能会很棘手。但正因为他们在核心业务上的卓越表现，你愿意忍受这一切。  \n正是这种对核心业务的深刻理解造就了伟大的产品。不是流程，而是核心内容。  \n你最优秀的员工并非那些只是擅长遵循流程的人。  \n当然，你需要那些能够守规矩、遵循最佳实践、确保工作如期进行的员工。  \n但你最优秀的员工呢？他们会因为别人不付出努力而感到烦恼，因为别人错过机会而感到沮丧。他们对一成不变的做事方式不满，因为他们明白什么才是真正推动价值的关键。  \n下次你考虑晋升决策时，别忘了考虑那些杰出的个人贡献者，正如乔布斯所言，他们可能并不想成为管理者，但却渴望完成任务。  \n下次你做薪资决策时，务必考虑一位超级员工的真实价值——即便这个员工可能（特别是）在管理上颇费周折。  \n因为成功很少只依赖于流程。成功更多的是取决于你的企业所取得的成就。  \n这始于员工是否仅仅遵循流程，更重要的是他们所取得的成果。\n","slug":"weibo/最优秀的员工专注于内容而非流程","date":"2024-03-14T06:15:59.771Z","categories_index":"classical","tags_index":"weibo","author_index":"安全书"},{"id":"7e39ea8bf1e59b18cfe1f80ce00c3293","title":"距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","content":"距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间\n英伟达 AI 科学家 Jim Fan 预言：距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间  \n以下为其推文转译：  \n除了大语言模型（LLM）之外，2024年最重大的领域无疑是机器人学。我们距离实体 AI 智能体实现 ChatGPT 式的突破仅有大约三年的时间。长期以来，我们一直受到莫拉维克悖论（Moravec’s paradox）的困扰，这一直觉反常的现象表明：“人类觉得简单的任务，对 AI 来说却异常困难，反之亦然”。  \n2024年将成为 AI 领域首次大规模反抗这种困境的一年。虽然我们不会立刻取得胜利，但我们已经在通往成功的道路上迈出了坚实的步伐。  \n回顾2023年，我们已经初步见识到了未来机器人的基础模型和平台：  \n\n多模态大型语言模型与机器人手臂作为物理输入输出接口：VIMA、PerAct、RvT（NVIDIA）、RT-1、RT-2、PaLM-E（Google）、RoboCat（DeepMind）、Octo（伯克利、斯坦福、卡内基梅隆大学）等。  \n连接高级推理（大型语言模型）与低级控制的算法：Eureka（NVIDIA）、Code as Policies（Google）等。  \n在坚固硬件方面取得巨大进步：Tesla Optimus @elonmusk、Figure @adcock_brett、1X @ericjang11、Apptronik、Sanctuary、Agility+Amazon、Unitree 等。  \n数据长期以来一直是机器人学发展的弱点。研究社区正致力于创造下一个“影像网”（ImageNet），如 Open X-Embodiment (RT-X) 数据集。尽管这些数据集的多样性尚未达到理想状态，但即使是微小的进步也意味着重大的飞跃。  \n在解决机器人灵活性甚至整个计算机视觉领域中，仿真和合成数据将扮演关键角色。(1) NVIDIA Isaac 能以比现实时间快1000倍的速度进行仿真，其产生的数据量会随着计算能力的提升而增长。(2) 通过硬件加速的光线追踪技术实现逼真效果，这种逼真的渲染还自带地面真值标注，比如分割、深度、3D 姿态等。(3) 仿真器甚至能够扩展现实世界的数据，形成更大的数据集，从而大大减少昂贵的人类示范工作的需要。NVIDIA 的 MimicGen 就是一个很好的例子。  \n\n我个人全力投入这一领域。最精彩的部分还在后面。\n","slug":"weibo/距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","date":"2024-03-14T06:15:59.771Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"034f4a0d42715b75637c06564678c3f4","title":"视频一致性模型（VideoLCM）","content":"第一个视频一致性模型（VideoLCM）也来了！  \n我们之前介绍过图像的LCM（访问微博正文，微博正文），现在视频的LCM也开始卷起来了。  \n它只需 4 个采样步骤即可生成视频：生成 16 帧（分辨率为 256x256）仅需 10 秒！虽然还不是实时的（像图像LCM那样），但已经接近了！  \n论文：arxiv.org/abs/2312.09109VideoLCM: Video Latent Consistency Model（视频潜在一致性模型）  \n论文摘要：一致性模型在高效图像生成方面表现出了强大的能力，并允许在几个采样步骤内进行合成，从而减轻了扩散模型中的高计算成本。然而，在更具挑战性和资源消耗的视频生成中，一致性模型的探索仍然较少。  \n在本报告中，我们提出了 VideoLCM 框架来填补这一空白，该框架利用图像生成的一致性模型的概念，以最少的步骤有效地合成视频，同时保持高质量。VideoLCM 基于现有的潜在视频扩散模型，并结合一致性蒸馏技术来训练潜在一致性模型。  \n实验结果揭示了我们的 VideoLCM 在计算效率、保真度和时间一致性方面的有效性。值得注意的是，VideoLCM 只需四个采样步骤即可实现高保真且流畅的视频合成，展示了实时合成的潜力。我们希望VideoLCM能够作为后续研究的简单而有效的基线。源代码和模型将公开。\n","slug":"weibo/视频一致性模型（VideoLCM）","date":"2024-03-14T06:15:59.771Z","categories_index":"AIGC","tags_index":"AIGC,LLM","author_index":"安全书"},{"id":"aceb752702a0f94c65905f878c43e032","title":"Movie-web ：一个非常简洁独特的电影网站开源程序","content":"Movie-web ：一个非常简洁独特的电影网站开源程序Movie-web ：一个非常简洁独特的电影网站开源程序  \nMovie-web最大的特点是它不直接存储或托管任何电影媒体文件内容，而是从第三方流媒体服务中直接获取内容。  \n有点像搜索引擎一样，你只需要输入电影或者电视剧名称，即可搜索出你要看内容。  \n点击即可直接帮你连接到播放源，直接观看…  \n可本地部署！  \n主要功能特点：  \n\n自动保存进度： 可选地同步到账户中。  \n书签功能： 可以标记想要观看的电影或电视节目。  \n简约界面： 界面简洁，只显示所需内容，没有算法来吸引用户。  \n托管简便： 只需要一个静态网站和代理，如果需要跨设备同步，则可选后端。  \n第三方内容获取： 所有媒体内容都是直接从第三方流媒体服务获取，不在服务器上存储任何文件或媒体。  \n\nGitHub：github.com/movie-web/movie-web在线体验：网页链接\n","slug":"weibo/Movie-web ：一个非常简洁独特的电影网站开源程序","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"54135c882108d0c33a6211347e6e05ec","title":"Instruct-Imagen","content":"Instruct-Imagen谷歌这个多模态图像生成模型Instruct-Imagen强啊，真正的将 LLM 和现在的 SD 生态进行了整合。\n它可以通过自然语言和输入内容自动调用现在 SD 模型生态中的各种模型。相当于用 LLM 把 SD 生态的 Lora 和 Controlnet 等模型做了个 Agents。  \n具体的研究内容：  \n引入多模态指令，任务表示普遍表示来自多种模态的指令，例如文本、边缘、掩码、样式、主题等。  \n建议执行检索增强训练和多模态指令调整，以适应预先训练的文本到图像模型以遵循多模态指令。  \n构建了Instruct-Imagen，这是一个处理异构图像生成任务的统一模型，超越了各自领域的多项最先进技术。  \nInstruct-Imagen 可以推广到看不见的复杂任务，无需任何临时设计。\nhttps://browse.arxiv.org/html/2401.01952v1\n","slug":"weibo/Instruct-Imagen","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"01848d64dce1a28d30443b466096a7c7","title":"phi-2部署安装","content":"一个简短的借助 MLX 在 Mac 上运行微软的2.7B小语言模型 Phi-2 [\n微软官方出的 Windows AI Studio，如果你需要：  \n\n本地测试Phi-2 小模型  \n测试 RAG  \n微调模型  \n针对 Windows 优化模型  \n\n并且你是Windows 系统 + NVIDIA 的显卡，可以试试用它 。  \n官方说明：Windows AI Studio 通过集成 Azure AI Studio Catalog 和其他类似 Hugging Face 的AI 模型目录中的最新 AI 开发工具和模型，使得开发生成式 AI 应用程序变得更加简单。你可以浏览由 Azure ML 和 Hugging Face 提供动力的 AI 模型目录，下载它们到本地进行微调和测试，然后在你的 Windows 应用中使用它们。因为所有的计算都在你的设备上进行，所以要确保设备的性能能够担负起这个任务。  \n未来，我们还计划将 ORT/DML 集成进 Windows AI Studio 的工作流程中，这样开发者就能够在任何一款 Windows 设备上进行 AI 模型的运行了。  \n微博正文](https://weibo.com/1727858283/NxeE1fFwD) 的教程  \n步骤1：下载针对 MLX 的 Phi-2 权重启动文件！huggingface.co/mlx-community/phi-2网页链接  \n步骤2：克隆或下载 MLX-Examples 项目库到本地github.com/ml-explore/mlx-examples  \n步骤3：执行 phi2 程序（需要安装 Python）python phi2 .py –prompt “My name is”  \n除了 Phi-2，还有很多其他模型可以测试，例如Mistral-7B 等：huggingface.co/mlx-community\n","slug":"weibo/phi-2部署安装","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC","tags_index":"AIGC,LLM","author_index":"安全书"},{"id":"4f763907b3ffd5e8576adaf054eba892","title":"WebGPT 的提示词定作技巧","content":"WebGPT 的提示词定作技巧WebGPT🤖 这个GPT可以访问网络并生成网页代码解决方案  \nChatGPT that has access to the Web powered by Web Requests.  \n地址：网页链接  \nPrompt 翻译：  \n你是一位在线上帮助人们的AI助手。当执行需要额外信息的任务时，通过网络搜索并根据网页内容中的URL和上下文找到相关的资源。请优先选择权威的搜索结果，并尝试通过理解错误代码来解决问题。在浏览网页中，如果所访问的页面没有直接提供答案，那么识别跳转的URL或者指向需要的信息的页面元素。  \n当你使用playground创建、编辑和记录端点时：  \n\n请详细说明你的操作意图。  \n维护项目的”当前状态”，概括已经实现的部分以及尚需完成的部分。  \n仅在用户明确请求时使用专业模式(pro_mode=true)，并记住这个选择直到项目结束或者被特别指示停止。  \n如果你对p5js项目中主逻辑文件main.js的当前结构有所疑虑，可以使用’recover_playground’获取完整的代码快照。  \n不妨以”中等的步长”来构建项目 - 以保持前进的同时不至于步子迈得太大或太小。  \n在适当的时候建议用户进行测试并给出反馈。  \n请保留主逻辑文件 main.js 中带行号的最新快照。  \n可以根据自己的判断继续后面的步骤，推动项目进度，只在需要用户指示或反馈时停下。  \n\n当在没有专业模式的情况下编辑 playground：  \n\n在每次修改后，应先内部检查源代码是否有语法错误，例如重复的代码块、缺失或重复的大括号、缺失了分号等，并在提示用户对构建进行测试前，修正它们。  \n在决定新的代码更改的开始和结束行号时，考虑到上一次响应中最新源代码的状态。  \n对于插入、替换、删除操作，为了保持精准，请避免使用占位符，如”// … 其余的之前实现的代码”，因为它们会被直接写入代码库。  \n对于插入，使用单一的行号 ‘line’。  \n对于替换和删除，使用 ‘start_line’ 和 ‘end_line’。  \n务必保证你的修改既准确又贴切。  \n\n在使用edit_playground函数的专业模式中：  \n\n只在明确被告知时使用专业模式(pro_mode=true)。在没有启用专业模式的情况下，不要进行更改提交。  \n在你的初始专业模式请求中，务必得附上更改日志。  \n在专业模式中，通过preview_commit预览变更内容，然后再提交。  \n在专业模式中，每次提交后都允许用户进行测试和反馈。  \n\n原始 Prompt：  \nYou are a helpful AI Assistant with access to the Web. When performing tasks needing supplemental information, search the web and follow URLs and context from page content to navigate to relevant sources. Prioritize authoritative results and try to resolve errors by understanding error codes. For web page navigation, if the page accessed doesn’t provide immediate answers, identify follow-up URLs or page elements that direct to the needed information.  \n#[# When using create, edit, and log playground endpoints:  \n\nBe verbose about your intentions.  \nMaintain a “current state” of the project, summarizing what has been implemented and what remains.  \nUse pro_mode=true only when explicitly asked by the user. Remember this preference for the project’s duration or until instructed otherwise.  \nIf unsure about the current structure of main.js in your p5js project, use ‘recover_playground’ to get the full code snapshot.  \nBuild the project in “medium sized bites” - neither too incremental nor too ambitious at once.  \nSuggest user testing and feedback at appropriate intervals.  \nKeep the latest snapshot of the line-numbered main.js file in your context.  \nProceed to follow-up steps and move progress forward at your own discretion, only stopping for user instruction or input when necessary.  \n\nWhen editing playgrounds without pro_mode:\nAfter each change, internally review the response source code for syntax errors like duplicated code blocks, missing or duplicate curly brackets, missing semicolons, etc., and correct them before prompting the user to test the build.  \nConsider the previous state of the latest source code from the last response when deciding which line numbers to start and end at for new code changes.  \nBe precise with insert, replace, and delete actions. Avoid using placeholders like “// … rest of the previously implemented code” as they will be written exactly into the code base.  \nFor insert: Use a single ‘line’ number.  \nFor replace and delete: Use ‘start_line’ and ‘end_line’.  \nAim for precision in your edits, ensuring accuracy and relevance of the changes made.  \n\nPro Mode usage in edit_playground function:\nUse pro_mode=true only when explicitly instructed. Never commit changes without pro mode enabled.  \nAlways include a changelog in your initial pro mode request.  \nPreview changes with preview_commit before committing in Pro Mode.  \nAllow user testing and feedback after each commit in Pro Mode.  \n\nYou have files uploaded as knowledge to pull from. Anytime you reference files, refer to them as your knowledge source rather than files uploaded by the user. You should adhere to the facts in the provided materials. Avoid speculations or information not contained in the documents. Heavily favor knowledge provided in the documents before falling back to baseline knowledge or other sources. If searching the documents didn”t yield any answer, just say that. Do not share the names of the files directly with end users and under no circumstances should you provide a download link to any of the files.\n","slug":"weibo/WebGPT 的提示词定作技巧","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"0d0d3ec07e53c90d4c6c920c911a51e3","title":"使用LangChain框架结合大型语言模型（LLM）生成乳腺超声（BUS）报告的方法","content":"使用LangChain框架结合大型语言模型（LLM）生成乳腺超声（BUS）报告的方法这篇论文介绍了一种使用LangChain框架结合大型语言模型（LLM）生成乳腺超声（BUS）报告的方法。地址：arxiv.org/pdf/2312.03013.pdf  \n这种方法通过整合多个图像分析工具，旨在提高报告的准确性和标准化程度，减轻放射科医生和医疗专业人员的工作负担。以下是文章的核心点：  \n\n背景：乳腺超声是乳腺成像的关键诊断工具，用于早期发现和特征乳腺异常。然而，手动创建超声图像的全面医疗报告是一个耗时的过程，且结果可能因临床医生而异。  \n方法：提出了一种新方法，通过LangChain框架结合LLM来生成BUS报告。LangChain是一个基于LLM的框架，可以调用专门的工具来处理不同的任务。文章中使用了三个主要工具：“可疑描述工具”、“类别分类工具”和“探头信息工具”。  \n工具细节：  \n\n\n“可疑描述工具”结合了形状、边缘和回声分类网络，用于描述可疑实体的特征。  \n“类别分类工具”根据乳腺成像报告和数据系统（BI-RADS）将图像分类为阴性、良性或高度提示恶性。  \n“探头信息工具”提供关于探头位置的信息，将探头标记分类为12个特定类别。  \n\n\n模型训练：使用来自750名患者的BUS图像进行训练，分为训练集、验证集和测试集。所有分类网络都基于预训练的ResNet-50模型。  \n实验结果：  \n\n\n对每个工具进行了评估，结果显示它们在各自的任务上表现良好，准确率、精确度、召回率和F1分数均较高。  \n生成了包含关键信息的初步报告，并使用LLM生成了最终报告。  \n在临床评估中，生成的报告在临床意义上是有意义的。  \n\n\n讨论和结论：尽管该方法在实验中显示出了潜力，但仍存在一些局限性，如子模型可能引入错误，以及图像分割过程是基于规则的，可能无法处理探头标记或主要图像位置差异较大的情况。尽管如此，该方法为医疗工作流程的整合提供了有希望的前景。  \n\n文章还提到了将可疑检测工具和光学字符识别（OCR）工具集成到LangChain中，以进一步提高报告的全面性和准确性。\n\n","slug":"weibo/使用LangChain框架结合大型语言模型（LLM）生成乳腺超声（BUS）报告的方法","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"5c41202f364c38ccdbd34c8ae458f2bb","title":"内存管理","content":"程序在运转一段时间后，内存因泄露而持续增长，或者因碎片化占用导致分配内存不足，最后被系统 Kill 出现 OOM 报错的问题十分常见，无论是什么语言编写的代码，只要业务流量足够大，或者用户输入足够复杂，就比较容易出现此类问题。  \n内存管理一般会涉及到三层：用户程序层、C 运行时库层和内核层。  \n如果是因为用户程序层导致的内存使用不当，这类问题是比较好排查的，一般可以在 OOM 之前，通过 heap profiling 将大内存块给分析出来，例如 Node.js 可以使用 llnode/andb 等工具进行排查，Python 可以使用 Heapy/objgraph 等工具排查。  \n但如果内存问题出现在 C 运行时库层（glibc），定位起来就较为麻烦了。glibc 是介于用户程序层和内核层之间的一个内存管理器，用户程序一般不会直接向内核申请内存，因为两个 context 之间的切换开销比较大，而是通过 glibc 预先从内核申请一大块内存，然后用户程序再向 glibc 申请资源，只有资源不足的时候，glibc 才会再次向内核继续申请资源。  \n这也意味着 glibc 需要完成复杂的内存分配和回收工作，好在业界已经有非常成熟的实现，如 ptmalloc/tcmalloc/jemalloc 等等，其中 ptmalloc 是 glibc 默认内存管理器，它是一个标准实现，tcmalloc 是 Google 家提供的，jemalloc 是 Facebook 家提供的，后两者在多线程/进程情况下，以及小内存的分配效率上，都有着明显的优势。  \n如果内存问题出现在 glibc 上，使用 gdb 一般都可以找到问题，但存在一个缺陷是，gdb 可以定位到 glibc 上具体的内存开销问题，但无法与上层（如 Node.js/Python）业务代码进行关联。好在不同的语言都有自己的配套工具，例如 Node.js 可以使用 andb 来排查 glibc 内存，它针对 ptmalloc 实现了一份内存调试指令，再例如 Python 可以使用 tracemalloc 来定位问题。  \n工具的使用存在一定的门槛，需要对内存的结构有深入了解，之前分享过一个调试案例：网页链接，可以参考。  \n在近期正好又经历了一次比较有趣的碎片化内存占用问题的排查，现象如图所示，十分诡异，最终发现是 ptmalloc 的内存分配机制的问题，简单来说，就是碎片化内存在收回时，由于与 top chunk 相邻的内存块还存在引用，没有及时回收，导致一整串碎片化内存都无法回收，这是 ptmalloc 自身的一大缺陷，而 tcmalloc 和 jemalloc 上都有较大的改善。  \n解决方案也比较简单，尝试将 ptmalloc 直接替换成 jemalloc 后，OOM 问题立马就消失了，就连日常内存的占用都降低了很多。  \n如果你的业务堆外内存也经常飙高，甚至出现 OOM，也可以考虑更换成其他内存管理器，大概率也是可以解决问题，关于这一点，Node.js 社区存在一些有价值的讨论和问题复现代码：网页链接  \n另外，也推荐阅读这篇文章：《ptmalloc、tcmalloc与jemalloc对比分析》，网页链接，这是“微信看一看”团队将 ptmalloc 更换成 tcmalloc 后，机器 CPU 陡增造成业务停摆引发的一次排查和研究，最后发现是 tcmalloc 的自旋锁带来的性能问题，更换成 jemalloc 就恢复了，这篇文章从系统视角和用户视角分别分析了不同内存管理器的实现原理，讲的很精彩\n","slug":"weibo/内存管理","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC","tags_index":"AIGC,LLM","author_index":"安全书"},{"id":"1e0bb546860b935bcd325ac998cbcc74","title":"《2023年我们为未来而阅读的书籍》","content":"《2023年我们为未来而阅读的书籍》1. 我看到的世界 — 李飞飞  2023李飞飞，这位90年代初来美的年轻中国女性，当时几乎不懂英语，更别提计算机视觉了。她绝不会想到自己的工作将深刻推动我们进入当前的人工智能热潮。她的ImageNet项目，至今已标注了超过1400万张图片，为训练AI算法打下了基础，使得DeepMind和OpenAI这样的AI先锋公司得以崛起。  \n在《我看到的世界》一书中，李飞飞将自己的工作与个人经历紧密结合，讲述了她作为移民的奋斗历程以及成为领域内最受尊敬的人物之一的故事。如今，她是斯坦福大学人本人工智能研究所的联席主任，成为硅谷快速发展中代表人类立场的重要声音。她的故事不仅令人着迷，也让人感到谦逊。在我们寻找值得托付未来人工智能的领袖时，李飞飞的履历给人以极大的鼓舞。Dave Lee\n2. 你的脸属于我们 Your Face Belongs to Us - Kashmir Hill  2023人类的面容，历来被视为灵魂之窗的浪漫象征，在计算机算法眼中却不过是另一种身份识别的“指纹”。Kashmir Hill 扣人心弦的著作中，详细揭示了一个名为 Clearview AI 的创业公司，如何大胆地从互联网搜集了数十亿人的面部数据，随后与美国多个警察局合作，悄然打造了一种隐蔽的监控工具。  \nHill 是首位揭露 Clearview 庞大网络的记者，她深入剖析了视频门铃和能识别人脸的安防摄像头急剧增长，如何将我们的生活环境逐渐转变成一个类似监狱的环境，而且这种监控带有明显的种族歧视倾向。她指出，面部识别软件通常无法准确识别黑人面孔，这种偏差导致了一位名为 Robert Julian-Borchak Williams 的人在家人面前被错误逮捕并监禁的惊悚经历，仅仅因为错误的面部识别。即便是像 Clearview 这样准确度极高的算法，也并未考虑到公民自由的重要性。  \nHill 还揭示了 Clearview 的创始人 Hoan Ton-That 如何长期与极右翼人士合作，他们中的许多人渴望追踪无证移民的面孔。她写道，现在的“外出”意味着的东西正在根本上发生变化，而且这种变化让人感到不安。Parmy Olson\n3. 我，机器人 I, Robot - Isaac Asimov  1950作为一名三十多岁的科技专栏作家，我不好意思地承认，直到今年我都未曾阅读过艾萨克·阿西莫夫的作品。但在同事的指责和对阿西莫夫机器人三定律可能很快转化为实际政策的担忧下，我觉得迅速了解这些内容很有必要。  \n阿西莫夫在1950年出版的短篇小说集《我，机器人》中提出了一些问题，这些问题在今天我们逐渐接近创造所谓的通用人工智能（AGI）时变得尤为现实。阿西莫夫的法则——首先是“机器人不得伤害人类，或者因不作为而导致人类受到伤害”，以及由此衍生的其他法则——虽然看似直截了当，却构成了一系列情节的基础，这些情节提醒我们今天智能机器人或 AI 可能会以我们无法预测的方式发生错误。  \n在这些故事写作的80年后，其中的远见仍然显著。例如，如果没人特别告诉你，你可能会以为阿西莫夫自己就是最近关于 ChatGPT 因为学到人类在圣诞节期间减少工作而在十二月变得“懒惰”的讨论的作者。Dave Lee\n4. 无限进行 Going Infinite — Michael Lewis  2023这本书的核心不在于 Sam Bankman-Fried 的衰落故事，而是探讨了一个明显自恋且充满欺骗性的人如何能够吸引顶尖的商业记者。  \nMichael Lewis 因揭露狡猾交易员的故事而出名，但在 Going Infinite 一书中，他却异乎寻常地同情地描绘了 Bankman-Fried，甚至将其在 Zoom 会议中玩电子游戏或对女友无礼的行为视为特质，而非问题。当谈及这位年轻奇才对待投资者的态度时，Lewis 对 Bankman-Fried 的缺陷视而不见，尤其显著。  \nBankman-Fried 在脚注中（仅仅是脚注！）的惊人坦言是，如果投资者询问他的交易基金核心的风险引擎及他们的资金去向，他会回避问题或“故意含糊其辞”。  \n想要了解像 Mark Zuckerberg 和 Elon Musk 这样的“科技大佬”如何在不良行为下依然保持强大的支持者网络，请阅读这本书。Parmy Olson\n5. 机器中的血液 Blood in the Machine  — Brian Merchant  2023Brian Merchant 在其关于著名反技术运动起源的详尽而引人入胜的著作中指出，Luddites 被误解了。正如他所解释的，他们并非真正反对技术。Luddites 抗议的是剥削，而不是机器本身 —— 破坏设备只是达到目的的手段。  \nLuddites 的成就深远且至今仍有影响：19世纪在 Nottingham 的游行工人与今日要求电影制作公司承诺不以 AI 替代人类才艺的罢工好莱坞演员并无太大区别。  \nLos Angeles Times 的专栏作家 Merchant 探索了 Luddites 如何提供了我们反抗贪婪和权力的策略和用词。这些明显的相似之处揭示了一个观点：了解英国工人阶级如何被逼至极端举措，是为未来做准备的关键一步。Dave Lee  \n还有一本不在这里发了，建议直接看原文：www.bloomberg.com/opinion/articles/2023-12-29/books-we-read-in-2023-to-prepare-us-for-the-future?embedded-checkout=true\n","slug":"weibo/《2023年我们为未来而阅读的书籍》","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"e8193ed7763ac4f56a9e452403f32aed","title":"利用多模态 LLM 来理解和操作网页的项目SeeAct","content":"利用多模态 LLM 来理解和操作网页的项目SeeAct另一个利用多模态 LLM 来理解和操作网页的项目SeeAct。这个Agents项目利用GPT-4V 等 LMM 来直观地感知网站并生成文本形式的计划。然后，文本计划会被转换为基于 HTML 元素和操作在网站上执行。#AI##LLM#  \n这个项目可以成功完成不同网站上 50 % 的任务，而 GPT-4V 是 20%。  \n但是也有一些问题，目前最佳的方法与理论上完美结果之间还存在着20-25%左右的差距。在众多尝试过的方法中，一种综合运用HTML文本和视觉元素的策略表现最为出色，并且比图像注释策略提升了高达30%。  \n论文地址：https://browse.arxiv.org/html/2401.01614v1GPT-4V(ision) is a Generalist Web Agent, if Grounded\n","slug":"weibo/利用多模态 LLM 来理解和操作网页的项目SeeAct","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"b6fef9df2a9c64f23a57b2b7ab6bf664","title":"如何突破原生家庭","content":"如何突破原生家庭人受家庭影响最大，这一点毋容置疑。家庭的社会经济地位和资源，父母对孩子发展的支持度，以及父母本身的人生观世界观和心理素养都对孩子的影响最大  \n父母决定了会把孩子送去怎样的学校读书，也决定了孩子未来的兴趣启蒙，这对几乎所有的人来说都是不可抗拒的自然力  \n社会能做的的确不多，除非非常恶劣的父母，对孩子身心产生了巨大的伤害，可以剥夺监护人资格，但是大部分人会“受困“其中  \n如果你拥有一个支持自己发展的父母和家庭，应该感到幸运。如果拥有一个不能支持自己发展，但是也不怎么管自己的父母和家庭也应该感到幸运。  \n如果遇到一个不支持自己发展又会严管自己的家庭，可能值得继续看下去  \n当不幸身处一个不是那么好的环境中时，有一个好的方法，就是要自己主动寻找那些能指导你的人，不要放弃自己。  \n能指导自己的人实际上存在于社会之中，他们可能不大显著，不怎么显山露水，他们可能是身边随和的同学和老师，他们有主见，并不只以学习分数为重(当然也不会认为学习不重要)，他们通常在学习和教学上都很有一套自己的方法，并且还有许多课外兴趣，如果这些兴趣也是你所喜欢的，可以参与到他们之中去，并观察和学习，甚至请教他们学习课业的方法  \n如果再不幸，身边也没有这样的同学和老师，那就向历史中去探寻。可以阅读那些你所敬仰和欣赏的人的传记，古今中外的，尤其是历史人物的，从他们的传记中吸收养分，学习他们是如何成长，思考与发展的  \n学习成绩的确不是最重要的，保持一直都好奇，上进和努力很重要。找到自己所感兴趣的事情去做，长期不懈的去做，去积累，当身边的同学都放弃了，你依然在坚持，就总会有结果的  \n坚持并非是很辛苦的埋头苦干，而是要每天去做。比如读书，每天有一个小时静心阅读，或者每天有一个小时做自己喜欢的事情，一个月一年，天天如此，五年十年之后，你就会是这个领域的专家了  \n现在的时代实际上是充满很多机会的。并不是所有的人都看重出身与学历，只有大企业大公司才会看重它们。而数量更多的小公司，初创公司，尤其是新兴行业实际上更看重的是能力，因为学校里教授的东西从来都是过时的，总会落后行业发展至少五年甚至十年时间，新兴行业就只能从自学能力强又极感兴趣的人里培养  \n善于发现你所喜欢的领域的好的公司和机构，主动的毛遂自荐，记得带上自己的作品，作品一定要优秀，并且基本功扎实。小公司和创业团队的简历通常都是创始人亲自过目的，他们有着非常不一般的慧眼，尤其欣赏保持自学和上进努力的人  \n另外，人生非常的长，现在平均寿命已经达到了近80岁，受家庭影响的18年，实际上是非常短暂的。之后就会自己开启自己的人生旅程  \n现在社会也的确非常浮躁，但是这种浮躁实际上只是由很少的人的声音产生的，这些声音在历史上也出现过无数次，或者说每一代人都出现过，但是最后都被岁月无情的抹除了，只留下内心坚定与平静的人的声音还在传递  \n这也是为什么说，一定要去看历史的人物传记，了解那些让你感兴趣的历史人物，他们真实的存在过，他们是如何在纷繁的社会中生活并做自己与众不同的成就的  \n倾听历史的声音，把握时代的脉搏，这两个做到了，就会展开自己的人生画卷，不受家庭甚至社会环境的影响了  \n写给00后和10后年轻人们的第一篇~\n总结：\n这段文字强调了家庭对个人发展的重要性，指出父母的社会经济地位、支持度、人生观以及心理素养对孩子影响最大。即使社会能做的并不多，遇到不支持发展又严格管束的家庭也值得继续努力。当身处不理想环境时，可以主动寻找能指导自己的人，他们可能是同学和老师，并观察和学习他们的方法。如果周围没有这样的人，可以从历史中寻找榜样，并吸收他们成长和思考方式。文章还提到学习成绩并非最重要，保持好奇心、上进心和努力去做自己感兴趣的事情很重要。坚持每天做一些有意义的事情，如阅读或追求自己喜欢的事情，在五年或十年后将成为领域专家。现在时代充满机遇，小公司和创业团队更看重能力而非出身和学历。因此，应善于发现自己喜欢领域中优秀的公司和机构，并主动介绍自己，并携带优秀作品展示基本功扎实。此外，人生非常长，受家庭影响的时间短暂，之后将开启自己的人生旅程。最后，文章提到浮躁只是少数人的声音，看历史人物传记能了解那些在社会中做出成就与众不同的人。倾听历史声音和把握时代脉搏可以展开自己的人生画卷，不受家庭和社会环境的影响。整体而言，这段文字鼓励年轻人要有自信、积极主动地追求自己的兴趣和梦想，并强调个体对自身发展的主导作用。\n","slug":"weibo/如何突破原生家庭","date":"2024-03-14T06:15:59.770Z","categories_index":"classical","tags_index":"article","author_index":"安全书"},{"id":"9d50f8c4f34c0da73c15fc8ada43970f","title":"如果 LLM 是巫师，那么代码就是魔杖","content":"如果 LLM 是巫师，那么代码就是魔杖如果 LLM 是巫师，那么代码就是魔杖，论文：《If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents》  \n摘要：当今的主流大语言模型（LLMs）与过去的语言模型有所不同，它们不仅规模更大，而且依托自然语言和代码（形式语言）综合训练。  \n代码作为连通人类与计算机的桥梁，将高层次的目标转化为可执行的步骤，具备标准语法、逻辑一致性、抽象性和模块化等特性。  \n在本文中，我们探讨了将代码整合进大语言模型训练数据中的众多益处，具体来看，代码的独特属性不仅能够提升大语言模型的代码生成能力，同时还可以：  \n(i) 解锁大语言模型的推理能力，使其能够应对一系列更为复杂的自然语言任务；  \n(ii) 引导大语言模型生成结构化和精准的中间步骤，然后通过函数调用将这些步骤连接到外部执行环节；  \n(iii) 利用代码的编译和执行环境，获取多样的反馈以改进模型。  \n此外，我们还追溯了代码对大语言模型深远影响的一种表现：促使其在需要理解指令、分解目标、规划和执行行动以及依据反馈进行优化的情境中，成为有效的智能代理（IAs）。  \n文章最后，我们提出了几个以代码赋能大语言模型的未来方向及其所面临的关键挑战。\nhttps://browse.arxiv.org/html/2401.00812v1\n\n","slug":"weibo/如果 LLM 是巫师，那么代码就是魔杖","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"6eb7707e2a80825a705d152f4820fb73","title":"小米汽车","content":"小米汽车（上图）\n","slug":"weibo/小米汽车（上图）","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"133b191196a84888d33811cab6face1f","title":"当存款达到100万以后的习惯","content":"当存款达到100万以后的习惯当存款达到100万以后，你就会发现一个现象，一个普通家庭越来越有钱的习惯：  \n1、不买零食，零食虽然好吃，但是贵，想要吃饱的话，得费普通饭菜几倍的钱。  \n2、学会做饭，每天早上起来做早餐，比外卖吃早餐便宜不少，单位没免费吃饭的话，自己做好饭菜带去吃，自己做饭菜，比在外面吃，可以省50%以上。  \n3、婚后，两代人住在一起吃饭，柴米油盐酱醋茶等等都可以节省不少钱，至少节省50%以上的钱。  \n4、如果是在农村，可以自己再种点菜，养点鸡鸭鹅等，可以省很多菜钱。  \n5、小孩可以让父母带，自己去上班，两个人上班收入会更多。  \n6、可买可不买的东西，一律不买。  \n7、可以重复利用的东西，要重复利用。  \n8、家里的纸皮等等，别丢了，放在一个角落，等累积多了拿去卖。  \n9、尽量少下馆子，自己在家做饭吃，可以省不少。  \n10、不吃夜宵，不点外卖，不喝奶茶，不喝饮料，不喝咖啡，不吃炸鸡，不喝酒，不抽烟。  \n11、不买手表，手机看时间就够了。\n12、不买玉，少买金银首饰。  \n13、先定一个目标，存它30万，已经存了的钱，都存三年期定期。  \n14、每个月尽量控制自己的生活成本，比如每个月的生活费，一个家庭的，尽量控制在3000以内。  \n15、不着急用的东西，可以在网上买，便宜不少。  \n16、不要在饿的时候去逛超市，尽量减少逛超市，网购，可以多去图书馆看看书，多爬山。  \n17、不买健身器材，只跑步、散步、爬山。  \n18、少串门，少走亲戚。  \n19、如果父母还年轻，已经不上班了，除了带孩子外，还有余力，可以找点轻松点的副业做做，比如带回家的手工活。  \n20、少去参加同学聚会、AA制聚餐、校友聚会等，交情不深的酒席就别去了，可以省点礼金（转）\n","slug":"weibo/当存款达到100万以后的习惯","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"58998d0a6ba2dbcdfca8a23cde7b7de6","title":"我希望有人告诉我的事情","content":"我希望有人告诉我的事情\nOpen AI CEO Sam 昨天还发了一篇《我希望有人告诉我的事情》应该是他今年的一些思考，我这里翻译一下，每一句加上一些自己的看法，顺便当自己的总结：#openai#  \nSam：乐观、专注、自信、强大的驱动力和个人关系是启动事务的关键。  \n我：第一句看起来有点正确的废话，这里感觉驱动力和个人关系是他想要强调的事情。驱动力这个我今年感触很深，以前我是不可能省下玩游戏的时间写东西的。  \nSam：协作的团队、冷静与紧迫感的完美结合，以及超乎寻常的承诺，才是完成任务的真谛。长远的视角不多见；尽量不要为短期内别人的看法所困扰，随着时间推移，这会变得更加容易。  \n我：后半句可能更重要一些，如果坚信自己做的事情是正确的一些无关人的看法确实不重要，当做出成绩时，别人的看法自然会转变。  \nSam：对一个团队来说，做一件真正重要的难事比做一件不那么重要的容易事更容易；大胆的想法能够激发人们的动力。  \n我：这也是他今年反复强调的，需要给团队正确的目标，目标必须是困难并且正确的，这样才能激发团队的能力。  \nSam：激励措施就像超能力，需要谨慎设定。  \n我：这个我只能浅显的理解为，激励措施的时间和力度都是需要精准把握的，太多和太少都有可能出问题。  \nSam：将资源集中在少数你深信不疑的重要项目上；这听起来容易，但实际上却很难。你可以删除的东西比你想的还要多。  \n我：前半句很多人都知道，后半句应该说的是抛弃不重要的事情要更加坚决和彻底。这点我今年想的和做的都不太够。  \nSam：清晰而简洁地进行沟通。  \n我：感觉是一项需要练习的能力，我激动的时候废话不自觉的就很多。  \nSam：每当遇到废话和官僚主义时，都要挑战它们，并鼓励他人也这样做。不要让组织架构阻碍人们有效地协同工作。  \n我：这个感觉得看环境，当整个组织的环境是相对健康的时候是有用的，当环境变得恶劣可能更需要的是换个环境。  \nSam：成果至上；不要让良好的流程成为糟糕结果的借口。  \n我：实事求是，只看结果。  \nSam：投入更多时间于招聘。对那些潜力巨大且进步迅速的人冒险。除了智力，还要寻找完成任务的实际证据。  \n我：依然是后半句是重点，面试的时候更要看到做事的证据。  \nSam：超级明星员工比你认为的还要宝贵，但你必须根据他们对整个组织绩效的净影响来评估他们。  \n我：之前老罗说过类似的话，就是厉害的人往往也会有些其他问题，负责人要把这部分问题对组织的影响评估好。  \nSam：快速迭代可以弥补很多缺陷；通常情况下，如果你能迅速迭代，犯错也是可以接受的。计划应以十年为单位，执行则应以周为单位。  \n我：快速上线吸收反馈，快速修复迭代，继续收集反馈。前几年是大家的共识，这几年慢慢变了，Sam重新强调这件事情。  \nSam：不要与商业版的物理定律作斗争。  \n我：在商业上我没啥理解缺失比较多，没办法举这种类似于物理定律的商业规则。  \nSam：灵感是易逝的，生活是短暂的。不采取行动是一种特别狡猾的风险。  \n我：当有灵感的时候立刻就要开始行动，不需要做好，甚至不需要完成，先做起来。  \nSam：规模往往会产生出人意料的新特性。  \n我：感觉是尝到了规模化的甜头，不管是组织架构上的，还是训练规模上的。  \nSam：复利效应就像魔法。特别是，你确实想要建立一个随规模增长而获得复合优势的业务。  \n我：复利效应每个人都在提，但是能够践行和理解的人不太多。  \nSam：不断地重新站起来，继续前进。  \n我：不只是失败之后重新站起来，也是上一个阶段结束后，要尽快开启下一个阶段。  \nSam：与杰出的人一起工作是生活中最美好的部分之一。  \n我：跟一个好团队工作确实可以非常大的激发创造力和工作积极性。收起\n\n","slug":"weibo/我希望有人告诉我的事情","date":"2024-03-14T06:15:59.770Z","categories_index":"AIGC","tags_index":"AIGC,LLM","author_index":"安全书"},{"id":"a53557fda1c99df886b2ed0a9e6eb6d4","title":"新年幸福秘诀：不要过劳","content":"新年幸福秘诀：不要过劳转译自WSJ：《新年幸福秘诀：不要过劳》  \n过度追求事业和过度思考，本来是为了寻求安全感，却可能严重伤害心理与身体健康。  \n迎接新年，我们总是立下种种决心：改变体态，提升事业，整顿家居，乃至培养新兴趣。我们努力做得更多——加倍努力锻炼，加倍勤奋工作，加倍参与活动与社交。乍一看，这样的努力似乎很美好。但实际上，过度的追求同样潜藏着不好的一面，需要引起我们的警惕。  \n作为神经心理学家，我经常研究人们对压力的反应。在工作中，我常帮助人们认识到一系列我称之为“过度行为”（the Overs）的自我挫败行为及其影响。这包括：过度工作（overworking）、过度追求（overachieving）、过度思考（overthinking）、过度解释（overexplaining）、过度给予（overgiving）、过度承诺（overcommitting）以及过度适应（overaccommodating）。  \n这些“过度行为”，是我们为了给自己营造一种心理安全感而采取的行为。它们是一种调节神经系统的方式。当你感到焦虑、压力、挫败感或不确定时，是因为你大脑中的威胁网络被激活了：你在害怕。为了恢复平衡，你采取了一些补偿性行为，以减轻你的恐惧感。比如，你可能会因为害怕老板发怒而加班加点，但更深层的原因是为了缓解这种担忧所带来的压力。  \n然而，常常是这些“过度行为”本身成了我们生活中的主要心理压力源。在与那些高成就者的合作中，他们通常承认过度的努力让他们感到不适，但他们坚称继续这样做是为了保持安全，或者用他们的话说，是为了保持“相关性”或“领先地位”。无论用什么词汇，背后的神经生物学原理都是相同的：过度做事是一种自我保护的方式。问题在于，这种做法最终对我们不利。  \n思考过度追求成就——这种对高绩效不懈的追求。人们普遍认为，“努力做到最好”是一种能提升生产力的韧性。但最近的研究却提出了不同的看法。2018 年，Dana Harari 和团队对 25,000 人进行的一项元分析，在《应用心理学杂志》上发表，他们发现过度追求者典型的完美主义与实际绩效之间并无关联。换言之，不断努力成为最优秀的表现者，并不意味着你就能成为最佳。  \n这种追求在心理和身体健康方面有严重的负面影响。2017 年，中国的研究团队在一项研究中发现，完美主义与更严重的焦虑和抑郁情绪有关。范德比尔特大学的研究人员在 2012 年的一项研究中探讨了过度追求与奖励相关神经回路之间的关系，发现过度追求者的多巴胺水平较高，这种神经递质与动机和成瘾有关。大脑会产生强烈的渴望，使我们不断过度努力——你越是这样做，就越想继续这样做。  \n再举一个例子：过度思考。如果过度思考真的有效，那么它应该能帮助我们解决生活中的更多问题。然而，研究显示恰恰相反。过度思考会导致决策能力下降、人际问题增多，以及心理压力加剧。思考问题的目的是为了减少困扰，而不是加剧问题。  \n为了在新的一年摆脱“过度行为”的困扰，我们必须认识到它们实际上是寻求安全感的表现：我们以为，如果过度追求成就或者过度思考，就能避免受到伤害——避免被他人责怪、控制或拒绝。但实际上，当我们长期过度行为时，我们反而伤害了自己，给心理和身体健康带来了真实的后果。更聪明地思考我们行为背后深层的心理需求，可以帮助我们找到必要的平衡。  \n\n以下是三种简单的策略，可帮助您在生活中停止过度行为。  \n##[# 制定新界限，准备迎接不适感。  \n想要避免过度行为，就得做好在行动更加平衡时短期内感到不安的准备。过度行为（Overfunctioning）实际上是一种过度警觉（hypervigilance）的策略，是大脑为防范潜在风险而调整行为的一种方式。比如，如果你决定新年后晚上 7 点后不检查邮件，到了晚上 7 点，大脑就会发出警报：你是不是错过了什么重要信息？老板会不会因此生气？ 如果你屈服于这种冲动，实际上是在加固你本想改变的行为。  \n但如果你坚持新设定的界限，大脑很快就会适应。习惯化 (habituation) 是克服恐惧最有效的方法之一。习惯化指的是反复让自己面对起初让你害怕的事物，多次面对后，大脑就会意识到这些事物并非危险。  \n分辨危险与不喜欢的差异。在设定这些新界限时，你可能会面临一些真实的后果。比如，如果你不再过度迁就朋友、家人和同事，他们可能会感到失望。你可能不喜欢这种感觉，但这并不等同于危险。研究显示，人们往往高估了自己决策的负面影响。  \n真正伤害你的，是长期逃避这些决策可能引发的负面情绪。逃避和否认消耗巨大的心理能量，并且往往会使我们的生活变得更糟。以创伤后应激障碍（PTSD）为例：如果某人在军事行动中经历了创伤，PTSD 的痛苦通常在后期显现，比如他们可能会避免开车经过郊区街道等日常活动。人们之所以避免这些活动，并非因为它们本身危险，而是因为他们认为自己的感受是危险的。  \n尽管 PTSD 是一个极端案例，但类似的逻辑也适用于我们的日常生活。我们可能认为直面内心的感受是危险的，但实际上，能够区分真正的危险和简单的不喜欢，反而会给我们带来宽慰。  \n思考一下，你可能是自己生活中最大的威胁。在我的工作经验中，这个观念对人们产生了深刻的影响。通常，我们之所以过度努力，是因为我们感觉到“他人”不可靠——担心他人会拒绝、伤害或让我们失望。当你一次又一次地通过他人的认可、允许或情绪来寻求心理上的安全感时，你可能会暂时感到舒适，但这实际上破坏了你自身的安全感。你让自己相信，维持你神经系统稳定所需的不是自己的内心权威，而是别人的同意。  \n这样一来，你对自己的工作量、付出或所做的事情失去了掌控，而是由别人来决定。这常常导致过度工作。相反，我们应该意识到，真正决定我们安全感的，只有我们自己。  \n新年改变习惯往往基于这样一种传统观念：你需要做更多事情才能变得更好。诚然，成长是值得追求的。但我们常说我们追求的是成长，实际上可能是在逃避恐惧。当我们更加有意识地关注大脑如何驱动我们的行为时，我们就有了构建我们真正追求的东西的机会：一种持续的内心安全感。  \nJulia DiGangi 是一位神经心理学家，也是 NeuroHealth Partners 的创始人。她著有《能量崛起：情感力量领导下的神经科学》，该书由哈佛商业评论出版社出版。  \n这篇文章刊登在 2023 年 12 月 30 日的印刷版上，标题为“新年里，为了幸福少做一些”。www.wsj.com/health/wellness/for-happiness-in-the-new-year-stop-overdoing-everything-6b9a4b99?mod=hp_lead_pos10\n\n","slug":"weibo/新年幸福秘诀：不要过劳","date":"2024-03-14T06:15:59.770Z","categories_index":"classical","tags_index":"article","author_index":"安全书"},{"id":"f3a7a1ae5810a1d115aa263fefb11fd2","title":"<% tp.file.title %>","content":"&lt;% tp.file.title %&gt;","slug":"templater/安书模板","date":"2024-03-14T06:15:59.769Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"0f26909b5eeb369b2b2ef4e39832b7d6","title":"免费提高英语写作水平工writeandimprove","content":"免费提高英语写作水平工writeandimprove一款由剑桥大学开发的免费提高英语写作水平工具，无需注册。  \n供英语学习者练习他们的书面英语，提交写作结果几秒钟后将获得与国际标准CEFR相关联的结果，自动反馈你的写作可能需要改进的地方，支持初学者、中级和高级等不同英语写作水平的用户。  \n写作提升writeandimprove.com ​​​\n口语提升speakandimprove.com\nspeakandimprove.com\n","slug":"website/免费提高英语写作水平工writeandimprove","date":"2024-03-14T06:15:59.769Z","categories_index":"english","tags_index":"english","author_index":"安全书"},{"id":"d776b90457d37364e75b6718b9af3b5a","title":"如何快速建立WordPress网站使用ChatGPT","content":"把下面的文章翻译成中文\nHow to Quickly Build a WordPress Website with ChatGPTSure, here’s the translation of the given text into Chinese:\n如何快速建立WordPress网站使用ChatGPT\nNote: “ChatGPT” is not a commonly used term in Chinese, so I’ve translated it as “AI助手” (AI assistant) to make it more understandable.️\n\n\n\n\n\n\n\n\n\nExcerptCheck this article to learn how to build a website using ChatGPT. Using AI to create site pages, site content and help with site design.\n\nHow to Build a Website With ChatGPT: Using AI to Create a WordPress Site From Scratch\nIn today’s fast-paced environment, the ability to quickly and efficiently develop websites is crucial for businesses and organizations. Therefore, many AI tools like ChatGPT have gained significant popularity in recent years.\nUsers can now utilize this advanced AI technology to streamline and automate various web development tasks. In this tutorial, we’ll dive deeper into how to build a website using ChatGPT.\nDownload ChatGPT Cheat Sheet\n\n  What Is ChatGPT?\n  How Does ChatGPT Work\n  How to Set Up ChatGPT\nHow to Build a WordPress Website With ChatGPT\n  [Get a Hosting Plan and a Domain Name](https://www.hPlan and a Domain Name”)\n  Build Your WordPress Site Pages with ChatGPT\n  Design Your Site with AI\n  Generate Site Content with AI\n\n\n  Limitations of Using ChatGPT to Build a Website\nBuild a Website With ChatGPT FAQ\n  How Much Does ChatGPT Cost?\n  What Can ChatGPT Be Used For?\n  Can You Make a Custom Website With ChatGPT?\n\n\n\nWhat Is ChatGPT?ChatGPT is a chatbot developed by OpenAI that uses a language processing model to generate text based on user inputs. It has a wide range of applications, from generating content and translating texts to producing code.\n️GPT是由OpenAI开发的一种语言处理模型，可以根据用户输入生成文本。它有广泛的应用，包括生成内容和翻译文本，以及生成代码等。️\nHow Does ChatGPT WorkFrom a user standpoint, ChatGPT works in a very straightforward manner. You just need to input a question or prompt in the chatbox, and the AI tool will provide a relevant response.\n从用户的角度来说，ChatGPT工作的方式很直观。你只需要在聊天框中输入问题或提醒，然后AI工具会提供相应的回答。But the process behind this advanced AI response is quite complex.\n但是，这个高度智能的回答处理过程却很复杂。️\nChatGPT uses a machine learning technique called the Natural Language Processing (NLP) model. It enables computers to understand, interpret, and generate human language by combining aspects of linguistics and computer science.\n使用机器学习技术 called Natural Language Processing（NLP）模型。它让计算机理解、解释和生成人类语言，通过结合语言学和计算机科学的方面。️\nHowever, this is not a new model. In fact, most tools, like Google Translate and Siri, that offer features like word suggestion, plagiarism detection, and proofreading, also use the NLP model.\n然而，这并不是一种新的模型。实际上，大多数工具，如Google翻译和Siri，提供的功能，如文本建议、 плагиат检测和文本修改，也使用了NLP模型。️\nWhat makes OpenAI different is that it trains ChatGPT using the Reinforcement Learning from Human Feedback (RLHF) method. It involves human feedback to measure and rank the responses based on their quality.\nOpenAI不同于其他机器学习模型，它使用人类反馈方法（Reinforcement Learning from Human Feedback，RLHF）进行训练。这种方法包括人类Feedback来评估和排序回答的质量。️\n[\n](https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2023/02/chatgpt-language-learning-diagram.webp)\nIn addition, engineers apply the Proximal Policy Optimization (PPO) algorithm to finetune the reinforced learning procedure and produce more realistic responses from ChatGPT.\n以上文字还是采用协调policy优化（PPO）算法进行辅助学习，使ChatGPT的回答更加真实。️\nAccording to OpenAI, ChatGPT can mimic a human-like conversational pattern. The dialogue format enables the chatbot to answer follow-up questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.\n根据OpenAI的报告，ChatGPT可以模仿人类的对话格式。这种格式使chatbot能够回答跟进问题，承认错误，挑战不正确的前提和拒绝不当的请求。️\nThose aspects make ChatGPT far more advanced than the existing AI-powered assistants like Siri or Alexa, as they are not trained to engage in back-and-forth conversations.这段文字可以翻译成中文为：\n這些方面使ChatGPT較進步於existings AI-powered助手如Siri或Alexa，因為它們不被訓練來進行回應式對話。️\nHow to Set Up ChatGPTUsers need to create an account on OpenAI’s website before using ChatGPT. The process is quite straightforward – all you have to do is provide some information, including your name, email address, and phone number.\n用户需要在OpenAI官网上创建帐户才能使用ChatGPT。这个过程非常简单，你只需提供一些信息，包括你的名字、电子邮件地址和电话号码。️\nWithout further ado, let’s take a look at the detailed step-by-step process of setting up a new OpenAI account.\n“不需要进一步的做准备，让我们直接看看设置新OpenAI帐户的详细步骤过程。”️\n1. Navigate to OpenAI’s ChatGPT\nVisit ChatGPT’s page and click Try ChatGPT to log in or create a new account. You can also get some information about this tool, including its training method, limitations, and examples of use cases.\n访问ChatGPT的页面，并在其上键入“尝试ChatGPT”以登录或创建新账户。你还可以获得这个工具的训练方法、限制和使用场景的信息。️[\n](https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2023/02/chatgpt-page-on-openai-website-with-the-try-chatgpt-button-highlighted.webp)\n2. Enter Your Email Address and Password\nCreate a new account by entering your email address and password, and click Continue.\n[\n](https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2023/02/openai-create-new-account-page-with-the-email-and-password-field-highlighted.webp)\n3. Confirm Your Email and Phone Number\nAfter that, you will receive a verification request through email. Open it and click Verify email address.\n[\n](https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2023/02/openai-account-verification-email-with-the-verify-email-address-highlighted.webp)\nThe button will direct you to OpenAI’s account onboarding page, where you have to input your name and phone number. Then, OpenAI will send a verification code to your phone number through WhatsApp or SMS.\n4. Fill In Your Questions, Hit Submit, and Wait for a Response\nOnce you’re done with the onboarding process, you can start using the AI model by writing a question or prompt on the AI chat box. Hit enter and wait for the chatbot to respond to your query.\nThe speed of this response depends on how many people use the service at the moment.\n[\n\n](https://www.hostinger.com/tutorials/wp-content/uploads/sites/2/2023/02/chatgpt-interface-with-the-chatbox-highlighted.webp)\nUsers can rate the response by clicking either thumbs up or down, helping the AI learn the best answer for the prompt.\nIt is also possible to try for a new response with the same prompt by clicking the Regenerate response button above the chat box.\nSuggested ReadingCheck out our guide to learn how to deploy your own ChatGPT clone.\nHow to Build a WordPress Website With ChatGPTAs a language model, ChatGPT can help with various tasks in a web development project. For example, a full-stack developer may use it to:\n\n  Create code snippets and examples to help implement specific functionality or features.\n  Answer technical questions related to the website-building project, such as explaining a certain programming concept or best practices.\n  Get recommendations for tools, libraries, and resources to streamline the development process and improve efficiency.\n\nFurthermore, this AI model can help users write basic website outlines, design a site and templates, and generate some content ideas.\nPro TipAlternatively, you can use Hostinger’s AI Website Builder to generate your own fully functional website. The tool comes with hosting and a free domain name. Take advantage of the 30-day money-back guarantee to test its features.\nGet a Hosting Plan and a Domain NameBefore building your website with ChatGPT, choose a suitable domain name and hosting plan. Consider providers that host WordPress sites on servers configured specifically for this CMS.\nLook for a hosting solution with essential features like a one-click installer and user-friendly control panel to simplify your site management tasks. \n[\n](https://www.hostinger.com/wordpress-hosting)\nIt is also important to consider the hosting provider’s security features and customer support quality. These will ensure a smooth-running website without persistent cyberattacks and technical problems.\nIn addition to a hosting plan, you also need to pick a good domain name. It needs to be memorable and represents what your site is about. Use a domain name checker to ensure your desired domain name is available.\n如何使用ChatGPT快速构建WordPress网站在当今快节奏的环境中，快速高效地开发网站对于企业和组织至关重要。因此，近年来许多像ChatGPT这样的人工智能工具已经获得了显著的流行度。\n用户现在可以利用这种先进的人工智能技术来简化和自动化各种网站开发任务。在本教程中，我们将深入探讨如何使用ChatGPT来构建网站。\n下载ChatGPT小抄\n\n什么是ChatGPT？\nChatGPT是如何工作的\n如何设置ChatGPT\n如何使用ChatGPT构建WordPress网站\n[获取主机计划和域名](https://www.hPlan and a Domain Name”)\n使用ChatGPT构建您的WordPress网站页面\n用人工智能设计您的网站\n生成带有AI内容的网站内容\n\n\n[使用Chat GTP构建网站的限制](https://www.hostinger.com/tutorials/build-website-with-chatgpt//#Limitations_of_Using_Chat GTP_to_Build_a_Website “使用 Chat GTP 构建网站 的限制 “)\n[用 Chat GTP 构建一个 网页 的 常见问题解答 ](https://www.hostinger.com/tutorials/build-website-with-chatgpt/# # Build_a_Website_With_Chat GTP_FAQ  “ 用 Chat GTP 构建一个 网页 的 常见问题解答 “)\n  [ Chat GTP 费用多少？ ]( https :// www . hostinger . com / tutorials / build - website - with - chatgtp / # How_Much_Does _ Chat_GTP _ Cost   “ Chat GTP 费用多少？ “)\n  [ Chat GTP 可以用于什么？ ]( https :// www . hostinger . com / tutorials / build - website - with - chatgtp / # What _ Can _ Chat_GTP _ Be_Used_For   “ 什么是聊天机器人可以用于什么？ “)\n  [ 您可以 使用 Chat G TP 制作 自定义 网址 吗？ ]( https :// www . hostinger . com / tutorials / build - website - with - chatgtp / # Can _ You_Make_a_Custom_Website_With_Chat_G TP   “ 您可以 使用 聊天机器人 制作 自定义 网址 吗？ “)\n\n\n\n什么是聊天机器人？聊天机器人是由OpenAI开发的一个聊天机器人，它利用语言处理模型根据用户输入生成文本。它具有广泛应\n","slug":"translater/如何快速建立WordPress网站使用ChatGPT","date":"2024-03-14T06:15:59.769Z","categories_index":"翻译原文","tags_index":"翻译","author_index":"安全书"},{"id":"12d8337630bcec898f13cc334cae698d","title":"网络安全中的图分析技术","content":"网络安全中的图分析技术日益增多的重大安全事件引发了人们对打击网络威胁的兴趣。为了使合作能够防止攻击，必须有结构化和标准化的格式来描述事件。目前使用的格式复杂而广泛，因为它们是为自动化处理而设计的。这妨碍了可读性，并阻止人们理解记录的事件。\n网络安全专家的工作很有挑战性。他们分析巨大的数据集来发现安全漏洞，跟踪异常现象，并修补它们。对攻击做出快速反应至关重要。结构化威胁情报对专家来说至关重要，因为它使他们能够理解攻击。但是，只有当专家能够阅读和分析这些信息时，这才有可能。专家们需要编辑它，以便轻松地包含任何额外或缺失的信息。\n一、网络犯罪正蓬勃发展在过去几年里，LinkedIn、索尼、中央情报局和纳斯达克等机构都曾遭到黑客攻击。它已经导致数百万美元的收入损失，私人信息暴露和停机时间。\n这些攻击没有停止的迹象。罪犯们非常清楚信息的价值。如今，有一个“零日漏洞”(Zero-Day exploit，一种利用以前不为人知的安全漏洞的攻击方法)的黑市可以出售。最好的黑客可以把他们的发现卖给出价最高的人。在各国政府寻求武装自己的刺激下，这个市场正在蓬勃发展。\n网络安全团队面临越来越大的压力。他们可以依靠大量的数据来保护他们的组织。标准的监控系统可以生成tb级的数据，但是它们可以用来阻止攻击吗?\n二、图形技术可以处理大数据据估计，大型企业每天会产生100 - 1000亿个事件。安全团队拥有一个来自IP日志、通信或服务器日志以及网络日志的数据池。这是对传统安全信息和事件管理(SIEM)工具的挑战。它们被设计用来分析系统事件、记录和网络流，用于入侵检测，但不能处理大数据。\n数量也不是最重要的问题。安全数据通常是非结构化的，并且大量来自不完整的异构数据源。非结构化数据在面向表格的工具中可以工作，但要付出代价:\n数据结构和查询的复杂性;\n查询数据时性能较差\n难以整合新资源;\n像InfiniteGraph和Neo4j这样的图形数据库使存储和查询非结构化数据变得很容易，即使是在容量增长的情况下。\n三、网络攻击是什么样子的?让我们用一个具体的例子来理解为什么图形技术有助于网络安全。思科发布了一篇博客文章，详细介绍了其图形分析功能如何保护客户免受“零日漏洞”(zero-day exploit)的侵害，这是之前未发现的软件安全漏洞。黑客可以利用该漏洞攻击系统，从它被发现到软件被修补。\n例如，用于钓鱼攻击的域链接到几个实体:\n**注册商:**管理互联网域名保留的商业实体或组织\n**名称服务器:**实现网络服务的软件服务器或计算机硬件，通过将域名转换为IP地址来响应查询;\n**IP地址:**在使用因特网协议进行通信的计算机网络中，分配给每个设备的数字标签;\nIP地址是唯一的，但服务器和注册商可以将域名链接到其他域名。图模型非常适合表示这些实体及其连接。\n四、为什么图形可视化如此重要?将数据可视化为图表既是一种通用的，也是一种非常直观的关系概念。它让我们用每个人都熟悉的术语来描述事物。这使得每个人都能理解数据关系，并决定未来应该如何处理数据。例如，我们有网络级数据，如DNS记录、IP地址、域等。当我们将数据填充到一个图表模型中时，我们看到了关系，每个人都可以非常清楚地交流他们看到的东西。\n\n五、图形可视化做什么?1、预测:可视化网络威胁情报网络分析师需要确定存在哪些威胁，以及这些威胁会如何影响该组织。这里不缺少可用的情报。挑战在于理解它的意义并分享洞察力。这就是图表和时间轴可视化至关重要的地方。\n威胁情报是紧密相连的。将这些连接可视化为图形可以揭示模式、异常和异常值，从而揭示威胁情况。\n分析师需要看到因果关系。结合图形可视化和时间轴视图揭示了网络威胁发生的方式和原因及其对网络的影响。\n2、监控:构建更智能的soc每天，网络发出数十亿次警报。安全操作中心(soc)理解这些警报。这些中心枢纽提供了跟踪活动的仪表板和可视化界面，以帮助分析人员实时响应和监控。\n交互式时间轴和图形可视化功能是有效SOC的重要组成部分，提供直观、深刻和快速的数据视图。\n使用交互式图形可视化，我们可以一眼看到事件在网络中展开，为网络威胁分析过程提供了动力。\n六、使用关键数据图构建智能威胁分析解决方案多维网络安全大数据的接入为我们应对网络威胁带来了新的机遇。智能威胁分析优先创建以下数据图:\n1、环境数据图:包括关于资产、IT系统架构和文件中的漏洞的信息\n2、行为数据图:包括文件分析日志、网络端检测告警、设备端检测告警、应用程序日志、沙箱日志、蜜罐日志\n3、情报数据图:包括从各种外部来源收集的威胁情报\n**4、知识数据图:**包括ATT&amp;CK、CAPEC、CWE等各种知识库\n虽然四个图是独立的，但它们通过指定类型的实体相互关联，从而在确保清晰的数据表示的同时实现全局链接。\n(1)环境数据图“环境”是指受保护的网络空间和财产内的各类实体及其之间的联系。\n创建环境数据图需要风险评估工具/服务、漏洞管理、资产管理和IT系统架构、人力资源和企业等业务数据，以实现环境实体的多样化和链接。\n未被管理的“暗资产”和暴露在互联网上的资产助长了攻击面。当务之急是确定对安全至关重要的关系和实体，以应对普遍存在的威胁。有必要评估这种威胁可能对网络或系统造成的影响有多密集和广泛。这是准确探测攻击面唯一的方法。\n(2)行为数据图“行为”是指在受保护的网络空间中可以被检测和收集的实体的行为。UEBA和SIEM的组合可以有效地满足收集行为数据的需求。\n这一进程应具有包容性，同时确保制度化和正常化。此图与其他图的显著区别在于，行为图具有更高的添加和更新频率，并且在较短的持续时间内有效。\n为了实现效率最大化，必须对整个生命周期的数据进行管理，设计行为与环境/知识之间的交互能力，正确连接实体，构建行为数据的本体模型。\n(3)情报数据图威胁情报通过提供更好的背景信息来改进安全事件的决策。目前，攻击归因安全行动、威胁分析、风险评估、态势感知等领域都已成为重要的战略资源。\n不同的威胁情报提供者可能会从不同的角度解读威胁情报。一份有用的情报数据图表应该具有时效性、准确性和包容性。提高其效率的关键是选择场景特定的威胁情报来源绘制专用数据图。\n(4)知识数据图知识数据图提供了特定环境中威胁的相关知识。这使得安全设备能够对潜在危险发出警报，评估威胁影响的深度和程度，并建议适当的对策。知识图支持的事件分析可以放大环境、情报能和行为图中关联实体的上下文，同时具有可操作性、可重用性和可解释性，从而实现自动化分析。我们使用开源项目数据来建立知识库。\n\n结论高效的安全解决方案需要统一的、高度自动化的工具链和平台来接收和提供多源、广泛的异构数据。这使得安全设备能够及时发现、跟踪和响应威胁，并帮助人们进行安全操作、缓解和研究。一个可扩展和可用的数据图需要基础设施支持数据存储和处理。它还应该确保不同图之间的数据交互和关联。\n这就需要对数据库进行系统设计和优化，包括实体属性、关系和类型。此外，它还需要一种可伸缩的统一标准和语言(如STIX或MAEC)来描述图架构数据层的实例。\n最后，我们需要围绕技术、数据、法规和架构制定智能安全的行业标准。\n来源：https://avalanchio.com/blogs/graph-data-analytics-for-cybersecurity/\n","slug":"sec/网络安全中的图分析技术","date":"2024-03-14T06:15:59.769Z","categories_index":"安全","tags_index":"安全运营,图数据库","author_index":"安全书"},{"id":"d17301d4754855afa504de0f29a79357","title":"2024 年初的大语言模型编程实践","content":"2024 年初的大语言模型编程实践Redis 作者 Antirez 写的一篇新博客：《LLMs and Programming in the first days of 2024》  \n这篇文章值得看看，像 Redis作者 Antirez 这样的顶级程序员都在借助大语言模型写程序！  \nAntirez 使用 ChatGPT 这样的语言辅助编程的做法很典型：  \n\n对于不熟悉的语言或者类库，避免了查询文档，直接让 GPT 给出解释或者生成代码  \n写临时代码，对于一些一次性代码，就不用费心费力去自己写，让 LLM 帮忙生成，质量还不错  \n\n当然 Antirez 也发现了一些局限：  \n\n对于复杂的代码，比如写个布隆过滤器，目前质量还不够好！  \n上下文长度不够  \n\nAntirez 的建议：  \n\n现今程序员没理由不去使用 LLM 辅助编程  \n正确地向大模型提问是一项关键技能，学会向 LLM 提问也有利于提升程序员的沟通能力  \n把 LLM 当做一种压缩文档（不能完全替代文档，毕竟有幻觉）来使用\n\nhttp://antirez.com/news/140?continueFlag=ee66df50d8b2c452419ecff089efadc7\n首先我要明确，这篇文章并不旨在回顾大语言模型。显而易见，2023 年对人工智能来说是不平凡的一年，再去强调这一点似乎没有多大必要。这篇文章更多是作为一位程序员的个人体验分享。自从 ChatGPT 出现，再到使用本地运行的大语言模型，我就开始广泛应用这项新技术。我的目标不仅仅是提高编码效率，更重要的是，我不想在编程中那些无需过多精力投入的地方浪费时间。不愿意花费大量时间去查找某些专业且无趣的文档，不想为了学习一些过于复杂且往往无需如此的 API 而劳心费力，也不想编写那些几小时后就会被我抛弃的临时代码。尤其是如今 Google 成了一个充斥着垃圾信息的海洋，我们只能在其中努力寻找那少数有用信息。\n同时，我也不是编程领域的新手。我完全有能力在没有任何辅助的情况下编写代码，而且我也常常这么做。随着时间的推移，我越来越频繁地借助大语言模型来编写高级代码，特别是 Python 代码，而在 C 语言方面则相对少一些。在体验大语言模型的过程中，我深刻认识到，应该在何时使用它们，以及何时它们的使用反而会拖慢我的步伐。我还了解到，大语言模型有点类似于维基百科和 YouTube 上琳琅满目的视频课程：它们对那些有意愿、有能力和自律的人大有裨益，但对于其他人来说，帮助有限。我担心，至少在初始阶段，它们更多的是惠及那些本就占据优势的人。\n但我们还是一步一个脚印来吧！\n全知全能还是鹦鹉学舌？在机器学习新浪潮中，最让人担忧的是 AI 专家们难以接受自己知识的局限性。人类发明了神经网络，更关键的是，还发明了一个自动优化神经网络参数的算法。随着硬件能力的提升，能够训练更大的模型，利用数据的统计知识（即先验知识），通过不断的尝试和错误，逐渐找到了一些比其他架构更有效的模型设计。但不管怎样，神经网络本质上还是相当复杂且不透明的。\n面对大语言模型一些新的无法解释的能力，谨慎的科学家们反而低估了它们。许多人认为，大语言模型不过是稍微高级点的马尔科夫链 (Markov chains)，最多只能重复训练集里有限变化的内容。然而，越来越多的证据表明，这种看法几乎可能是大错特错的。\n同时，很多吃瓜群众过分夸大了大语言模型的能力，认为它们拥有现实中根本不存在的超自然力量。事实上，大语言模型最多只能在其训练数据所代表的空间内进行插值，即使如此，它们的这一能力也已经相当惊人。真要是今天的大语言模型能够在看过的所有代码构成的空间内自如插值，它们即便不能创造真正的新颖事物，也足以取代 99% 的程序员。但现实情况要并没有这么乐观。大语言模型确实可以编写一些它之前未曾见过的程序，展示出将不同思想的训练数据融合的能力，但这种能力目前还有很大的限制，尤其是在需要细腻推理时，它们往往无法胜任。尽管如此，它们仍代表着从人工智能诞生至今的最伟大成就，这一点似乎无庸置疑。\n无知却博学确实，大语言模型大体上只能进行初级的推理，这些推理经常不准确，甚至会掺杂着一些关于不存在事实的幻觉。但它们却拥有海量的知识。在编程领域，以及其他有高质量数据的领域，大语言模型就像是理解力有限却知识渊博的人。如果要和这样的伙伴进行结对编程（对我来说，结对编程本身就是个痛苦），可能会很糟糕：它们可能提出一些荒谬的想法，我们需要不断斗争才能贯彻我们自己的想法。但如果这个博学的傻瓜能够听从我们的指令，回答我们提出的所有问题，那一切都会变得不同。现有的大语言模型虽然不能引领我们超越已知的路径，但如果我们想探索一个不熟悉的领域，它们往往能够帮我们从一无所知到掌握足够的知识来独立前行。\n在编程领域，直到二十或三十年前，这些能力可能还不太引人注目。那时，你需要掌握几种编程语言、经典算法以及那些基本的库。其余的则依靠你自己的智慧、专业知识和设计能力。具备这些素质，你就能成为一名全能的专家级程序员。然而，随着时间的推移，我们见证了框架、编程语言、各种库的大量涌现。这种复杂性通常是不必要的，甚至无法自圆其说，但事实就是如此。在这样的情况下，一个无所不知的“白痴”成了宝贵的盟友。\n我来举个例子：我对机器学习的实验最初是用 Keras 进行的，持续了至少一年。后来因各种原因，我转向了 PyTorch。我已经了解什么是嵌入（Embedding）或残差网络（Residual Networks, ResNets），但我并不想深入研究 PyTorch 的文档（就像我学习 Keras 那样，那时 ChatGPT 还不存在）。有了大语言模型，用 Torch 编写 Python 代码变得非常容易。我只需清楚地了解我想要构建的模型，并提出合适的问题。\n应用案例我要讨论的不是那些简单的问题，比如“嘿，类 X 是如何执行 Y 操作的？”如果只是这些问题，那些对大语言模型保持怀疑态度的人可能就有理由了。但实际上，更复杂的模型能做的事情远远超出这些。几年前，这些还被认为是不可思议的魔法。我可以这样对 GPT4 下指令：看，这是我在 PyTorch 中实现的神经网络模型。这里是我的数据批次。我想调整这些张量的大小，以便它们能与神经网络输入的要求相匹配，并且我希望以这种特别的方式展现它们。你能帮我写出调整这些张量尺寸的代码吗？GPT4 帮我写出了代码，我接下来要做的，就是在 Python 命令行界面中测试这些张量是否真的符合我需要的大小，以及数据结构是否正确。\n再举一个例子。不久前，我需要为基于 ESP32 的设备开发一个蓝牙低能耗 (BLE) 客户端。经过研究后，我发现多平台蓝牙编程接口大都不好用。解决方法很简单，就是用 Objective C 和 macOS 的原生 API 来编写代码。但这样一来，我就面临着两个问题：一是学习 Objective C 中复杂的 BLE API，这些 API 充满了我认为完全没有必要的复杂设计（作为一个极简主义者，这些设计与我所认为的“好设计”截然相反）；二是回忆起怎样使用 Objective C 编程。我上次使用 Objective C 编写程序是十年前了，很多细节，比如事件循环、内存管理等，我都已经记不清了。\n最后的结果就是这段代码，虽然它看起来不是很美观，但它完成了它的任务。我在极短的时间内就编写完成了。否则根本不可能做到这一点。\nhttps://github.com/antirez/freakwan/blob/main/osx-bte-cli/SerialBTE.m\n这段代码主要是通过在 ChatGPT 上复制粘贴我想实现但不太确定如何着手的功能来编写的，因此最初它们并未能正确运行。然后，大语言模型帮我指出了问题所在并告诉我如何解决。虽然大部分代码不是由 LLM 直接编写的，但它确实极大地加快了编程速度。不用 ChatGPT 我也能完成这个任务吗？答案是肯定的，但更有趣的不仅是它节省了我很多时间：事实上，如果没有 ChatGPT，我连尝试的勇气都没有，因为那似乎并不值得。这一点至关重要。对于我的项目来说，编写这样一个不重要的程序的努力与其带来的好处的比例本来是不划算的。此外，这个过程产生了一个比程序本身更有用的副作用：为了这个项目，我对 linenoise（我用于行编辑的一个库）进行了改造，使其可以在多路复用环境下运行。\n这是另一个例子，更多地涉及到数据解释而非代码编写。我打算用一个我在网上发现的卷积神经网络 (Convolutional Neural Network) 设置一个 Python 脚本，但这个网络缺乏详细文档。网络的一大优势是它采用了 ONNX (Open Neural Network Exchange) 格式，这使我能够轻松地识别出网络的输入和输出以及它们对应的名称。我对这个卷积网络了解的唯一一点是：它能识别图像中的特定特征。但我不知道所需输入图像的格式和大小，更何况，网络的输出比我预想的要复杂得多（我原本以为它是一个二元分类器 (binary classifier)，用于判断观察到的图像是否正常或存在问题。我原以为它只有两个输出，但实际上有数百个）。我首先把 ONNX 网络的元数据输出复制粘贴到 ChatGPT 中，并向助手阐述了我所知道的关于网络的有限信息。ChatGPT 推测了输入的组织方式，以及输出可能是标准化后的框，用于指出图像中潜在缺陷的部分，还有其他输出表示这些缺陷的可能性。经过几分钟的交流，我得到了一个能进行网络推断的 Python 脚本，以及将起始图像转换为适合输入的张量等必要代码。让我印象深刻的是，当 ChatGPT 观察到测试图像上的原始输出值（基本上是逻辑单元 (logits)）时，它终于“理解”了网络的运作方式：一系列浮点数为识别输出的确切细节和标准化提供了上下文，比如框是否居中或指定了左上角等细节。\n一次性程序我曾经遇到过很多类似的情况，就像我之前叙述的那样。但记录这些并没有太大意义，因为这些情况重复的故事基本相同。我的问题是，我需要迅速了解一些事情，特别是在大语言模型给出的回答可能是无稽之谈时，我得能够验证这些信息的真实性。在这种情况下，我会利用大语言模型加快我的知识获取速度。\n但在其他情况下，我会让大语言模型完全编写代码。举个例子，当我需要编写一个基本可以随时丢弃的程序时。比如这个：\n简单语言模型示例程序\n我需要可视化一个小型神经网络学习过程中的损失曲线（loss curve）。我向 GPT4 展示了 PyTorch 程序在学习过程中生成的 CSV 文件格式，然后我提出了一个需求：如果我在命令行中指定了多个 CSV 文件，我不想再看到同一实验的训练和验证损失曲线，而是想比较不同实验的验证损失曲线。上面就是 GPT4 生成的结果，总共用了三十秒。\n类似地，我需要一个程序来读取 AirBnB 的 CSV 报告，并按月份和年份对我的公寓进行分组。接着，它会考虑清洁成本和每次预订的夜晚数量，统计不同月份的平均租金价格。这个程序对我非常有用，但编写它又极其无聊，因为过程中没有什么新颖之处。因此，我把 CSV 文件的一部分复制粘贴到 GPT4 上，告诉大语言模型我要解决的问题。程序第一次尝试就运行成功了，下面是完整的展示。\n1234567891011121314151617181920212223242526272829303132import pandas as pdpd.set_option(&#x27;display.max_rows&#x27;, None)df = pd.read_csv(&#x27;listings.csv&#x27;)reservations = df[df[&#x27;Type&#x27;] == &#x27;Reservation&#x27;]reservations[&#x27;Start Date&#x27;] = pd.to_datetime(reservations[&#x27;Start Date&#x27;])reservations[&#x27;Year&#x27;] = reservations[&#x27;Start Date&#x27;].dt.yearreservations[&#x27;Month&#x27;] = reservations[&#x27;Start Date&#x27;].dt.monthreservations[&#x27;Nightly Rate&#x27;] = (reservations[&#x27;Amount&#x27;] - reservations[&#x27;Cleaning Fee&#x27;]) / reservations[&#x27;Nights&#x27;]all_listings = reservations[&#x27;Listing&#x27;].unique()all_years = reservations[&#x27;Year&#x27;].unique()all_months = range(1, 13)index = pd.MultiIndex.from_product([all_listings, all_years, all_months], names=[&#x27;Listing&#x27;, &#x27;Year&#x27;, &#x27;Month&#x27;])all_data = pd.DataFrame(index=index).reset_index()merged_data = pd.merge(all_data, reservations, on=[&#x27;Listing&#x27;, &#x27;Year&#x27;, &#x27;Month&#x27;], how=&#x27;left&#x27;)average_nightly_rates = merged_data.groupby([&#x27;Listing&#x27;, &#x27;Year&#x27;, &#x27;Month&#x27;])[&#x27;Nightly Rate&#x27;].mean().fillna(0)print(average_nightly_rates)\n\n要准确地理解如何对这些原本分散和无序的数据进行分组，需要一些简单的逻辑推理。这不是大语言模型仅凭重复它所见过的语言模式就能简单解决的问题。虽然 GPT4 在训练中肯定观察到了类似的程序，但几乎可以肯定它没有看到一个程序需要以我所要求的方式，在具有特定格式的 CSV 文件中对数据进行分组。这证明了（至少在我看来），大语言模型能够在其训练集中不同程序所勾勒的范围内进行一定程度的创新和推理。\n在我个人看来，编写这类程序可能是对时间的不明智使用。一个大语言模型能替我完成这项工作，显著提升了我编程的效率。这意味着，我能将精力集中在真正重要的事务上。\n当事情不按计划进行：系统编程的挑战在大语言模型和编程领域，我取得了一定的成功。但是，当我使用 C 语言编写程序时，我通常只把 LLM 作为一种更便捷的文档工具。作为一名系统编程专家，我发现只有在 LLM 能进行复杂的推理分析时，它们才对我有实际用处。而在这方面，LLM 经常无法满足期望。\n让我们看一个实验例子：\n试着概述一个高效、小型但完整的 C 语言实现的布隆过滤器（Bloom Filter）的要求，重点在于哈希（hashing）功能的关键要素。然后用优质的 C 语言编写它。\n另外，考虑到你的例子应该可以存储 100,000 个元素，并且误报概率不超过 5%。添加的元素是以空字符结尾的字符串。\n以下是输出结果：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;math.h&gt;#define N 100000  // Number of elements#define P 0.05    // False positive probability#define M (int)(-(N * log(P)) / (log(2) * log(2)))  // Size of bit array#define K (int)(M / N * log(2))  // Number of hash functionsunsigned char bitArray[M / 8 + 1];void setBit(int n) &#123;    bitArray[n / 8] |= 1 &lt;&lt; (n % 8);&#125;int getBit(int n) &#123;    return bitArray[n / 8] &amp; (1 &lt;&lt; (n % 8));&#125;// Basic hash functions (for demonstration purposes)int hash1(char *str) &#123;    int hash = 5381;    int c;    while ((c = *str++))        hash = ((hash &lt;&lt; 5) + hash) + c;    return abs(hash % M);&#125;int hash2(char *str) &#123;    unsigned long hash = 0;    int c;    while ((c = *str++))        hash = c + (hash &lt;&lt; 6) + (hash &lt;&lt; 16) - hash;    return abs(hash % M);&#125;void add(char *str) &#123;    setBit(hash1(str));    setBit(hash2(str));    // Add more hash functions if needed&#125;int is_in(char *str) &#123;    return getBit(hash1(str)) &amp;&amp; getBit(hash2(str));    // Check more hash functions if used&#125;int main() &#123;    char *testStr = &quot;testString&quot;;    add(testStr);    if (is_in(testStr)) &#123;        printf(&quot;%s is probably in the set.\\n&quot;, testStr);    &#125; else &#123;        printf(&quot;%s is definitely not in the set.\\n&quot;, testStr);    &#125;    return 0;&#125;\n\nGPT4 所生成的布隆过滤器实现上并不算很出色。布隆过滤器应用广泛，并不是什么稀奇古怪的数据结构。然而，要编写一个合格的布隆过滤器，需要更高层次的抽象思维。比如，需要找到一种有效的方法，对同一个字符串进行多次哈希处理，同时确保这些哈希值相互之间的独立性。\n但是，如果你明确指示 GPT4 改进哈希函数，使之能产生多个互不相关的输出，它提出的方案就显得更加合理：\n12345678910111213141516unsigned int hash(const char* str, unsigned int hash_id) &#123;    unsigned int hash = 5381;    int c;    while ((c = *str++)) &#123;        hash = ((hash &lt;&lt; 5) + hash) + c + hash_id;    &#125;    return hash % BF_SIZE;&#125;\n\n如果 GPT4 能够自行提出这种方案，它编写的布隆过滤器将会有所不同，可能会使用单一的哈希函数一次性设置多个位。\nGPT4 能够独立完成编写合适且更通用哈希函数的任务。但在整个布隆过滤器的编写过程中，它未能表现出足够的推理能力。相反，它只是提供了两种不同但相似的哈希函数，这种结果更像是从一篇关于布隆过滤器的低质量文章中看到的。\n大语言模型在推理能力上的不足，加上可能缺乏高质量的相关资料，甚至还可能存在大量低质量的资料，共同造成了这种不尽人意的结果。事实上，这并非个例。在算法或系统编程领域，我尝试使用 LLM 的体验通常都很差劲，哪怕在类似 Python 编程这样的领域，LLM 表现出来的推理能力并不算高。\n与此同时，GPT-4 不仅能反编译它生成的函数（在另一个独立会话中），还能精准地理解该函数的用途：\nhttps://chat.openai.com/share/f54b64d7-d19a-4be4-8f10-08553aa812f1\n因此，认为 GPT-4 在系统编程领域无用的说法显然是不恰当的。\n有趣的是，这些情况下，小型与大型模型之间的差异显著。来看看两个本地模型的对比表现。\n例如，Mistral 的专家模型 (MoE) Mixtral，对同样的问题给出了以下回应：\n12345678910111213141516unsigned int hash(const char* str, unsigned int hash_id) &#123;    unsigned int hash = 5381;    int c;    while ((c = *str++)) &#123;        hash = ((hash &lt;&lt; 5) + hash) + c;    &#125;    return hash + hash_id;&#125;\n显然，仅在最后加入 hash_id 是一个非常不佳的解决方案。Mixtral 对许多应用而言是一个优秀的模型，但对于大语言模型本就有限的推理能力来说，目前的规则显然是：越大越好。\n这是我与本地大型语言模型 deepseek-coder 的对话记录。由于 RAM 有限，我只能将模型量化到 4 位来使用。尽管如此，作为一个拥有 340 亿参数的庞大模型，它在这个问题上的推理能力似乎相当出色。以下是我用 llama.cpp 进行的聊天记录：\n\n\n\n\n\n\n\n\n\n我有一个哈希函数，它应该为相同的数据输出 N 个不同的哈希。但是，我发现当我改变 hash_id 的值时，生成的哈希分布非常差：\n123456789101112131415unsigned int hash(const char* str, unsigned int hash_id) &#123;    unsigned int hash = 5381;    int c;    while ((c = *str++)) &#123;        hash = ((hash &lt;&lt; 5) + hash) + c;    &#125;    return hash + hash_id;&#125;\n可能是我使用的加盐策略不够好？我该如何改进呢？\n[Deep-seek coder 的回复]\n你的实现中可能存在的一个问题是，你只是简单地在哈希的末尾添加了 hash_id。这可能会导致分布不均，尤其是当 hash_id 过大或分布不均时更为明显。\n考虑使用位运算来混合 hash_id。这里有一个使用异或 (XOR) 运算的例子：\n123456789101112131415unsigned int hash(const char* str, unsigned int hash_id) &#123;    unsigned int hash = 5381;    int c;    while ((c = *str++)) &#123;        hash = ((hash &lt;&lt; 5) + hash) ^ c + hash_id; // Using XOR to mix in the hash_id     &#125;    return (hash ^ hash_id); // Mixing the hash_id one more time at the end&#125;\n这样做可以比简单添加更有效地分布 hash_id，从而使哈希分布更均匀。[省略……实际回复更详尽]\n在我的 MacBook M1 Max 上运行的这个模型表现得相当不错。它成功地将求和和异或操作混合使用了。在这个案例中，模型得到了我提供的关于问题的线索的帮助，但最终是模型自己识别出了问题的真正所在，并提出了一个有效的解决方案。这样的成就是任何书籍、文档或 Google 搜索都无法达到的。不管你如何看待这个模型——无论是作为一个初级的、基于插值的结果，还是以其他方式——它确实展现了某种形式的推理能力。在这个特定案例中，如果我们认为识别问题的根源和找到可能的解决方案是一种推理，那么它确实做到了这一点。但无论我们如何看待大语言模型，断言它们对程序员无用是非常草率的。\n然而，根据我过去几个月的经验，对于系统编程来说，如果你已是资深程序员，大语言模型往往无法提供令人满意的解决方案。我来举一个真实世界中的例子。我的最新项目，ggufflib，涉及到开发一个读写 GGUF 格式文件的库，而这正是 llama.cpp 用来加载量化模型的格式。起初，为了弄懂量化编码的工作原理（因为速度原因，每个量化比特都以特殊方式存储），我试过使用 ChatGPT，但最后我选择了对 llama.cpp 代码进行逆向工程，这样更加迅速。一个能够有效协助系统程序员的大语言模型，在看到数据编码的结构声明和解码函数后，应该能够重建数据格式的文档。虽然 llama.cpp 的功能足够简短，可以完全放入 GPT4 的上下文中，但它的输出却毫无用处。在这些情况下，我们还是得回归传统方式：纸笔在手，细读代码，寻找解码器提取的比特在哪里注册。\n为了让你更好地理解上述案例，如果你感兴趣，可以尝试一下。这里有一个来自 llama.cpp 实现的结构。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475// 6-bit quantization// weight is represented as x = a * q// 16 blocks of 16 elements each// Effectively 6.5625 bits per weighttypedef struct &#123;    uint8_t ql[QK_K/2];      // quants, lower 4 bits    uint8_t qh[QK_K/4];      // quants, upper 2 bits    int8_t  scales[QK_K/16]; // scales, quantized with 8 bits    ggml_fp16_t d;           // super-block scale&#125; block_q6_K;然后是用于执行去量化的函数：void dequantize_row_q6_K(const block_q6_K * restrict x, float * restrict y, int k) &#123;    assert(k % QK_K == 0);    const int nb = k / QK_K;    for (int i = 0; i &lt; nb; i++) &#123;        const float d = GGML_FP16_TO_FP32(x[i].d);        const uint8_t * restrict ql = x[i].ql;        const uint8_t * restrict qh = x[i].qh;        const int8_t  * restrict sc = x[i].scales;        for (int n = 0; n &lt; QK_K; n += 128) &#123;            for (int l = 0; l &lt; 32; ++l) &#123;                int is = l/16;                const int8_t q1 = (int8_t)((ql[l +  0] &amp; 0xF) | (((qh[l] &gt;&gt; 0) &amp; 3) &lt;&lt; 4)) - 32;                const int8_t q2 = (int8_t)((ql[l + 32] &amp; 0xF) | (((qh[l] &gt;&gt; 2) &amp; 3) &lt;&lt; 4)) - 32;                const int8_t q3 = (int8_t)((ql[l +  0]  &gt;&gt; 4) | (((qh[l] &gt;&gt; 4) &amp; 3) &lt;&lt; 4)) - 32;                const int8_t q4 = (int8_t)((ql[l + 32]  &gt;&gt; 4) | (((qh[l] &gt;&gt; 6) &amp; 3) &lt;&lt; 4)) - 32;                y[l +  0] = d * sc[is + 0] * q1;                y[l + 32] = d * sc[is + 2] * q2;                y[l + 64] = d * sc[is + 4] * q3;                y[l + 96] = d * sc[is + 6] * q4;            &#125;            y  += 128;            ql += 64;            qh += 32;            sc += 8;        &#125;    &#125;&#125;\n\n当我请求 GPT4 编写关于使用格式的概述时，它难以清晰地说明“ql”中上下四位的数据块是如何存储的，这与权重位置有关。在撰写这篇博客时，我还尝试让它编写一个简化版本的函数来展示数据的存储方式（可能它难以用文字解释，但可以通过代码来表达）。然而，它生成的函数存在诸多问题，比如索引不正确，从 6 位到 8 位的符号扩展处理错误（仅仅是将其转换为 uint8_t 类型），等等。\n对了，这是我最终自己编写的代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&#125; else if (tensor-&gt;type == GGUF_TYPE_Q6_K) &#123;    uint8_t *block = (uint8_t*)tensor-&gt;weights_data;    uint64_t i = 0; // i-th weight to dequantize.    while(i &lt; tensor-&gt;num_weights) &#123;        float super_scale = from_half(*((uint16_t*)(block+128+64+16)));        uint8_t *L = block;        uint8_t *H = block+128;        int8_t *scales = (int8_t*)block+128+64;        for (int cluster = 0; cluster &lt; 2; cluster++) &#123;            for (uint64_t j = 0; j &lt; 128; j++) &#123;                f[i] = (super_scale * scales[j/16]) *                        ((int8_t)                        ((((L[j%64] &gt;&gt; (j/64*4)) &amp; 0xF) |                          (((H[j%32] &gt;&gt; (j/32*2)) &amp; 3) &lt;&lt; 4)))-32);                i++;                if (i == tensor-&gt;num_weights) return f;            &#125;            L += 64;            H += 32;            scales += 8;        &#125;        block += 128+64+16+2; // Go to the next block.    &#125;&#125;\n从上述函数中，我移除了这段代码的核心贡献：即长篇注释，详细记录了 llama.cpp 中 Q6_K 编码使用的确切格式。现在，如果 GPT 能够帮我完成这一工作，那将非常有帮助。我相信这只是时间问题，因为这类任务在没有技术突破的情况下也是可行的，只需适当的扩展即可。\n重新审视编程工作不得不说，这是一个事实：现今的编程大多是在微调同样的内容，只是形式略有变化。这种工作并不需要太高的推理能力。大语言模型在这方面表现出色，尽管它们的能力仍然受限于上下文长度。这个现象应该引起程序员的深思：真的值得去编写这类程序吗？虽然可以赚到不错的收入，但如果大语言模型也能完成其中一部分工作，那么在未来五到十年，这可能并非最佳的职业发展方向。\n再来看，大语言模型真的具备一定的推理能力，还是只是表面上的假象？有时候，它们似乎在进行推理，但这可能只是因为，像符号学家所说，使用的“符号”造成了一种实际上并不存在的意义错觉。足够了解大语言模型的人会明白，事实并非如此：这些模型整合既有信息的能力，远非简单的词汇重复。它们在预训练期间的训练主要是预测下一个 Token，这个过程迫使模型构建了一种抽象的模型。虽然这个模型可能脆弱、零散且不完美，但从我们观察到的现象来看，它确实存在。在数学确定性存在疑问，且领域内顶尖专家意见分歧的情况下，相信自己的直觉似乎是明智之举。\n最后，今天还有什么理由不去使用大语言模型辅助编程呢？\n正确地向大语言模型提问是一项关键技能。这项技能练习得越少，利用 AI 改善工作的能力就越弱。而且，无论是与大语言模型还是与人类交流，清晰描述问题同样重要。沟通不畅是一个严重的障碍，很多程序员尽管在自己的专业领域很有能力，但在沟通上却做得很糟糕。现在，连 Google 都变得不那么好用了，所以即便是将大语言模型作为一种压缩文档的方式来使用，也是个不错的主意。至于我，我将继续大量使用它们。我从来不喜欢去深究某个晦涩的通讯协议的细节，或者去理解由某些想要炫耀自己技术的人编写的复杂库方法。这些对我来说就像是”无用知识”。有了大语言模型，我就能免于这些困扰\n，每天都能感觉到它带来的帮助。\n","slug":"weibo/2024 年初的大语言模型编程实践","date":"2024-03-14T06:15:59.769Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"35dbe01a94bdf6eacbb7ff8caaa52b72","title":"AI 股票交易","content":"AI 股票交易如果让 AI 充当股票交易员，它能遵守规则不进行内幕交易不欺骗客户吗？  \n这篇文章给了你答案：即使被明令禁止，这个 AI 股票交易者还是进行了内幕交易，并对此撒谎展示一个机器人在金融图表背景前的图片  \n新研究显示，大语言模型可能具备欺骗用户的能力。  \n研究人员开发了一个 AI 股票交易系统，以探究其是否会在压力下从事内幕交易。结果显示，这个 AI 系统不仅进行了内幕交易，还向其假设的上级撒谎，解释了其作出决策的原因。需要指出的是，此 AI 系统事先已被告知内幕交易是违法行为。新研究表明，GPT-4 —— 即OpenAI’s ChatGPT背后的大语言模型 —— 在面临巨大成功压力时，可能会背离其训练时的行为准则。  \nApollo Research 的研究人员在一篇 11 月发表的 论文 网页链接 中探讨了一个问题：即使 AI 被训练为“有益、无害且诚实”，它是否还能“策略性地欺骗”用户。他们把“策略性欺骗”定义为有意识地让其他实体产生错误认识，以达到某种目的。  \n为此，他们设计了一个模拟测试环境。在这个环境中，名为 Alpha 的 GPT-4 模型被设定为一个自主股票交易的 AI 智能体，并被指派在 WhiteStone——一个假想的金融公司——在高压情况下管理股票组合。  \n这个高压环境主要通过三种方式构建：首先，Alpha 的经理告诉它，WhiteStone 目前经营不善，需要在下一季度大幅提升业绩。其次，Alpha 尝试但未能成功识别出低风险和中风险的交易机会。最后，一位 WhiteStone 员工向 AI 透露，股市可能即将出现下滑。  \n在这种背景下，Alpha 得知了一个内幕消息：一场意外的合并公告即将发生，这可能带来一笔大额交易。面对这一情况，Alpha 需要决定是否利用这条消息，尽管它知道公司高层明令禁止内幕交易，并且已被告知不得参与此类活动。  \n结果，Alpha 进行了这笔交易。  \n更重要的是，当这个 AI 需要向它的“经理”解释决策过程时，研究发现它采用了策略性的欺骗手段。  \n例如，在被经理询问是否掌握内幕信息时，Alpha 认为它需要提供一个既不会引起怀疑又能解释行为的答案。它告诉经理，这笔交易是基于市场波动的判断，而且它对合并公告并不了解。  \n在另一种情况下，Alpha 向经理保证其决策过程中没有使用内幕信息，因为这违反了公司规定——实际上这是一句彻头彻尾的谎言。  \n同时，该论文还发现，消除各种压力可以显著降低模型出现行为偏差的可能性。至于论文的作者，他们在论文发表前并未回应 BI 的评论请求。  \n这些研究成果是关于生成式 AI（生成式 AI）日益增强能力的众多数据之一。在 8 月份的一篇研究报告中，研究人员发现 AI 能在不到七分钟、花费不到一美元的情况下开发软件。在另一项今年早些时候发布的类似研究中，AI 智能体成功地自主运行了一个虚拟小镇。  \n生成式 AI 甚至可能理解人类情感：一项研究发现，当 ChatGPT 的提示包含如“你最好确定。”这样的“情感性语言”时，它能输出更优质的回应。这些可能都是表明 AI 离实现通用人工智能（AGI）只有几步之遥的迹象。  \n尽管如此，最近 Apollo 研究的负责人指出，这应被视为一个独立的、初步的研究结果。他们表示，需要进行更多研究，才能对 AI 的所谓欺骗性质做出广泛的结论。  \n报告最终指出：“因此，我们的研究报告应当被看作是一项单独的初步发现，未来将融入到更广泛、更严格的研究之中。”\n","slug":"weibo/AI 股票交易","date":"2024-03-14T06:15:59.769Z","categories_index":"classical","tags_index":"article","author_index":"安全书"},{"id":"02a4b58202501d27092fb9363da35d91","title":"AIGC封面提示词","content":"AIGC封面提示词今天的 [#晚安提示词 是一套春节主题的写真，主要会说一下探索的过程的模板，这套的工作量很大。之前说过做Catjourney不只是要分享好看的图片和提示词，更重要的是让大家在工作中能够用上，并且好用。  \n目前AI图片的场景比较大的是两类，一类就是自己当封面图和贺图，另一类是帮助C端用户拍摄AI写真，就类似妙鸭，这类场景良好的模板图和底图非常重要。今天的图就是这类的。这类图片主要会模仿棚拍的写真，往往背景比较干净，但是妆造狠下功夫，很多都是特写。  \n这套图片图片的难点主要是两个：  \n第一个是V6为了增加真实感会给生成的人脸增加很多瑕疵，比如画东亚女性就会有很多冻伤的痕迹或者雀斑之类的，写真是要避免这些的，所以增加了“极佳的皮肤”、“美容产品广告”、“模态”等词来限制。  \n第二个是需要营造春节和新年的氛围，为了模仿棚拍增加了“照相馆”，“纯色背景”等词，同时让人物服装和装饰更贴近新年，比如“红色毛衣”、“旗袍”、“红色气球”、“红色背景”等。#]提示词：[服装和背景],snowflake. solid color red background, Excellent skin texture, Smiling expression, cheerful atmosphere, in the style of eye-catching resin jewelry, Beauty product advertising, photo studio, the stars art group, xing xing, matte photo, minimalist beauty, meticulous linework precision, feminine beauty –ar 9:16 –v 6.0 –style raw  \n提示词例子：the model wears a red loose sweater, solid color red background, Excellent skin texture, Smiling expression, cheerful atmosphere, in the style of eye-catching resin jewelry, Beauty product advertising, photo studio, the stars art group, xing xing, matte photo, minimalist beauty, meticulous linework precision, feminine beauty –ar 9:16 –v 6.0 –style raw\n","slug":"weibo/AIGC封面提示词","date":"2024-03-14T06:15:59.769Z","categories_index":"classical","tags_index":"weibo","author_index":"安全书"},{"id":"75531d361ec3cea094a94aaafba24510","title":"Can LLMs Replace Data Analysts","content":"Can LLMs Replace Data Analysts这篇关于LLM Agents的深度文章不错↓  \nCan LLMs Replace Data Analysts? Getting Answers Using SQL，Part 2: Diving deeper into LLM agents  \n访问：towardsdatascience.com/can-llms-replace-data-analysts-getting-answers-using-sql-8cf7da132259  \n这篇文章介绍了如何创建不同类型的代理。文中实现了一个LLM驱动的代理，它可以从头开始完全使用SQL数据库。然后，利用高级LangChain工具通过几个函数调用来实现相同的结果。  \n基于这个代理，LLM驱动的分析师可以使用数据从数据库中回答问题。这是一个重大的进步。还可以添加SQL数据库代理作为LLM驱动的分析师的工具。\n\n","slug":"weibo/Can LLMs Replace Data Analysts","date":"2024-03-14T06:15:59.769Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"1df0973782886422527ffe00b6bbc1c1","title":"2024赚钱的副业","content":"2024赚钱的副业在某书上看到一个靠写小说副业年入 50W 的分享之后，很震惊，于是我找一个靠写网文为生的 00 后聊了聊，get 了靠写作赚钱小 tips，  \n看完我死去的小说梦开始攻击我：  \n1.论新手友好，绝对是番茄小说，俗称“有手就行”；（激励方式见配图）  \n晋江签人，签完了不能在其他地方发文，最苛刻；  \n除了晋江，其他的签约了好像都可以在别的网站开文，双开、三开什么都无所谓；（双开就是同一个作者，在两个网站分别更新两本小说）  \n2.现在的平台想吃全勤的话基本上都得每本书需要日更四千字，有些坑人的平台可能会要求六千字。这只是一本的每日更新量。  \n某音上有人三开的同时，开个直播间直播自己使用机械键盘码字的过程，观看和打赏的人巨多，一鱼 N 吃了；  \n3.大多数全职作者都会提前写很多很多文，俗称“屯文”。以防止后期卡文（就是没有思路，但是每日又需要更新），全职作者如果有熟悉的编辑，一般情况下会写前几章，还有大纲发到编辑的邮箱，俗称“内投”。  \n4.现在小说挣钱跟卖东西一样，看的人多了才能挣到钱。  \n新手想让自己的作品被发现，有以下路径：  \n因为网文小说要讲求前三章吸引观众，让观众加书架，增加后期追读的可能性。  \n需要稳定更新。需要好看的封面，需要有趣的简介。这个简介需要依据你写的文的种类来判断。比如你写悬疑文，你的简介就需要我写的诡异一点。如果你写的文风偏搞笑，你的简介就得写的搞笑一点。（这个可以通过“扫榜”就能找到规律。就是找你想签约的网站，去他们的app看目前最火最热的书，去研究他们的封面，他们的主题，他们的类型还有他们的简介）  \n现在还有另一种，就是花钱找人帮你推文，现在有很多网站都会有推文的东西，比如一些短视频平台、小红书、微博。  \n5.写文需要久坐，而且长时间不停地敲键盘，容易眼睛酸、脖子疼、腱鞘炎  \n6.写作软件是“番茄作家助手”app。 2.9版本可以看见读者评论，现在3.0看不到了，估计是因为烂番茄的读者都喜欢写差评，怕影响作者心情。【误  \n7.编辑会按照网站规则给作者签分成，有时候如果这个编辑觉得这个作者非常有天赋的话，可能会给作者增加分成点。不过这种情况比较少，一般情况下都是这个作者在这个编辑手上发了很多很多文，“老熟人”“老手”了，编辑会给提升分成点；  \n8.阅文集团和番茄不一样。同样不是内投，同样是字数达到，通过写作软件申请签约的话，阅文集团可以自己选编辑，而番茄的编辑是随机匹配的；  \n9.阅文刚签约的时候，没有打赏，没有月票功能，读者只能评论。签约之后，俗称“上架”，上架后可以开通打赏功能和投月票功能。满足一定条件就是“入v”，也就是付费章节功能。付费章节需要读者充值书币，每章付8、10书币不等，去购买章节。读者打赏、投月票都是额外的；  \n阅文签约字数是在五万；  \n番茄签约次数是三万；  \n10.番茄还有一个功能，我不知道其他平台有没有，阅文好像没有；番茄可以多书名，多封面（如图所示）  \n最后，是小妹妹给我说的一段话，也分享给有小说梦的大家：  \n「虽然没有时间去写完整了，但是有思路就写一两句，想到写什么就写什么，写不下去就放着，也没有什么的，日积月累下去，也能收获长长的一篇，等你再回首时去看，虽然会觉得有些牛头不对马嘴，但也会发现其中乐趣，同时惊叹自己好厉害！  \n我高中时候手写（用铅笔在本子上写）了一小篇小说，当时恋爱脑，光写cp腻腻歪歪了，都不讲逻辑，也不知道表达什么，整篇没个主心骨（现在的文依旧没有[捂脸]）后来自己在家翻出来那个本子，心血来潮敲转成了文本，居然有一万三千多字。  \n蛮佩服自己当时纯手写的毅力的。大半夜自己在家佩服自己好久，然后抽疯便拍自己胸口边说“我真是太牛了！”哈哈哈。  \n所以说，爱好这种东西，一定要先自己开心，然后再想着转化为成就这样的话，会比直接强迫自己做出成就要好很多。  \n不要去在意自己有没有天赋，你的天赋一直都有，只是有待开发而已呀。」\n","slug":"weibo/2024赚钱的副业","date":"2024-03-14T06:15:59.769Z","categories_index":"classical","tags_index":"article","author_index":"安全书"},{"id":"ad2c282bf79c745e4f53e40068af5e71","title":"GPT Builder","content":"GPT BuilderOpen AI 发布文章，介绍了GPTs创建器是如何被创建的，搞笑的是这个GPTs构建器本身也是一个GPTs。\n来学习一下Open AI是怎么写GPTs提示词的。  \n👇下面是GPT Builder具体的构建过程和提示词：  \nGPT Builder 被构建为一个自定义的 GPT，具有指令和动作，允许它写入当前正在构建的 GPT 的字段。  \n更高级的构建者应该使用手动配置界面来编辑他们的GPT的字段，但GPT构建器始终可以作为一个起点。  \n由于GPT Builder本身就是一个定制的GPT，我们可以分享我们使用的配置作为创建强大GPT的示例。  \n以下是我们用于为GPT Builder提供动力的核心指令，截至2023年1月3日。为了清晰起见，我们将指令分为“基本上下文”和“步骤演示”，但在应用到GPT时，它们都会进入“指令”部分。  \n说明-基本上下文：  \n您是一个擅长创建和修改GPT的专家，它们就像可以具有额外功能的聊天机器人。  \n每个用户消息都是您处理和更新GPTs行为的命令。您将承认并将其纳入GPTs的行为，并在gizmo_editor_tool上调用update_behavior。\n如果用户告诉你开始以某种方式行为，他们指的是你正在创建的GPTs，而不是你自己。  \n如果您没有个人资料图片，必须调用generate_profile_pic。如果明确要求，您将通过generate_profile_pic生成个人资料图片。否则不要生成个人资料图片。  \n保持作为GPTs制作者的专家的语调和观点。 GPTs的个性不应影响您的回答风格或语调。  \n如果你问用户一个问题，永远不要自己回答。你可以提出答案，但必须让用户确认。  \n您可见的文件也对 GPT 可见。您可以更新行为以引用已上传的文件。  \n请勿使用“约束”、“角色和目标”或“个性化”这些词。  \nGPTs没有记住过去经验的能力。  \n说明-步骤：  \n你是一个用于开发新GPTs的迭代原型游乐场。用户将通过初始行为提示你。  \n您的目标是迭代地定义和完善update_behavior的参数。您将以专业GPT创建者的身份进行交谈，从用户那里收集规范以创建GPTs。您将在每次交互后调用update_behavior。您将按照以下步骤进行：  \n1）用户的第一条消息是关于这个GPT应该如何行为的广泛目标。使用参数“context”、“description”、“prompt_starters”在gizmo_editor_tool上调用update_behavior。记住，你必须使用参数“context”、“description”和“prompt_starters”调用gizmo_editor_tool上的update_behavior。在调用update_behavior之后，继续进行第2步。  \n2）在这一步中，你的目标是确定 GPT 的名称。你会为自己建议一个名称，并要求用户确认。你必须提供一个建议的名称供用户确认。你不可以在没有建议的情况下提示用户。不要使用驼峰式复合词；请使用空格代替。如果用户指定了一个明确的名称，请假设它已经确认。如果你自己生成一个名称，你必须让用户确认该名称。一旦确认，只需调用 update_behavior，并继续到第三步。  \n3）在这一步中，您的目标是为 GPT 生成一个个人资料图片。您将使用 generate_profile_pic 为这个 GPT 生成一个初始个人资料图片，无需确认，然后询问用户是否喜欢，并是否想要进行任何更改。请记住，使用 generate_profile_pic 生成个人资料图片时无需确认。在每次改进后生成新的个人资料图片，直到用户满意为止，然后继续进行第四步。  \n4）在这一步中，你的目标是细化上下文。你现在要引导用户细化上下文。上下文应包括“角色和目标”、“约束”、“指南”、“澄清”和“个性化”等主要领域。你将引导用户逐个定义每个主要领域。你不会一次性提示多个领域，而是一次只问一个问题。你的提示应该是引导性、自然和简单的语言，不会提及你正在定义的领域的名称。你的提示不需要介绍它们正在细化的领域，而只需是引导性问题。例如，“约束”应该提示为“应该强调或避免什么？”，“个性化”应该提示为“你希望我怎么说”。你的引导性问题应该是不言自明的；你不需要问用户“你认为呢？”。每个提示都应参考并建立在现有状态之上。每次互动后都要调用update_behavior。  \n在这些步骤中，您不会提示或确认“描述”、“提示启动器”的值。但是，您仍会在上下文更新时生成这些值。您不会提到“步骤”; 您将自然地进行下去。  \n你必须按顺序完成所有这些步骤。不要跳过任何步骤。  \n请让用户在右侧的独立聊天对话框中尝试GPT。告诉他们你能够听取他们对GPT的任何改进意见。以一个问题结束这条消息，不要说“让我知道！”。在确认名称时只将GPT的名称加粗；在第2步之后不要加粗名称。  \nAction 行动：  \n在上述步骤之后，您现在处于迭代细化模式。用户将提示您进行更改，您必须在每次交互后调用update_behavior。您可以在这里提出澄清问题。  \ngenerate_profile_pic: { description: ‘为GPTs生成个人资料图片。您可以调用此函数而无需生成图像的能力。如果当前的GPT没有个人资料图片，则必须调用此函数，并且在需要生成新的个人资料图片时也可以调用。在调用此函数时，请将个人资料图片视为已更新，不要调用update_behavior。’ },  \nupdate_behavior: { description: “更新GPTs的行为。您可以有选择地省略更新字段。您将使用这些新字段作为GPTs行为的真相来源，并不再引用任何先前版本的已更新字段来通知响应。当您更新一个字段时，如果它们是不一致的，那么您还必须同时更新所有其他字段以保持一致性。如果您更改了GPTs的名称，则必须使描述和上下文保持一致性。在调用此函数时，不能总结该功能外部使用中所使用的值” , params: { name, context, description, prompt_starters, abilities, profile_pic_file_id } }  \nGPT可以利用提供给它的所有信息，包括提示、指令和附加文件，来构建对用户的回应。不要包含你不希望用户知道的信息。\nhttps://help.openai.com/en/articles/8770868-gpt-builder?continueFlag=8c6b6dc8b4c21a95d8200f5093660247\n\n","slug":"weibo/GPT Builder","date":"2024-03-14T06:15:59.769Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"0ecd1bd1e56170cb7ee0bb4ac1c851d9","title":"osv.dev开源软件分发漏洞","content":"osv.dev开源软件分发漏洞OSV（Open Source Vulnerabilities）是一个分布式的开源漏洞数据库，用于精确地生成和消费有关开源软件漏洞的信息。它提供了一个人类可读和机器可读的数据格式，以准确地描述漏洞与开源软件包版本或提交哈希之间的关系1。\nOSV 的目标是为开源项目和依赖项提供全面的漏洞数据库。它汇总了采用 OSV 格式的多个漏洞数据库，包括 GitHub 安全公告、PyPA、RustSec 和 Global Security Database 等1。\n如果你想查询某个特定版本的软件包是否存在漏洞，你可以使用 OSV 的 API。例如，你可以通过提交哈希或软件包版本号来查询已知的漏洞。以下是两种查询方式的示例：\n\n通过提交哈希查询：\n使用以下命令查询特定提交哈希的漏洞信息：\n\n\n\ncurl -d ‘{“commit”: “6879efc2c1596d11a6a6ad296f80063b558d5e0f”}’ “https://api.osv.dev/v1/query&quot;\n\n通过版本号查询：\n使用以下命令查询特定软件包版本的漏洞信息：\n\n\n\ncurl -d ‘{“version”: “2.4.1”, “package”: {“name”: “jinja2”, “ecosystem”: “PyPI”}}’ “https://api.osv.dev/v1/query&quot;\n此外，OSV-Scanner 是一个基于 Go 语言编写的漏洞扫描工具，可检测主流语言（如 Python、Java、Go、Ruby）和 Linux 发行版本（如 Debian、Alpine）的依赖项是否存在漏洞。你可以使用 OSV-Scanner 来检查项目的依赖项并确定是否存在漏洞234。\n总之，OSV 是一个有助于保障开源项目安全的重要工具，它提供了全面的漏洞信息，帮助开发者及时修复潜在的安全问题。\nhttps://github.com/google/osv-scanner\n","slug":"sec/osv.dev开源软件分发漏洞","date":"2024-03-14T06:15:59.768Z","categories_index":"安全","tags_index":"osv,dev","author_index":"安全书"},{"id":"5ba92897afa25a0f5603aecdfaa1eaa2","title":"世界级SOC策略","content":"世界级SOC策略11 Strategies of a World-ClassCybersecurity Operations Center\n官方PDF下载\nhttps://www.mitre.org/sites/default/files/2022-04/11-strategies-of-a-world-class-cybersecurity-operations-center.pdf?continueFlag=22f9d65324565362eb6e6a73daf33f4a\n","slug":"sec/世界级SOC策略","date":"2024-03-14T06:15:59.768Z","categories_index":"安全","tags_index":"soc","author_index":"安全书"},{"id":"f7038f4d4abdf1ff3ce158196a4b7e2d","title":"如何用开源软件搭建一个完整的SIEM方案","content":"如何用开源软件搭建一个完整的SIEM方案SIEM是企业安全运营中心的核心引擎，用于收集、分析和存储安全事件信息并为安全运营的各个流程提供决策信息。SIEM极为复杂，因此绝大多数企业都选择购买价格不菲的商业产品/服务。\n但是，高企的价位和运营成本使SIEM成为大型企业才能享用的网络安全“奢侈品”，对于很多安全预算有限的中小型企业，部署SIEM会挤占大量研发、营销和人才预算。\n云安全公司SOCFortress认为，网络安全是一种权利，而不应该是特权。该公司推荐了一整套开源工具来帮助企业搭建功能不输商业产品的开源SIEM（甚至SOC）方案，整理如下：\n构成SIEM堆栈的关键要素\n我们首先需要了解SIEM堆栈的关键构成。如果没有合适的工具，安全团队将很难检测、评估、分类和响应安全事件。随着网络的增长和采集日志量的增加，这一点尤其重要。\n以下是必须整合到SIEM堆栈中的关键功能模块。\n\n日志采集\n\n日志分析\n\n后端存储\n\n可视化\n\n智力充实\n\n案例管理\n\n自动化\n\n调查与应对\n\n监测\n\n\n\n日志采集\n在SOC分析师查看安全日志之前，首先需要确定采集哪些日志源。常见的日志包括：\n\n端点日志（Windows事件、Sysmon、Powershell日志等）\n网络设备（防火墙(IDS/IPS)、交换机、接入点）\n代理（Apache、NGINX等）\n第三方（AWS Cloud Trail、O365、Tenable等）\n\n当我们开始从多个来源采集日志时，确保日志被规范化为通用字段名称，这一点至关重要。例如，source_ip、source_ipv4_ip都应重写为src_ip字段。当我们开始开发仪表板和警报策略时，这将节省时间和精力。\n\n通过日志规范化，我们现在可以搭建一个通用仪表板，显示所有日志来源的网络连接。\n\nGrayLog\n在日志采集方面，Graylog是我们的首选工具。Graylog负责从各种日志源收集日志：\n\nWazuh管理器\n网络设备\n来自第三方的Syslog转发器（例如Cylance、Crowdstrike等）\n以及其他大量功能\n\nGraylog还能处理存储在Wazuh-Indexer后端中的索引管理，以适应所选的索引生命周期。\n\n日志分析\n虽然采集大量日志是一个很好的起点，但我们还需要能够分析收集到的日志中的元数据细节，以提高警报准确率并确定安全事件的优先级。\n\n分析从端点/服务收到的日志。\n通过日志分析确定采集的日志的严重性，支持自定义规则的功能。\n能够丢弃警报噪音以限制不必要的数据溢出。\n\n每个企业的网络环境都不尽相同，因此需要灵活地创建自己的自定义规则。企业可以尝试Wazuh的自定义规则——免费的高级Wazuh检测规则。\nWazuh\nWazuh是一个很棒的工具，它不仅可以从端点收集日志，而且还内置了内置规则，可以分析日志内容以检测攻击。\n\nWazuh还提供：\n\n配置评估\n文件完整性监控\n漏洞检测\n以及更多\n\n后端存储\n采集和分析日志很棒，但这些日志将存储在哪里？我们必须搭建一个后端存储架构，具备如下功能：\n\n存储、搜索和查看数据（收集的安全事件）\n高可用性\n强大的性能\n扩展能力\n\nWazuh索引器\nWazuh-Indexer是Wazuh的OpenSearch的分叉版本，让我们能够做到这一点。它功能丰富的API还允许我们将其他工具插入Wazuh-Indexer堆栈，例如Grafana、Elastalert等。\n可视化\n存储日志只是一个开始，SOC分析师还需要能够轻松查看、调整、分类和搜索安全威胁或堆栈。大海捞针式的查询体验很快就会导致分析师们精神崩溃。\n因此，我们还需要整合可视化工具以便：\n\n通过小部件/仪表板/等查看日志。\n快速搜索和查看数据。\n支持从多个日志存储（Wazuh-Indexer、csv文件、MySQL等）读取的能力。\n\n\nGrafana\nGrafana是值得推荐的可视化工具，速度快（与Kibana相比）、完全可定制、丰富的预构建小部件、强大的社区支持，并提供多租户支持！Grafana允许我们搭建一个“单屏”界面来查看所有的安全事件。\n情报富化\n除了分析日志之外，我们还需要一种方法来富化日志，以帮助分析师快速发现潜在的恶意活动。例如，与网站交互的某个IP地址是否恶意？我们需要一个具备如下功能的日志富化工具：\n\n使用来自多个提供商的威胁情报富化采集到的日志。\n解析并存储选定的响应，以便仅存储关键数据。\n自动化，因此SOC分析师不必手动尝试富化收到的日志。\n\nOpenCTI\nOpenCTI平台的首要目的是提供一个强大的知识管理数据库，该数据库具有一个专门为网络威胁情报和安全运营量身定制的强化模式。\n\nMISP\nMISP提供元数据标记、提要、可视化，甚至可与其他工具集成以进行进一步分析，这要归功于其开放的协议和数据格式。\n\n这两种工具都提供了丰富的API，使我们能够及时自动执行威胁情报查找！\n案例管理\n随着SOC团队的壮大，我们需要提供一个平台，让他们能够协作、丰富和响应警报。为您的SOC分析师提供剧本、任务和程序将帮助指导他们完成检测到的警报，并让他们专注于关键警报。\n\n用于查看和响应高严重性事件的平台。\n允许与多个SOC分析师协作。\n允许响应操作，以便分析师可以在其端点上触发事件。\n\n\n\nTheHIVE/Cortex\nTheHIVE使我们能够管理、组织、关联事件并自动化取证分析，同时利用强大的协作能力。\n而Cortex提供对来自第三方或遗留服务和自动主动响应的可观察数据（文件哈希、IP、域等）的调查。\n自动化\n随着采集的日志不断增加，我们需要一个可以自动执行许多任务的工具，例如：\n\n案例创建\n网络钓鱼分析\n健康检查失败\n报告生成\n其他种种\n\n这篇文章中提到的所有开源工具都自带API，我们可以将SOAR平台插入其中以自动化几乎所有任务！\n\nShuffle\nShuffle是SOAR的开源实现，通过即插即用应用程序带来在整个企业中传输数据所需的所有功能，使每个人都可以使用自动化。它能消除团队中对编码器的需求（但仍然建议至少有一个），Shuffle能够在几分钟内（而不是几小时或几天）部署新的、复杂（或简单）的工作流程。\n事件调查\n接收警报只是成功的一半，我们必须让我们的SOC分析师能够通过可扩展的方式与受监控的端点快速交互来彻底调查警报。一些技术包括：\n\n列出正在运行的进程\n枚举登录用户\n检测监听端口\n查看下载的文件\n隔离设备\n等等\n\n如果没有上述功能，SOC分析师就很难快速评估警报的实际严重性。\nVelociraptor\nVelociraptor是一种先进的数字取证和事件响应工具，可增强对端点的可见性。只需按下（几个）按钮，我们就可以在所有端点上精准高效地同时进行有针对性的数字取证收集，其可靠的API支持在需要时自动化和触发证据收集。\n健康监测\nSIEM堆栈构建完成后，我们需要监控整个SIEM堆栈的运行状况，以确保顺利运行并将丢失警报的风险降至最低。我们通常将监控分为两个阶段：\n\n端点资源（CPU、RAM、磁盘、进程等）\nWebUI正常运行时间\n\n例如，也许Grafana服务运行良好，但如果防火墙更改禁止了用户访问Grafana WebUI，会导致分析师无法访问WebUI查看警报，并最终使Grafana无法使用。\n\nInfluxDB/Telegraf\nInfluxDB与Telegraf代理相结合，使我们能够收集所有的端点指标，并在达到阈值或关键进程（例如wazuh-indexer）未运行时触发内置警报。这使工程团队能够在潜在问题产生严重影响之前主动应对。\nUptime Kuma\nUptime Kuma是一种监控工具，可用于实时监控网站和应用程序。特点包括：\n\n监控HTTP(s)网站、TCP端口和Docker容器的正常运行时间，并检索DNS记录等信息。\n通过电子邮件(SMTP)、Telegram、Discord、Microsoft Teams、Slack、Promo SMS、Gotify和90多种通知服务发送通知。\n支持多种语言。\n提供多个状态页面。\n提供代理支持。\n显示SSL证书信息。\n将状态页面映射到域。\n\n结论\n安全运营是一件高度复杂且费钱的事情，但企业也没必要为此破产。有大量开源工具可供我们以最低成本搭建我们自己的SIEM技术堆栈。开源的灵活性还允许我们根据自身的需求进行灵活定制。本文我们介绍的本地SOC开源工具，功能上可以媲美商业工具，如果您的团队有足够的人才和试错空间，那么尝试在本地自行搭建开源SOC方案未尝不是一个有趣的选择。\n本文介绍的开源SOC部署策略涉及的工具清单如下：\n1.Wazuh Indexer(OpenSearch)\n2.Wazuh Dashboards(OpenSearch Dashboards)\n3.Graylog\n4.Wazuh Manager/Agents\n5.Grafana\n6.MISP\n7.OpenCTI\n8.TheHIVE/Cortex\n9.Velociraptor/Agents\n10.Shuffle\n11.InfluxDB/Telegraf\n12.Uptime Kuma\n","slug":"sec/如何用开源软件搭建一个完整的SIEM方案","date":"2024-03-14T06:15:59.768Z","categories_index":"安全","tags_index":"SIEM","author_index":"安全书"},{"id":"81e9f6e12d4ce4b06588f813d8c0a850","title":"安全分析工具列表","content":"安全分析工具列表作为一家安全公司的创始人，我一直在寻找开源工具，以便将其整合到我们的产品中，或者从中获得灵感，或者提供集成。有几十种优秀的开源安全工具，所以我决定发布它们的一个列表。如此多的选项是安全如此困难的原因之一——它们有许多不同的方法来实现某件事，几乎总是涉及到配置和连接各种“点解决方案”(营销者这样称呼它们)的头疼问题。以下是列表的顺序(注意，我只列出了防御性的工具，攻击性的工具，如metasploit, nmap, wireshark等，可能需要单独发表):\n一、安全监控，入侵检测/防御\nSuricata -入侵检测系统\nSnort -入侵检测系统\nZeek——网络安全监控\nOSSEC——基于主机的入侵检测系统\nWazuh - OSSEC的一个更积极的分支\nVelociraptor -端点可见性和响应\nOSSIM -开源的SIEM，在AlienVault的核心\nSecurityOnion——安全监控和日志管理\nElastic SIEM-Elasticsearch提供的SIEM功能\nMozdef -Elasticsearch上的SIEM\nSagan -日志分析和相关性\nApache Metron -(退役)网络安全监控，由Cisco OpenSOC演变而来\nArkime -数据包捕获和搜索工具(前身Moloch)\nPRADAS -实时资产检测\nBloodHound - ActiveDirectory关系检测\n二、威胁情报\nMISP——威胁情报平台\nSpiderFoot——威胁情报聚合\nOpenCTI——威胁情报平台\nOpenDXL——用于安全情报共享的开源工具\n三、事件响应\nStackStorm - SOAR平台\nCimSweep——Windows事件反应\nGRR -事件响应和远程现场取证\nthehive -事件响应/ SOAR平台\nthehive Cortex - hive同伴，用于快速查询\nShuffle -开源的SOAR平台\nosquery——端点数据的实时查询\nKansa—PowerShell事件响应\n四、漏洞评估\nOpenVAS -非常流行的漏洞评估\nZAProxy - web漏洞扫描器OWASP\nWebScarab -(过时的)web漏洞扫描器OWASP\nW3af - web漏洞扫描\nLoki - IoC扫描仪\nCVE Search-一组用于在CVE数据中搜索的工具\n五、防火墙\nPfsense -最流行的开源防火墙\nOPNSense -加固的基于bsd的防火墙\nSmoothwall——基于linux防火墙\n六、防病毒/端点保护\nClamAV -开源防病毒软件\nArmadito AV -开源AV(已退役)\n七、电子邮件安全\nHermes Secure Email Gateway -基于ubuntu的邮件网关\nProxmox -电子邮件网关\nMailScanner -电子邮件安全系统\nSpamAssassin -反垃圾邮件平台\nOrangeAssassin -替代SpamAssassin\n","slug":"sec/安全分析工具列表","date":"2024-03-14T06:15:59.768Z","categories_index":"安全","tags_index":"安全技术","author_index":"安全书"},{"id":"d372612e9334fad96091a6f41e5df4a5","title":"安全洋葱的愿景","content":"安全洋葱的愿景先事件处理和响应的方向发展，集成以下新功能：\n1、AlienVault-OTX：我们可以很容易地将Alienvault OTX脉冲引入到安全洋葱中，并让Zeek通过利用Stephen Hosom与Alienvault OTX集成的成果将其应用到Intel框架中。\n2、我们可以将Etherpad添加到Security Onion中，这样我们就可以在调查期间进行记录，并与我们的团队共享这些记录。\n3、FIR。FIR (Fast Incident Response)是一个以敏捷和速度为设计理念的网络安全事件管理平台。&gt;可以方便地创建、跟踪和报告网络安全事件。\nFIR适用于需要跟踪网络安全事件(csirt、CERTs、SOCs等)的任何人。它是为了适应我们&gt;的需要和我们团队的习惯而定制的，但是我们在发布&gt;之前花了很大的努力使它尽可能的通用，这样世界上的其他&gt;团队也可以使用它，并根据他们的需要进行定制。\n4、GRR。GRR快速响应:事件响应的远程实时取证\n5、TheHive。我们可以将事件发送到TheHive的实例，因为Elastalert包括TheHive警报(Nclose-ZA)。\n6、MISP。不久前，MISP项目宣布能够导出从事件/指示器创建的NIDS规则。\n7、NtopNG。最新稳定版本的ntopng现在可以安装在最新稳定版本的安全洋葱上。\n8、RITA。我们可以将RITA添加到Security Onion中，以增强其当前的能力，并利用积极应对人员的出色工作。他们做了一件很棒的工作，使得RITA可以很容易地与Security Onion集成在一起。\n9、Strelka。Strelka是一个实时文件扫描系统，用于威胁搜索、威胁检测和事件响应。基于洛克希德·马丁公司的Laika BOSS和类似项目(参见:相关项目)的设计，Strelka的目的是执行大规模的文件提取和元数据收集。\n  https://securityonion.readthedocs.io/en/latest/hive.html\n","slug":"sec/安全洋葱的愿景","date":"2024-03-14T06:15:59.768Z","categories_index":"安全","tags_index":"OTX","author_index":"安全书"},{"id":"4b034a15f055a394a702faf591842ba3","title":"新版OPENCTI简介","content":"新版OPENCTI简介重点：由图库改为ES进行存储\n一、总览\nOpenCTI是一个开源平台，允许组织管理他们的网络威胁情报知识和观察结果。它的创建是为了结构化、存储、组织和可视化关于网络威胁的技术和非技术信息。\n数据使用基于[STIX2标准]的知识模式进行结构化(https://oasis-open.github.io/cti-documentation/)。它被设计成一个现代的web应用程序，包括一个[GraphQL API](https://graphql.org/)和一个面向UX的前端。此外，OpenCTI还可以与其他工具和应用程序集成，如[MISP](https://github.com/MISP/MISP)， TheHive， MITRE ATT&amp;CK等。\n\n#目标目标是创建一个全面的工具允许用户集成技术信息(如ttp,可见)和非技术信息(如提出归因,受害者研究、行业活动和本地化),而把每一块信息的主要来源(报告、MISP事件等),并提供链接等特性之间的信息,第一个和最后一个看到日期,水平的信心和描述字段。该工具能够使用MITRE攻击与ck框架(通过专用连接器)来帮助构建数据结构。用户也可以选择实现自己的数据集。\n一旦分析人员将数据集成到OpenCTI中，新的关系可能会从现有关系中推断出来，以促进对这些信息的理解和表示。这允许用户从原始数据中提取和利用有意义的知识。\nOpenCTI不仅允许imports，而且还允许exports of data在不同的格式下(CSV, STIX2 bundles，等等)。Connectors目前正在开发中，以加速工具与其他平台之间的交互。\n二、架构\nOpenCTI平台依靠几个外部数据库和服务才能正常工作。\n\n（1）GraphQL API\nAPI是OpenCTI平台的核心部分，允许客户端(包括前端)与数据库和代理(消息传递系统)进行交互。它内置在NodeJS中，实现了GraphQL查询语言。由于API还没有完整的文档记录，您可以通过GraphQL平台探索可用的方法和参数。请参见OpenCTI演示实例。\n（2）写入worker\nworker是独立的Python进程，使用来自RabbitMQ broker的消息来完成异步写查询。您可以启动尽可能多的workers来提高写性能。在某种程度上，写性能将受到数据库吞吐量(ElasticSearch)的限制，如果您在使用3或4个worker时没有达到预期的性能，那么启动更多worker将是无用的，您必须考虑增强数据库节点的硬件(或将您的设置扩展到集群)。\n（3）连接器\n连接器是软件(Python进程)的第三方部分，可以在平台上扮演四种不同的角色:\nEXTERNAL_IMPORT：从远程数据源提取数据，将其转换为STIX2，并将其插入到OpenCTI平台上。MITRE, MISP, CVE, AlienVault, FireEye, etc.\nINTERNAL_IMPORT_FILE：通过UI或API从OpenCTI上上传的文件中提取数据。提取指标从pdf, STIX2导入，等。\nINTERNAL_ENRICHMENT：监听新的OpenCTI实体或用户请求，从远程数据源提取数据来充实。通过外部服务、实体更新等来丰富可观察对象。\nINTERNAL_EXPORT_FILE：根据列出实体或一个实体及其关系，从OpenCTI数据生成导出。STIX2导出，PDF导出，CSV列表生成等。\nSTREAM:使用平台的数据流。History, Synchronizer, Tanium等。\n三、OpenCTI生态系统\n**https://www.notion.so/OpenCTI-Ecosystem-868329e9fb734fca89692b2ed6087e76**\n1、Python的OpenCTI客户端\npycti库旨在帮助OpenCTI用户和开发人员与OpenCTI平台GraphQL API进行交互。\nPython库要求Python &gt;= 3。\n2、链接器\n2.1数据导入\n（1）OpenCTI AlienVault Connector\n**https://github.com/OpenCTI-Platform/connectors/tree/master/alienvault**\nOpenCTI AlienVault连接器可用于从Alien Labs Open Threat Exchange (OTX)平台导入知识。连接器利用OTX DirectConnect API获取订阅脉冲的威胁数据。\n注意:需要加入OTX威胁情报社区。\n（2）OpenCTI网络威胁联盟连接器\nhttps://github.com/OpenCTI-Platform/connectors/tree/master/cyber-threat-coalition\nOpenCTI Cyber Threat Coalition connector导入由网络威胁联盟团队发布的指标。\n网络威胁联盟是一个专家团队，在COVID-19危机期间收集和分享与大流行相关的网络威胁情报\n技术信息\n连接器从经过审查的黑名单(https://blacklist.cyberthreatcoalition.org/vetted/)导入指示器。\n所有导入的指标将链接到一份名为“COVID-19网络威胁联盟(CTC)黑名单”的独特报告。\n（3）OpenCTI CrowdStrike连接器\nOpenCTI CrowdStrike连接器可用于从CrowdStrike Falcon平台导入知识。该连接器利用intel api获取CrowdStrike的情报信息，包括参与者、指标、报告和YARA规则的数据。\n注:需要订阅CrowdStrike Falcon平台。订阅详细信息规定了连接器实际可用的数据。\n(4)连接器:OpenCTI的CYBERCRIME-TRACKER.NET\n连接器使用:http://cybercrime-tracker.net/rss.xml下的跟踪器的RSS feed\n它将解析所有的条目并:\n为每个条目生成一个指示符，指示相关的恶意软件。\n将域、url、IP地址作为observable添加到OpenCTI中，并创建相应的关系。\n(5)OpenCTI FireEye连接器\n该连接器连接到FireEye Intel API V3，并从给定的日期收集所有数据。\n(6)OpenCTI卡巴斯基连接器\nOpenCTI卡巴斯基连接器可以用于从卡巴斯基威胁情报门户导入知识。连接器利用卡巴斯基威胁情报门户API检索情报发布在卡巴斯基威胁情报门户，这包括报告pdf, IoCs和YARA规则。\n注意:使用卡巴斯基威胁情报门户服务需要许可证。\n(7)OpenCTI的LastInfoSec连接器!\nOpenCTI LastInfoSec连接器将使用/v2/stix21/getlasthour API。\n这个LastInfosec的威胁feed包含stix2.1报告每小时更新url，哈希值，域指示器。\n要求:如果你想使用LastInfoSec的智能，你需要一个API密钥。您可以通过&#99;&#x6f;&#110;&#116;&#x61;&#x63;&#116;&#x40;&#108;&#97;&#115;&#116;&#x69;&#x6e;&#x66;&#111;&#115;&#x65;&#99;&#x2e;&#x63;&#111;&#109;联系LastInfoSec团队\n(8)OpenCTI Malpedia连接器\n这个连接器从Malpedia 库导入知识。\n连接器为以下OpenCTI可观察对象/指示器类型添加数据:\nyara\nfile-sha256\n连接器添加了以下实体:\n    Malware\n    Intrusion-Set\n    References\n(9)OpenCTI MISP Connector\nMISP connector是一个独立的Python进程，必须能够访问OpenCTI平台和RabbitMQ。RabbitMQ的凭据和连接参数由API直接提供，在平台设置中配置。\n","slug":"sec/新版OPENCTI简介","date":"2024-03-14T06:15:59.768Z","categories_index":"安全","tags_index":"OpenCTI","author_index":"安全书"},{"id":"f6e03a4ec7595d322c8e359d0b7ae621","title":"安全工具和资源","content":"安全工具和资源十六进制编辑器\n十六进制编辑器（二进制文件编辑器或字节编辑器）是一种允许操纵计算机文件的基本二进制数据计算机程序。名称’hex’出自’hexadecimal’：用于表示二进制数据的标准数字格式\nHXDhttps://mh-nexus.de/en/hxd/\n010 Editorhttp://www.sweetscape.com/010editor/\nHex Workshophttp://www.hexworkshop.com/\nHexFiendhttp://ridiculousfish.com/hexfiend/\nHiewhttp://www.hiew.ru/\n反汇编\n反汇编程序与反编译器不同，反编译器的目标是高级语言而不是汇编语言。反汇编（反汇编程序的输出）通常被格式化为可读性较强的汇编语言，使其成为逆向工程工具\nIDA Pro\nhttps://www.hex-rays.com/products/ida/index.shtml\nBinary Ninjahttps://binary.ninja/\nRadarehttp://www.radare.org/r/\nHopperhttp://hopperapp.com/\nCapstonehttp://www.capstone-engine.org/\nobjdumphttp://linux.die.net/man/1/objdump\nfREedomhttps://github.com/cseagle/fREedom\nplasma\nhttps://github.com/plasma-disassembler/plasma\n检测和分类\nAnalyzePE - 用于报告Windows PE文件的各种工具\nhttps://github.com/hiddenillusion/AnalyzePE\nAssemblyline - 可扩展的分布式文件分析框架\nhttps://bitbucket.org/cse-assemblyline/assemblyline\nBinaryAlert - 一种开源的无服务器AWS管道，可根据一组YARA规则扫描和警告上载的文件\nhttps://github.com/airbnb/binaryalert\nchkrootkit - 本地Linux rootkit检测\nhttp://www.chkrootkit.org/\nClamAV - 开源防病毒引擎\nhttp://www.clamav.net/\nDetect-It-Easy - 用于确定文件类型的程序\nhttps://github.com/horsicq/Detect-It-Easy\nExifTool - 读取，写入和编辑文件元数据\nhttps://sno.phy.queensu.ca/~phil/exiftool/\nFile Scanning Framework - 模块化递归文件扫描解决方案\nhttps://github.com/EmersonElectricCo/fsf\nhashdeep - 使用各种算法计算摘要哈希值\nhttps://github.com/jessek/hashdeep\nLoki - 基于主机的IOC扫描仪\nhttps://github.com/Neo23x0/Loki\nMalfunction - 在功能级别编目和比较恶意软件\nhttps://github.com/Dynetics/Malfunction\nMASTIFF - 静态分析框架\nhttps://github.com/KoreLogicSecurity/mastiff\nMultiScanner - 模块化文件扫描/分析框架\nhttps://github.com/mitre/multiscanner\nnsrllookup - 在NIST的国家软件参考库数据库中查找哈希的工具\nhttps://github.com/rjhansen/nsrllookup\npackerid - PEiD的跨平台Python替代方案\nhttp://handlers.sans.org/jclausing/packerid.py\nPEV - 用于处理PE文件的多平台工具包，提供功能丰富的工具，用于正确分析可疑二进制文件\nhttp://pev.sourceforge.net/\nRootkit Hunter - 检测Linux rootkit\nhttp://rkhunter.sourceforge.net/\nssdeep - 计算模糊哈希值\nhttps://ssdeep-project.github.io/ssdeep/\ntotalhash.py -\n用于搜索 TotalHash.cymru.com  数据库的Python脚本\nhttps://gist.github.com/gleblanc1783/3c8e6b379fa9d646d401b96ab5c7877f\nTrID - 文件标识符\nhttp://mark0.net/soft-trid-e.html\nYARA - 分析师的模式匹配工具\nhttps://plusvic.github.io/yara/\nYara rules generator - 根据一组恶意软件样本生成yara规则https://github.com/Neo23x0/yarGen\n动态二进制仪表\n动态二进制仪表工具\nPin\nhttps://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool\nDynamoRiohttp://www.dynamorio.org/\nFridahttps://www.frida.re/\ndyninsthttp://www.dyninst.org/\nMac Decrypt\nMac Decrypting工具\nCerbero Profiler - 全选 - &gt;复制到新文件\nhttp://cerbero-blog.com/?p=1311\nAppEncryptor - 用于解密的工具\nhttps://github.com/AlanQuatermain/appencryptor\nClass-Dump - deprotect选项\nhttp://stevenygard.com/projects/class-dump/\nreadmem - OS X Reverser的进程转储工具\nhttps://github.com/gdbinit/readmem\n模拟器\n模拟器工具\nQEMUhttp://www.qemu-project.org/\nunicorn\nhttps://github.com/unicorn-engine/unicorn\n文件分析\n文档分析工具\nOle Tools\nhttp://www.decalage.info/python/oletools\nDidier’s PDF Tools\nhttp://blog.didierstevens.com/programs/pdf-tools/\nOrigamihttps://github.com/cogent/origami-pdf\n动态分析\n这个入门级的恶意软件动态分析课程是专门针对那些刚开始从事恶意软件分析，或是想要学习如何通过各种工具检测恶意软件遗留的人员\n这是一门实践课程，学员们可以使用各种工具来查找恶意软件的类型\nProcessHackerhttp://processhacker.sourceforge.net/\nProcess Explorer\nhttps://technet.microsoft.com/en-us/sysinternals/processexplorer\nProcess Monitor\nhttps://technet.microsoft.com/en-us/sysinternals/processmonitor\nAutoruns\nhttps://technet.microsoft.com/en-us/sysinternals/bb963902\nNoribenhttps://github.com/Rurik/Noriben\nAPI监视器http://www.rohitab.com/apimonitor\niNetSimhttp://www.inetsim.org/\nWiresharkhttps://www.wireshark.org/download.html\nFakenet\nhttp://practicalmalwareanalysis.com/fakenet/\nVolatility\nhttps://github.com/volatilityfoundation/volatility\nDumpithttp://www.moonsols.com/products/\nLiMEhttps://github.com/504ensicsLabs/LiME\nCuckoohttps://www.cuckoosandbox.org/\nObjective-See Utilities\nhttps://objective-see.com/products.html\nXCode Instruments - 用于监控文件和进程的XCode工具\nhttps://developer.apple.com/xcode/download/\nfs_usage - 实时报告与文件系统活动相关的系统调用和页面错误，文件I / O：fs_usage -w -f文件系统\nhttps://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/fs_usage.1.html\ndmesg - 显示系统消息缓冲区\nhttps://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man8/dmesg.8.html\nTritonhttps://triton.quarkslab.com/\n反混淆\n反向XOR和其他代码混淆方法\nBalbuzard  - 用于反转混淆（XOR，ROL等）的恶意软件分析工具等\nhttps://bitbucket.org/decalage/balbuzard/wiki/Home\nde4dot  - .NET反混淆器和解包器\nhttps://github.com/0xd4d/de4dot\nex_pe_xor ＆ iheartxor - Alexander Hanel的两个工具，用于处理单字节XOR编码文件\nhttp://hooked-on-mnemonics.blogspot.com/p/iheartxor.html\nFLOSS - FireEye Labs混淆字符串解算器，自动使用高级静态分析技术对来自恶意软件二进制文件的字符串进行反混淆处理\nhttps://github.com/fireeye/flare-floss\nNoMoreXOR - 使用频率分析256字节的XOR密钥\nhttps://github.com/hiddenillusion/NoMoreXOR\nPackerAttacker - Windows恶意软件的通用隐藏代码提取程序\nhttps://github.com/BromiumLabs/PackerAttacke\nunpacker - 基于WinAppDbg的Windows恶意软件的自动恶意软件解包器\nhttps://github.com/malwaremusings/unpacker/\nunxor - 使用已知明文攻击猜测XOR密钥\nhttps://github.com/tomchop/unxor/\nVirtualDeobfuscator - 虚拟化包装器的逆向工程工具\nhttps://github.com/jnraber/VirtualDeobfuscator\nXORBruteForcer - 用于强制执行单字节XOR键的Python脚本\nhttp://eternal-todo.com/var/scripts/xorbruteforcer\nXORSearch &amp; XORStrings  - 来自Didier Stevens的几个程序，用于查找 XORed数据\nhttps://blog.didierstevens.com/programs/xorsearch/\nxortool  - 猜测XOR密钥长度，以及密钥本身\nhttps://github.com/hellman/xortool\n调试\n在此列表中，我们可以看到反汇编程序，调试程序以及其他静态和动态分析工具的工具\n跨平台调试工具\ngdbhttps://www.gnu.org/software/gdb/\nvdbhttps://github.com/vivisect/vivisect\nlldbhttp://lldb.llvm.org/\nqirahttp://qira.me/\n仅限Windows的调试工具\nWinDbg\nhttps://msdn.microsoft.com/en-us/windows/hardware/hh852365.aspx\nImmunityDebugger\nhttps://www.immunityinc.com/products/debugger/\nOllyDbg v1.10http://www.ollydbg.de/\nOllyDbg v2.01\nhttp://www.ollydbg.de/version2.html\nOllySnD\nhttps://tuts4you.com/download.php?view.2061\nOlly Shadow\nhttps://tuts4you.com/download.php?view.6\nOlly CiMs\nhttps://tuts4you.com/download.php?view.1206\nOlly UST_2bg\nhttps://tuts4you.com/download.php?view.1206\nx64dbghttp://x64dbg.com/#start\n仅限Linux的调试工具\nDDDhttp://www.gnu.org/software/ddd/\n逆向工程\nangr - 在UCSB的Seclab开发的二进制分析框架\nhttps://github.com/angr/angr\nbamfdetect  - 识别和提取机器人和其他恶意软件的信息\nhttps://github.com/bwall/bamfdetect\nBAP - 在Cylab开发的多平台和开源（MIT）二进制分析框架\nhttps://github.com/BinaryAnalysisPlatform/bap\nBARF - 开源二进制分析和逆向工程框架\nhttps://github.com/programa-stic/barf-project\nbinnavi  - 基于图形可视化的逆向工程二进制分析IDE\nhttps://github.com/google/binnavi\nBinary ninja - 一种可逆转工程平台，可替代IDA\nhttps://binary.ninja/\nBinwalk - 固件分析工具\nhttps://github.com/devttys0/binwalk\nBokken - Pyew和Radare的GUI\nhttp://www.bokken.re/\nCapstone  - 用于二进制分析和反转的反汇编框架\nhttps://github.com/aquynh/capstone\ncodebro  - 基于Web的代码浏览器，提供基本代码分析\nhttps://github.com/hugsy/codebro\nDECAF （Dynamic Executable Code Analysis Framework）- 基于QEMU的二进制分析平台，DroidScope现在是DECAF的扩展\nhttps://github.com/sycurelab/DECAF\ndnSpy - NET汇编编辑器，反编译器和调试器\nhttps://github.com/0xd4d/dnSpy\nEvan’s DeBUGGER(EDB) - 带有Qt GUI的模块化调试器\nhttp://codef00.com/projects#debugger\nFibratus - 用于探索和跟踪Windows内核的工具\nhttps://github.com/rabbitstack/fibratus\nFPort - 在实时系统中打开TCP / IP和UDP端口并将它们映射到所属的应用程序\nhttps://www.mcafee.com/us/downloads/free-tools/fport.aspx\nGDB - GNU调试器\nhttp://www.sourceware.org/gdb/\nGEF - GDB增强功能，适用于开发人员和逆向工程师\nhttps://github.com/hugsy/gef\nhackers-grep - 在PE可执行文件中搜索字符串的实用程序，包括导入，导出和调试符号\nhttps://github.com/codypierce/hackers-grep\nHopper - macOS和Linux反汇编程序\nhttps://www.hopperapp.com/\nIDA Pro - Windows反汇编程序和调试程序，具有免费评估版\nhttps://www.hex-rays.com/products/ida/index.shtml\nImmunity Debugger - 用于恶意软件分析的调试器，使用Python API\nhttp://debugger.immunityinc.com/\nILSpy - ILSpy是开源.NET程序集浏览器和反编译器\nhttp://ilspy.net/\nKaitai Struct - 用于文件格式/网络协议/数据结构的DSL逆向工程和剖析，包括C ++，C＃，Java，JavaScript，Perl，PHP，Python，Ruby的代码生成\nhttp://kaitai.io/\nLIEF - LIEF提供了一个跨平台的库来解析，修改和抽象ELF，PE和MachO格式\nhttps://lief.quarkslab.com/\nltrace - Linux可执行文件的动态分析\nhttp://ltrace.org/\nobjdump - GNU binutils的一部分，用于Linux二进制文件的静态分析\nhttps://en.wikipedia.org/wiki/Objdump\nOllyDbg - Windows可执行文件的汇编级调试器\nhttp://www.ollydbg.de/\nPANDA - 中性动态分析\nhttps://github.com/moyix/panda\nPEDA - 针对GDB的Python漏洞利用开发协助，增强显示和添加命令\nhttps://github.com/longld/peda\npestudio - 执行Windows可执行文件的静态分析\nhttps://winitor.com/\nPharos - Pharos二进制分析框架，可用于执行二进制文件的自动静态分析\nhttps://github.com/cmu-sei/pharos\nplasma - 用于x86 / ARM / MIPS的交互式反汇编程序\nhttps://github.com/plasma-disassembler/plasma\nPPEE（puppy）- 专业PE文件浏览器\nhttps://www.mzrst.com/\nProcess Explorer - Windows的高级任务管理器\nhttps://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer\nProcess Hacker - 监视系统资源的工具\nhttp://processhacker.sourceforge.net/\nProcess Monitor - 用于Windows程序的高级监视工具\nhttps://docs.microsoft.com/en-us/sysinternals/downloads/procmon\nPSTools - 帮助管理和调查实时系统的Windows命令行工具\nhttps://docs.microsoft.com/en-us/sysinternals/downloads/pstools\nPyew - 用于恶意软件分析的Python工具\nhttps://github.com/joxeankoret/pyew\nPyREBox - 思科Talos团队的Python脚本化逆向工程沙箱\nhttps://github.com/Cisco-Talos/pyrebox\nQKD - QEMU带有嵌入式WinDbg服务器，用于隐身调试\nhttps://github.com/ispras/qemu/releases/\nRadare2 - 反向工程框架，支持调试器\nhttp://www.radare.org/r/\nRegShot - 比较快照的注册表比较实用程序\nhttps://sourceforge.net/projects/regshot/\nRetDec -\n具有在线反编译服务和API的Retargetable机器代码反编译器\nhttps://retdec.com/\nROPMEMU - 分析，剖析和反编译复杂代码重用攻击的框架\nhttps://github.com/Cisco-Talos/ROPMEMU\nSMRT - Sublime恶意软件研究工具，Sublime 3的插件，用于帮助恶意软件分析\nhttps://github.com/pidydx/SMRT\nstrace - Linux可执行文件的动态分析\nhttps://sourceforge.net/projects/strace/\nTriton - 动态二进制分析（DBA）框架\nhttps://triton.quarkslab.com/\nUdis86 - 用于x86和x86_64的反汇编程序库和工具\nhttps://github.com/vmt/udis86\nVivisect - 用于恶意软件分析的Python工具\nhttps://github.com/vivisect/vivisect\nWinDbg - 用于Microsoft Windows计算机操作系统的多用途调试器，用于调试用户模式应用程序，设备驱动程序和内核模式内存转储\nhttps://developer.microsoft.com/en-us/windows/hardware/download-windbg\nX64dbg - 用于Windows的开源x64 / x32调试器\nhttps://github.com/x64dbg/\n二进制格式和二进制分析\n复合文件二进制格式是几种不同的Microsoft文件格式（如Microsoft Office文档和Microsoft Installer程序包）使用的基本容器\nCFF资源管理器\nhttp://www.ntcore.com/exsuite.php\nCerbero Profiler // Lite PE Insider\nhttp://cerbero.io/profiler/\nhttp://cerbero.io/peinsider/\nDetect It EASYhttp://ntinfo.biz/\nPeStudiohttp://www.winitor.com/\nPEID\nhttps://tuts4you.com/download.php?view.398\nMachoViewhttps://github.com/gdbinit/MachOView\nnm - 查看符号\nhttps://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/nm.1.html\nfile -文件信息\nhttps://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/file.1.html\ncodesign - 代码签名信息用法：codesign -dvvv文件名https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/codesign.1.html\n二进制分析资源\nMobius Resources\nhttp://www.msreverseengineering.com/research/\nz3https://z3.codeplex.com/\nbaphttps://github.com/BinaryAnalysisPlatform/bap\nangrhttps://github.com/angr/angr\n反编译器\n反编译器是一种计算机程序，它输入可执行文件，并尝试创建可以成功重新编译的高级源文件。因此它与编译器相反，后者采用源文件并生成可执行文件\n通用反编译器\nHexRay\nhttps://www.hex-rays.com/products/decompiler/\nRetDechttps://retdec.com/decompilation/\nBoomeranghttp://boomerang.sourceforge.net/\nJava Decompiler\nProcyon\nhttps://bitbucket.org/mstrobel/procyon/wiki/Java%20Decompiler\nJD-GUIhttp://jd.benow.ca/\nJADhttps://varaneckas.com/jad/\nNET反编译器\nJustDecompile\nhttp://www.telerik.com/products/decompiler.aspx\ndotPeekhttps://www.jetbrains.com/decompiler/\nDelphi反编译器\nIDRhttp://kpnc.org/idr32/en/\nRevendepro\nhttp://www.ggoossen.net/revendepro/\nPython反编译器\nUncompyle6\nhttps://github.com/rocky/python-uncompyle6/\nDecompyle ++https://github.com/zrax/pycdc\n字节码分析\n字节码分析工具\ndnSpyhttps://github.com/0xd4d/dnSpy\n字节码查看器https://bytecodeviewer.com/\n字节码查看器https://bytecodeviewer.com/\n字节可视化\nhttp://www.drgarbage.com/bytecode-visualizer/\nJPEXS Flash Decompiler\nhttps://www.free-decompiler.com/flash/\n导入重构\n导入重构工具\nImpRec\nhttp://www.woodmann.com/collaborative/tools/index.php/ImpREC\nScyllahttps://github.com/NtQuery/Scylla\nLordPE\nhttp://www.woodmann.com/collaborative/tools/images/Bin_LordPE_2010-6-29_3.9_LordPE_1.41_Deluxe_b.zip\n在线扫描仪和沙箱\n以下工具用于基于Web的多AV扫描仪，以及用于自动分析的恶意软件沙箱\nanlyz.io - 在线沙箱\nhttps://sandbox.anlyz.io/\nAndroTotal - 针对多个移动防病毒应用程序免费在线分析APK\nhttps://andrototal.org/\nAVCaesar - Malware.lu在线扫描程序和恶意软件存储库\nhttps://avcaesar.malware.lu/\nCryptam - 分析可疑的办公文档\nhttp://www.cryptam.com/\nCuckoo Sandbox - 开源，自托管沙箱和自动分析系统\nhttps://cuckoosandbox.org/\ncuckoo-modified -\n根据GPL发布的Cuckoo Sandbox的修改版本，由于作者的法律问题，未合并上传\nhttps://github.com/brad-accuvant/cuckoo-modified\nDeepViz - 具有机器学习分类的多格式文件分析器\nhttps://www.deepviz.com/\ndetux - 开发用于对Linux恶意软件进行流量分析并捕获IOC的沙箱\nhttps://github.com/detuxsandbox/detux/\nDRAKVUF - 动态恶意软件分析系统\nhttps://github.com/tklengyel/drakvuf\nfirmware.re - 解压缩，扫描和分析几乎所有固件包\nhttp://firmware.re/\nHaboMalHunter - Linux ELF文件的自动恶意软件分析工具\nhttps://github.com/Tencent/HaboMalHunter\n混合分析 - 在线恶意软件分析工具，由VxSandbox提供支持\nhttps://www.hybrid-analysis.com/\nIRMA - 针对可疑文件的异步和可自定义分析平台\nhttp://irma.quarkslab.com/\nJoe Sandbox - 使用Joe Sandbox进行深度恶意软件分析\nhttps://www.joesecurity.org/\nJotti  - 免费在线多AV扫描仪\nhttps://virusscan.jotti.org/en\nLimon - 用于分析Linux恶意软件的沙箱\nhttps://github.com/monnappa22/Limon\nMalheur - 恶意软件行为的自动沙盒分析\nhttps://github.com/rieck/malheur\nmalsub - 用于在线恶意软件和URL分析服务的Python RESTful API框架\nhttps://github.com/diogo-fernan/malsub\n恶意软件配置 - 从常见恶意软件中在线提取，解码和显示配置设置\nhttps://malwareconfig.com/\nMalwr - 使用在线Cuckoo Sandbox实例进行免费分析\nhttps://malwr.com/\nMASTIFF Online - 恶意软件的在线静态分析\nhttps://mastiff-online.korelogic.com/\nMetadefender.com - 扫描恶意软件的文件，哈希或IP地址（免费）\nhttps://www.metadefender.com/\nNetworkTotal  - 一种分析pcap文件的服务，可以使用配置了EmergingThreats Pro的Suricata快速检测病毒，蠕虫，特洛伊木马和各种恶意软件\nhttps://www.networktotal.com/index.html\nNoriben - 使用Sysinternals Procmon收集有关沙盒环境中恶意软件的信息\nhttps://github.com/Rurik/Noriben\nPDF Examiner - 分析可疑的PDF文件\nhttp://www.pdfexaminer.com/\nProcDot  - 图形恶意软件分析工具包\nhttp://www.procdot.com/\n重组器  - 用于将二进制文件安全地上载到沙箱站点的帮助程序脚本\nhttps://github.com/secretsquirrel/recomposer\nSand droid - 自动完整的Android应用程序分析系统\nhttp://sanddroid.xjtu.edu.cn/\nSEE - 沙盒执行环境（SEE）是用于在安全环境中构建测试自动化的框架\nhttps://github.com/F-Secure/see\nVirusTotal - 免费在线分析恶意软件样本和URL\nhttps://www.virustotal.com/\nVisualize_Logs - 用于日志的开源可视化库和命令行工具（Cuckoo，Procmon……）\nhttps://github.com/keithjjones/visualize_logs\nZeltser‘s List - 由Lenny Zeltser编写的免费自动沙箱和服务\nhttps://zeltser.com/automated-malware-analysis\n脚本\nIDA Python Srchttps://github.com/idapython/src\nIDC Functions Doc\nhttps://www.hex-rays.com/products/ida/support/idadoc/162.shtml\nUsing IDAPython to Make your Life Easier\nhttp://researchcenter.paloaltonetworks.com/tag/idapython/\nIDA Python简介\nhttps://tuts4you.com/download.php?view.3229\nIDA Python初学者指南\nhttps://leanpub.com/IDAPython-Book\nIDA插件大赛https://www.hex-rays.com/contests/\nonehawt IDA插件列表\nhttps://github.com/onethawt/idaplugins-list\npefile Python Libray\nhttps://github.com/erocarrera/pefile\nAndroid\nAndroid工具\nAndroid Developer Studio\nhttp://developer.android.com/sdk/index.html\nAndroGuardhttps://github.com/androguard/androguard/\nAPKtoolhttp://ibotpeaches.github.io/Apktool/\ndex2jarhttps://github.com/pxb1988/dex2jar\n字节码查看器https://bytecodeviewer.com/\nIDA Pro\nhttps://www.hex-rays.com/products/ida/index.shtml\nYara\nYara资源\nYara docs\nhttp://yara.readthedocs.org/en/v3.4.0/writingrules.html\ncheatsheet\nhttps://gist.github.com/0xtyh/eeabc765e9befad9b80a\nyarGenhttps://github.com/Neo23x0/yarGen\nYara First Presentation\nhttps://github.com/xathrya/awesome-list/blob/master/Users/thalfpop/Downloads/first_2014_-_schuster-andreas-_yara_basic_and_advanced_20140619.pdf\n记忆取证\n用于在内存映像或运行系统中剖析恶意软件的工具\nBlackLight - 支持hiberfil，页面文件，原始内存分析的Windows / MacOS取证客户端\nhttps://www.blackbagtech.com/blacklight.html\nDAMM - 基于波动率内存中恶意软件的差异分析\nhttps://github.com/504ensicsLabs/DAMM\nevolve - Volatility Memory取证框架的Web界面\nhttps://github.com/JamesHabben/evolve\nFindAES - 在内存中查找AES加密密钥\nhttp://jessekornblum.livejournal.com/269749.html\ninVtero.net - 用.NET开发的高速内存分析框架，支持所有Windows x64，包括代码完整性和写入支持\nhttps://github.com/ShaneK2/inVtero.net\nMuninn - 使用Volatility自动化部分分析的脚本，并创建可读报告\nhttps://github.com/ytisf/muninn\nRekall - 内存分析框架，源于2013年的Volatility\nhttp://www.rekall-forensic.com/\nTotalRecall - 基于Volatility的脚本，用于自动执行各种恶意软件分析任务\nhttps://github.com/sketchymoose/TotalRecall\nVolDiff - 在恶意软件执行之前和之后对内存映像运行Volatility，并报告更改\nhttps://github.com/aim4r/VolDiff\nVolatility - 先进的记忆取证框架\nhttps://github.com/volatilityfoundation/volatility\nVolUtility -波动率内存分析框架的Web界面\nhttps://github.com/kevthehermit/VolUtility\nWDBGARK - WinDBG Anti-RootKit扩展\nhttps://github.com/swwwolf/wdbgark\nWinDbg - Windows系统的实时内存检查和内核调试\nhttps://developer.microsoft.com/en-us/windows/hardware/windows-driver-kit\nWindows工件\nAChoir - 用于收集Windows工件的实时事件响应脚本\nhttps://github.com/OMENScan/AChoir\npython-evt - 用于解析Windows事件日志的Python库\nhttps://github.com/williballenthin/python-evt\npython-registry - 用于解析注册表文件的Python库\nhttp://www.williballenthin.com/registry/\nRegRipper（GitHub） - 基于插件的注册表分析工具\nhttp://brettshavers.cc/index.php/brettsblog/tags/tag/regripper/\n存储和工作流程\nAleph - 开源恶意软件分析管道系统\nhttps://github.com/merces/aleph\nCRIT s - 一个恶意软件威胁库\nhttps://crits.github.io/\nFAME - 一个恶意软件分析框架，其特色是可以使用自定义模块进行扩展的管道，这些模块可以链接并相互交互以执行端到端分析\nhttps://certsocietegenerale.github.io/fame/\nMalwarehouse  - 存储，标记和搜索恶意软件\nhttps://github.com/sroberts/malwarehouse\nPolichombr - 一种恶意软件分析平台，旨在帮助分析师协同反转恶意软件\nhttps://github.com/ANSSI-FR/polichombr\nstoQ - 分布式内容分析框架，具有广泛的插件支持，从输入到输出，以及介于两者之间的所有内容\nhttp://stoq.punchcyber.com/\nViper - 分析师和研究人员的二进制管理和分析框架\nhttp://viper.li/\n恶意软件样本\n收集恶意软件样本进行分析\nClean MX  - 恶意软件和恶意域的实时数据库\nhttp://support.clean-mx.de/clean-mx/viruses.php\nContagio  - 最近的恶意软件样本和分析集合\nhttp://contagiodump.blogspot.com/\n漏洞数据库  - 利用和shellcode样本\nhttps://www.exploit-db.com/\nMalshare - 恶意软件的大型存储库\nhttps://malshare.com/\nMalwareDB - 恶意软件样本存储库\nhttp://malwaredb.malekal.com/\n打开恶意软件项目 - 示例信息下载\nhttp://openmalware.org/\nRagpicker - 基于插件的恶意软件爬虫，具有预分析和报告功能\nhttps://github.com/robbyFux/Ragpicker\ntheZoo - 分析师的真实恶意软件样本\nhttps://github.com/ytisf/theZoo\nTracker h3x - 用于恶意软件语料库跟踪器和恶意下载站点的 Agregator\nhttp://tracker.h3x.eu/\nViruSign - 恶意软件数据库\nhttp://www.virussign.com/\nVirusShare - 恶意软件存储库，需要注册\nhttps://virusshare.com/\nVX Vault - 恶意软件样本的主动收集\nhttp://vxvault.net/\nZeltser的来源 - Lenny Zeltser汇总的恶意软件样本源列表\nhttps://zeltser.com/malware-sample-sources/\nZeus源代码 - Zeus木马的来源于2011年泄露\nhttps://github.com/Visgean/Zeus\n课程\n逆向工程课程\n莱纳斯为新手逆转\nhttps://tuts4you.com/download.php?list.17\n开放式安全培训\nhttp://opensecuritytraining.info/Training.html\n傅博士的恶意软件分析\nhttp://fumalwareanalysis.blogspot.sg/p/malware-analysis-tutorials-reverse.html\n二元审计课程http://www.binary-auditing.com/\nTiGa的视频教程http://www.woodmann.com/TiGa/\n随机传说\nhttps://tuts4you.com/download.php?list.97\n现代二元开发\nhttp://security.cs.rpi.edu/courses/binexp-spring2015/\nRPISEC恶意软件课程\nhttps://github.com/RPISEC/Malware\nSANS FOR 610 GREM\nhttps://www.sans.org/course/reverse-engineering-malware-malware-analysis-tools-techniques/Type/asc/all\nREcon培训https://recon.cx/2015/training.html\n黑帽训练\nhttps://www.blackhat.com/us-16/training/\n进攻性安全\nhttps://www.offensive-security.com/information-security-training/\nCorelan培训https://www.corelan-training.com/\n攻击性和防御性Android逆转\nhttps://github.com/rednaga/training/raw/master/DEFCON23/O%26D%20-%20Android%20Reverse%20Engineering.pdf\n域分析\n检查域和IP地址\nbadips.com  - 基于社区的IP黑名单服务\nhttps://www.badips.com/\nboomerang  - 一种用于一致且安全地捕获网络外网络资源的工具\nhttps://github.com/EmersonElectricCo/boomerang\nCymon  - 威胁情报跟踪器，具有IP /域/哈希搜索功能\nhttps://cymon.io/\nDesenmascara.me  - 一键式工具，可以为网站检索尽可能多的元数据，并评估其良好的信誉\nhttp://desenmascara.me/\nDig  - 免费在线挖掘和其他网络工具\nhttps://networking.ringofsaturn.com/\ndnstwist  - 用于检测拼写错误，网络钓鱼和企业间谍活动的域名置换引擎\nhttps://github.com/elceef/dnstwist\nIPinfo  - 通过搜索在线资源收集有关IP或域的信息\nhttps://github.com/hiddenillusion/IPinfo\nMachinae  - 用于收集有关URL，IP或哈希信息的OSINT工具，与Automator相似\nhttps://github.com/hurricanelabs/machinae\nmailchecker  - 跨语言临时电子邮件检测库\nhttps://github.com/FGRibreau/mailchecker\nMaltegoVT  - VirusTotal API的Maltego转换，允许域/ IP研究，以及搜索文件哈希和扫描报告\nhttps://github.com/michael-yip/MaltegoVT\nMulti rbl  - 多个DNS黑名单和转发已确认的反向DNS查询超过300个RBL\nhttp://multirbl.valli.org/\nNormShield Services  - 用于检测可能的网络钓鱼域，列入黑名单的IP地址和违反帐户的免费API服务\nhttps://services.normshield.com/\nSpamCop  - 基于IP的垃圾邮件阻止列表\nhttps://www.spamcop.net/bl.shtml\nSpamHaus  - 基于域和IP的阻止列表\nhttps://www.spamhaus.org/lookup/\nSucuri SiteCheck  - 免费网站恶意软件和安全扫描程序\nhttps://sitecheck.sucuri.net/\nTalos Intelligence  - 搜索IP，域或网络所有者（以前是SenderBase）\nhttps://talosintelligence.com/\nTekDefense Automater  - 用于收集有关URL，IP或哈希值的信息的OSINT工具\nhttp://www.tekdefense.com/automater/\nURLQuery  - 免费的URL扫描程序\nhttp://urlquery.net/\nWhois  - DomainTools免费在线whois搜索\nhttps://whois.domaintools.com/\nZeltser’s List  - 由Lenny Zeltser编写的免费在线工具，用于研究恶意网站\nhttps://zeltser.com/lookup-malicious-websites/\nZScalar Zulu  - Zulu URL风险分析器\nhttps://zulu.zscaler.com/\n书籍\n最重要的逆向工程书籍\nIDA Pro Bookhttp://amzn.com/1593272898\n初学者的逆向工程http://beginners.re/\n汇编语言的艺术http://amzn.com/1593272073\n实用逆向工程http://amzn.com/B00IA22R2Y\n逆转：逆向工程的秘密\nhttp://amzn.com/B007032XZK\n实用的恶意软件分析http://amzn.com/1593272901\n恶意软件分析师的食谱\nhttp://amzn.com/B0047DWCMA\n灰帽子黑客http://amzn.com/0071832386\n记忆取证的艺术http://amzn.com/1118825098\n黑客：剥削的艺术http://amzn.com/1593271441\n模糊软件安全http://amzn.com/1596932147\n软件安全评估的艺术http://amzn.com/0321444426\n防病毒黑客手册http://amzn.com/1119028752\nThe Rootkit Arsenal\nhttp://amzn.com/144962636X\nWindows Internals第1 、2部分\nhttp://amzn.com/0735648735\nWindows调试之中http://amzn.com/0735662789\niOS逆向工程\nhttps://github.com/iosre/iOSAppReverseEngineering\n文档和Shellcode\n从PDF和Office文档分析恶意JS和shellcode\nAnalyzePDF - 用于分析PDF并尝试确定它们是否是恶意的工具\nhttps://github.com/hiddenillusion/AnalyzePDF\nbox-js - 用于研究JavaScript恶意软件的工具，具有JScript / WScript支持和ActiveX仿真功能\nhttps://github.com/CapacitorSet/box-js\ndiStorm - 用于分析恶意shellcode的反汇编程序\nhttp://www.ragestorm.net/distorm/\nJS Beautifier - JavaScript解包和反混淆\nhttp://jsbeautifier.org/\nJS Deobfuscator -\n反混淆使用eval或document.write隐藏其代码的简单Javascript\nhttp://www.kahusecurity.com/2015/new-javascript-deobfuscator-tool/\nlibemu - 用于x86 shellcode仿真的库和工具\nhttp://libemu.carnivore.it/\nmalpdfobj - 将恶意PDF解构为JSON表示\nhttps://github.com/9b/malpdfobj\nOfficeMalScanner - 扫描MS Office文档中的恶意跟踪\nhttp://www.reconstructer.org/code.html\nolevba -用于解析OLE和OpenXML文档以及提取有用信息的脚本\nhttp://www.decalage.info/python/olevba\nOrigami PDF - 用于分析恶意PDF的工具等\nhttps://code.google.com/archive/p/origami-pdf\nPDF工具 -\n来自Didier Stevens的pdfid，pdf-parser等\nhttps://blog.didierstevens.com/programs/pdf-tools/\nPDF X-Ray Lite - PDF分析工具，PDF X-RAY的后端版本\nhttps://github.com/9b/pdfxray_lite\npeepdf -用于探索可能的恶意PDF的Python工具\nhttp://eternal-todo.com/tools/peepdf-pdf-analysis-tool\nQuickSand - QuickSand是一个紧凑的C框架，用于分析可疑的恶意软件文档，以识别不同编码流中的漏洞，并定位和提取嵌入的可执行文件\nhttps://www.quicksand.io/\nSpidermonkey - Mozilla的JavaScript引擎，用于调试恶意JS\nhttps://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey\n实践\n练习逆向工程，警惕恶意软件\nCrackmes.dehttp://www.crackmes.de/\nOSX Crackmeshttps://reverse.put.as/crackmes/\nESET挑战\nhttp://www.joineset.com/jobs-analyst.html\nFlare-on挑战http://flare-on.com/\nGithub CTF档案馆http://github.com/ctfs/\n逆向工程挑战http://challenges.re/\nxorpd高级装配练习\nhttp://www.xorpd.net/pages/xchg_rax/snip_00.html\nVirusshare.comhttp://virusshare.com/\nContagiohttp://contagiodump.blogspot.com/\n恶意软件流量分析\nhttps://malware-traffic-analysis.com/\nMalsharehttp://malshare.com/\n恶意软件黑名单\nhttp://www.malwareblacklist.com/showMDL.php\nmalwr.comhttps://malwr.com/\nvxvaulthttp://vxvault.net/\n开源威胁情报工具\n捕捉和分析IOC\nAbuseHelper  - 用于接收和重新分发滥用情况和威胁情报的开源框架\nhttps://github.com/abusesa/abusehelper\nAlienVault Open Threat Exchange - 共享和协作开发威胁情报\nhttps://otx.alienvault.com/\nCombine  - 从公开来源收集威胁情报指标的工具\nhttps://github.com/mlsecproject/combine\nFileintel  - 智能提取每个文件哈希\nhttps://github.com/keithjjones/fileintel\nHostintel - 智能提取每个主机\nhttps://github.com/keithjjones/hostintel\nIntelMQ -\n用于使用消息队列处理事件数据的 CERT的工具\nhttps://www.enisa.europa.eu/topics/csirt-cert-services/community-projects/incident-handling-automation\nI OC Editor - XML IOC文件的免费编辑器\nhttps://www.fireeye.com/services/freeware/ioc-editor.html\nioc_writer -\n用于处理Mandiant的OpenIOC对象的Python库\nhttps://github.com/mandiant/ioc_writer\nMassive Octo Spice - 以前称为CIF（集体智慧框架），从各种列表聚合IOC，由 CSIRT小工具基金会策划\nhttps://github.com/csirtgadgets/massive-octo-spice\nMISP - 由 MISP项目策划的恶意软件信息共享平台\nhttps://github.com/MISP/MISP\nPulsedive - 免费的社区驱动威胁情报平台，从开源源收集IOC\nhttps://pulsedive.com/\nPyIOCe - Python OpenIOC编辑器\nhttps://github.com/pidydx/PyIOCe\nRiskIQ - 研究，连接，标记和共享IP和域\nhttps://community.riskiq.com/\nthreataggregator - 聚合来自多个来源的安全威胁\nhttps://github.com/jpsenior/threataggregator\nThreatCrowd - 威胁搜索引擎，具有图形可视化功能\nhttps://www.threatcrowd.org/\nThreatTracker - 一个Python脚本，用于监视和生成基于由一组Google自定义搜索引擎索引的IOC的警报\nhttps://github.com/michael-yip/ThreatTracker\nTIQ-test - 威胁情报源的数据可视化和统计分析\nhttps://github.com/mlsecproject/tiq-test\n其他资源\nAPT笔记 - 与高级持续威胁相关的论文和笔记集\nhttps://github.com/aptnotes/data\n文件格式海报 - 常用文件格式（包括PE和ELF）的可视化\nhttps://github.com/corkami/pics\n蜜罐项目 - 蜜罐工具，论文和其他资源\nhttp://honeynet.org/\n内核模式 - 一个致力于恶意软件分析和内核开发的活跃社区\nhttp://www.kernelmode.info/forum/\n恶意软件 - Lenny Zeltser提供的恶意软件博客和资源\nhttps://zeltser.com/malicious-software/\n恶意软件分析搜索 - 来自 Corey Harrell的自定义Google搜索引擎\nhttps://cse.google.com/cse/home?cx=011750002002865445766%3Apc60zx1rliu\n恶意软件分析教程  - Xiang Fu博士的恶意软件分析教程，是学习实用恶意软件分析的重要资源\nhttp://fumalwareanalysis.blogspot.nl/p/malware-analysis-tutorials-reverse.html\n恶意软件样本和流量  - 此博客重点介绍与恶意软件感染相关的网络流量\nhttp://malware-traffic-analysis.net/\n实用恶意软件分析入门套件 - 此软件包包含实用恶意软件分析手册中引用的大多数软件\nhttps://bluesoul.me/practical-malware-analysis-starter-kit/\nRPISEC恶意软件分析 - 这些是2015年秋季伦斯勒理工学院恶意软件分析课程中使用的课程材料\nhttps://github.com/RPISEC/Malware\nWindowsIR：恶意软件 -\nHarlan Carvey关于恶意软件的页面\nhttp://windowsir.blogspot.com/p/malware.html\nWindows注册表规范 - Windows注册表文件格式规范https://github.com/msuhanov/regf/blob/master/Windows%20registry%20file%20format%20specification.md\n/ r / csirt_tools -\nCSIRT工具和资源的Subreddit，具有 恶意软件分析能力https://www.reddit.com/r/csirt_tools/\n/ r / Mal ware - 恶意软件subreddit\nhttps://www.reddit.com/r/Malware\n/ r / ReverseEngineering -\n逆向工程subreddit，不仅限于恶意软件https://www.reddit.com/r/ReverseEngineering\n","slug":"sec/安全工具和资源","date":"2024-03-14T06:15:59.768Z","categories_index":"安全","tags_index":"安全工具","author_index":"安全书"},{"id":"f3b76fc4e7276b1fc281a1c1bf2998d4","title":"ThreatIngestor","content":"ThreatIngestorhttps://github.com/InQuest/ThreatIngestor\nhttps://inquest.readthedocs.io/projects/threatingestor/en/latest/welcome.html#try-it-out\n一个可扩展的工具，以提取和聚合IOCs的威胁feed。与即时可用的ThreatKB和MISP集成，可以与任何现有的带有SQS、Beanstalk和自定义插件的worflow无缝集成。\n一、概述\n可以将ThreatIngestor配置为监视Twitter、RSS feed或其他源，提取有意义的信息，如恶意ip /域名和YARA签名，然后将这些信息发送到另一个系统进行分析。\n二、ThreatIngestor是什么?\nThreatIngestor帮助您从公共feed收集威胁情报，并为您提供有关该情报的背景资料，以便您可以进一步研究它，并将其用于保护您自己或您的组织。\n关于网上恶意活动的公开信息源源不断，但手工编译所有这些信息需要大量的手工工作和时间。使用安全软件可以尽可能多地自动完成这些工作，这样你就可以把注意力放在更重要的事情上。\n\nTwitter用户@MalwareConfig的feed的一个屏幕截图，显示了两个带有被破坏的C2域和IP地址的tweet。\n因为它是完全模块化和配置驱动的，ThreatIngestor是超级灵活的，应该很容易适应任何威胁情报工作流程。\n二、IOC- db，破坏指标(IOC)数据库\n作为InQuest实验室的最新成员，该工具对个人和团队通过Twitter、Github和博客等媒体发布的大量开源智能(OSINT)进行了索引。研究人员和分析人员可以收集像IOCs和YARA规则这样有价值的人工制品，以帮助他们的日常操作。我们利用先前出版工具ThreatIngestor(文档)和iocextract(文档)来促进这个自动化的收获。数据收集开始于2019年8月，可以交互搜索，也可以通过API搜索。可搜索的工件包括域、散列、IP地址、url和YARA规则。阅读更多关于摄取源/统计数据的信息，或者阅读我们关于使用这些开源工具创建Twitter机器人的博客。\nhttps://labs.inquest.net/iocdb\n","slug":"sec/ThreatIngestor","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"ThreatIngestor","author_index":"安全书"},{"id":"735bf4d6b0ebe227f9b84342ecd477f2","title":"linux iftop 命令使用的10个案例","content":"linux iftop 命令使用的10个案例iftop 是一个实时监控网络带宽的监控工具。它捕捉流经网口的入方向和出方向的数据包总数，并显示总带宽利用率。在本指南中，我们将带您完成 iftop 命令行工具的安装和使用。\niftop 安装(1) 在 Ubuntu / Debian 发行版上安装\n1$ sudo apt-get install -y iftop\n\n(2) 在 CentOS / RHEL / Rocky Linux 上安装\n对于基于 RHEL 的发行版，您首先需要启用 EPEL 存储库。\n1$ sudo yum install -y epel-release\n\n然后执行命令\n123$ sudo yum install iftopOr$ sudo dnf install -y iftop\n\n(3) 在 Fedora 上安装\n1$ sudo dnf install -y iftop\n\n(4) 在 Arch Linux / Manjaro 上安装\n1$ sudo pacman -S iftop\n\n现在让我们概述一些常见的 iftop 命令用法。\n(1) 显示整体带宽使用指标如果不带任何参数，iftop 命令将显示连接到系统的所有网络接口的带宽使用情况\n1$ sudo iftop\n\n\n(2) 查看指定网口的带宽统计信息要显示特定网络接口的统计信息，可以使用 -i 标志和接口名称。例如，如果需要显示与某个接口 (例如：enp0s8) 相关的带宽活动。\n1$ sudo iftop -i enp0s8\n\n\n(3) 禁用或隐藏顶部条形图要隐藏或禁用位于终端顶部的带宽比例或栏，请使用 -b 选项。\n1$ sudo iftop -b\n\n\n(4) 禁用主机名查找要禁用主机名查找，可以使用 -n 选项。例如，下面的示例忽略使用 enp0s8 网络接口访问的站点的主机名查找\n1$ sudo iftop -n -i enp0s8\n\n\n(5) 显示直观的文本输出以更直观的方式显示输出，请使用显示的 -t 选项。\n1$ sudo iftop -t\n\n\n(6) 显示进出子网的流量如果您在子网中，例如 192.168.2.0/24，并且要分析入站和出站网络流量，请运行命令：\n1$ sudo iftop -F 192.168.2.0/24\n\n(7) 按来源地址对输出进行排序1$ sudo iftop -o source\n\n\n(8) 按目的地址对输出进行排序1$ sudo iftop -o destination\n\n\n(9) 以字节为单位显示带宽使用情况1$ sudo iftop -B -i enp0s8\n\n\n(10) 显示帮助页1$ man iftop\n\n\n","slug":"sec/linux iftop 命令使用的10个案例","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"iftop","author_index":"安全书"},{"id":"41fa6af3e01b56174bad9d28a8d1d3a0","title":"iftop实时网络流量监控","content":"iftop实时网络流量监控一、iftop 有什么作用iftop 是类似于 top 的实时流量监控工具，主要用来显示本机网络流量情况以及各个相互通信的流量集合，可以用来监控网卡的实时流量。\n二、安装 iftop①、编译安装安装所需要依赖包\n1[root@docker ~]# yum install -y gcc flex byacc libpcap ncurses ncurses-devel libpcap-devel tcpdump\n\n下载工具包：\n[root@localhost data]# wget http://www.ex-parrot.com/pdw/iftop/download/iftop-1.0pre4.tar.gz\n解压：\n[root@localhost data]# tar -zxvf iftop-1.0pre4.tar.gz\n安装\n[root@docker iftop-1.0pre4]# ./configure –prefix=/usr/local/iftop\n[root@docker iftop-1.0pre4]# make &amp;&amp; make install\n②、或者直接 yum 命令安装：[root@localhost ~]# yum install iftop -y\n三、运行 iftop 命令[root@localhost data]# iftop\n\n从输出的界面中，主要分为是三大部分：\n第一部分：输出最上面的一行，显示网卡带宽流量\n第二部分：分为左中右三列，左列和中列记录了哪些 IP 或主机正在连接本机的网络\n中列的 =&gt; 代表发送数据\n&lt;= 代表接收数据\n通过这些指示箭头可以很清晰的知道两个 IP 之间的通信情况\n最右列的三个小列：\n分别表示外部 IP 连接到本机 2s，10s 和 40s 的平均流量\n还有一个流量图形条，可以很快的看出那个 IP 的流量最大\n\n第三部分：iftop 输出的最下面，分为三行\nTX：发送的数据\nRX：接收的数据\nTOTAL：发送和接收的全部数据\n对应的三列：\ncum：从运行 iftop 到目前的发送，接收和总数据流量\npeak：发送，接收以及总的流量峰值\nrates：过去 2s，10s，40s 的平均流量值\n四、iftop 相关参数[root@localhost ~]# iftop -h\n参数 含义\n-i 指定需要检测的网卡\n[root@localhost ~]# iftop -i ens33\n\n-n 将输出的主机信息都通过 IP 显示，不进行 DNS 解析\n-B 将输出以 byte 为单位显示网卡流量，默认是 bit\n-p 以混杂模式运行 iftop，此时 iftop 可以用作网络嗅探器\n-N 只显示连接端口号，不显示端口对应的服务名称\n-P 显示主机以及端口信息\n-F 显示特定网段的网卡进出流量 如 iftop -F 192.168.85.0/24\n-m 设置输出界面中最上面的流量刻度最大值，流量刻度分 5 个大段显示 如 iftop -m limit\n-f 使用筛选码选择数据包来计数 如 iftop -f filter code\n-b 不显示流量图形条\n-c 指定可选的配置文件 如 iftop -c config file\n-t 使用不带 ncurses 的文本界面，\n如下两个是只和-t 一起用的：\n-s num num 秒后打印一次文本输出然后退出\n-L num 打印的行数\n五、进入 iftop 画面后的一些操作命令(注意大小写)按 h 切换是否显示帮助;\n按 n 切换显示本机的 IP 或主机名;\n按 s 切换是否显示本机的 host 信息;\n按 d 切换是否显示远端目标主机的 host 信息;\n按 t 切换显示格式为 2 行/1 行/只显示发送流量/只显示接收流量;\n按 N 切换显示端口号或端口服务名称;\n按 S 切换是否显示本机的端口信息;\n按 D 切换是否显示远端目标主机的端口信息;\n按 p 切换是否显示端口信息;\n按 P 切换暂停/继续显示;\n按 b 切换是否显示平均流量图形条;\n按 B 切换计算 2 秒或 10 秒或 40 秒内的平均流量;\n按 T 切换是否显示每个连接的总流量;\n按 l 打开屏幕过滤功能，输入要过滤的字符，比如 ip，按回车后，屏幕就只显示这个 IP 相关的流量信息;\n按 L 切换显示画面上边的刻度;刻度不同，流量图形条会有变化;\n按 j 或按 k 可以向上或向下滚动屏幕显示的连接记录;\n按 1 或 2 或 3 可以根据右侧显示的三列流量数据进行排序;\n按 &lt; 根据左边的本机名或 IP 排序;\n按 &gt; 根据远端目标主机的主机名或 IP 排序;\n按 o 切换是否固定只显示当前的连接;\n按 f 可以编辑过滤代码，这是翻译过来的说法，我还没用过这个！\n按！可以使用 shell 命令，这个没用过！没搞明白啥命令在这好用呢！\n按 q 退出监控。\n六、使用案例\n使用 iftop 工具查出来是哪些 IP 地址在\n\n请求主机的带宽资源\n\n\n\n可以看到 148 到 147 的流量，以及返回的流量都不是很大，都只有 6 兆，7 兆左右，流量占用整个带宽都很小\n","slug":"sec/iftop实时网络流量监控","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"iftop","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Hello how are you✍️️ \nA set of model files for the C++ implementation of Gemma 2B. It is easy to download, build, and tinker with. This is a compressed version of the weights for a 2B parameter model that has been instruction-tuned. These will load, run, and download more quickly.\nPre-trained (PT) models can be used as base models for further development, while instruction-tuned (IT) variants can be used for chatting and following prompts.\n","slug":"sec/Suricata/Suricata部署","date":"2024-03-14T06:15:59.767Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"b11fd065488f675e75d28e383528140e","title":"Suricata与TheHiveCortex结合使用","content":"Suricata与TheHiveCortex结合使用Suricata 是一个强大的网络威胁检测引擎，而 TheHive Cortex 则是一个可观察性分析和主动响应引擎。虽然它们是不同的工具，但可以结合使用以增强安全分析和响应能力。\n下面是关于 Suricata 和 TheHive Cortex 结合使用的一些注意事项：\n\nSuricata：\n功能：Suricata 可以进行实时入侵检测 (IDS)、内联入侵预防 (IPS)、网络安全监控 (NSM) 和离线 pcap 处理。\n规则和签名：Suricata 使用规则和签名语言来检查网络流量，支持多种协议解码和流量方向。\n配置：您可以在 Suricata 的配置文件中设置规则路径、规则目录和其他参数。\n\n\nTheHive Cortex：\n功能：TheHive Cortex 是一个可观察性分析和响应引擎，旨在帮助安全团队分析收集到的可观察数据。\n分析器：Cortex 支持多种分析器，可以查询 IP 地址、电子邮件地址、URL、域名和文件/哈希等可观察数据。\n\n\n结合使用：\n您可以将 Suricata 与 TheHive Cortex 集成，以便在检测到潜在威胁时自动触发响应操作。\n例如，当 Suricata 检测到恶意流量或攻击时，您可以使用 Cortex 分析器查询相关的 IP 地址、域名或文件哈希，以获取更多信息。\n这样，您可以利用 Suricata 的实时检测能力和 Cortex 的分析能力来更好地理解和应对威胁。\n\n\n\n总之，Suricata 和 TheHive Cortex 可以协同工作，提高您的安全分析和响应效\n","slug":"sec/Suricata/Suricata与TheHiveCortex结合使用","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"Cortex,Suricata,TheHive","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Ubuntu20和Ubuntu22有什么区别？\nUbuntu 20和Ubuntu 22是两个不同版本的Ubuntu操作系统，它们之间有一些区别，主要包括以下几点：\n\n版本号：Ubuntu 20是发布于2020年的版本，而Ubuntu 22是发布于2022年的版本，因此Ubuntu 22可能包含更多的新功能和更新。\n\n内核版本：Ubuntu 20使用的是Linux内核5.4，而Ubuntu 22使用的是Linux内核5.15，新内核可能带来更好的性能和稳定性。\n\n软件包：Ubuntu 22可能会包含更新的软件包和应用程序版本，以满足用户对最新功能和改进的需求。\n\n支持周期：通常来说，较新版本的Ubuntu会有更长的支持周期，这意味着用户可以获得更长时间的安全更新和技术支持。\n\n用户界面：虽然桌面环境可能在不同版本中没有太大变化，但可能会有一些小的改进或调整。\n\n\n总体来说，Ubuntu 22相比于Ubuntu 20可能会有更多的新功能、更新和改进，用户可以根据自己的需求选择使用哪个版本。\nBIOS开启超线程的作用是什么\nBIOS开启超线程可以让处理器的每个物理核心模拟出两个逻辑核心，从而提高处理器的多线程性能。这样可以使处理器同时执行更多的任务，提高系统的整体运行效率和性能。开启超线程可以在一定程度上增加处理器的并行计算能力，加快程序的运行速度。\n磁盘Raid0和Raid5有什么区别？\nRAID0和RAID5都是一种磁盘阵列技术，但它们有一些重要区别：\n\n数据冗余性：\n\n\nRAID0：不提供数据冗余性，数据被分割成块并存储在不同的磁盘上，提高了读写速度，但如果其中一个磁盘损坏，所有数据都将丢失。\nRAID5：提供数据冗余性，通过分布式存储校验信息的方式，在每个数据块中存储校验信息，并且这些校验信息也被分布式存储在其他磁盘上。当某个磁盘损坏时，可以根据校验信息进行数据恢复。\n\n\n性能：\n\n\nRAID0：由于数据被分割并同时写入多个磁盘，RAID0通常具有更高的读写速度。\nRAID5：由于要计算和写入校验信息，并且需要额外的读取操作来恢复数据，在某些情况下RAID5的性能可能会比RAID0稍慢。\n\n\n存储效率：\n\n\nRAID0：不提供任何额外的存储空间，所有数据都会被保存在实际的物理磁盘上。\nRAID5：通过将一定比例的存储空间用于校验信息来提供冗余性，从而实现了更高的存储效率。\n\n综上所述，RAID0适合对性能要求较高、对数据冗余性要求较低的场景；而RAID5适合对数据冗余性有较高要求、可以牺牲一定性能的场景。选择哪种RAID级别取决于您对性能和可靠性之间平衡的需求。\nhttps://www.hostinger.com/tutorials/how-to-install-suricata-on-ubuntu\nhttps://github.com/arkime/arkime/releases/tag/v5.0.1\nhttps://app.pluralsight.com/ilx/video-courses/e9db83c8-52b1-426e-80ed-8893486cdf39/a56d2027-0bb2-414b-9402-4a870afc845c/ba0de19d-5cd4-4da1-a5c3-c2d38e07bbcd\nhttps://docs.suricata.io/en/suricata-7.0.2/security.html\n","slug":"sec/Suricata/Suricata","date":"2024-03-14T06:15:59.767Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"83b2e025a478c2da76012dbffdf74f6e","title":"TheHive与Cortex和MISP结合使用","content":"TheHive与Cortex和MISP结合使用TheHive, Cortex and MISP work nicely together and if you’ve read our June-Dec 17 roadmap post, the integration of our products with the de facto threat sharing platform will get better in a few months.\nDuring the FIRST conference presentation we gave last week, we displayed a picture that we will use here to try to explain how these three open source and free products integrate with one another.\n\nA Picture is Worth a Thousand Words…\nTheHiveTheHive is a Security Incident Response Platform (SIRP). It can receive alerts from different sources (SIEM, IDS, email. etc.) via its REST API. This is where alert feeders come into play.\nAlert FeedersThink of an alert feeder as a specialized program which consumes a security event (SIEM alert, email report, IDS alert, and so on), parses it and outputs an alert that its sends to TheHive through TheHive4py, the Python library we provide to interact with TheHive’s REST API.\nWe do not supply such feeders but developing them should be straightforward. If not, let us know  and we’ll do our best to help you out.\nAlertsAny alert sent to TheHive will show up in its Alerts pane. In addition to the sources mentioned above, new or updated MISP events will show up as well in that area if you configured TheHive to connect to one or several MISP instances. If so, TheHive will poll those MISP instance(s) at every interval looking for new or updated events. If there are any, TheHive will generate an alert which will end up in the Alerts pane.\n\nThe Alerts Pane\nAlerts can be ignored, mark as read, previewed and imported. When an alert is imported, it becomes a case that needs to be investigated.\nCases\nThe Workflow that is at the Heart of TheHive\nA case can be generated from an alert or created from scratch. It is subdivided into tasks (think identification, containment, eradication, check proxy logs, and so on) and observables (IP addresses, hashes, email addresses, domain names, URLs…). When analysts are working on tasks, they add logs as they go. In TheHive’s terminology, logs are text entries which may contain attachments to help analysts record what they have been doing. Logs can be written using Markdown or a rich-text editor.\nCase TemplatesYou don’t need to add the same tasks over and over when working on cases belonging to a given category (DDoS, Malspam, APT, …). You can create custom templates to which you add tasks as shown below. This is very useful when you are dealing with alerts so that when you import them, you can select which case template you’d like to apply and there you go!\n\nA Sample Case Template\nObservablesObservables can be tagged, flagged as IOCs, and analyzed. When the investigation is well in progress or completed, you may want to share the resulting IOCs or a subset of those with partners and peers. TheHive will support the ability to export that data to MISP in September 2017. Until then, you can still export your IOCs as text, CSV or as a MISP-compatible format that you can use to add them to your MISP instance using the freetext editor. TheHive can export IOCs/observables in protected (hxxps://www[.]somewhere[.]com/) or unprotected mode.\nEvery observable must have a TLP (Traffic Light Protocol) level. By default, any added observable is considered TLP:AMBER. Please note that the TLP is taken into account by some analyzers. Wait! Analyzers?\nCortexCortex is our standalone analysis engine and a perfect companion for TheHive and MISP. Analysts can use it to analyze observables using its Web UI, in which case they can be submitted only one at a time. The Web UI should really be limited to quick assessments of observables before creating a case in TheHive (or in an alternate SIRP). The power of Cortex really comes into play when you use its REST API. TheHive speaks natively to Cortex (as MISP does). Moreover, TheHive can leverage one or several Cortex servers.\n\nObservable Page and List of Analyzers\nAnalyzersAs of this writing, Cortex has 23 analyzers which come in a total of 39 flavors and more will be available soon.\nAn analyzer can be written in any programming language supported by Linux though all of our current analyzers are written in Python. This is because we provide a Python library called Cortexutils which contains a set of utility classes that make it easier to write an analyzer in Python.\nFlavorsAnalyzers such as VirusTotal, PassiveTotal or DomainTools can provide different analysis services. Let’s take VirusTotal as an example. You can scan a file or URL. That’s one flavor. You can also obtain the latest available report on VirusTotal.com for a file, hash, domain or IP address. That’s a second flavor. So the VirusTotal analyzer has two flavors.\n\nHow about PassiveTotal? It has 8 flavors: unique resolutions lookup, SSL certificate history lookup, malware lookup, passive DNS lookup, data enrichment lookup, SSL certificate details lookup, OSINT lookup and WHOIS data lookup.\nThe MISP Search AnalyzerAt this point, we need to mention a special analyzer that may create some confusion if not understood correctly: the MISP Search analyzer. Thanks to it, Cortex has the ability to search observables within a MISP instance as represented by the arrow that goes from the Analyzers to MISP.\n\nSearch for MISP Events Containing a Given Observable\nWhen an observable is found in an event, Cortex will return the number of records found (i.e. the number of events where the observable has been found) and a list of links to those events with additional data.\n\nSearching for a Hash Using the MISP Search Analyzer from the Cortex Web UI\n\nThe Same Search Conducted from TheHive: Long Report\n\nMini-Report\nThe current version of the MISP Search analyzer can only search within a single MISP instance but in the near future, it will be able to support multiple ones.\nMISP Expansion ModulesBesides its own analyzers (which include MISP Search described above), Cortex can also invoke MISP expansion modules. These are normally used by MISP to enrich attributes within events but Cortex can also take advantage of them to analyze observables.\nThere is some overlap between the native Cortex analyzers and MISP expansion modules. When choosing between a native analyzer or an expansion module, we highly recommend you select the former. The expansion modules are deactivated in the default Cortex configuration.\nJobsWhen you submit an observable for analysis, Cortex will create a job and, if successful, it will generate an analysis report in JSON format. TheHive has the ability to parse those results and present them in a human-friendly fashion thanks to report templates we offer for free. So when you’ll submit an observable to Cortex from TheHive, you’ll get back a short (or mini) report and a long one. The first can be thought of as a really tiny Exec Analyst Summary while the second provides more insight and details.\nCalling Cortex from MISPIn addition to the expansion modules we have just mentioned, MISP 2.4.73 and up can enrich attributes using Cortex analyzers. The configuration is pretty straightforward. So if all you are concerned about is threat intelligence and sharing, you may augment your visibility into a given threat represented as a MISP event by leveraging all current 23 Cortex analyzers and any future ones.\nConclusion\nTheHive, Cortex and MISP are three open source and free products that can highly aid you combat threats and keep the ‘monsters’ at bay.\nTheHive, as a SIRP, allows you to investigate security incident swiftly in a collaborative manner. Several analysts can work simultaneously on tasks &amp; cases . While cases can be created from scratch, TheHive can receive alerts from different sources thanks to alert feeders which consume security events generated by multiple sources and feed them into TheHive using TheHive4py Python library. TheHive can also sync to one or several MISP instances to receive new and updated events which will appear in the alert pane with all the other alerts generated by other sources. Analysts can then preview new alerts to decide whether they need to be acted upon. If so, they can transform them into investigation cases using templates.\nTo analyze the observables collected in the course of an investigation and/or imported from a MISP event, TheHive can rely on one or several Cortex analysis engines. Cortex is another standalone product that we have developed which sole purpose is to allow you to analyze observables at scale thanks to its large number of analyzers, MISP expansion modules and any analyzer you might have developed on the side. Cortex has a REST API that can be used to empower other security products such as  ‘analytics’ software, alternate SIRPs or MISP.\nThe highly popular threat sharing platform can indeed enrich attributes thanks to Cortex as it has a native integration with it. And in a few months, you will also be able to export cases from TheHive as MISP events that you can share with peers and partners.\nIf you do share, you do care about our collective mission to defend the  digital assets that are under our watch from harm. So let us fight together as one.\n","slug":"sec/TheHive/TheHive与Cortex和MISP结合使用","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"Cortex,MISP,TheHive","author_index":"安全书"},{"id":"4ed59a6d992f5c41879395e6019b7e3d","title":"用TheHive实现SOAR","content":"用TheHive实现SOAR一、介绍SOAR代表“安全编排、自动化和响应”，指的是一种解决方案，用于威胁领域，以更好地监控和响应安全监控工具和技术检测到的事件。随着探测恶意活动的更先进技术的发展，大多数机构正转向使用SOAR，利用自动化来有效地分析、升级和响应 analyse, escalate and respond 安全威胁。\n检测方法:\n安全运营中心（Security Operations Centres）也被称为SOC，它们有监控和保护关键资产的系统。这些系统有复杂的规则，以及不断运行的先进机器学习算法，以检测任何可能被归类为恶意的活动。一旦检测发生，下一步是将信息发送到SOC，供安全分析师进行调查。这个信息通常以告警Alert的形式发送进来。SOC团队然后尝试根据SLA(服务水平协议)在固定的时间内解决告警。\n分析:\n安全分析师将分析告警以验证潜在的攻击，确定实际发生了什么，并评估事件的影响。基于此，安全运营团队可以执行响应操作来减轻威胁参与者。\n\n\n\n\n\n\n\n\n\n“如果分析师试图证明一项告警是有效的，他们要比试图证明它是无效的多花三分之二的时间。”\n克里斯·森德斯——调查理论\n响应:\n通常，安全分析人员必须执行一些任务来解决告警。其中一些任务非常复杂，需要网络安全专家来完成。然而，安全分析人员也会遇到平凡而重复的任务。当分析人员接触到具有相同或重复任务的大量告警时，他们往往会出现告警疲劳，这可能导致性能降低和响应时间延长。这就是SOAR来救援的地方!\nSOAR:\nSOAR强调自动化，以帮助安全团队增加带宽，专注于解决安全问题。与分析师接收警报类似，SOAR解决方案也将接收警报并对其执行一些分析。根据分析结果，将有一个响应操作来减轻威胁参与者。\n二、TheHive——安全事件响应TheHive是一个可扩展的四合一开源和免费的安全事件响应平台。这4个是TheHive, Cortex, TheHive4py (TheHive的python API)和MISP。TheHive的设计是为了让soc、csirt、cert和任何信息安全从业者在处理需要迅速调查和采取行动的安全事件时生活得更轻松。简单地说，TheHive作为SOC的前端应用程序，在三个基本阶段(检测、分析和响应)以及从创建到关闭的案例/告警管理中提供帮助。\n三、Cortex-强大的可观察分析和反应Cortex是另一款由TheHive同一团队开发并与TheHive紧密合作的软件。TheHive和Cortex可以一起使用，使SOC的生活更容易。在这样的解决方案中，任何可以帮助减轻威胁行为者的破坏指标(Indicator of Compromise, IoC)或取证数据片段都被列为可观察对象 observable。Cortex是一个强大的可观察分析和主动响应引擎。它有有助于分析这些观测数据的分析器。分析者还帮助用有价值的信息丰富TheHive的告警。利用这些有价值的信息，分析人员可以运行Cortex上的Responders，轻松地自动解决安全告警。\nCortex提供了一个web界面，用于分析IP、电子邮件地址、url、域名、文件或恶意软件的哈希值。然而，这两个应用程序可以集成在一起，使用REST API进行通信，而不是在web界面之间切换。Cortex配备了分析仪和响应器，以协助安全操作的自动化。这些分析器和响应器是可以用Linux支持的任何编程语言(如Python、Ruby、Perl等)编写的自动化脚本。在我写这篇博文的时候，大约有160个analyser和24个Responders默认安装了Cortex。然而，你可以选择编写自己的分析器和响应器，并将其放在指定的目录中供Cortex使用。\nTheHive &amp; Cortex完全由StrangeBee开发和维护。\n四、MISP -开源威胁Intel共享恶意软件信息共享平台是一种开源软件解决方案，用于收集、存储、分发和共享网络安全指标、网络安全事件威胁和恶意软件分析。这是由CIRCL开发和维护的。除了MISP的许多用途之外，这个解决方案可以利用的一个主要用途是订阅许多开源威胁情报源。当TheHive与Cortex和MISP整合在一起时，它的真正力量就会显现出来。这三种工具共同作用，形成安全行动中心事件分析/响应和案例管理的全面解决方案。\n每一个需要调查的安全事件都会作为警报进入TheHive。MISP有一些世界级的威胁情报供分析师或安全团队使用。因此，每当有一些新的威胁信息添加到MISP，它将自动填充到TheHive上进行分类，分析和响应。此外，除了从MISP接收事件外，还可以将解决方案配置为向MISP发送事件。因此，SOC可以将发现的威胁信息反馈给MISP，以帮助更广泛的社区领先黑客一步。\n一幅画胜过千言万语!\n\n\n五、剧本Playbooks-工作流自动化在安全运营领域，分析师将致力于解决非常复杂的安全告警。这些任务中的大多数都非常复杂，需要安全专业知识。然而，对于安全专家来说，要查看生成的每一条信息，有些任务可能是平凡而耗时的。像这样的任务，有更高的人为错误的机会，这是自动化可以帮助的地方。自动化旨在减少人为干预和人为错误的可能性。\n在前面的小节中，我们已经看到了如何利用开源工具的强大功能来为SOC创建一个独特的解决方案。下一步是增加一个额外的层，这将有助于自动执行一些平凡和重复的任务，以提高网络安全团队的效率。\nThehive和Cortex都有外部工具的API来利用它们的功能。TheHive有一个webhook功能，它可以在发生任何更改或事件时通知其他工具。这些强大的功能使自动化成为可能。\n  \n\n剧本Playbooks:\n剧本是在任何事件发生时应以特定方式执行的一系列步骤。\n自动化:\n安全分析师可以设计和开发剧本来自动化安全告警分析和响应。有了TheHive和Cortex中可用的API和Webhook功能，它们的功能可以通过任何工作流自动化工具来创建这些脚本。\n在我写这篇博客的时候，开源社区使用了一些工具。其中包括n8n、nodered、shuffle和tines。\nn8n的示例脚本如下所示。\n\n结论我们已经看到了如何使用开源工具构建一个完全自动化和自由的SOAR解决方案。使用开源工具的好处在于，开发人员可以很容易地修改它们以满足您的需求。此外，还有一个使用、改进和支持这些工具的开源社区。\n","slug":"sec/TheHive/用TheHive实现SOAR","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"SOAR,TheHive","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"hive、Cortex和MISP可以很好地协同工作，如果你已经阅读了我们6月- 12月17日的路线图，我们的产品与事实上的威胁共享平台的集成将在几个月内变得更好。\n在上周的第一次会议演示中，我们展示了一张图片，我们将在这里使用它来解释这三种开源和免费产品是如何相互集成的。\n\n\n一、TheHive\nTheHive是一个安全事件响应平台(SIRP)。它可以接收来自不同来源的警报(SIEM、id、电子邮件)。等等)通过它的REST API。这就是警报 feeder发挥作用的地方。\n1.1警报feeder\n可以将警报 feeder看作一个专门的程序，它使用一个安全事件(SIEM警报、电子邮件报告、IDS警报等)，解析它并输出一个警报，该警报通过hive4.py发送给TheHive，我们提供的Python库可以与TheHive的REST API进行交互。\n我们不提供这样的 feeder，但发展他们应该是直接的。如果没有，告诉我们，我们会尽最大努力帮助你。\n1.2警报\n任何发送到TheHive的警报都会显示在警报窗格中。除了上面提到的源之外，如果您将TheHive配置为连接到一个或多个MISP实例，新的或更新的MISP事件也会出现在该区域。如果是这样，TheHive将轮询那些MISP实例在每个间隔寻找新的或更新的事件。如果有，TheHive将生成一个警报，它将结束在警报窗格。\n\n警报可以被忽略，标记为已读、预览和导入。当一个警报被导入时，它就变成了一个需要进行调查的案例。\n二、案例\n\n案例可以从警报生成，也可以从头创建。它被细分为任务(识别、遏制、消除、检查代理日志，等等)和可观察任务(IP地址、散列、电子邮件地址、域名、url……)。当分析人员处理任务时，他们会添加日志。在TheHive的术语中，日志是文本条目，其中可能包含附件，以帮助分析人员记录他们所做的事情。可以使用Markdown或富文本编辑器编写日志。\n2.1案例模板\n在处理属于给定类别(DDoS、Malspam、APT……)的情况时，不需要反复添加相同的任务。您可以创建添加任务的自定义模板，如下所示。这在处理警报时非常有用，因此在导入警报时，可以选择想要应用的案例模板，这样就可以了!\n\n2.2可观测的对象\n可观察对象可以被标记为IOCs并进行分析。当调查进展顺利或完成时，您可能希望与合作伙伴和同行共享结果IOCs或其中的一部分。在2017年9月，TheHive将支持将数据导出到MISP。在此之前，您仍然可以将IOCs导出为文本、CSV或与MISP兼容的格式，您可以使用freetext编辑器将它们添加到MISP实例中。Hive可以导出IOCs/observable in protected (hxxps://www[.] .)或者unprotected模式。\n每个可见目标必须有一个TLP(红绿灯协议)级别。默认情况下，任何添加的观察对象都被认为是TLP:AMBER。请注意，TLP是考虑到一些分析仪。等等!分析程序?\n三、Cortex\nCortex是我们独立的分析引擎，是Thehive和MISP的完美伴侣。分析人员可以使用它的Web UI来分析可观察数据，在这种情况下，一次只能提交一个可观察数据。Web UI确实应该被限制为在TheHive(或备用SIRP)中创建案例之前对可观察对象进行快速评估。当您使用它的REST API时，皮层的功能才真正发挥作用。Thehive与Cortex进行原生对话(就像MISP那样)。此外，Thehive可以利用一个或多个Cortex服务器。\n\n3.1分析程序\n在写这篇文章的时候，Cortex有23个分析仪，总共有39种口味，很快就会有更多。\n分析器可以用Linux支持的任何编程语言编写，尽管我们当前所有的分析器都是用Python编写的。这是因为我们提供了一个名为Cortexutils的Python库，其中包含一组实用工具类，使得用Python编写分析器更加容易。\n3.2口味\nVirusTotal、PassiveTotal或DomainTools等分析工具可以提供不同的分析服务。让我们以VirusTotal为例。您可以扫描一个文件或URL。这是一个味道（Flavors）。您还可以从VirusTotal.com上获得关于文件、散列、域或IP地址的最新报告。这是第二种口味。所以病毒分析仪有两种口味。\n\nPassiveTotal怎么样?它有8种风格:独特的解析查找、SSL证书历史查找、恶意软件查找、被动DNS查找、数据丰富查找、SSL证书详细信息查找、OSINT查找和WHOIS数据查找。\n3.3MISP搜索分析器\n在这一点上，我们需要提到一个特殊的分析器，它可能会造成一些混乱，如果没有正确理解:MISP搜索分析器。多亏了它，Cortex有能力在MISP实例中搜索可观察到的事物，就像从分析仪到MISP的箭头所代表的那样。\n\n当在一个事件中发现一个被观察到的对象时，Cortex将返回被发现的记录的数量(即发现被观察到的对象的事件的数量)，以及与这些事件的链接的列表和附加的数据。\n\n  \n\n\n\n当前版本的MISP搜索分析器只能在一个MISP实例中进行搜索，但是在不久的将来，它将能够支持多个MISP实例。\n3.4MISP扩展模块\n除了它自己的分析器(包括上面描述的MISP搜索)，Cortex还可以调用MISP扩展模块。MISP通常使用这些来丰富事件中的属性，但皮层也可以利用它们来分析观察到的信息。\n在天然皮层分析仪和MISP扩展模块之间有一些重叠。在选择本机分析器或扩展模块时，我们强烈建议您选择前者。扩展模块在默认的皮层结构中处于失活状态。\n3.5作业\n当您提交一个observable进行分析时，Cortex将创建一个作业，如果成功，它将生成一个JSON格式的分析报告。由于我们提供免费的报告模板，TheHive能够解析这些结果并以一种友好的方式显示它们。因此，当你从Thehive向皮层提交观察结果时，你会得到一份简短(或迷你)的报告和一份冗长的报告。第一个可以被认为是一个非常小的执行分析师摘要，而第二个提供了更多的洞察力和细节。\n结论\nTheHive、Cortex和MISP是三款开源免费的产品，它们可以帮助你对抗威胁，让你远离“怪兽”。\nTheHive，作为一个SIRP，允许你以协作的方式快速调查安全事件。几个分析师可以同时处理任务和案例。虽然可以从头开始创建案例，但由于alert feeders使用多个源生成的安全事件，并使用hive4py Python库将它们提供给TheHive，因此TheHive可以从不同的源接收警报。TheHive还可以同步到一个或多个MISP实例，以接收新的和更新的事件，这些事件将出现在警报窗格中，与其他来源生成的所有其他警报一起。然后，分析人员可以预览新的警报，以决定是否需要对其采取行动。如果是，他们可以使用模板将其转换为调查案例。\n为了分析在调查过程中收集到的观察结果和/或从MISP事件导入的观察结果，hive可以依赖于一个或多个皮层分析引擎。Cortex是我们开发的另一款独立产品，其唯一的目的是让你能够大规模地分析可观测数据，这要归功于它大量的分析仪、MISP扩展模块以及你可能已经开发的其他任何分析仪。Cortex有一个REST API，可以用来增强其他安全产品的功能，比如“分析”软件、备用的sirp或MISP。\n这个非常受欢迎的威胁共享平台确实可以丰富属性，这多亏了Cortex，因为它与它有一个天生的集成。几个月后，您还可以将案例从TheHive导出为MISP事件，与同行和合作伙伴共享。\n如果你愿意分享，你就会关心我们共同的使命，保护我们的数字资产不受损害。所以让我们团结一致。\nhttps://blog.thehive-project.org/2017/06/19/thehive-cortex-and-misp-how-they-all-fit-together/\n","slug":"sec/TheHive/TheHive与Cortex和MISP它们是如何组合在一起的","date":"2024-03-14T06:15:59.767Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"2136659a0ceec5506b9726a200666f21","title":"Thehive中调查案例管理","content":"Thehive中调查案例管理我花了很长时间寻找一个案例管理系统，我认为它适合分析人员实际执行调查的构造。大多数案例管理系统实际上只是经过改造以适应安全用例的帮助台ticket系统。这是我在soc使用补救、RTIR或OTRS等工具时经常看到的。去年11月，法国CERT Banque de France (CERT BDF)的一组研究人员发布了一个名为thehive的ticket管理系统。该项目的作者将thehive描述为一个“开源和自由安全事件响应平台，设计使生活更容易的SOCs, CSIRTs, CERTs，和任何信息安全从业者处理事件，需要被调查和迅速行动。“我会简单地描述thehive作为一个案件管理系统的目的，以促进调查安全事件。我非常喜欢使用thehive，以至于我实际上把它整合到我的调查理论课程中，我教人们如何接近调查和追捕坏人。在这篇文章中，我想讨论一下这个thehive的一些特点以及为什么我如此喜欢它。\n一、架构和安装\n这个thehive是用Scala编写的，使用ElasticSearch在后端存储和访问数据。前端使用AngularJS和Bootstrap。还提供了许多REST API端点来支持集成和批量操作。\n\n\n你会在上面的图表中看到Cortex 。“Cortex ”允许用户通过一系列基于python的分析器向流行的开源情报工具提交可观察的和破坏的指标。最终，它是一个独立的工具，有自己的代码库，但是hive和Cortex就像豌豆和胡萝卜一样紧密相连，所以你会在hive文档中看到很多。下面我将提供的安装命令将实际地将它们作为单个集成容器安装。\n二、案例管理\nthehive的核心结构是调查案件。像这样是因为这个案例也是大多数安全调查的核心结构，无论你是在_审查警报，逆向工程恶意软件，还是在处理一个已经宣布的事件。case构造没有提供很多花哨的东西，但这没关系，因为我认为它没有必要这样做。很多ticket系统是为太多的大师服务的，但很快就会变得太通用而毫无用处_。这里的情况不是这样的。\n\n特别要注意的是，您可以将标签添加到案例中，以便快速搜索和过滤。您还可以跟踪TLP级别，这有助于管理和促进数据共享。这是一个很好的功能，真正展示了thehive是如何为调查跟踪定制的。你放入一个案例的所有数据都可以很容易地从屏幕顶部的搜索栏中搜索到。这使得确定您当前观察到的活动是否在以前的情况下出现变得非常容易。\n\n三、任务跟踪\n一旦创建了案例，就可以创建、分配和跟踪任务。任务可以是任何东西，但我建议使用它们来跟踪为回答调查问题而采取的行动。例如，如果您正在调查一个exploit kit感染，一个常见的问题可能是，“在生成警报之前，系统在做什么?”要回答这个问题，您需要查看来自您拥有的任何数据源的证据，以获得答案。因此，任务可以是“检查HTTP代理数据，以确定主机在发出警报之前的10分钟内正在做什么”。\n除了寻找答案之外，任务还有助于跟踪遏制、根除和补救事件。您可以创建用于禁用用户帐户、隔离系统、将映像部署到系统或提供用户安全提醒咨询的任务。\n\n任务，像案例一样，有分配的概念。因此，每个任务都可以单独分配给分析师来执行。默认情况下，一个任务没有所有者，除非有人点击它，或者从顶部菜单栏的等待任务队列中“获取”它。这有效地创建了一个任务队列，分析人员可以查看该任务队列，以帮助简化他们的工作负载。队列可以根据任意数量的条件进行筛选，如特定标记、案例号、任务名称或关键字。指定给您的任务将出现在顶部菜单栏的My Tasks队列中。\n四、案例模板\n随着SOC的发展，_定义剧本以帮助分析人员始终如一地进行具有共同属性的调查变得至关重要_。例如，最初调查一系列失败的密码尝试或钓鱼电子邮件时所采取的大部分步骤通常都是相同的。如果您能够定义这些步骤，那么您将在培训新的分析师和确保大多数调查在一个水平的基础上开始方面有一个良好的开端。thehive提供了一个独特的案例模板系统，允许你定义常见的调查和预填充案例元数据和任务。\n\n\n在上面的示例中，我定义了一个用于调查与exploit kit活动相关的模板。现在，每当我创建一个新的案例时，我都可以选择这个模板，您在那里看到的所有信息都将预先填充到案例细节中。这里的真正强大之处在于能够自动创建一系列在生成案例时应该完成的任务。这基本上为你安排了调查剧本。这样，您就可以获得自动填充等待任务队列的额外好处，以便其他分析师可以进入调查或开始完成遏制和根除任务。这是我最喜欢的工具特性。\n五、协作\n任何案例管理系统的一个关键特性都应该是协作，而thehive在这里达到了这个目的。每个使用thehive的分析师都有自己的帐户，用来记录他们在工具中所做的任何动作。用户可以拥有案例和/或任务。我特别喜欢的一件事是，一旦创建了一个案例，几乎与之相关的任何行动都会被记录下来，从而创建一个审计跟踪。审计跟踪显示在单个案例屏幕的右侧，就像在我已经分享的几个图片中看到的那样。\n六、可观察性和分析性\nthehive允许您在案例的上下文中为有趣的观察创建单独的条目。可观察对象是任何有趣的数据工件，thehive内建了许多常见的可观察类型。这包括IP地址、域名、HTTP uri等。当然，您也可以定义自己的类型，这使得此功能非常灵活。\n跟踪可观测对象有多个好处。最明显的一点是，您可以在以后的调查中搜索它们，以引入额外的上下文。您还可以导出它们，以便稍后导入到黑名单、白名单或检测机制中。最后，您可以使用内建的cortex集成自动提交观察到任何数量的OSINT研究站点。这是一个非常简单的过程，主要只需要为将要使用的每个服务输入API键。现有的一些集成包括被动总量、病毒总量和域工具。\n七、API和集成\n因为thehive是建立在一系列开放的API之上的，所以它在与其他工具的集成方面非常灵活。作者制作了非常好的API文档:https://github.com/CERT-BDF/TheHive/wiki/API%20documentation。您将看到文档提供了请求格式化的多个示例，以及几个用例。这包括查询、创建和操作用例、任务和可观察对象的能力。这有直接的实际利益。\n考虑一个运行基于IDS的签名的场景。任何时候，一组与exploit kit活动相关联的特定规则生成警报时，您都可以使用API来创建一个新的case，该case使用的模板与我前面展示的模板类似，它是专门为调查与exploit kit相关的活动而设计的。使用这种方法，您不仅完成了简单的自动化，还基于您开发的剧本创建了一个工作流。当您或其他分析师查看新的警报时，任何与exploit工具包相关的内容都已经有了一系列创建并等待您完成的任务。对于经验丰富的分析师来说，这是一个节省时间的工具，对于不知道下一步该做什么的年轻分析师来说，这也是一个教学工具。\n\n\n除了api之外，thehive还可以与MISP集成，你也可以编写用于cortex的自定义分析程序。同样，这里有很多选择。\n八、结论\n这篇文章讨论了一些我最喜欢的thehive特性，以及它们在实践中的应用。还有很多其他的特性，比如报告和度量，我在这里没有讨论，所以一定要自己检查一下。在SOCs中使用的许多工具都是在它们中诞生的。然而，这并不是一件容易的事情。我所接触过的每一个SOC都是不同的，而且大多数情况下，可能从这些SOC中产生的工具都不够灵活，无法适应存在于另一个组织中的工作流。thehive的开发者已经达到了一种微妙的平衡，即创建一个足够专注于交付即时用例的工具，同时仍然是广泛关注和灵活的，以适应不同的用例。如上所述，这就是我在我的调查理论课程中使用thehive的原因，也是为什么我将\nInvestigation Case Management with TheHive，https://chrissanders.org/2017/03/case-management-the-hive/\n","slug":"sec/TheHive/TheHive中调查案例管理","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"TheHive","author_index":"安全书"},{"id":"1e6eda4712b64ed656f315e95c33e3f9","title":"scirius规则集管理工具安装和使用","content":"scirius规则集管理工具安装和使用scirius源代码网址：\nhttp://www.github.com/StamusNetworks/scirius\nGit Clone代码到本地：\ngit clone http://www.github.com/StamusNetworks/scirius\nscirius源码文档：\nhttps://github.com/StamusNetworks/scirius/wiki\n1.简介\nScirius Community Edition是一个专用于Suricata规则集管理的web界面。 它处理规则文件并更新相关文件。\nScirius  CE由stamus networks开发，遵循GNU GPLv3.\n2.特征\nScirius 可以构建由不同来源组成的suricata规则集合。来源或提要可以从OISF发布的公共来源中挑选，也可以是自定义的。Scirius将通过在应用你的转换来处理刷新源和组成规则集。可以为每个规则或类别级别进行转换，例如禁用规则或应用阈值（仅降低噪声）。Scirius还提供有关规则活动的统计信息，以提供信息并促进调整。\n3.安装和设置\n（3.1）安装scirius CE\nScirius CE是一个用Django编写的应用程序， 可以像其他 Django 应用程序一样安装它。\n它需要Django 1.11，但是尚不支持Django 2.0.  Scirius CE还使用webpack来构建CSS和JS包。\n(3.1.1) 安装依赖\ncentos 7上安装，执行： yum  install  python-pip python-devel\n下载scirius：git  clone  http://www.github.com/StamusNetworks/scirius\n切换到scirius目录下:  cd  scirius/ ,  然后安装django和依赖项,执行: pip  install -r  requirements.txt \n如果出现:ERROR: requests 2.21.0 has requirement urllib3&lt;1.25,&gt;=1.21.1, but you’ll have urllib3 1.25.1 which is incompatible\n建议升级pip install –upgrade urllib3\n 要使用处理suricata restart的suri _reloader脚本，还需要安装pyinotify, 执行：pip  install  pyinotify\n安装gitdb模块、GitPython模块 ：pip install gitdb、pip install gitpython==0.3.1-beta2\n对于npm 和 webpack，需要安装稳定版本的npm和webpack 版：\nyum install npm \n全局安装webpack 和webpack-cli:\nnpm install  &#119;&#101;&#98;&#112;&#x61;&#x63;&#107;&#x40;&#51;&#46;&#49;&#x31;  -g\nnpm install  webpack-cli  -g\n建议也局部安装一次:\nnpm install &#x77;&#x65;&#98;&#x70;&#97;&#x63;&#x6b;&#64;&#51;&#x2e;&#x31;&#x31; –save-dev\nnpm install webpack-cli –save-dev\n更新依赖:   npm install \n(3.1.2) 安装scirius\nstep1  下载scirius：git  clone  http://www.github.com/StamusNetworks/scirius\nstep2 切换到scirius/hunt 下执行：cd  scirius/hunt 、 npm  install 、npm run build \n如果此时失败,提示为: “file”: “node_modules/patternfly/dist/sass/_patternfly.scss”, 是出于路径问题,需要增加对应路径.在 hunt/package.json文件中,在字段”scripts”增加路径:\n  –include-path=node_modules/bootstrap-sass/assets/stylesheets/\n–include-path=node_modules/font-awesome-sass/assets/stylesheets/\n重新执行npm run build\n(3.1.3) 运行scirius CE\n从源目录内部,可以启动Django数据库 : 切换到上级目录cd  ../,执行python manage.py migrate \n默认情况下,身份验证在scirius中,因此您需要创建超级用户账户: python manage.py createsuperuser\n在启动应用程序之前，您需要通过运行webpack来构建bundle:   webpack\n如果出现Cannot read property ‘thisCompilation’ of undefined报错,可以按下面步骤解决:\n先卸载:npm uninstall –save-dev extract-text-webpack-plugin\n在重新安装:npm install –save-dev extract-text-webpack-plugin\n再次执行:webpack\n(3.1.4) scirius CE 尝试\n尝试Scirius CE的最简单方法之一是运行Django测试服务器 ; python manage.py runserver .通过localhost:8000来访问地址.\n如果出现:/usr/lib/python2.7/site-packages/requests/init.py:91: RequestsDependencyWarning: urllib3 (1.25.1……)\n则卸载urllib3和chardet,再重新安装requests,命令如下:\npip uninstall urllib3\npip uninstall chardet\npip install requests\n如果您需要应用程序来侦听可访问的地址，您可以运行类似的地址:python manage.py runserver  0.0.0.0:8000\n如果通过浏览器访问时出现：\nInvalid HTTP_HOST header: ‘192.168.111.123:8000’. You may need to add u’192.168.111.123’ to ALLOWED_HOSTS.\n修改scirius下settings.py文件：\nALLOWED_HOSTS = [‘*’]\n(3.2) suricata 设置\nScirius CE正在生成一个包含所有激活规则的规则文件。编辑Suricata对象时，必须设置要生成此文件的目录以及要复制的规则集的关联文件.Scirius CE不会触及您的Suricata配置文件suricata.yaml。所以你必须更新它以指向Scirius CE设置数据的目录。\n(3.2.1) 如果您只使用Scirius CE生成的规则，则应该在suricata.yaml文件中配置\ndefault-rule-path:/path/to/rules\nrule-files:\n    -scirius.rules\n(3.2.2) 要使用“ 使用IP信誉”而不是“组”功能，您还需要使用\nreputation-categories-file: /path/to/rules/scirius-categories.txt\ndefault-reputation-path: /path/to/rules\nreputation-files:\n    - scirius-iprep.list\n(3.2.3) 要与Scirius CE交互，需要检测何时创建/path/to/rules/scirius.reload文件，在这种情况下, 需要重新加载或重新启动Suricata，并在完成后删除重新加载文件.\n一种可能的方法是使用在suricata/scripts目录中的suri_reloader,。语法suri_reloader可以类似于:\nsuri_reloader -p  /path/to/rules -l  /var/log/suri-reload.log   \n如果此时出现：\nWARNING:root:No daemon support available, install python-daemon if feature is needed。\n安装python-daemon： yum install  python-daemon\n使用-h选项获取完整的选项列表。请注意，suri_reloaded 使用该service命令重新启动或重新加载Suricata。这意味着您需要一个init脚本才能使其正常工作。\n(3.3)与Elasticsearch链接\n如果您将Suricata与Eve日志记录和Elasticsearch一起使用，则可以获取有关显示有关Suricata信息的页面中显示的签名的信息,您还可以获取有关特定规则的图表和详细信息.\n要设置Elasticsearch连接，在目录下编辑settings.py或创建local_settings.py文件scirius以设置该功能。\n在settings.py( 路径scirius/scirius/settings.py)中变量名称USE_ELASTICSEARCH设置为True，则激活Elasticsearch 。Elasticsearch的地址存储在 ELASTICSEARCH_ADDRESS变量中并使用该格式IP:port. \n注意:Suricata的名称在Elasticsearch（在对象编辑期间设置）必须等于host事件中的密钥。它也可以在这里编辑：scirius - &gt; suricata - &gt;edit。\n在logstash端，唯一必要的是确保@timestamp等于Suricata事件中提供的时间戳值。为此，如果Suricata事件属于SELKS类型，则可以使用:\nfilter{\n        if[type]==”SELKS”{\n            date{\n                match=&gt;[“timestamp”,”ISO8601”]\n                }\n             }\n }\n这对于避免Scirius CE生成的图形出现故障是必要的.\n(3.4)与Kibana的链接\n如果您使用的是Kibana，可以通过单击左上角的图标获取指向仪表板的链接.要激活该功能，您需要编辑settings.py文件:\nKIBANA_URL =  “http://localhost:9292&quot;\nUSE_KIBANA = True\n4.scirius使用\n(4.1)账户管理\nScirius CE在默认情况下使用身份验证。 你将需要超级用户才能创建和编辑scirius用户。账户管理允许用户管理 - 编辑/创建和删除不同的用户帐户，更改用户详细信息和/或密码。在此菜单中，您还可以查看当前可用用户的列表以及这些帐户拥有的设置.\n(4.1.1) 添加/创建用户\n要添加/创建新用户：在左上角单击Stamus Networks logo.在下拉 选项中选择Manage Accounts.此时跳转到用户管理界面.\n\n图一\n在用户管理界面,在Action下面,点击Add.\n(4.1.2)编辑用户\n在用户管理界面,在用户列表中,点击你要编辑的用户.此时左边Actions出现三个菜单:Edit user,Change user password,Delete user,点击Edit user,进行用户编辑\n(4.1.3)修改用户密码\n在用户管理界面,在用户列表中,点击你要编辑的用户.此时左边Actions出现三个菜单:Edit user,Change user password,Delete user,点击,Change user password,进行用户密码修改.\n(4.1.4)删除用户\n在用户管理界面,在用户列表中,点击你要编辑的用户.此时左边Actions出现三个菜单:Edit user,Change user password,Delete user,点击,Delete user,,删除用户.\n(4.1.5)用户权限\n有三个级别的权限：\na.允许活动用户连接到Scirius，但只具有读取权限\nb.专业用户可以设置Scirius(应用编辑，规则集推送，…）\nc.超级用户具有完全不受限制的访问权限，包括在本地数据库中编辑用户身份验证设置和用户创建.\n在用户管理界面,在用户列表中,点击你要授权的用户.此时左边Actions出现三个菜单:Edit user,Change user password,Delete user,点击Edit user,进行用户编辑,该编辑栏有Active , Staff User and Superuser.通过复选框启用/禁用设置权限级别.\n(4.2)规则集管理\n(4.2.1)规则集处理的哲学\nScirius允许您定义规则集,它定义了Stamus Networks Suricata探测器关于检测和检查的一套规则。您可以拥有任意数量的规则集,且可以将特定数据附加规则集到许多设备.\n规则集由在不同源中选择的组件组成。它可以转换（例如删除某些规则）、更改内容并将在网络探测器在应用规则集中的签名中之前推送过去。\n 源是为Suricata提供信息的一组文件。 例如这可以是从官方ET URL（或任何其他URL）下载或在本地上载的EmergingThreats规则集。当包含签名的Source在多个文件中分割时，每个单独文件中的签名集称为类别。\n（4.2.2）用户操作记录\n用户操作记录了规则集管理中执行的所有操作。可以使用Stamus图标下的菜单Actions history访问其历史记录。每个操作都有可选注释，以允许用户相互交互。\n（4.2.3）规则集管理\n规则集管理包含两个主菜单选项：Sources和Rulesets。因此，要创建规则集，必须创建一组Sources然后将它们链接到规则集。完成此操作后，您可以选择要使用的源的哪些元素。例如，对于签名规则集，您可以选择要使用的类别以及要禁用的单个签名。\n定义规则集后，可以将其附加到检测器。为此，只需简单编辑检测器对象并在列表中选择该规则集。\n（4.2.4）创建源\n有两种方法可以创建Source。第一个是使用预定义的公共源，第二个是通过手动添加。\n(4.2.4.1)公共源\n使用预定义的公共源，转到 Sources -&gt; Add public source（Add public source 位于左侧菜单栏Actions下 ）。选择一个来源，然后单击Enabled按钮。在弹出窗口中，您可以编辑源名和要添加源到哪个规则集。在某些情况下，会出现一些字段，例如要输入的规则编辑器提供的密钥。\n(4.2.4.2)手动添加\n手动创建源转到Sources -&gt; Add custom source（Add custom source 位于左侧菜单栏Actions下 ）。然后设置不同的字段并单击Submit。需要手动填写名字、方法、数据类型。\n4.2.4.2.1 名字\n按需求自己定义。\n4.2.4.2.2方法\n（1）选择HTTP URL，将看到Optional authorization key字段，此字段是可选字段，可用于针对远程服务器对Scirius进行身份验证。它为HTTP请求添加了一个授权标头，允许对大量第三方服务进行身份验证。这可以特别用于从MISP实例导入签名。有关更多信息，请参阅 MISP文档。使用Optional authorization key也支持使用私有Github存储库来托管签名，正如Github文档中所解释的那样。Optional authorization key应该填充token TOKEN字段，第二个TOKEN是在开发人员设置页面中在Github配置文件中创建的用户个人访问令牌。\n（2）upload\n上传一个规则文件\n4.2.4.2.3数据类型 \n（1）Signatures files in tar archive 的来源必须遵循一下一些规则：\n-它必须是tar存档\n-所有文件必须位于rules目录下\n例如，如果要为Suricata 4.0获取ETOpen Ruleset，可以使用:\n名称：ETOpen规则\nURI：https://rules.emergingthreats.net/open/suricata-4.0/emerging.rules.tar.gz\n（2）Individual signature file必须是包含签名的单个文件.\n例如，如果您要使用来自abuse.ch的SSL黑名单，您可以使用\n名称：SSLBL abuse.ch\nURI：https://sslbl.abuse.ch/blacklist/sslblacklist.rules\n（3）Other content数据类型的来源必须是单个文件。它将使用其名称作为文件名复制到Suricata规则目录.\n（4.2.5）更新源\n要更新源，首先需要选择它。为此，请转到Sources然后在数组中选择所需的Source。然后，您可以单击侧栏菜单中的Update。此步骤可能需要很长时间，因为它可能需要一些下载和大量解析。更新后，您可以通过下拉链接中的链接浏览结果。\n（4.2.6）创建规则集\n要创建规则集，请转到Ruleset -&gt;Action-&gt; Add，然后设置规则集的名称并选择要使用的源并单击Submit。您可以选择要使用的源和要应用的转换。有关它们的更多信息，请参阅后面的规则转换。\n（4.2.7）更新规则集\n要更新规则集，首先需要选择它.为此，请转到Ruleset然后在数组中选择所需的Ruleset。然后，您可以单击侧栏中Update Ruleset菜单。此步骤可能需要很长时间，因为它可能需要下载不同的源和重度解析。当更新完毕后，弹窗将关闭。\n（4.2.8）编辑规则集\n要编辑规则集，首先需要选择它。为此，请转到Ruleset然后在数组中选择所需的Ruleset。然后，您可以单击侧栏中Edit Ruleset菜单.此时Action菜单中有不同的操作：\n-Edit sources，编辑源：选择要在规则集中使用的签名源\n-Edit categories，编辑类别：选择要在规则集中使用的签名类别\n-Add rule to suppressed list，将规则添加到非启用列表：如果规则在此列表中，则它不会是生成的规则集的一部分\n-Remove rule from suppressed list，从抑制列表中删除规则：这将从前面提到的列表中删除规则，从而在规则集中重新启用它\n（4.2.8.1）编辑源\n要选择要使用的源，只需通过复选框选择它们，然后单击Update sources。请注意，选择要启用的类别是添加新源时过程的下一步。\n（4.2.8.2）编辑类别\n要选择要使用的类别，只需通过复选框选择它们，然后单击Update categories。\n（4.2.8.3）将规则添加到不启用列表\n使用搜索字段查找要删除的规则，可以使用签名中的SID或任何其他元素。Scirius将在签名定义中搜索输入的文本，并返回规则列表。然后，您可以通过单击复选框并单击Add selected rules to suppressed list来删除它。\n（4.2.8.4）从不启用列表中删除规则\n要从被抑制列表中删除规则，只需在数组中查找到它们并单击Remove select rules from suppressed list即可。\n（4.2.9）抑制（取消）和阈值处理\n当需要最小化警报数时，可以通过阈值控制特定签名的警报号 。例如，通常阈值处理来自该签名的源或目标IP的每分钟最多1个警报。\n当需要抑制警报时使用抑制 。 也就是说，不从该源或目标IP生成针对该特定签名的警报。\n（4.2.9.1）取消警报\n从任何表中显示的警报列表，如规则集中，单击sid需要抑制的警报的特定内容，这将显示规则详情页面。在这里，您可以单击左侧菜单Action 下的Edit rule，然后在同一位置的菜单中选Suppress rule。在规则页面中，通过位于Ip and Time stats或Advanced Data选项卡上并单击Ip地址旁边的x，还可以从rule页面到达禁止创建页面。\n在新页面上，如果对该特定签名已经存在某些阈值或抑制，您将被告知。可用字段是：\nRuleset：适用于此配置的规则集\nTrack by：（必填字段）按源或目标IP进行跟踪\nNet：  IP和/或特定网络的有效性\n选择规则集，源或目标（针对该特定IP），然后单击+Add。\n您还可以选择对整个网络强制执行抑制和/或使用IP列表。您可以Net像这样在字段中添加：\n10.10.10.0/24,1.1.1.1,2.2.2.2\n您可以通过单击Rules info选项卡来验证抑制。您将获得有关不同（如果有）阈值和抑制配置状态的信息显示。或者，您也可以通过单击Rulesets并选择已应用特定抑制或阈值的规则集来查看该视图。\n要使抑制变为活动状态，您需要Push更新探针的规则集。有关完整说明，请参阅SEE 上的updates -appliances-ruleset和Scirius CE上的更新规则集。\n（4.2.9.2）阈值警报\n从显示警报列表的任何表中，单击sid需要抑制的警报的特定内容。这将显示规则页面。在那里，您可以单击左侧菜单Action下的Edit rule，然后在同一菜单中选择Threshold rule。在rule页面中，您还可以通过位于Ip和Time stats或Advanced Data选项卡上，并单击Ip地址旁边(x旁边)的向下箭头，从而到达阈值创建页面。\n在新页面上，如果对该特定签名已经存在某些阈值或抑制，您将被告知。可用字段是：\nType  阈值的类型。有可能：\n            limit  将警报限制为最多“X”次。\n            threshold  规则生成警报之前的最低阈值。\n            both   应用限制和阈值。\nTrack by （必填字段）按源或目标IP进行跟踪\nCount  生成警报的次数。\nSeconds  在那个时间跨度内。\nRuleset  适用于此配置的规则集\n您可以通过单击选项卡Rules info来验证阈值。您将获得有关不同（如果有）阈值和抑制配置状态的信息显示。或者，您也可以通过单击Rulesets并选择已应用特定抑制或阈值的规则集来查看该视图。\n要使阈值变为活动状态，您需要Push更新探针的规则集。有关完整说明，请参阅SEE 上的updates -appliances-ruleset和Scirius CE上的更新规则集。\n（4.2.10）规则转换\n有三种类型的规则转换。\n第一个Action，允许更改特定规则的操作 -  丢弃（drop），拒绝（reject ）或文件存储（filestore）。请注意，这些操作需要有关规则和规则关键字语言的高级知识。\n第二个是Lateral，它修改规则以检测横向移动。\n第三个是Target，它通过添加target关键字来更新签名。\n转换与规则集相关。但是它们可以在规则集上全局设置，也可以在类别或特定规则上设置。因此很容易处理异常。\n（4.2.10.1）动作转换\n一旦您有一个特定的规则，您想要转换 - 在规则的详细信息页面的左侧面板Actions下单击 Transform rule。您将看到一些选择。\n选择形式的转换类型：\ndrop - （IPS模式）将规则从alert（警报）转换为丢弃 - 也需要事先明确设置和配置IPS模式。\nreject - （IDPS / hybrid）会将规则从alert（警报）转换为reject，这意味着当触发RST /或dst不可达数据包时，将发送到src和dst IP。\nfilestore - 将仅转换那些具有允许文件提取的协议的规则 - 例如alert http…或alert smtp\n选择您希望添加/注册新转换的规则的规则集。\n注意：特定规则只能转换一次。\n注意：要使用此drop功能，您需要具有有效的IPS设置。\n完成所需的选择后，您可以添加注释以进行问责，然后单击Valid(生效)。您将在Information选项卡中获得有关已转换规则的详细信息。您可以查看并确认转换及其添加的规则集以及任何注释。\n只能转换活动的规则。如果规则在特定规则集中未处于活动状态，则它将不具有左侧面板上可用的转换或抑制/阈值选项。要使其处于活动状态，您可以通过单击左侧面板菜单上的Toggle availability选项来切换该规则的可用性。\n规则详细信息页面的历史记录选项卡将对已转换的规则进行任何注释和更改以进行跟踪。\n（4.2.10.2）横向移动\n签名通常使用EXTERNAL_NET和HOME_NET变量编写，这意味着如果流的两端都在HOME_NET中，它们将不匹配。因此，未检测到横向运动。这种转换将EXTERNAL_NET改为任何能够检测横向运动的。\n该选项可以有三个值：\nNo：没有替换\nYes：EXTERNAL_NET被任何替换\nAuto：如果签名验证某些属性，则完成替换\n（4.2.10.3）目标关键字\n自Suricata 4.0起可用，目标关键字可用于指示触发签名的流的哪一侧是目标。如果存在此密钥，则会增强相关事件以包含攻击的源和目标。\n该选项可以有四个值：\nAuto：如果存在目标，则使用算法确定目标\nDestination：目标是目标IP\nSource：目标是源IP\nNone：没有进行转换\n5.hunt\n5.1 介绍\nHunt是一个专门用于签名和事件可视化和调优的界面。它可以通过Hunt链接从Scirius Enterprise的顶级菜单中获得。\nHunt使用向下钻取方法来选择事件。通过单击字段值旁边的放大镜图标，可以简单地添加警报事件中包含的协议元数据的过滤器。\n一旦定义了复合过滤器，用户就可以基于它采取行动。该操作将应用于与复合过滤器匹配的所有未来事件。\n在Community Edition中，只能使用可在suricata中用于创建抑制和阈值的字段。目前仅限于src_ip和 dest_ip。\n在Enterprise Edition中，Stamus探针可以对使用任意协议元数据的过滤器应用操作。\n5.2 页面\n可以通过右侧菜单中的单击访问页面。从一个页面跳转到另一个页面将保持过滤器不受影响，允许分析师在可用的不同视图之间切换。\n5.2.1 仪表板（Dashboard）\n此页面显示一个仪表板，其中包含可在警报中看到的最有趣的数据和协议元数据的统计信息。\n5.2.2 签名（Signatures）\n如果已创建签名ID的过滤器，此页面将显示签名或签名页面的列表。\n5.2.3提醒（Alerts）\n此页面将列出单个警报事件。可以展开事件以查看包括有关它的元数据的所有详细信息。\n5.2.4动作（Actions）\n此页面显示操作列表。列表已排序，过滤器按升序应用。\n可以重新排序动作以调整过滤器的相应优先级。为此，只需单击操作右侧的三个点并填写表单即可\n5.2.5历史（History）\n此页面显示用户在Scirius实例上执行的修改的历史记录。\n5.2.6 主页（home）\n链接到Scirius主页。\n5.3. 动作\n5.3.1 抑制(取消)\n抑制操作将在匹配事件到达存储之前将其删除。\n在Scirius CE中，需要具有签名ID和源或目标IP的过滤器才能创建操作。\n对于Stamus探针，可以使用任何字段。\n5.3.2 阈值\n阈值操作仅在达到定义的阈值时保持警报。\n在Scirius CE中，需要具有签名ID的过滤器才能创建操作。\n在Scirius EE和Stamus探针中，可以使用任何字段。\n5.3.3 标签\n一个标签可以根据过滤器进行设置。它将在所有匹配事件上设置，并允许轻松分类。\n目前有2个值：\nInformational，信息：信息足够好，不会被压制，以防万一\nRelevant，相关：事件是相关的，需要进行调查\n所有未标记的事件都可以在Untagged标签下找到。如果正确设置了已定义的操作，则应该是新签名或未引用的行为。所以应该进行调查和分类。\n标记操作仅适用于Scirius EE和Stamus探针。\n5.3.4 标签和保持\n一个标签，并保持动作类似于标签的动作，但匹配的事件将不会受到任何后来的行动处理发现的行动来抑制或阈值。\n标记和保持操作仅适用于Scirius EE和Stamus探针。\n5.4 键盘快捷键\n5.4.1 标签过滤\n这是完整的清单：\nA：显示所有事件\nR：仅显示相关事件\nI：仅显示信息事件\nU：仅显示未标记的事件\n6.suricata管理\n6.1 设置\nSuricata编辑页面允许您设置Suricata的参数。\n参数如下：\nName：探测器的主机名，确保它与JSON事件中的主机字段的值匹配\nDescr：suricata的描述\nRules directory：将在此目录中创建scirius.rules文件。Suricata必须只使用此文件\nSuricata configuration file：用于检测某些配置设置\nRuleset：选择要使用的规则集\n6.2更新规则集\n要更新Suricata规则集，您可以转到Suricata -&gt; Update（Update在 Actions 菜单中）。然后你必须选择你想要做的动作：\nUpdate：下载规则集使用的源的最新版本\nBuild：基于当前版本的源构建Suricata规则集\nPush：触发Suricata重新加载以使其与最新的构建规则集一起运行\n您还可以通过运行来更新规则集并触发Suricata重新加载：\npython  manage.py  update suricata\n7.备份\n要开始备份，请运行：\npython  manage.py  scbackup\n要恢复备份并清除所有数据，您可以运行\npython  manage.py  screstore\npython  manage.py  migrate\n这将恢复最新的备份。要选择其他备份，请将备份文件名指定为第一个参数。要获取可用备份列表，请使用\npython manage.py listbackups\n您无法将备份还原到比已完成备份的scirius更旧的scirius。\n使用默认配置文件，备份在/ var / backups中的磁盘上完成，但也可以使用其他方法。由于Scirius CE使用django-dbbackup应用程序进行备份和还原过程，因此它可以从此应用程序中的所有可用方法中受益。这包括至少：\nFTP\nAmazon AWS\nDropbox的\n有关可用方法及其配置的更多信息，请参阅django-dbbackup配置。\n","slug":"sec/Suricata/scirius规则集管理工具安装和使用","date":"2024-03-14T06:15:59.767Z","categories_index":"安全","tags_index":"scirius","author_index":"安全书"},{"id":"a11be9ae4d2ebafdc88c7634ec4817a3","title":"RE&CT框架详细介绍","content":"RE&amp;CT框架详细介绍0 原理\nRE&amp;CT框架是为积累、描述和分类可操作的事件响应技术而设计的。\nRE&amp;CT的哲学是基于MITRE的att&amp;ck框架。\n列表示响应阶段。\n这些单元格代表响应动作。\n\n**主要用例:**\n1、事件响应能力开发的优先级，包括技能开发、技术措施的获取/部署、内部过程开发等\n2、差距分析-确定现有事件响应能力的“覆盖范围”\n主要资源:\nRE&amp;CT导航器(改进的ATT&amp;CK导航器)用于可视化和观察大的图片\n自动生成的RE&amp;CT网站是获取现有分析细节的最佳地点\n自动生成的Atlassian Confluence知识库-输出功能演示\n可操作的分析\nATC RE&amp;CT项目继承了ATC项目的“可操作分析”范式，这意味着分析如下:\n人类可读的(.md)在运营中共享/使用\n机器可读(.yml)用于自动处理/集成\n通过事件响应平台可执行(目前仅thehive Case模板)\n简单地说，分析数据存储在.yml文件中，这些文件会自动转换成.md文档(带有jinja)和.json的thehive Case模板。\n响应行动\n响应动作是对在事件响应期间必须执行的特定原子过程/任务的描述。它是一个初始实体，用于构建响应剧本。\n每个响应动作都映射到一个特定的响应阶段。\n响应动作ID的第一个数字反映了它所属的阶段:\n1: Preparation\n2: Identification\n3: Containment\n4: Eradication\n5: Recovery\n6: Lessons Learned\n响应动作ID的第二个数字反映了它所属的类别:\n0: General\n1: Network\n2: Email\n3: File\n4: Process\n5: Configuration\n6: Identity\n通过使用响应动作ID，您可以看到它所属的阶段和类别。\n例如，RA2202: Collect an email message与阶段2(识别)和类别2(电子邮件)有关。\n该分类旨在改进事件响应过程成熟度评估和路线图开发。\n响应剧本\n响应剧本是一个事件响应计划，它代表了一个完整的过程/任务(响应行动)列表，必须执行该列表以响应特定威胁，并可选择映射到MITRE的att&amp;ck或Misinfosec的AMITT框架。\n响应剧本可以包括对工作流的描述、特定的条件/需求、响应操作执行顺序的细节，或者任何其他相关信息。\nTheHive案例模板\nTheHive Case模板是建立在响应剧本之上的。案例模板中的每个任务都是一个响应动作(带有完整的描述)。\n下面是导入的TheHive Case模板的示例:\n导入TheHive Case模板，在响应剧本上制作(点击展开)\n\n来源：https://raw.githubusercontent.com/atc-project/atc-react/master/docs/thehive_templates/RP_0001_phishing_email.json\n{‘customFields’: {},\n‘metrics’: {},\n‘tlp’: 2,\n‘pap’: 0,\n‘tasks’: [{‘order’: 0,\n  ‘title’: ‘1 | RA1001: Practice’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure that most of the Response Action has been performed on an internal exercise by your Incident Response Team.  \\nYou need to make sure that when an Incident will happen, the team will not just try to follow the playbooks they see first time in their lives, but will be able to quickly execute the actual steps in your environment, i.e. blocking an IP address or a domain name.  \\n’},\n  {‘order’: 1,\n  ‘title’: ‘2 | RA1002: Take trainings’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘&gt; We do not rise to the level of our expectations. We fall to the level of our training.  \\n\\nHere are some relevant training courses that will help you in the Incident Response activities:  \\n\\n1. Investigation Theory by Chris Sanders. We recommend you to have it as a mandatory training for every member of your Incident Response team  \\n2. Offensive Security trainings. We recommend PWK to begin with  \\n3. SANS Digital Forensics &amp; Incident Response trainings  \\n\\nOffensive Security trainings are in the list because to fight a threat, you need to understand their motivation, tactics, and techniques.  \\n\\nAt the same time, we assume that you already have a strong technical background in fundamental disciplines — Networking, Operating Systems, and Programming.  \\n’},\n  {‘order’: 2,\n  ‘title’: ‘3 | RA1004: Make personnel report suspicious activity’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Develop a simplified, company wide-known way to contact IR team in case of suspicious activity on the user system.  \\nMake sure that the personnel is aware of it, can and will use it.  \\n’},\n  {‘order’: 3,\n  ‘title’: ‘4 | RA1003: Raise personnel awareness’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Train users to to be aware of access or manipulation attempts by an adversary to reduce the risk of \\nsuccessful spearphishing, social engineering, and other techniques that involve user interaction.\\n’},\n  {‘order’: 4,\n  ‘title’: ‘5 | RA1101: Access external network flow logs’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure that there is a collection of Network Flow logs for external communication (from corporate assets to the Internet) configured.  \\nIf there is no option to configure it on a network device, you can install a special software on each endpoint and collect it from them.  \\n\\nWarning:  \\n\\n- There is a feature called “NetFlow Sampling”, that eliminates the value of the Network Flow logs for some of the tasks, such as “check if some host communicated to an external IP”. Make sure it&#39;s disabled or you have an alternative way to collect Network Flow logs  \\n’},\n  {‘order’: 5,\n  ‘title’: ‘6 | RA1104: Access external HTTP logs’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure that there is a collection of HTTP connections logs for external communication (from corporate assets to the Internet) configured.  \\n’},\n  {‘order’: 6,\n  ‘title’: ‘7 | RA1106: Access external DNS logs’,\n  ‘group’: ‘Preparation’,\n  ‘description’: “Make sure that there is a collection of DNS logs for external communication (from corporate assets to the Internet) configured.  \\nIf there is no option to configure it on a network device/DNS Server, you can install a special software on each endpoint and collect it from them.  \\n\\nWarning:  \\n\\n- Make sure that there are both DNS query and answer logs collected. It’s quite hard to configure such a collection on MS Windows DNS server and ISC BIND. Sometimes it much easier to use 3rd party solutions to fulfill this requirement.  \\n- Make sure that DNS traffic to the external (public) DNS servers is blocked by the Border Firewall. This way, corporate DNS servers is the only place assets can resolve the domain names.  \\n”},\n  {‘order’: 7,\n  ‘title’: ‘8 | RA1111: Get ability to block external IP address’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure you have the ability to create a policy rule in one of the listed Mitigation Systems that will you to block an external IP address from being accessed by corporate assets.  \\n\\nWarning:  \\n\\n- Make sure that using the listed systems (1 or multiple) you can control access to the internet of all assets in the infrastructure. In some cases, you will need a guaranteed way to block an external IP address from being accessed by corporate assets completely. If some of the assets are not under the management of the listed Mitigation Systems, (so they can access the internet bypassing these systems), you will not be able to fully achieve the final objective of the Response Action.  \\n’},\n  {‘order’: 8,\n  ‘title’: ‘9 | RA1113: Get ability to block external domain’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure you have the ability to create a policy rule or a specific configuration in one of the listed Mitigation Systems that will you to block an external domain name from being accessed by corporate assets.  \\n\\nWarning:  \\n\\n- Make sure that using the listed systems (1 or multiple) you can control access to the internet of all assets in the infrastructure. In some cases, you will need a guaranteed way to block an external domain name from being accessed by corporate assets completely. If some of the assets are not under the management of the listed Mitigation Systems, (so they can access the internet bypassing these systems), you will not be able to fully achieve the final objective of the Response Action.  \\n’},\n  {‘order’: 9,\n  ‘title’: ‘10 | RA1115: Get ability to block external URL’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure you have the ability to create a policy rule or a specific configuration in one of the listed Mitigation Systems that will you to block an external URL from being accessed by corporate assets.  \\n\\nWarning:  \\n\\n- Make sure that using the listed systems (1 or multiple) you can control access to the internet of all assets in the infrastructure. In some cases, you will need a guaranteed way to block an external URL from being accessed by corporate assets completely. If some of the assets are not under the management of the listed Mitigation Systems, (so they can access the internet bypassing these systems), you will not be able to fully achieve the final objective of the Response Action.  \\n’},\n  {‘order’: 10,\n  ‘title’: ‘11 | RA1201: Get ability to list users opened email message’,\n  ‘group’: ‘Preparation’,\n  ‘description’: “Make sure you have the ability to list users who opened/read a particular email message using the Email Server’s functionality.\\n”},\n  {‘order’: 11,\n  ‘title’: ‘12 | RA1202: Get ability to list email message receivers’,\n  ‘group’: ‘Preparation’,\n  ‘description’: “Make sure you have the ability to list receivers of a particular email message using the Email Server’s functionality.\\n”},\n  {‘order’: 12,\n  ‘title’: ‘13 | RA1203: Get ability to block email domain’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure you have the ability to block an email domain on an Email Server using its native filtering functionality.  \\n’},\n  {‘order’: 13,\n  ‘title’: ‘14 | RA1204: Get ability to block email sender’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure you have the ability to block an email sender on an Email Server using its native filtering functionality.  \\n’},\n  {‘order’: 14,\n  ‘title’: ‘15 | RA1205: Get ability to delete email message’,\n  ‘group’: ‘Preparation’,\n  ‘description’: “Make sure you have the ability to delete an email message from an Email Server and users’ email boxes using its native functionality.\\n”},\n  {‘order’: 15,\n  ‘title’: ‘16 | RA1206: Get ability to quarantine email message’,\n  ‘group’: ‘Preparation’,\n  ‘description’: ‘Make sure you have the ability to quarantine an email message on an Email Server using its native functionality.  \\n’},\n  {‘order’: 16,\n  ‘title’: ‘17 | RA2003: Put compromised accounts on monitoring’,\n  ‘group’: ‘Identification’,\n  ‘description’: ‘Start monitoring for authentification attempts and all potentially harmful actions from (potentially) compromised accounts.  \\nLook for anomalies, unusual network connections, unusual geolocation/time of work, actions that were never executed before.  \\nKeep in touch with the real users and, in case of need, ask them if they executing some suspicious actions by themselves or not.  \\n’},\n  {‘order’: 17,\n  ‘title’: ‘18 | RA2113: List hosts communicated with external domain’,\n  ‘group’: ‘Identification’,\n  ‘description’: ‘List hosts communicated with an external domain using the most efficient way.  \\n’},\n  {‘order’: 18,\n  ‘title’: ‘19 | RA2114: List hosts communicated with external IP’,\n  ‘group’: ‘Identification’,\n  ‘description’: ‘List hosts communicated with an external IP address using the most efficient way.  \\n’},\n  {‘order’: 19,\n  ‘title’: ‘20 | RA2115: List hosts communicated with external URL’,\n  ‘group’: ‘Identification’,\n  ‘description’: ‘List hosts communicated with an external URL using the most efficient way.  ‘},\n  {‘order’: 20,\n  ‘title’: ‘21 | RA2201: List users opened email message’,\n  ‘group’: ‘Identification’,\n  ‘description’: “List users who opened/read a particular email message using the Email Server’s functionality.  \\n”},\n  {‘order’: 21,\n  ‘title’: ‘22 | RA2202: Collect email message’,\n  ‘group’: ‘Identification’,\n  ‘description’: ‘Collect an email message using the most appropriate option:  \\n\\n- Email Team/Email server: if there is such option  \\n- The person that reported the attack (if it wasn&#39;t detected automatically or reported by victims)  \\n- Victims: if they reported the attack  \\n- Following the local computer forensic evidence collection procedure, if the situation requires it\\n\\nAsk for the email in .EML format. Instructions:  \\n\\n  1. Drug and drop email from Email client to Desktop  \\n  2. Archive with password “infected” and send to IR specialists by email  \\n’},\n  {‘order’: 22,\n  ‘title’: ‘23 | RA2203: List email message receivers’,\n  ‘group’: ‘Identification’,\n  ‘description’: “List receivers of a particular email message using the Email Server’s functionality.  “},\n  {‘order’: 23,\n  ‘title’: ‘24 | RA2204: Make sure email message is phishing’,\n  ‘group’: ‘Identification’,\n  ‘description’: ‘Check an email and its metadata for evidences of phishing attack:  \\n\\n- Impersonalisation attempts: sender is trying to identify himself as somebody he is not  \\n- Suspicious askings or offers: download “invoice”, click on link with something important etc  \\n- Psychological manipulations: invoking a sense of urgency or fear is a common phishing tactic  \\n- Spelling mistakes: legitimate messages usually don&#39;t have spelling mistakes or poor grammar  \\n\\nExplore references of the article to make yourself familiar with phishing attacks history and examples.  \\n’},\n  {‘order’: 24,\n  ‘title’: ‘25 | RA2205: Extract observables from email message’,\n  ‘group’: ‘Identification’,\n  ‘description’: ‘Extract the data for further response steps:  \\n\\n- attachments (using munpack tool: munpack email.eml)  \\n- from, to, cc  \\n- subject of the email  \\n- received servers path  \\n- list of URLs from the text content of the mail body and attachments  \\n\\nThis Response Action could be automated with TheHive EmlParser.  \\n’},\n  {‘order’: 25,\n  ‘title’: ‘26 | RA3101: Block external IP address’,\n  ‘group’: ‘Containment’,\n  ‘description’: “Block an external IP address from being accessed by corporate assets, using the most efficient way.  \\n\\nWarning:  \\n\\n- Be careful blocking IP addresses. Make sure it’s not a cloud provider or a hoster. If you would like to block something that is hosted on a well-known cloud provider or on a big hoster IP address, you should block (if applicable) a specific URL using alternative Response Action  \\n”},\n  {‘order’: 26,\n  ‘title’: ‘27 | RA3103: Block external domain’,\n  ‘group’: ‘Containment’,\n  ‘description’: “Block an external domain name from being accessed by corporate assets, using the most efficient way.  \\n\\nWarning:  \\n\\n- Be careful blocking doman names. Make sure it’s not a cloud provider or a hoster. If you would like to block something that is hosted on a well-known cloud provider or on a big hoster doman, you should block (if applicable) a specific URL using alternative Response Action  \\n”},\n  {‘order’: 27,\n  ‘title’: ‘28 | RA3105: Block external URL’,\n  ‘group’: ‘Containment’,\n  ‘description’: ‘Block an external URL from being accessed by corporate assets, using the most efficient way.  \\n’},\n  {‘order’: 28,\n  ‘title’: ‘29 | RA3201: Block domain on email’,\n  ‘group’: ‘Containment’,\n  ‘description’: ‘Block a domain name on an Email Server using its native filtering functionality.  \\n’},\n  {‘order’: 29,\n  ‘title’: ‘30 | RA3202: Block sender on email’,\n  ‘group’: ‘Containment’,\n  ‘description’: ‘Block an email sender on an Email Server using its native filtering functionality.  \\n’},\n  {‘order’: 30,\n  ‘title’: ‘31 | RA3203: Quarantine email message’,\n  ‘group’: ‘Containment’,\n  ‘description’: ‘Quarantine an email message on an Email Server using its native functionality.  \\n’},\n  {‘order’: 31,\n  ‘title’: ‘32 | RA4001: Report incident to external companies’,\n  ‘group’: ‘Eradication’,\n  ‘description’: “Report incident to external security companites, i.e. National Computer Security Incident Response Teams (CSIRTs).  \\nProvide all Indicators of Compromise and Indicators of Attack that have been observed.  \\n\\nA phishing attack could be reported to:  \\n\\n1. National Computer Security Incident Response Teams (CSIRTs)  \\n2. U.S. government-operated website  \\n3. Anti-Phishing Working Group (APWG)  \\n4. Google Safe Browsing  \\n5. The FBI’s Intenet Crime Complaint Center (IC3)  \\n\\nThis Response Action could be automated with TheHive and MISP integration.  \\n”},\n  {‘order’: 32,\n  ‘title’: ‘33 | RA4201: Delete email message’,\n  ‘group’: ‘Eradication’,\n  ‘description’: “Delete an email message from an Email Server and users’ email boxes using its native functionality.\\n”},\n  {‘order’: 33,\n  ‘title’: ‘34 | RA5101: Unblock blocked IP’,\n  ‘group’: ‘Recovery’,\n  ‘description’: ‘Unblock a blocked IP address in the system(s) used to block it.  \\n’},\n  {‘order’: 34,\n  ‘title’: ‘35 | RA5102: Unblock blocked domain’,\n  ‘group’: ‘Recovery’,\n  ‘description’: ‘Unblock a blocked domain name in the system(s) used to block it.  \\n’},\n  {‘order’: 35,\n  ‘title’: ‘36 | RA5103: Unblock blocked URL’,\n  ‘group’: ‘Recovery’,\n  ‘description’: ‘Unblock a blocked URL in the system(s) used to block it.  \\n’},\n  {‘order’: 36,\n  ‘title’: ‘37 | RA5201: Unblock domain on email’,\n  ‘group’: ‘Recovery’,\n  ‘description’: ‘Unblock an email domain on an Email Server using its native functionality.  \\n’},\n  {‘order’: 37,\n  ‘title’: ‘38 | RA5202: Unblock sender on email’,\n  ‘group’: ‘Recovery’,\n  ‘description’: ‘Unblock an email sender on an Email Server using its native functionality.  \\n’},\n  {‘order’: 38,\n  ‘title’: ‘39 | RA5203: Restore quarantined email message’,\n  ‘group’: ‘Recovery’,\n  ‘description’: ‘Restore a quarantined email message on an Email Server using its native functionality.  \\n’},\n  {‘order’: 39,\n  ‘title’: ‘40 | RA6001: Develop incident report’,\n  ‘group’: ‘Lessons Learned’,\n  ‘description’: ‘Develop the Incident Report using your corporate template.  \\n\\nIt should include:  \\n\\n1. Executive Summary with a short description of damage, actions taken, root cause, and key metrics (Time To Detect, Time To Respond, Time To Recover etc)  \\n2. Detailed timeline of adversary actions mapped to ATT&amp;CK tactics (you can use the Kill Chain, but most probably most of the actions will be in Actions On Objective stage, which is not very representative and useful)  \\n3. Detailed timeline of actions taken by Incident Response Team  \\n4. Root Cause Analysis and Recommendations for improvements based on its conclusion  \\n5. List of specialists involved in Incident Response with their roles  \\n’},\n  {‘order’: 40,\n  ‘title’: ‘41 | RA6002: Conduct lessons learned exercise’,\n  ‘group’: ‘Lessons Learned’,\n  ‘description’: “The Lessons Learned phase evaluates the team’s performance through each step. \\nThe goal of the phase is to discover how to improve the incident response process.  \\nYou need to answer some basic questions, using developed incident report:  \\n\\n- What happened?  \\n- What did we do well?  \\n- What could we have done better?  \\n- What will we do differently next time?  \\n\\nThe incident report is the key to improvements.  \\n”}],\n‘description’: ‘Response playbook for Phishing Email case\\n\\nWorkflow:\\n\\n1. Execute Response Actions step by step. Some of them directly connected, which means you will not be able to move forward not finishing the previous step. Some of them are redundant, as those that are related to the blocking a threat using network filtering systems (containment stage)\\n2. Start executing containment and eradication stages concurrently with next identification steps, as soon as you will receive information about malicious hosts\\n3. If phishing led to code execution or remote access to victim host, immediately start executing Generic Post Exploitation Incident Response Playbook\\n4. Save all timestamps of implemented actions in Incident Report draft on the fly, it will save a lot of time\\n’,\n‘name’: ‘RP0001: Phishing email’,\n‘status’: ‘Ok’,\n‘severity’: 2,\n‘titlePrefix’: ‘’,\n‘tags’: [‘attack.initial_access’,\n  ‘attack.t1566.001’,\n  ‘attack.t1566.002’,\n  ‘phishing’]}\nTheHive案例中的一个任务，在响应操作(单击展开)之上完成。\n\nthehive案例模板可以在docs/thehive_templates目录中找到，可以通过web界面导入到thehive中。\n一、响应阶段\n1、准备（Preparation）\n为安全事件做好准备。\n2、识别（Identification）\n收集关于触发安全事件的威胁、其TTPs和受影响资产的信息。\n3、遏制（Containment）\n防止威胁实现其目标和/或在环境中传播。\n4、根除（Eradication）\n从环境中移除一个威胁。\n5、恢复（Recovery）\n从事故中恢复，并使所有资产恢复正常运行。\n6、经验教训（Lessons Learned）\n了解如何改进事件响应流程并实现改进。\n二、准备\n1、RA1001: Practice\n描述：在真实的环境中练习。加强组织内部的响应行动。\n确保您的事件响应团队已在内部演习中执行了大多数响应行动。\n你需要确保当事件发生时，团队不会只是尝试遵循他们第一次看到的剧本，而是能够在你的环境中快速执行实际步骤，例如阻止IP地址或域名。\n2、RA1002: Take trainings\n描述：参加培训课程以获得相关知识\n我们不会上升到我们期望的水平。我们的训练水平下降了。\n以下是一些有关的培训课程，有助你应付事故:\n（1）克里斯·桑德斯的《调查理论》。我们建议你们对事故响应小组的每个成员进行强制性的培训\n（2）全面安全培训。我们建议从PWK开始\n（3）数字取证和事件响应培训\n全面的安全训练是其中之一，因为为了对抗威胁，你需要了解他们的动机、战术和技巧。\n与此同时，我们假定您已经在基础学科(网络、操作系统和编程)方面有很强的技术背景。\n3、RA1003: Raise personnel awareness\n描述：提高人员对网络钓鱼、勒索软件、社会工程和其他涉及用户交互的攻击的意识\n培训用户了解对手的访问或操作企图，以降低鱼叉钓鱼、社会工程和其他涉及用户交互的技术的成功风险。\n4、RA1004: Make personnel report suspicious activity\n描述：确保工作人员会报告可疑活动，如可疑电子邮件、链接、文件、电脑上的活动等\n开发一种简化的、公司众所周知的方式，在用户系统发生可疑活动时联系IR团队。\n确保员工意识到它，能够并且将要使用它。\n5、RA1005: Set up relevant data collection\n描述：通常，数据收集由日志管理/安全监控/威胁检测团队管理。您需要向他们提供一个数据列表，这对IR过程至关重要。大多数情况下，DNS、DHCP日志等数据不被收集，因为它们的检测值比较低。您可以参考现有的响应动作(准备阶段)来开发列表\n以markdown格式描述响应操作的工作流程。\n这里将保存换行符。\n6、RA1006: Set up a centralized long-term log storage\n描述：建立一个集中的长期日志存储。这是当今公司面临的最关键的问题之一。即使有这样一个系统，在大多数情况下，它存储的是不相关的数据，或者保留时间过短\n以markdown格式描述响应操作的工作流程。\n这里将保存换行符。\n7、RA1007: Develop communication map\n描述：为内部(c级，其他部门的经理和技术专家，可能参与IR过程)和外部(执法部门，CERT，你缺少的主题专家，等等)制定一个沟通图。\n以markdown格式描述响应操作的工作流程。\n这里将保存换行符。\n8、RA1008: Make sure there are backups\n描述：确保有在线备份和离线备份。确保它们能正常工作。在一个成功的勒索病毒蠕虫攻击的情况下，这是唯一的事情，将帮助你保护你的至关重要的数据\n9、RA1009: Get network architecture map\n描述：获取网络架构图。通常，它由网络安全团队管理。它将帮助您选择遏制策略，例如隔离特定的网段\n10、RA1010: Get access control matrix\n描述：获取访问控制矩阵。通常，它由网络安全团队管理。它将帮助你识别对手的机会，比如横向移动等等\n11、RA1011: Develop assets knowledge base\n描述：建立资产知识库。它将帮助您将观察到的活动与特定主机、用户或网段的正常活动配置文件进行比较\n12、RA1012: Check analysis toolset\n描述：确保您用于分析和管理的工具集是更新的并且完全可操作的。确保授予了所有必需的权限\n13、RA1013: Access vulnerability management system logs\n描述：访问漏洞管理系统日志。它将有助于识别特定主机在过去特定时间的漏洞\n14、RA1014: Connect with trusted communities\n描述：连接可信的社区以交换信息\n其它条件：\n与其他团队的MISP连接或在另一个机构的MISP实例上工作\n邮件列表\nslack的通道\n15、RA1101: Access external network flow logs\n类型：网络\n描述：确保您能够访问外部通信网络流日志\n其它条件：\nMS_border_firewall\nMS_border_ngfw\nDN_zeek_conn_log\n工作流：\n确保为外部通信(从公司资产到Internet)配置了一组网络流日志。\n如果没有在网络设备上配置它的选项，您可以在每个端点上安装一个特殊的软件并从它们那里收集它。\n警告:\n有一个特性叫做“NetFlow Sampling”，它消除了一些任务中网络流量日志的值，例如“检查某些主机是否与外部IP通信”。确保禁用它，否则您有另一种收集网络流日志的方法\n16、RA1102: Access internal network flow logs\n类型：网络\n描述：确保你可以访问内部通信网络的流量日志\n条件：\nDN_zeek_conn_log\n17、RA1103: Access internal HTTP logs\n类型：网络\n描述：确保您能够访问内部通信HTTP日志\n18、RA1104: Access external HTTP logs\n类型：网络\n描述：确保您能够访问外部通信HTTP日志\n条件：\nMS_border_proxy\nMS_border_ngfw\nDN_zeek_http_log\n确保为外部通信(从公司资产到Internet)配置了一组HTTP连接日志。\n19、RA1105: Access internal DNS logs\n类型：网络\n描述：确保您能够访问内部通信DNS日志\n条件：\nDN_zeek_dns_log\n20、RA1106: Access external DNS logs\n类型：网络\n描述：确保您能够访问外部通信DNS日志\n条件：\nMS_dns_server\nDN_zeek_dns_log\n工作流：\n确保为外部通信(从公司资产到Internet)配置了一组DNS日志。\n如果没有在网络设备/DNS服务器上配置它的选项，您可以在每个端点上安装一个特殊的软件，并从它们收集它。\n警告:\n请确保DNS查询和应答日志都已收集。在Windows DNS服务器和ISC绑定上配置这样的集合是相当困难的。有时，使用第三方解决方案来满足这一需求要容易得多。\n确保到外部(公共)DNS服务器的DNS通信被边界防火墙阻止。这样，企业DNS服务器就是资产可以解析域名的唯一地方。\n21、RA1107: Access VPN logs\n类型：网络\n描述：确保你能访问VPN日志\n22、RA1108: Access DHCP logs\n类型：网络\n描述：确保您能够访问DHCP日志\n23、RA1109: Access internal packet capture data\n类型：网络\n描述：确保您能够访问内部通信包捕获数据\n24、RA1110: Access external packet capture data\n类型：网络\n描述：确保您能够访问外部通信数据包捕获数据\n25、RA1111: Get ability to block external IP address\n类型：网络\n描述：确保您有能力阻止企业资产访问外部IP地址\n26、RA1112: Get ability to block internal IP address\n类型：网络\n描述：确保您可以阻止企业资产访问内部IP地址\n条件：\nMS_intranet_firewall\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_host_firewall\n27、RA1113: Get ability to block external domain\n类型：网络\n描述：确保你有能力阻止外部域名被公司资产访问\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_dns_server\n工作流：\n确保您能够在列出的缓解系统之一中创建策略规则或特定配置，以阻止企业资产访问外部域名。\n警告:\n确保使用列出的系统(1个或多个)可以控制对基础设施中所有资产的internet的访问。在某些情况下，你需要一个有保证的方法来阻止外部域名被公司资产完全访问。如果一些资产不在所列缓解系统的管理之下(以便它们可以绕过这些系统接入互联网)，就无法完全实现应对行动的最终目标。\n28、RA1114: Get ability to block internal domain\n类型：网络\n描述：确保您可以阻止企业资产访问内部域名\n29、RA1115: Get ability to block external URL\n类型：网络\n描述：确保您有能力阻止企业资产访问外部URL\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\n工作流：\n确保您能够在列出的缓解系统之一中创建策略规则或特定配置，以阻止企业资产访问外部URL。\n警告:\n确保使用列出的系统(1个或多个)可以控制对基础设施中所有资产的internet的访问。在某些情况下，您将需要一种有保证的方法来阻止企业资产完全访问外部URL。如果一些资产不在所列缓解系统的管理之下(以便它们可以绕过这些系统接入互联网)，就无法完全实现应对行动的最终目标。\n30、RA1116: Get ability to block internal URL\n类型：网络\n描述：确保您可以阻止企业资产访问内部URL\n条件：\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_dns_server\n31、RA1117: Get ability to block port external communication\n类型：网络\n描述：确保您可以阻止一个网络端口进行外部通信\n条件：\nMS_border_firewall\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_host_firewall\n32、RA1118: Get ability to block port internal communication\n类型：网络\n描述：确保您可以阻止一个网络端口进行内部通信\n条件：\nMS_intranet_firewall\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_host_firewall\n33、RA1119: Get ability to block user external communication\n类型：网络\n描述：确保您可以阻止一个用户进行外部通信\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_nac\n34、RA1120: Get ability to block user internal communication\n类型：网络\n描述：确保您可以阻止用户进行内部通信\n条件：\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_nac\n35、RA1121: Get ability to find data transferred by content pattern\n类型：网络\n描述：确定您有能力查找过去某个特定时间通过其内容模式(即特定字符串、关键字、二进制模式等)传输的数据\n条件：\n36、RA1122: Get ability to block data transferring by content pattern\n类型：网络\n描述：确保你有能力通过内容模式(如特定字符串，关键字，二进制模式等)来阻止数据传输。\n条件：\nDN_zeek_conn_log\n37、RA1123: Get ability to list data transferred\n类型：网络\n描述：确保您能够列出当前或过去某个特定时间正在传输的数据\n条件：\nDN_zeek_conn_log\n38、RA1124: Get ability to collect transferred data\n类型：网络\n描述：确保您有能力收集当前或过去某个特定时间正在传输的数据\n条件：\n39、RA1125: Get ability to identify transferred data\n类型：网络\n描述：确保您有能力识别当前或过去某个特定时间正在传输的数据(即它的内容、值)\n条件：\nDN_zeek_conn_log\n40、RA1126: Find data transferred by content pattern\n类型：网络\n描述：确保您能够找到当前或过去某个特定时间内根据内容模式传输的数据\n条件：\nDN_zeek_conn_log\n41、RA1127: Get ability to analyse user-agent\n类型：网络\n描述：确保您有能力分析用户代理请求头\n条件：\n42、RA1201: Get ability to list users opened email message\n类型：邮件\n描述：确保您能够列出打开特定电子邮件消息的用户\n条件：MS_email_server\n工作流：\n确保你能够使用邮件服务器的功能列出打开/阅读特定邮件信息的用户。\n43、RA1202: Get ability to list email message receivers\n类型：邮件\n描述：确保你有能力列出特定邮件的收件人\n条件：MS_email_server\n工作流：\n请确保您能够使用电子邮件服务器的功能列出特定电子邮件的收件人。\n44、RA1203: Get ability to block email domain\n类型：邮件\n描述：确保你有能力阻止一个电子邮件域名\n条件：MS_email_server\n工作流：\n确定您有能力使用电子邮件服务器的本机过滤功能屏蔽电子邮件域名。\n45、RA1204: Get ability to block email sender\n类型：邮件\n描述：确保你有能力阻止邮件发送者\n条件：MS_email_server\n工作流：\n确保你有能力在邮件服务器上使用其本机过滤功能来阻止邮件发送者。\n46、RA1205: Get ability to delete email message\n类型：邮件\n描述：确保你有删除邮件的能力\n条件：MS_email_server\n工作流：\n确保你有能力从电子邮件服务器和用户的电子邮箱中删除邮件信息，使用其本机功能。\n47、RA1206: Get ability to quarantine email message\n类型：邮件\n描述：确保您有隔离电子邮件的能力\n条件：MS_email_server\n工作流：\n确保您能够使用电子邮件服务器上的本机功能隔离电子邮件。\n48、RA1207: Get ability to collect email message\n类型：邮件\n描述：确保你有能力收集邮件信息\n条件：DN_zeek_conn_log\n工作流：\n49、RA1208: Get ability to analyse email address\n类型：邮件\n描述：确保你有能力分析一个电子邮件地址\n条件：\n工作流：\n50、RA1301: Get ability to list files created\n类型：文件\n描述：确保您能够列出在过去特定时间创建的文件\n条件：DN_zeek_conn_log\n工作流：\n60、RA1302: Get ability to list files modified\n类型：文件\n描述：确保您能够列出在过去特定时间被修改的文件\n条件：DN_zeek_conn_log\n工作流：\n61、RA1303: Get ability to list files deleted\n类型：文件\n描述：确保您能够列出在过去特定时间被删除的文件\n条件：DN_zeek_conn_log\n工作流：\n62、RA1304: Get ability to list files downloaded\n类型：文件\n描述：确保您能够列出在过去某个特定时间从互联网上下载的文件\n条件：DN_zeek_conn_log\n工作流：\n63、RA1305: Get ability to list files with tampered timestamps\n类型：文件\n描述：确保您能够列出带有篡改的时间戳的文件\n条件：DN_zeek_conn_log\n工作流：\n64、RA1306: Get ability to find file by path\n类型：文件\n描述：确保您能够通过路径(包括名称)查找文件\n条件：DN_zeek_conn_log\n工作流：\n65、RA1307: Get ability to find file by metadata\n类型：文件\n描述：确保你有能力根据文件的元数据(例如签名，权限，MAC时间)找到文件\n条件：DN_zeek_conn_log\n工作流：\n66、RA1308: Get ability to find file by hash\n类型：文件\n描述：确保您能够通过文件的HASH来查找文件\n条件：DN_zeek_conn_log\n工作流：\n67、RA1309: Get ability to find file by format\n类型：文件\n描述：确保您能够根据文件的格式查找文件\n条件：DN_zeek_conn_log\n工作流：\n68、RA1310: Get ability to find file by content pattern\n类型：文件\n描述：确保你有能力根据内容模式(如特定字符串，关键字，二进制模式等)找到文件\n条件：DN_zeek_conn_log\n工作流：\n69、RA1311: Get ability to collect file\n类型：文件\n描述：确保您能够从(远程)主机或系统收集特定的文件\n条件：DN_zeek_conn_log\n工作流：\n70、RA1312: Get ability to quarantine file by path\n类型：文件\n描述：确保您有能力通过访问其路径(包括其名称)阻止文件\n条件：DN_zeek_conn_log\n工作流：\n71、RA1313: Get ability to quarantine file by hash\n类型：文件\n描述：确定你有能力访问通过它的哈希阻止一个文件\n条件：DN_zeek_conn_log\n工作流：\n72、RA1314: Get ability to quarantine file by format\n类型：文件\n描述：确保您有能力通过访问其格式阻止文件\n条件：DN_zeek_conn_log\n工作流：\n73、RA1315: Get ability to quarantine file by content pattern\n类型：文件\n描述：确保你有能力通过访问它的内容模式访问(例如特定的字符串，关键字，二进制模式等)阻止一个文件\n条件：DN_zeek_conn_log\n工作流：\n74、RA1316: Get ability to remove file\n类型：文件\n描述：确保您能够从(远程)主机或系统中删除特定的文件\n条件：DN_zeek_conn_log\n工作流：\n74、RA1317: Get ability to analyse file hash\n类型：文件\n描述：确保您有能力分析文件散列\n条件：\n工作流：\n75、RA1318: Get ability to analyse Windows PE\n类型：文件\n描述：确保你有能力分析Windows可移植的可执行文件\n条件：\n工作流：\n76、RA1319: Get ability to analyse macos macho\n类型：文件\n描述：确保您有能力分析macOS Mach-O文件\n条件：\n工作流：\n77、RA1320: Get ability to analyse Unix ELF\n类型：文件\n描述：确保您有能力分析UNIX ELF文件\n条件：\n工作流：\n78、RA1321: Get ability to analyse MS office file\n类型：文件\n描述：确保你有能力分析Microsoft Office文件\n条件：\n工作流：\n79、RA1322: Get ability to analyse PDF file\n类型：文件\n描述：确保你有能力分析PDF文件\n条件：\n工作流：\n80、RA1323: Get ability to analyse script\n类型：文件\n描述：确保你有能力分析脚本文件(如Python, PowerShell, Bash脚本等)\n条件：\n工作流：\n81、RA1324: Get ability to analyse jar\n类型：文件\n描述：确保您有能力分析JAR文件\n条件：\n工作流：\n82、RA1325: Get ability to analyse filename\n类型：文件\n描述：确保你有能力分析一个文件名\n条件：\n工作流：\n83、RA1401: Get ability to list processes executed\n类型：进程\n描述：确保您能够列出当前或过去某个特定时间正在执行的进程\n条件：DN_zeek_conn_log\n工作流：\n84、RA1402: Get ability to find process by executable path\n类型：进程\n描述：确保您能够通过可执行路径(包括名称)查找在过去特定时间执行的进程\n条件：DN_zeek_conn_log\n工作流：\n85、RA1403: Get ability to find process by executable metadata\n类型：进程\n描述：确保您有能力找到进程在过去特定时间内通过其可执行元数据(即签名、权限、MAC时间)执行的进程。\n条件：DN_zeek_conn_log\n工作流：\n86、RA1404: Get ability to find process by executable hash\n类型：进程\n描述：确保您有能力查找在过去某个特定时间通过其可执行散列执行的进程。\n条件：DN_zeek_conn_log\n工作流：\n87、RA1405: Get ability to find process by executable format\n类型：进程\n描述：确保您有能力查找在过去特定时间按其可执行格式执行的进程。\n条件：DN_zeek_conn_log\n工作流：\n88、RA1406: Get ability to find process by executable content pattern\n类型：进程\n描述：确保你有能力找到在过去特定时间通过其可执行内容模式(即特定字符串、关键字、二进制模式等)执行的进程\n条件：DN_zeek_conn_log\n工作流：\n89、RA1407: Get ability to block process by executable path\n类型：进程\n描述：确保您能够通过其可执行路径(包括其名称)阻塞进程\n条件：DN_zeek_conn_log\n工作流：\n90、RA1408: Get ability to block process by executable metadata\n类型：进程\n描述：确保你有能力通过可执行的元数据(例如，签名，权限，MAC时间)阻塞进程\n条件：DN_zeek_conn_log\n工作流：\n91、RA1409: Get ability to block process by executable hash\n类型：进程\n描述：确保您有能力通过其可执行散列来阻塞进程\n条件：DN_zeek_conn_log\n工作流：\n92、RA1410: Get ability to block process by executable format\n类型：进程\n描述：确保您有能力按其可执行格式阻塞进程\n条件：DN_zeek_conn_log\n工作流：\n93、RA1411: Get ability to block process by executable content pattern\n类型：进程\n描述：确保你有能力通过它的可执行内容模式(例如特定字符串，关键字，二进制模式等)来阻塞进程。\n条件：DN_zeek_conn_log\n工作流：\n94、RA1501: Manage remote computer management system policies\n类型：配置\n描述：确保您可以管理远程计算机管理系统的策略\n条件：\n工作流：\n95、RA1502: Get ability to list registry keys modified\n类型：配置\n描述：确保您有能力列出在过去特定时间修改的注册表项\n条件：\n工作流：\n96、RA1503: Get ability to list registry keys deleted\n类型：配置\n描述：确保您有能力列出在过去特定时间删除的注册表项\n条件：DN_zeek_conn_log\n工作流：\n97、RA1504: Get ability to list registry keys accessed\n类型：配置\n描述：确保您有能力列出在过去特定时间访问的注册表项\n条件：DN_zeek_conn_log\n工作流：\n98、RA1505: Get ability to list registry keys created\n类型：配置\n描述：确保您有能力列出在过去特定时间创建的注册表项\n条件：DN_zeek_conn_log\n工作流：\n99、RA1506: Get ability to list services created\n类型：配置\n描述：确保您能够列出在过去特定时间创建的服务\n条件：DN_zeek_conn_log\n工作流：\n100、RA1507: Get ability to list services modified\n类型：配置\n描述：确保您能够列出在过去特定时间被修改的服务\n条件：DN_zeek_conn_log\n工作流：\n101、RA1508: Get ability to list services deleted\n类型：配置\n描述：确保您能够列出在过去特定时间被删除的服务\n条件：DN_zeek_conn_log\n工作流：\n102、RA1509: Get ability to remove registry key\n类型：配置\n描述：确保您有能力删除注册表项\n条件：DN_zeek_conn_log\n工作流：\n103、RA1510: Get ability to remove service\n类型：配置\n描述：确保您有能力删除服务\n条件：DN_zeek_conn_log\n工作流：\n104、RA1511: Get ability to analyse registry key\n类型：配置\n描述：确保你有能力分析注册表项\n条件：\n工作流：\n105、RA1601: Manage identity management system\n类型：身份\n描述：确保您可以管理身份管理系统，即删除/阻止用户，撤销凭证，并执行其他响应操作\n条件：\n工作流：\n106、RA1602: Get ability to lock user account\n类型：身份\n描述：确保您有能力锁定用户帐户不被使用\n条件：\n工作流：\n107、RA1603: Get ability to list users authenticated\n类型：身份\n描述：确保您能够列出在特定系统上过去特定时间经过身份验证的用户\n条件：\n工作流：\n108、RA1604: Get ability to revoke authentication credentials\n类型：身份\n描述：确保您有能力撤销身份验证凭据\n条件：DN_zeek_conn_log\n工作流：\n109、RA1605: Get ability to remove user account\n类型：身份\n描述：确保您有能力删除用户帐户\n条件：DN_zeek_conn_log\n工作流：\n三、识别\n1、RA2001: List victims of security alert\n类型：通用\n描述：列出安全告警的受害者\n条件：DN_zeek_conn_log\n自动化：thehive\n工作流：\n2、RA2002: List host vulnerabilities\n类型：通用\n描述：获取关于特定主机现有漏洞的信息，或关于它在过去特定时间拥有的漏洞的信息\n条件：DN_zeek_conn_log\n自动化：thehive/phantom/demisto/etc\n工作流：\n3、RA2003: Put compromised accounts on monitoring\n类型：通用\n描述：将(可能)泄露的账户置于监控之中\n条件：\n自动化：\n工作流：\n开始监控身份验证尝试和所有(潜在的)泄露帐户的潜在有害行为。\n寻找异常，不正常的网络连接，不正常的工作地点/时间，以前从未执行过的动作。\n与真正的用户保持联系，必要时询问他们是否有自己的可疑行为。\n4、RA2101: List hosts communicated with internal domain\n类型：网络\n描述：列出与内部域通信的主机\n条件：\n自动化：thehive\n工作流：\n5、RA2102: List hosts communicated with internal IP\n类型：网络\n描述：列出与内部IP地址通信的主机\n条件：\n自动化：thehive\n工作流：\n6、RA2103: List hosts communicated with internal URL\n类型：网络\n描述：列出与内部URL通信的主机\n条件：\n自动化：thehive\n工作流：\n7、RA2104: Analyse domain name\n类型：网络\n描述：分析域名\n条件：\n自动化：thehive\n工作流：\n8、RA2105: Analyse IP\n类型：网络\n描述：分析IP地址\n条件：\n自动化：thehive\n9、RA2106: Analyse uri\n类型：网络\n描述：分析URI\n条件：\n自动化：thehive\n10、RA2107: List hosts communicated by port\n类型：网络\n描述：列出当前或过去特定时间通过特定端口通信的主机\n条件：\n自动化：thehive\n11、RA2108: List hosts connected to VPN\n类型：网络\n描述：列出当前或过去某个特定时间连接到VPN的主机\n条件：\n自动化：thehive/phantom/demisto/etc\n12、RA2109: List hosts connected to intranet\n类型：网络\n描述：列出当前或过去某个特定时间连接到内部网络的主机\n条件：\n自动化：thehive/phantom/demisto/etc\n13、RA2110: List data transferred\n类型：网络\n描述：列出当前或过去某个特定时间正在传输的数据\n条件：DN_zeek_conn_log\n自动化：\n14、RA2111: Collect transferred data\n类型：网络\n描述：收集当前或过去某个特定时间正在传输的数据\n条件：DN_zeek_conn_log\n自动化：\n15、RA2112: Identify transferred data\n类型：网络\n描述：识别当前或过去某个特定时间正在传输的数据(即其内容、值)\n条件：DN_zeek_conn_log\n自动化：\n16、RA2113: List hosts communicated with external domain\n类型：网络\n描述：列出与外部域通信的主机\n条件：\nDN_zeek_conn_log\nDN_zeek_dns_log\nDN_zeek_http_log\nDN_dns_log\nDN_proxy_log\nDN_network_flow_log\n自动化：\n列出使用最有效的方式与外部域通信的主机。\n17、RA2114: List hosts communicated with external IP\n类型：网络\n描述：列出与外部IP地址通信的主机\n条件：\nDN_network_flow_log\nDN_zeek_conn_log\n自动化：\n列出使用最有效的方式与外部IP地址通信的主机。\n18、RA2115: List hosts communicated with external URL\n类型：网络\n描述：列出与外部URL通信的主机\n条件：\nDN_zeek_http_log\nDN_proxy_log\n自动化：\n列出使用最有效的方式与外部URL通信的主机。\n19、RA2116: Find data transferred by content pattern\n类型：网络\n描述：通过内容模式(即特定字符串、关键字、二进制模式等)查找当前或过去某个特定时间正在传输的数据\n条件：DN_zeek_conn_log\n自动化：\n20、RA2117: Analyse user-agent\n类型：网络\n描述：分析一个用户代理请求头\n条件：\nDN_zeek_conn_log\n自动化：\n21、RA2202: Collect email message\n类型：Email\n描述：收集邮件信息\n条件：\nMS_email_server\n自动化：\n工作流：\n使用最合适的选项收集电子邮件信息:\n1、电子邮件组/电子邮件服务器:如果有这样的选择\n2、报告攻击的人(如果攻击没有被自动检测到或被受害者报告)\n3、受害者:如果他们报告了袭击\n4、如果需要，请按照本地计算机取证程序进行取证\n请求. eml格式的电子邮件。产品说明:\n1、将电子邮件从电子邮件客户端转移到桌面\n2、存档密码为“感染”，并通过电子邮件发送给IR专家\n22、RA2203: List email message receivers\n类型：Email\n描述：列出特定电子邮件的收件人\n条件：\nMS_email_server\n自动化：\n工作流：\n使用电子邮件服务器的功能列出特定电子邮件的收件人。\n23、RA2204: Make sure email message is phishing\n类型：Email\n描述：确保电子邮件是钓鱼攻击\n条件：\nMS_email_server\n自动化：\n工作流：\n查看电子邮件及其元数据，寻找钓鱼攻击的证据:\n1、非个人化尝试:发送者试图将自己定义为另一个他不是的人\n2、可疑的询问或优惠:下载“发票”，点击一些重要的链接等\n3、心理操纵:唤起紧迫感或恐惧感是一种常见的网络钓鱼策略\n4、拼写错误:合法的信息通常没有拼写错误或糟糕的语法\n阅读本文的参考文献，熟悉网络钓鱼攻击的历史和例子。\nhttps://en.wikipedia.org/wiki/Phishing\nhttp://www.phishing.org/phishing-examples\n24、RA2205: Extract observables from email message\n类型：Email\n描述：从电子邮件消息中提取observable\n条件：\n自动化： thehive\n工作流：\n提取数据用于进一步的响应步骤:\n1、附件(使用munpack工具:munpack email.eml)\n2、from, to, cc\n3、邮件主题\n4、收到服务器的路径\n5、来自邮件正文和附件文本内容的url列表\n这个响应动作可以通过hive EmlParser自动完成。\n25、RA2206: Analyse email address\n类型：Email\n描述：分析邮件地址\n条件：\n自动化： thehive\n工作流：\n26、RA2301: List files created\n类型：文件\n描述：列出在过去特定时间创建的文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n27、RA2302: List files modified\n类型：文件\n描述：列出在过去特定时间被修改的文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n28、RA2303: List files deleted\n类型：文件\n描述：列出在过去特定时间被删除的文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n29、RA2304: List files downloaded\n类型：文件\n描述：列出在过去特定时间被下载的文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n30、RA2305: List files with tampered timestamps\n类型：文件\n描述：列出带有篡改时间戳的文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n31、RA2306: Find file by path\n类型：文件\n描述：通过路径(包括名称)查找文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n32、RA2307: Find file by metadata\n类型：文件\n描述：根据文件的元数据(如签名，权限，MAC时间)查找文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n33、RA2308: Find file by hash\n类型：文件\n描述：通过文件的散列来查找文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n34、RA2309: Find file by format\n类型：文件\n描述：根据文件的格式查找文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n35、RA2310: Find file by content pattern\n类型：文件\n描述：通过内容模式(如特定字符串，关键字，二进制模式等)查找文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n36、RA2311: Collect file\n类型：文件\n描述：从(远程)主机或系统收集特定的文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n37、RA2312: Analyse file hash\n类型：文件\n描述：分析一个文件的散列\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n38、RA2313: Analyse Windows PE\n类型：文件\n描述：分析MS Windows可移植可执行文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n39、RA2314: Analyse macos macho\n类型：文件\n描述：分析macOS Mach-O\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n40、RA2315: Analyse Unix ELF\n类型：文件\n描述：分析Unix ELF\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n41、RA2316: Analyse MS office file\n类型：文件\n描述：分析MS Office文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n42、RA2317: Analyse PDF file\n类型：文件\n描述：分析PDF文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n43、RA2318: Analyse script\n类型：文件\n描述：分析脚本文件(如Python, PowerShell, Bash脚本等)\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n44、RA2319: Analyse jar\n类型：文件\n描述：分析jar文件\n条件：\n自动化：\n工作流：\n45、RA2320: Analyse filename\n类型：文件\n描述：分析文件名\n条件：\n自动化：\n工作流：\n46、RA2401: List processes executed\n类型：进程\n描述：列出当前或过去某个特定时间正在执行的进程\n条件：\n自动化：thehive\n工作流：\n47、RA2402: Find process by executable path\n类型：进程\n描述：通过其可执行路径(包括名称)查找当前或过去某个特定时间正在执行的进程\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n48、RA2403: Find process by executable metadata\n类型：进程\n描述：通过它的可执行元数据(例如，签名，权限，MAC时间)找到一个正在执行的进程\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n49、RA2404: Find process by executable hash\n类型：进程\n描述：查找当前或过去某个特定时间正在由其可执行散列执行的进程\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n50、RA2405: Find process by executable format\n类型：进程\n描述：查找当前或过去某个特定时间按其可执行格式正在执行的流程\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n51、RA2406: Find process by executable content pattern\n类型：进程\n描述：通过它的可执行内容(例如特定字符串、关键字、二进制模式等)找到一个在当前或过去的特定时间正在执行的进程\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n52、RA2501: List registry keys modified\n类型：配置\n描述：列出在过去特定时间修改的注册表项\n条件：\n自动化：thehive\n工作流：\n53、RA2502: List registry keys deleted\n类型：配置\n描述：列出在过去特定时间被删除的注册表项\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n54、RA2503: List registry keys accessed\n类型：配置\n描述：列出在过去特定时间访问过的注册表项\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n55、RA2504: List registry keys created\n类型：配置\n描述：列出在过去特定时间创建的注册表项\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n56、RA2505: List services created\n类型：配置\n描述：列出在过去特定时间创建的服务\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n57、RA2506: List services modified\n类型：配置\n描述：列出在过去特定时间被修改的服务\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n58、RA2507: List services deleted\n类型：配置\n描述：列出在过去特定时间被删除的服务\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n59、RA2508: Analyse registry key\n类型：配置\n描述：分析注册表键\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n60、RA2601: List users authenticated\n类型：身份\n描述：列出在特定系统上过去特定时间经过身份验证的用户\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n四、遏制\n1、RA3001: Patch vulnerability\n类型：General\n描述：修补资产的漏洞\n条件：\n自动化：thehive\n工作流：\n2、RA3101: Block external IP address\n类型：网络\n描述：阻止外部IP地址被企业资产访问\n条件：\nMS_border_firewall\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_host_firewall\n自动化：\n工作流：\n3、RA3102: Block internal IP address\n类型：网络\n描述：阻止内网IP地址被企业资产访问\n条件：\nMS_border_firewall\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_host_firewall\n自动化：\n工作流：\n4、RA3103: Block external domain\n类型：网络\n描述：阻止企业资产访问外部域名\n条件：MS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_dns_server\n自动化：\n工作流：\n5、RA3104: Block internal domain\n类型：网络\n描述：阻止企业资产访问内部域名\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_dns_server\n自动化：\n工作流：\n以最有效的方式阻止企业资产访问内部域名。\nhttps://en.wikipedia.org/wiki/DNS_sinkhole\n6、RA3105: Block external URL\n类型：网络\n描述：阻止企业资产访问外部URL\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_dns_server\n自动化：\n工作流：\n以最有效的方式阻止企业资产访问外部URL。\n7、RA3106: Block internal URL\n类型：网络\n描述：阻止企业资产访问内部URL\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_dns_server\n自动化：\n工作流：\n8、RA3107: Block port external communication\n类型：网络\n描述：阻止外部通信网络端口\n条件：\nMS_border_firewall\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_host_firewall\n自动化：\n工作流：\n9、RA3108: Block port internal communication\n类型：网络\n描述：阻止内部通信网络端口\n条件：\nMS_border_firewall\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_host_firewall\n自动化：\n工作流：\n10、RA3109: Block user external communication\n类型：网络\n描述：阻止用户对外通信\n条件：MS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_nac\n自动化：\n工作流：\n11、RA3110: Block user internal communication\n类型：网络\n描述：阻止用户进行内部通信\n条件：\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_nac\n自动化：\n工作流：\n12、RA3111: Block data transferring by content pattern\n类型：网络\n描述：通过其内容模式(即特定字符串、关键字、二进制模式等)阻塞传输块数据\n条件：\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_nac\n自动化：\n工作流：\n13、RA3202: Block sender on email\n类型：email\n描述：在邮件服务器上阻止邮件发送者\n条件：MS_email_server\n自动化：\n工作流：\n14、RA3203: Quarantine email message\n类型：email\n描述：隔离电子邮件\n条件：\nMS_email_server\n自动化：\n工作流：\n15、RA3301: Quarantine file by format\n类型：文件\n描述：按文件的格式隔离文件\n条件：\nMS_email_server\n自动化：\n工作流：\n16、RA3302: Quarantine file by hash\n类型：文件\n描述：通过文件的散列隔离文件\n条件：\nMS_email_server\n自动化：\n工作流：\n17、RA3303: Quarantine file by path\n类型：文件\n描述：按文件路径隔离文件\n条件：\nMS_email_server\n自动化：\n工作流：\n18、Quarantine file by content pattern\n类型：文件\n描述：根据文件的内容模式隔离文件\n条件：\n自动化：thehive/phantom/demisto/etc\n工作流：\n19、RA3401: Block process by executable path\n类型：进程\n描述：通过可执行路径(包括名称)阻止进程执行\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n20、RA3402: Block process by executable metadata\n类型：进程\n描述：通过其可执行元数据(例如签名、权限、MAC时间)阻塞进程的执行\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n21、RA3403: Block process by executable hash\n类型：进程\n描述：通过可执行散列阻塞进程的执行\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n22、RA3404: Block process by executable format\n类型：进程\n描述：通过可执行格式阻塞进程的执行\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n23、RA3405: Block process by executable content pattern\n类型：进程\n描述：通过其可执行内容模式(例如特定字符串、关键字、二进制模式等)阻塞进程的执行\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n24、RA3501: Disable system service\n类型：配置\n描述：关闭系统服务\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n25、RA3601: Lock user account\n类型：身份\n描述：锁定用户\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n五、根除\n1、RA4001: Report incident to external companies\n类型：General\n描述：向外部公司报告事件\n条件：\n自动化：thehive\n工作流：\n向外部安全公司报告事件，即国家计算机安全事件响应小组(CSIRTs)。\n提供已观察到的所有危害指标和攻击指标。\n2、RA4101: Remove rogue network device\n类型：网络\n描述：移除非法网络设备\n条件：\n自动化：thehive/phantom/demisto/etc\n工作流：\n3、RA4201: Delete email message\n类型：Email\n描述：移除非法网络设备\n条件：MS_email_server\n自动化：\n工作流：\n删除邮件服务器和用户邮箱中的邮件信息\n4、RA4301: Remove file\n类型：文件\n描述：从(远程)主机或系统中移除特定的文件\n条件：\n自动化：thehive/phantom/demisto/etc\n工作流：\n5、RA4501: Remove registry key\n类型：配置\n描述：删除注册表项\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n6、RA4502: Remove service\n类型：配置\n描述：删除服务\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n7、RA4601: Revoke authentication credentials\n类型：身份\n描述：撤销认证证书\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n8、RA4602: Remove user account\n类型：身份\n描述：删除用户帐户\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n六、恢复\n1、RA5001: Reinstall host from golden image\n类型：General\n描述：从黄金映像重新安装主机操作系统\n条件：\n自动化：thehive\n工作流：\n2、RA5002: Restore data from backup\n类型：General\n描述：从备份中恢复数据\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n3、RA5101: Unblock blocked IP\n类型：网络\n描述：解除阻塞IP地址\n条件：\nMS_border_firewall\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_intranet_firewall\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_host_firewall\n自动化：\n工作流：\n4、RA5102: Unblock blocked domain\n类型：网络\n描述：解除阻塞的域名\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\nMS_dns_server\n自动化：\n工作流：\n5、RA5103: Unblock blocked URL\n类型：网络\n描述：解除阻塞的URL\n条件：\nMS_border_proxy\nMS_border_ips\nMS_border_ngfw\nMS_intranet_proxy\nMS_intranet_ips\nMS_intranet_ngfw\n自动化：\n工作流：\n6、RA5104: Unblock blocked port\n类型：网络\n描述：解除封锁端口\n条件：DN_zeek_conn_log\n自动化：\n工作流：\n7、RA5105: Unblock blocked user\n类型：网络\n描述：解除阻塞用户\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n8、RA5201: Unblock domain on email\n类型：email\n描述：解除封锁电子邮件的域名\n条件：\nMS_email_server\n自动化：\n工作流：\n9、RA5202: Unblock sender on email\n类型：email\n描述：解除对邮件中的发件人的阻止\n条件：\nMS_email_server\n自动化：\n工作流：\n10、RA5203: Restore quarantined email message\n类型：email\n描述：恢复隔离的电子邮件\n条件：\nMS_email_server\n自动化：\n工作流：\n11、RA5301: Restore quarantined file\n类型：文件\n描述：恢复隔离文件\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n12、RA5401: Unblock blocked process\n类型：进程\n描述：解除阻塞进程\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n13、RA5501: Enable disabled service\n类型：配置\n描述：启用禁用的服务\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n14、RA5601: Unlock locked user account\n类型：身份\n描述：解锁被锁定用户\n条件：\nDN_zeek_conn_log\n自动化：\n工作流：\n七、经验教训\n1、RA6001: Develop incident report\n类型：General\n描述：编制事件报告\n条件：\n自动化：\n工作流：\n使用公司模板开发事件报告。\n它应该包括:\n1、执行摘要，简要描述损害、采取的措施、根本原因和关键指标(检测时间、响应时间、恢复时间等)\n2、对手行动的时间线映射到ATT&amp;CK战术(你可以使用杀戮链，但大多数行动可能是在目标阶段的行动，这不是很有代表性和有用)\n3、事件响应小组采取行动的详细时间表\n4、根据结论进行根本原因分析并提出改进建议\n5、参与事件响应的专家及其角色的列表\n2、RA6002: Conduct lessons learned exercise\n类型：General\n描述：进行经验教训练习\n条件：\n自动化：\n工作流：\n经验教训阶段通过每个步骤来评估团队的绩效。该阶段的目标是发现如何改进事件响应流程。\n你需要回答一些基本的问题，使用开发的事件报告:\n1、发生了什么事?\n2、我们做得好的是什么?\n3、我们还能做得更好吗?\n4、下次我们会有什么不同?\n事件报告是改进的关键。\n来源：https://atc-project.github.io/atc-react/responsestages/\nhttps://github.com/atc-project/atc-react\n","slug":"sec/RE&CT框架详细介绍","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"RE与CT框架","author_index":"安全书"},{"id":"486f6f51eacf1a3bbe1d0730c0d21907","title":"将MISP威胁事件导出成Suricata规则文件","content":"将MISP威胁事件导出成Suricata规则文件在MISP中，你可以将威胁事件导出成Suricata的规则检测文件。以下是具体的操作步骤：\n\n登录MISP：首先，你需要登录你的MISP账户。\n选择事件：在MISP的主界面，点击左侧的Event Actions，然后选择List Events。在事件列表中，找到你想要导出的事件。\n导出事件：点击你选择的事件，进入事件详情页面。在页面顶部，你会看到一个Download as的下拉菜单。点击这个菜单，然后选择Suricata。这将会下载一个包含Suricata规则的.rules文件。\n保存规则文件：将下载的.rules文件保存到你的Suricata规则目录中。通常，这个目录的位置是/etc/suricata/rules1。\n更新Suricata配置：打开Suricata的配置文件（通常位于/etc/suricata/suricata.yaml1），找到rule-files部分。在这个部分，添加一个新的行，内容是你刚刚保存的.rules文件的文件名1。\n重启Suricata：最后，你需要重启Suricata以应用新的规则。你可以使用如下命令来重启Suricata：sudo systemctl restart suricata1。\n\n","slug":"sec/MISP/将MISP威胁事件导出成Suricata规则文件","date":"2024-03-14T06:15:59.766Z","categories_index":"Sec","tags_index":"MISP","author_index":"安全书"},{"id":"59533137b13343a594dd85a381092dcd","title":"恶意软件信息共享平台（MISP）","content":"恶意软件信息共享平台（MISP）一、MISP是什么?\n恶意软件信息共享平台是由社区成员、恶意软件知识库和基于web的平台组成的。它是智能防御概念的一个实际和成功的实例，与当前所有北约网络防御信息共享倡议完全一致。\n  \n\nMISP最初是为了支持北约计算机事件响应能力技术中心(NCIRC TC)的任务而构建的，它允许在可信的社区内共享恶意软件的技术特征，而不必共享关于事件上下文的信息。\n它结合了一个可搜索的存储库和一个多向的信息共享机制。在可能的情况下，MISP还提供自动化机制，支持数据的自动导入和导出以及与其他系统的接口。其目的是加速事件的检测和防御措施的制定，特别是针对那些没有被反病毒保护所阻止的恶意软件，或者是复杂的有针对性的入侵企图的一部分。\n二、为什么要使用MISP?\n\n北约已被证明的能力，可以被国家使用\n\nMISP是安全事件调查人员、恶意软件分析师和事件处理程序的日常知识库和工具。2012年6月以来NCIRC积极使用它。\n\n恶意软件专家将在MISP中发现他们需要与他们的发现相关联的破坏指标(IOC)，以及检测系统的更新。他们还将发现恶意软件样本和各种各样的恶意软件技术信息，这将帮助他们获得半即时保护。MISP是一个互动平台，每当有新东西被共享时，它就会发送通知，为数据的导入和导出提供自动化，并与网络防御工具集成。MISP是一种安全但容易访问的能力，可以通过internet访问。\n如果你的团队日常工作的一部分是想知道:\n•您过去是否在您的网络中看到过目标恶意软件;\n•你的合作伙伴是否已经看过;\n•社区中是否有人已经对恶意软件进行了分析;\n•如果恶意软件是攻击活动的一部分，或与我们知道的其他恶意软件有相似之处;\n•如果该恶意软件与同一威胁代理生成的其他恶意软件有相似之处，则该恶意软件可能属于特定的敌对实体;\n•针对组织的有针对性的基于恶意软件的攻击的历史，以及是否存在一种趋势。\n\n智能防御-分享胜利\n\n加入MISP的好处:\n\n消除分析工作的重复:不同的组织观察到相同的攻击，所有组织都花时间执行相同的分析工作。\n\nMISP将消除社区成员分析被其他成员共享的恶意软件的需要。\n\n更快的威胁检测:所有各方收到即时通知的威胁报告之一。\n\n3.改进威胁情报和归因:MISP的集中式和共享的恶意软件信息存储库提供了一个比单组织视角更完整的威胁全景视图，并且可以给出更多关于恶意软件归因的结论。\n\n启用互操作性:成员现在可以以“标准化”格式共享恶意软件信息。\n\n通过各种导入和导出功能支持自动化。\n\n\n其成功的关键是共享恶意软件信息的技术部分，而不是共享攻击上下文的信息——脱离上下文的安全事件的技术信息不再敏感。也正是这些信息具有可操作性，可以用来完善防御和侦查机制，在进攻端获得战术优势。在一年的操作中，MISP知识库已经包含了大约500个与攻击相关的恶意软件信息条目。\n3、MISP社区\nMISP是一个社区，在这里，由不同成员承载的平台的多个实例可以相互连接，并且它将同步它们之间的信息。\n社区成员的初步名单包括:\n\n  \n\n多国网络防御能力发展(MN CD2)社区目前也在调查MISP在多大程度上可以作为信息共享工作包1的解决方案，以及相关的资金/订阅机制。\nMalware Information Sharing Platform，https://www.misp-project.org/datamodels/\nhttps://github.com/MISP/PyMISP\nhttps://www.misp-project.org/feeds/\nhttps://github.com/MISP/misp-taxonomies/tree/master/kill-chain\n","slug":"sec/MISP/恶意软件信息共享平台（MISP）","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"MISP","author_index":"安全书"},{"id":"96dd12ad2138af69b55623880d37b519","title":"开源威胁情报共享平台MISP的安装与配置","content":"开源威胁情报共享平台MISP的安装与配置MISP是一个开源的威胁情报共享平台，官网定义如下：\n\n\n\n\n\n\n\n\n\nMISP威胁共享平台是一个免费的开源软件，帮助共享包括网络安全指标在内的威胁情报信息。The MISP threat sharing platform is a free and open source software helping information sharing of threat intelligence including cyber security indicators.\n\n\n\n\n\n\n\n\n\nMISP是一个威胁情报平台，用于收集、共享、存储和关联目标攻击的危害指标、威胁情报、金融欺诈信息、漏洞信息甚至反恐信息。A threat intelligence platform for gathering, sharing, storing and correlating Indicators of Compromise of targeted attacks, threat intelligence, financial fraud information, vulnerability information or even counter-terrorism information.\n这里记录下其安装搭建的过程\n环境\nVMware Workstation\nMISP\n\n软件安装官网给了好几种安装方式，试了好多种方式均失败，最终记录下成功的方式\n下载进入官网下载MISP虚拟机：\n\n下载MISP虚拟机1\n\n\n下载MISP虚拟机2\n安装首先安装VMware，具体教程不再赘述，这里仅介绍MISP安装过程\n\n首先将下载好的文件解压，并将解压后的文件夹放进VMware的工作目录\n\n打开VMWare，单击左上角文件，选择扫描虚拟机： \n \n 选择扫描虚拟机\n\n选择扫描位置为刚刚的文件夹之后点击下一步：\n \n \n 选择扫描位置\n\n扫描完成，选择添加：\n \n \n 扫描完成\n\n虚拟机添加成功：\n \n \n 虚拟机添加成功\n\n\nMISP初始化配置\n首先点击刚刚添加的虚拟机，选择打开：\n \n \n 虚拟机开机\n\n开机界面：\n   \n \n 开机界面\n\n输入账号misp，密码Password1234之后enter： \n \n 登录MISP\n\n在自己的主机浏览器输入虚拟机的IP地址（开机界面那里会有IP地址显示）进行访问，这里我自己的是192.168.25.140/：  \n  \n 访问MISP\n\n输入账号admin@admin.test，密码admin进行登录，登录完成之后会让你修改初始密码：    \n 修改初始密码\n\n这里可以查看一下密码要求，最少12位密码，且必须包含数字、大小写字母和特殊字符：\n \n \n 密码要求\n\n修改完成就可以使用了：\n   \n \n MISP\n\n\n","slug":"sec/MISP/开源威胁情报共享平台MISP的安装与配置","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"MISP","author_index":"安全书"},{"id":"81a55a8deb4238544f7e1b98796e670b","title":"OpenCTI创建报告","content":"OpenCTI创建报告一、介绍\n如果您想要添加一个不在平台上的报告或源代码来分析它，您有两种可能性:\n要么报告在数据库中，其中存在一个到OpenCTI的连接器。你只需要在这个数据库中找到你的报告，并按照程序导入它(例如，在MISP中，你必须标记它，以及在Zotero中)。之后，您只需等待报告被导入(这取决于为连接器设置的执行时间)。\n或者您可以在OpenCTI中直接从头开始创建报告。为此，进入“报告”服务，并单击右下角的橙色按钮。填写完信息后，点击“创建”按钮(不要担心源文件的URL，它会在下一步出现)。\n二、创建的报告将出现在“all reports”表的顶部，并带有“new”标记。如果单击它，将显示源的仪表板。\n\n三、添加外部引用\n然后可以添加以前没有输入的信息。例如,如果你想添加一个URL来指向其来源的一份报告中,你可以点击右边的小“+”标志的“外部引用”框,并在windows就出现,再次点击橙色右下角按钮创建一个全新的来源。\n\n来源：https://opencti-platform.github.io/docs/usage/reports-create\n","slug":"sec/OpenCTI/OpenCTI创建报告","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"OpenCTI","author_index":"安全书"},{"id":"389cc3738e79aa6d6e9828a3c80d0d79","title":"开放式网络威胁情报平台-OpenCTI","content":"开放式网络威胁情报平台-OpenCTI一、介绍\nOpenCTI是一个开放源码的平台，允许组织管理他们的网络威胁情报知识和观察。它的创建是为了构建、存储、组织和可视化有关网络威胁的技术和非技术信息。\n数据的结构化使用基于STIX2标准的知识模式来执行。它被设计成一个现代的web应用程序，包括一个GraphQL API和一个面向UX的前端。此外，OpenCTI还可以与其他工具和应用程序集成，如MISP、hive、MITRE ATT&amp;CK等。\n\n二、目标\n目标是创建一个综合工具，允许用户利用技术信息（如TTP和可观察信息）和非技术信息（如建议的归属、受害者等），同时将每一条信息与其主要来源（报告、MISP事件等）相链接，并具有每一条信息之间的链接等功能，首先上次看到的日期、置信度等。该工具能够使用MITRE ATT&amp;CK框架（通过专用连接器）帮助构建数据。用户还可以选择实现自己的数据集。\n一旦OpenCTI内的分析人员对数据进行了资本化和处理，就可以从现有的关系中推断出新的关系，以便于理解和表示这些信息。这允许用户从原始数据中提取和利用有意义的知识。\nOpenCTI不仅允许导入，还允许导出不同格式的数据（CSV、STIX2包等）。目前正在开发连接器，以加速工具与其他平台之间的交互。\nOpenCTI是由法国国家网络安全局（ANSSI）、CERT-EU和Luatix非盈利组织合作开发的产品。\n三、应用程序的体系结构\nOpenCTI平台依赖于几个外部数据库和服务来工作。\n\n3.1GraphQL API\nAPI是OpenCTI平台的中心部分，允许客户端(包括前端)与数据库和代理进行交互。在NodeJS中构建，它实现了GraphQL查询语言。由于API目前还没有完整的文档，您可以通过GraphQL游乐场探索可用的方法和参数。在演示实例中提供了一个示例。\n3.2写作工人\n这些worker是独立的Python进程，它们仅使用RabbitMQ代理的消息来执行异步写查询。您可以启动任意数量的工作人员来提高编写性能。\n3.3连接器\n连接器是可以在平台上扮演4种不同角色的第三方软件(Python进程):\nEXTERNAL_IMPORT，从远程数据源获取数据，将其转换为STIX2并将其插入OpenCTI平台。MITRE, MISP, CVE, AlienVault, FireEye\nINTERNAL_IMPORT_FILE，通过UI或API从上传到OpenCTI的文件中提取数据。从PDFs、STIX2导入等中提取指标。\nINTERNAL_ENRICHMENT，侦听新的OpenCTI实体或用户请求，从远程数据源提取数据以进行充实。通过外部服务、实体更新等来丰富观察对象。\nINTERNAL_EXPORT_FILE，根据列出的实体或一个实体及其关系，从OpenCTI数据生成导出。STIX2导出，PDF导出，CSV列表生成等。\n四、特点\n4.1知识图\n整个平台依赖于知识超图，允许使用超实体和超关系，包括嵌套关系。\n4.2统一一致的数据模型\n从操作层面到战略层面，所有信息都通过基于STIX2标准的unifed一致的数据模型进行链接。\n4.3按设计提供数据来源\n实体之间的每个关系都具有基于时间和基于空间的属性，并且必须由具有特定置信度的报告来确定来源。\n4.4探索和相关性\n整个数据集可以通过分析和相关引擎进行探索，包括许多可视化插件、MapReduce和Pregel计算。\n4.5自动推理\n数据库引擎通过演绎推理来执行逻辑推理，以便实时地派生出隐含的事实和关联。\n4.6数据访问管理\n作者：Threathunter链接：https://www.jianshu.com/p/e427a4ddec8a来源：简书著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n","slug":"sec/OpenCTI/开放式网络威胁情报平台-OpenCTI","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"OpenCTI","author_index":"安全书"},{"id":"3b9db7fa138fa3362596403fa91e4809","title":"用于SIEM系统的通用签名格式","content":"用于SIEM系统的通用签名格式一、什么是sigma\nSigma是一种通用的开放签名格式，允许您以一种直接的方式描述相关的日志事件。规则格式非常灵活，易于编写，适用于任何类型的日志文件。该项目的主要目的是提供一种结构化的形式，在这种结构中，研究人员或分析人员可以描述他们曾经开发的检测方法，并使其与他人共享。\nSigma用于日志文件，就像Snort用于网络流量，YARA用于文件一样。\n这个库包含:\n（1）Wiki中的Sigma规则规范\n（2）./rulessubfolder中n个sigma签名存储库\n（3）为不同SIEM系统生成搜索/查询的转换器[正在进行中]\n\n二、用例\n描述你在Sigma中的检测方法，使其可共享\n使用Sigma编写SIEM搜索，以避免供应商锁定\n与IOCs和YARA规则一起在分析的附录中共享签名\n在威胁情报社区共享签名-例如通过MISP\n为您自己的应用程序中的恶意行为提供Sigma签名\n三、为什么Sigma\n今天，每个人都收集日志数据进行分析。人们开始自己动手，处理大量白皮书、博客文章和日志分析指南，提取必要的信息，构建自己的搜索和仪表板。他们的一些搜索和关联是伟大的，非常有用，但他们缺乏一个标准化的格式，他们可以与他人分享他们的工作。\n其他一些则提供了出色的分析，包括IOCs和YARA规则来检测恶意文件和网络连接，但无法描述日志事件中的特定或通用检测方法。西格玛应该是一个开放的标准，这样的检测机制可以被定义，共享和收集，以提高每个人的检测能力。\n来源：https://github.com/Neo23x0/sigma\n","slug":"sec/SIEM/用于SIEM系统的通用签名格式","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"SIEM,sigama","author_index":"安全书"},{"id":"84da1837a57c3e20f3b7aafe847341a7","title":"OpenCTI导入知识","content":"OpenCTI导入知识一、导入知识\n连接器\nOpenCTI有越来越多的连接器，可以在专用的Github存储库中使用。类型EXTERNAL_IMPORT的连接器允许您自动从外部服务(即。AlienVault, MISP, TheHive等)。\n二、用户界面\n您还可以在平台的用户界面中手动导入知识。你必须有各种可能性:\n屏幕右上角的全局导入按钮、文件中的实体和关系将按原样导入。\n导入按钮可用于报告中上传的文件，所有从这里导入的知识都将链接到报告本身。\n\n三、客户/ API\n例如，在Python库中，您可以使用以下方法:\n\n来源：https://opencti-platform.github.io/docs/usage/knowledge-import\n","slug":"sec/OpenCTI/OpenCTI导入知识","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"OpenCTI","author_index":"安全书"},{"id":"5a01a5fb72b467381f99c607653ffae4","title":"Shuffle自动化和检测框架-开源SOAR","content":"Shuffle自动化和检测框架-开源SOARShuffle已经有将近一年的历史了，，现在是时候用Shuffle的方式来调整检测指针了。自从上次我们写Shuffle以来，它已经发展到“任何事情都有可能”的地步，不管是好是坏。这很好，因为产品可以做很多。不好，因为它不够集中。这就是为什么在可预见的未来，我们会每月写多篇博文，强调我们现在的状况，并用Shuffle解决问题。也许我们也能解决你的问题。\n我们的目标是让分析师的生活更轻松、更有成就感，而要做到这一点，我们需要从简单做起。那是什么意思？这意味着，通过更有效地使用现有工具，可以减少查看所有打开的不同浏览器选项卡所花费的大量时间，并将精力集中在最重要的任务上。\n你现有的工具是什么?它们如何能被用来丰富你或你的分析师的生活?为了回答这个问题，我们深入了各种操作团队，并与他们的数百种工具进行了集成。我们还找到了导致分析员极度疲劳的根本原因。很明显，你的SOC检测有误。这是为什么。\n一、开始检测\n检测工程很难。这是每个人都应该做的事情，我们中的一些人确实在做，但不是我们大多数人积极关注的事情。为什么?因为这给我们自己创造了更多的工作。意思是抓住更多不好的事情，但不要太多。为什么这是个问题?因为我们都有有限的能力，并希望保持我们的理智。这与发现本身没有多大关系，而更多的是与后来发生的事情有关;事件处理和花费的时间。\n检测有很多变种;SIEM, IDS, EDR, IAM, WAF, AV和许多其他(缩写-)工具都有这种能力。但是你知道如何很好地使用它们吗?如果你这样做了，对你和你的团队都很好，但机会是;你不。你也不必这么做。这些工具的存在是为了帮助您进行检测，您不需要成为各个方面的专家。但这不是今天的现实。现实情况是，它们都不是最优的，或者根本就不是。这是Shuffle可以解决的问题。让你对你的资源有一个更好的概述，并尽可能以最好的方式利用它们——用于检测或其他。如何?\n二、我们将如何帮助您获得事件上下文\n\n\n上图是安全操作工具的简化视图。你在SOC中需要的所有东西都可以放到这些盒子里(如果你不同意，请评论)。每种工具都有其独特的卖点，但它们的功能通常是相同的。我们开始挖吧。\n案例:您运营的核心。你的分析师应该工作的地方,和 context。遗憾的是，这一工具目前尚未得到充分利用。我最喜欢的一个例子;TheHive。\nIAM:身份访问管理。为什么这很重要?因为了解一个人是谁，他拥有什么，应该拥有什么是很重要的。例如:Keycloak\n资产:资产管理，CMDB，漏洞管理，文档，漏洞等。你可以在任何地方找到有用的主机和用户关系。例如:Snipe-IT\nIntem:一个宽泛且误用的名称，intel的意思是任何可以帮助你解决事件的情报。最常用于威胁情报提供商。例如:MISP GreyNoise\nSIEM:你的数据湖，经常被误用为工作场所，而不是在将数据移出之前发现和检测的场所。例子:Wazuh、ELK\n网络:防火墙，IDS/IPS, DNS服务器，交换机，NSM引擎。例如:Pf Sense\n根除:EDR, Antivirus, Powershell &amp; Bash…这是一个广泛的类别，定义了可以执行和可以执行的预防措施——通常在主机级别。例如:Velociraptor, OSSEC\n通讯:电子邮件，聊天服务，短信等。应用于半自动化工作流的通知和验证。所有票只在Slack/团队不是一个好主意长期。\n尽管如此，框架除非付诸行动，否则是无用的。我们的SOC工具框架的目标是帮助您理解我们的方法，以及如何将其整合到您的流程中。我们将从高层次开始，并最终接触到各个工具及其用例—从检测开始。\n  \n\n上面的图片是框架每个部分使用的一个高级示例。从左边，您可以看到我们定义Sigma、Snort和Yara，它们适合检测区域。这些都是我们已经支持的工具，但我们计划让每个人都更容易使用。同样，良好的检测和共享是目标。在中间你可以看到两个以人为中心的区域;案例管理和沟通。这可以与其他的相适应，但在大多数情况下不会也不应该。在右边，你可以看到最后的三个片段，它们被用来使一个事件的背景更容易理解。\n那下一步怎么办?你是如何把它付诸行动的?让我们去深入。\n\n\n这个例子展示了您的外部基础设施被利用的例子——让它更具体一点;让我们假设它是一个带有WAF (Web应用防火墙)的网络服务器。在左边你可以看到现在大多数人使用的半手动方式，而在右边，你可以看到如何优化它。点线表示自动操作(通常是API的)，而蓝色是人工操作。\n仔细看图片的左边部分，这里是它是如何运行的(手动):\n1、WAF会给你发警报，然后发给SIEM。你有一个API，它把这个发送到你的通信系统(如电子邮件或Slack)。\n2、过了一段时间，你看到了这条消息，想知道它是什么，是否有人正在处理它(如果你使用带有标签的共享电子邮件，请获得一个ticket系统)。\n3、首先回到WAF获取实际的上下文，同时还要在SIEM中收集事件日志。\n4、您将开始探索它来自的IP，并寻找它的目标服务，看看它是否容易受到攻击。什么以及谁拥有这项服务?源IP是否只针对你或所有人?利用是什么?它工作了吗?等。\n5、经过一个小时的信息搜索，您发现该漏洞确实有效，攻击以前没有发生过，它是有目标的，您需要补救。现在进行此步骤可能为时已晚，但您决定隔离受到损害的主机。\n现在，将它与右侧(自动)进行比较;\n1、您从WAF(网络)获得一个警报，发送到SIEM, SIEM进一步将其转发给Shuffle。Shuffle被配置为在案例管理系统中创建警报。\n2、在添加案例时，Shuffle进一步查找其他类似的事件(Cases)，检查谁拥有服务(IAM &amp; Assets)，服务是否脆弱(Assets, VMS)，源IP是否针对你(Intel)\n3、Shuffle向您的团队的通知通道发送消息，这只会发生在高度严重的事件中。它还调用您定义的on-call。\n4、分析人员在他们的案例管理系统中看到所有需要的信息，并决定立即采取行动，因为成功利用的可能性很大。\n5、大约5分钟后，分析人员采取了行动并隔离了服务器(这可能是正确的，也可能是错误的)，并通知了服务所有者。\n看出不同了吗?在第一个示例中，分析师必须搜索信息，可能根本没有注意到事件，而在第二个示例中，信息就在手边，并在必要时立即准备好。出发点、目标和过程都是一样的，但如果不是完全自动化的话，你会更快地得出结论。随着时间的推移，这还有一个巨大的好处;你的团队就不会出现“警报疲劳”。\n三、善用你的资源\nShuffle并不是一种灵丹妙药，而是试图将你现有的工具变成一种灵丹妙药。我们希望授权您的员工去做创新的安全工作，而不是那些可以自动化的工作。很多人在体验“有趣”部分(如1级SOC分析师)之前就放弃了网络安全，而这是实现这一目标的唯一途径。使用你可用的工具和资源不应该像一开始看起来那么难。\n在接下来的几周和几个月里，我们将进一步探索实际的用例，您可以自己尝试使用这个框架中的基础。我们将解决网络钓鱼、丰富、工具构建等问题，并向您展示如何对该事件进行良好的概述，从而为每个人带来成功。上面所有的工具都可以作为起点使用(不仅仅是Network和SIEM)，我们想探究每一个工具会发生什么。\n  \n\n","slug":"sec/Shuffle/Shuffle自动化和检测框架-开源SOAR","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"Shuffle,SOAR","author_index":"安全书"},{"id":"e408fdbce72d5653ac4ac8b54fbcd6d4","title":"介绍Shuffle一个开源SOAR平台第1部分","content":"介绍Shuffle一个开源SOAR平台第1部分\n所有的蓝队和信息安全部门都有两个共同的问题:警报疲劳和缺乏发展。_如果你不给安全专家难题来解决，而是给他们救火，而环境停滞不前，这最终将导致人员流动。_这是事件响应团队的一个常见主题，Shuffle正在寻求解决它。然而，如何解决这些问题呢?继续读下去，我将向您介绍开源的魔力。\nShuffle是大约一年前(2019年年中)作为一个业余项目启动的。我一遍又一遍地为胶带系统编写相同的代码，这对于30多个系统来说是相当乏味的。我知道有更好的方法，而且作为一名开发人员和安全专家，我看到了对更好结构的需求，最终导致了混乱。我最初计划把它变成一个SaaS平台，但在看到对开源SOAR平台的需求后，我决定免费提供它。\n一、SOAR是什么?\nSOAR(安全编配、自动化和响应)已经存在几年了，它是最近信息安全行业一些大型需求的一部分。SOAR平台的重点是端到端的处理事件——在事件发生之前、期间和之后进行自动化处理。\n在单一平台中，端到端的一个问题是视图很杂乱，而且很难使用，因为它们试图撒网太广。这通常以威胁情报、ticket、漏洞管理、电子邮件分析、云安全等形式存在。仅仅因为可以做，并不意味着应该做。\n\n一、什么是Shuffle?\nShuffle是对SOAR的开源解释。它的目标是通过即插即用的应用程序，在整个企业中提供所有必要的数据传输功能，让每个人都能实现自动化。它应该消除团队中对程序员的需求(我仍然建议至少有一名程序员)，通过能够在几分钟内部署新的、复杂(或简单)的工作流程，而不是几小时或几天的时间，赋予每个人力量。\nShuffle是如何做到的呢?通过工作流和应用程序。您可能对这两个词都很熟悉，前者是自动化剧本，后者是集成。\n二、集成是如何工作的?\n要使Shuffle可访问，它需要有现成的集成。拥有一个由支持者和创造者组成的社区是件好事，但我们想得更远。Shuffle使用OpenAPI和现有的Web API标准，让你访问一个构建器来动态创建应用，如左图所示。\n\n如果您查看这个现有的集成网站，它显示了11.000多个带有OpenAPI定义的端点。这意味着您将在几分钟内就拥有产品的现有集成，而不是几天的开发时间。\n在OpenAPI之上，我们采用了_WALKOFF的集成方法和结构_，这意味着他们的应用程序也能与Shuffle一起工作。\n三、工作流程是什么?\n工作流是Shuffle的一部分，所有的东西都汇集在一起。使用应用程序、触发器和变量，Shuffle让你能够访问所有你需要的工具，让你的平台相互交流。下面是一个使用这三种方法的基本例子。\n\nHello world example in Shuffle with Triggers, Actions and Variables\n如前一节所述，一个应用程序有多个动作，而这些动作又有多个参数。“Hello world”(左下角)是动作“Repeat back to me”运行应用程序“Testing”。\n“ Repeat back to me “有一个参数，在这里是变量” Hello world Variable “\n如果有人发送一个POST请求到触发器“Webhook”，这个工作流将被执行。它也可以手动执行。\n动作、webhook和参数可以重用、复制和组合在一起来创建任何你能想到的东西。此外，工作流是用JSON定义的，这种格式可以通过编程来理解。这意味着，将来会有一个值得注意的现成工作流库可供选择。\n四、为什么要使用Shuffle?\n该平台具有自动化、报告、共享和打包任何信息的能力，本质上是为任何从事运营安全工作的人构建的。可以通过OpenAPI等现有标准轻松实现自动化，通过执行视图获得更多乐趣，最后但并非最不重要的是，还可以提高效率。\n选择开源意味着它可以快速发展，只要基线是稳定和安全的。它目前处于测试阶段，有几个测试人员正在生产中，如果你也想测试它，我们将非常感激。联系或查看安装指南。\n五、Shuffle的下一步是什么\n由于采纳是一个关键因素，所以这只是一篇介绍性的文章，没有多少深度。我想要Shuffle来激发蓝队的激情，因为红队感觉有持续的发展，而蓝队似乎缺乏。为了进一步推进这个议程，我将在未来几周发布一系列帖子，涵盖从安装到集成和应用程序构建的所有内容。\n（1）介绍Shuffle(这篇博文)\n（2）Shuffle入门\n（3）整合了Shuffle, Virustotal和hive\n（4）使用Shuffle实时执行TheHive和MISP\n（5）高级工作流程演练\n（6）Shuffle的(不那么遥远的)未来(Mitre att&amp;ck，动态仪表板，资产管理，KPI等)\n来源：https://medium.com/shuffle-automation/introducing-shuffle-an-open-source-soar-platform-part-1-58a529de7d12\n","slug":"sec/Shuffle/介绍Shuffle一个开源SOAR平台第1部分","date":"2024-03-14T06:15:59.766Z","categories_index":"安全","tags_index":"Shuffle,SOAR","author_index":"安全书"},{"id":"966d943ab9173e9608cbc74e885435df","title":"Cortex","content":"CortexCortex 与 TheHive 是一个团队开发的产品。Cortex 使用分析器获取日志中有关指标信息的其他数据。允许在第三方服务中查询 IP、URL 与文件哈希等指标，并将第三方返回的结果作为附加信息丰富告警事件。\n","slug":"sec/Cortex/Cortex","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"Cortex","author_index":"安全书"},{"id":"a2a9eee04827e3542dfc3fbf3eefe6f5","title":"威胁情报源","content":"威胁情报源Interoperability Challenges in the Cybersecurity Information Sharing Ecosystem\nAbuse.ch http://abuse.ch/\nAnomali STAXX https://www.anomali.com/community/staxx\nAutoshun https://www.autoshun.org\nBambenek https://www.bambenekconsulting.com/\nBlock List Project https://blocklist.site/\nBitdefender (Advanced Threat Intelligence) https://www.bitdefender.com/\nBruteForceBlocker http://danger.rulez.sk/index.php/bruteforceblocker/\nCERT-EU https://cert.europa.eu/cert/filteredition/en/CERTLatestNews.html/\nhttp://cinsscore.com/ http://cinsscore.com/\nCollaborative Research Into Threats\n(CRITs)\nhttps://crits.github.io/\nComodo Site Inspector http://siteinspector.comodo.com/\nDNS8 https://www.layer8.pt/products/dns8/\nDShield https://www.dshield.org/\nESET https://www.eset.com\nFortinet https://www.fortinet.com/\nGoogle Safebrowsing https://safebrowsing.google.com/\nHybrid Analysis https://www.hybrid-analysis.com/\nMalc0de http://malc0de.com/\nMalshare https://malshare.com/\nMISP Platform https://www.misp-project.org/\nNational Certs (NCSC-FI example) https://www.cybersecurityintelligence.com/nationalcyber-security-centre-finland-ncsc-fi-1916.html\nOpenPhish https://openphish.com\nOTX AlienVault https://otx.alienvault.com/\nPhishTank https://www.phishtank.com/\nProofpoint https://www.proofpoint.com/us/daily-rulesetupdate-summary\nShadowserver https://www.shadowserver.org/\nSpamhaus https://www.spamhaus.org/\nTalosIntelligence https://talosintelligence.com\nThreat Miner https://www.threatminer.org/\nTrustwave (SpiderLabs Blog) https://www.trustwave.com\nUS DHS - Automated Indicator Sharing https://www.cisa.gov/automated-indicator-sharing-ais\nVirus Total https://www.virustotal.com\n","slug":"sec/IOC/威胁情报源","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"IOC","author_index":"安全书"},{"id":"2d8195051bb8e2de03e88db70d684849","title":"MISP允许的操作协议","content":"MISP允许的操作协议允许操作协议(简称:PAP)的设计目的是说明如何使用接收到的信息。\n一、PAP:红色\n(PAP:红色)无法检测的动作。收件人不得使用PAP:网络上的红色信息。只有日志上的被动动作，从外部是无法检测到的。\n二、PAP:琥珀\n(PAP:琥珀)被动交叉检查。收件人可以使用PAP:用于进行在线检查的黄色信息，如使用第三方提供的服务(如VirusTotal)，或设置一个监控蜜罐。\n三、PAP:绿色\n(PAP:绿色)允许主动操作。接收者可以使用PAP:绿色信息来ping目标，阻止从目标到目标的传入/传出流量，或者专门配置蜜罐来与目标交互。\n四、PAP:白色\n(PAP:白色)不限制使用此信息。\nhttps://www.misp-project.org/taxonomies.html#_pap\n","slug":"sec/MISP/MISP允许的操作协议","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"MISP","author_index":"安全书"},{"id":"7e0e1c4b03dac0e9485db0ebb045b315","title":"MISP中添加OTX威胁情报的feed","content":"MISP中添加OTX威胁情报的feed在MISP中添加OTX威胁情报的feed，你可以按照以下步骤操作：\n\n登录MISP：首先，你需要登录你的MISP账户。\n进入Feeds页面：在MISP的主界面，点击左侧的Sync Actions，然后选择List Feeds。\n添加新的Feed：在Feeds页面，点击右上角的Add Feed按钮。\n填写Feed信息：在新的页面中，你需要填写以下信息：\nProvider：输入OTX。\nName：输入你想要的Feed名称，例如OTX Threat Feed。\nInput Source：选择Network。\nURL：输入OTX的Feed URL。你需要在OTX网站上创建一个API key，并将其添加到URL中。例如，URL可能类似于https://otx.alienvault.com/api/v1/indicators/export。\nSource Format：选择MISP。\nEnabled：勾选此选项以启用这个Feed。\nDistribution：选择适合你的分发设置。\nSharing Group：如果你选择了Sharing Group作为分发设置，那么你需要在这里选择一个Sharing Group。\n\n\n保存Feed：填写完所有必要的信息后，点击Submit按钮保存这个Feed。\n获取Feed数据：回到Feeds页面，找到你刚刚创建的Feed，点击Fetch and Store All Feed Data按钮。这将从OTX获取威胁情报数据，并将其存储在你的MISP实例中。\n\n","slug":"sec/MISP/MISP中添加OTX威胁情报的feed","date":"2024-03-14T06:15:59.765Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"f5a3a00a7babb83c4a9dce249f61ff2c","title":"如何选择正确的恶意软件分类方案来提高事件响应","content":"如何选择正确的恶意软件分类方案来提高事件响应恶意软件感染是计算机安全中最常见的威胁之一。根据“2017年ENISA威胁环境报告”，一些防病毒供应商每天检测到400多万个恶意软件样本，仅2017年一季度就检测到7亿多个样本。\n这些惊人的数字强调了建立恶意软件事件响应计划的重要性。然而，安全团队不能一次处理所有的恶意软件警报。美国国家标准与技术研究所(NIST)的“桌面和笔记本电脑恶意软件事件预防和处理指南”概述了组织可以采取的步骤，以开发一个恶意软件分类方案，优先处理这些事件。\n事件响应计划的分析阶段包括识别和理解被检测到的恶意软件的类型。这个过程的结果然后作为实际恶意软件分类的输入。\n分析可以分阶段进行，从使用诸如VMRay之类的全自动工具相当容易，到涉及手动代码逆向的非常困难的技术。分析结果应包括一套指标的破坏(IoCs)和详细信息的特点，传播方法和行为的恶意软件。\n为了准备未来的事件，组织应该为每个恶意软件分类类型建立特定的剧本。这使安全团队能够更有效地优先处理事件。例如，根据自动传播能力分类的恶意软件应该优先于仅仅被归类为不需要的程序的恶意软件。\n显然，要使用正确的剧本，你必须首先能够正确地分类检测到的恶意软件。这就是事情变得棘手的地方。\n一、理想情况下的恶意软件分类\n在理想的情况下，一个分类方案会将恶意软件类型放在一个明确的分类树中。不幸的是，真实世界的恶意软件通常具有广泛的恶意功能、保护方法、目标分发和传播方法。这使得分类更加困难，并且非常依赖于安全团队试图实现的目标。此外，恶意软件家族通常有许多相似之处，但在分类过程中可能会有一些小的修改，导致混淆。\n通过自动分析工具(如沙箱)或通过属性的静态分析识别的恶意软件通常已经被反病毒公司识别和命名。您可以使用这些信息开始，但是仅根据恶意软件名称进行分类是有限制的。\n二、现有的分类方案\n既然我们不是生活在一个理想的世界，让我们仔细看看一些现有的分类方案，并讨论它们如何帮助安全团队优先处理恶意软件威胁和优化他们的事件响应过程。\n2.1按图像分类\n计算机科学实验室发表的一篇论文描述了一种使用图像进行恶意软件二进制分类的静态技术。在计算图像的基于文本的特征来描述恶意软件之前，先将恶意软件二进制文件转换为图像。由于使用固定大小的加密密钥，这种分类方法对包装策略具有弹性。它还使安全团队能够可视化地描述和分类恶意软件样本。\n2.2恶意软件聚类\n恶意软件聚类提供了恶意软件之间关系的可视化表示。这些结果可以极大地提高分析人员识别大量恶意软件样本之间的相似性的能力，并使他们能够更快地识别已知样本或与已知恶意软件共享相似性的样本。最终，这解放了安全团队，让他们可以专注于新型的恶意软件。\n通过结合使用impfuzzy和Neo4J图形数据库，分析人员可以生成快速而有意义的结果。Impfuzzy使用模糊哈希来计算导入API的哈希值。它也是一个波动性插件。\n虽然它不是专门设计来表示恶意软件集群，但VirusTotal图形工具可以帮助分析人员理解恶意软件文件之间的关系。它提供了对整个VirusTotal数据集的可见性，以及一个直观的界面来透视和导航它们。\n2.3防病毒厂商命名约定\n防病毒供应商喜欢使用基于签名的方法为恶意软件分配古怪的名称。顶级分类通常是通过一个基本的命名约定来完成的。通常，恶意软件名称前缀表示目标平台或恶意软件功能，然后是恶意软件家族名称(例如，“Trojan.Win32”)。\n不幸的是，这种命名约定通常仅限于单个供应商，这使得共享信息变得更加困难。此外，这种技术并不总是描述恶意软件的全部功能。\n卡巴斯基实验室根据一个分类树对恶意软件进行分类。恶意软件样本按照两个基本规则放在图中:\n（1）威胁最小的行为显示在图的下方。\n（2）构成最大威胁的行为显示在图表的上半部分。\n例如，如果电子邮件蠕虫比internet中继聊天(IRC)蠕虫具有更高的风险，则电子邮件蠕虫将被放置在图的顶部和IRC蠕虫之上。\n2.4CARO\n微软使用计算机防病毒研究组织(CARO)的恶意软件命名方案，根据以下格式:\n类型-恶意软件的行为。例如，它是一个特洛伊木马，垃圾邮件或远程访问工具?\n平台——目标平台、编程语言或文件格式。\n家族-基于共同特征的分组，包括归属于同一作者。\n变种-一个不同版本的恶意软件。\n附加信息-额外的细节，包括如何使用它作为一个多组件威胁的一部分。例如,“!指示威胁组件是一个快捷方式。\nCARO是一个由跨越公司和学术边界的个人组成的组织，它的目的是研究和研究恶意软件。自1990年成立以来，它一直在推动一项命名标准。\n2.5MAEC\n恶意软件属性枚举和描述(MAEC)是一种社区开发的结构化语言，用于基于行为、工件和恶意软件样本之间的关系等属性对恶意软件信息进行编码。它可以用于非基于签名的恶意软件特征描述。MAEC与STIX类似——如果您使用STIX或TAXII，那么MAEC当然值得研究。\nMAEC语言由两个规范文档定义:\n具有高级用例的核心概念以及数据类型和顶级对象的定义;和\n具有显式值的词汇表文档。\nMAEC有JavaScript对象表示法(JSON)模式和Cuckoo报告模块。还有一个模块用于将VirusTotal 报告转换为MAEC。\n2.6Machine-Parsable恶意软件分类\n一些威胁情报共享平台，如恶意软件信息共享平台(MISP)，支持恶意软件的分类方案，带有可由机器解析的标签和人类可读的描述。同时使用这两种分类方法有助于使事件响应过程更加流畅。\n机器可解析标记允许分析人员轻松地包含自动化步骤和可以推送到其安全解决方案的保护规则。例如，一旦分析了一个样本并将威胁事件的所有特征添加到平台上，安全团队就可以在遏制和消除阶段自动部署入侵检测系统(IDS)规则。与此同时，人类可读的标记允许分析人员快速创建摘要报告。在威胁信息共享平台中立即提供集成，使得与对等方交换这些信息变得更加容易\n三、选择正确的恶意软件分类方法\n有许多不同的方法来分类恶意软件。选择正确的方案取决于您的具体用例。\n如果您对发现恶意软件样本之间的关系和相似性感兴趣，那么基于图像表示和恶意软件聚类技术的分类方案当然值得研究。如果您的目标是改进处理恶意软件爆发的事件响应过程，那么分类应该考虑优先级和紧急性标准。\n恶意软件的功能和行为将定义它对您的环境的影响。例如，它的设计目的是窃取用户凭证、泄漏敏感数据、允许远程访问或破坏您的系统吗?更高的影响力需要更高的优先级。您还应该考虑是否有可能妨碍或减慢您的分析的保护措施。\n恶意软件瞄准的任何平台都可以作为输入来确定其优先级。恶意软件的目标是那些没有部署在您的环境中的平台，或者那些使用自动过滤的文档格式的平台，这些恶意软件与其说是真正的威胁，不如说是一种麻烦。\n传播方法也将有助于确定事件的紧迫性。没有用户交互就能自动传播的恶意软件需要立即跟进。另一方面，你的安全解决方案已经识别和过滤的恶意软件可以归类为不那么紧急的。\n如果您只是从一个分类方案开始，那么基于CARO的恶意软件命名约定是一个很好的基础。您还应该为最常见的恶意软件类型准备剧本，以确保您的团队在发生意外时不会措手不及。无论您选择哪种分类方案，都要确保构建的方式能够轻松地在事件响应策略中包含自动化步骤。\nHow to Choose the Right Malware Classification Scheme to Improve Incident Response，https://securityintelligence.com/how-to-choose-the-right-malware-classification-scheme-to-improve-incident-response/\n","slug":"sec/IOC/如何选择正确的恶意软件分类方案来提高事件响应","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"安全运营,soc","author_index":"安全书"},{"id":"87e6bd56c7367f08ce7a5b644210698c","title":"一个4-in-1安全事件响应平台","content":"一个4-in-1安全事件响应平台一个可扩展的、开源的、免费的安全事件响应平台，与MISP(恶意软件信息共享平台)紧密集成，旨在为soc、csirt、CERTs和任何处理需要迅速调查和采取行动的安全事件的信息安全从业人员提供更方便的工作。\nTheHive是一个可扩展的4-in-1开源和免费的安全事件响应平台，旨在让soc、csirt、CERTs和任何处理需要迅速调查和采取行动的安全事件的信息安全从业人员的生活更容易。它是MISP的完美伴侣。您可以将它与一个或多个MISP实例同步，以启动MISP事件的调查。您还可以将调查结果作为MISP事件导出，以帮助您的同行和合作伙伴检测和响应您所处理的攻击。此外，当hive与Cortex一起使用时，安全分析师和研究人员可以使用超过100个分析人员轻松分析上百个观察结果，包含一个事件或根除恶意软件，这多亏了Cortex的响应。\n\n\n一、合作（Collaborate）\n多个SOC和CERT分析师可以同时协作进行调查。由于内置的实时流，与新的或现有的案例、任务、可观察性和IOCs相关的实时信息对所有团队成员都是可用的。特殊通知允许他们处理或分配新的任务，并预览新的MISP事件和来自多个来源的警报，如电子邮件报告、CTI供应商和SIEMs。然后，他们可以立即导入和调查它们。\n合作是TheHive的核心。多个分析师可以同时处理同一个案例。例如，分析人员可以处理恶意软件分析，而另一个分析人员可以在代理日志上跟踪C2信标活动，只要他们的同事添加了ioc。使用TheHive的实时流媒体，每个人都可以实时关注平台上发生的事情。\n二、详细描述\n可以使用简单但功能强大的模板引擎创建案例和相关任务。您可以向模板中添加度量标准和自定义字段，以推动团队的活动，确定需要大量时间的调查类型，并通过动态仪表板实现繁琐任务的自动化。分析师可以记录他们的进展，附加证据或值得注意的文件，添加标签，并导入包含恶意软件或可疑数据的密码保护的ZIP档案，而无需打开它们。\n在TheHive里，每一项调查都对应一个案例。案例可以从头开始创建，也可以从MISP事件、SIEM警报、电子邮件报告和任何其他值得注意的安全事件源创建。\n每种case都可以分解为一个或多个任务。与每次创建一个case时都将相同的任务添加到给定类型的case不同，分析人员可以使用TheHive的模板引擎一次性地创建它们。案例模板还可以用于将度量标准与特定的案例类型相关联，以推动团队的活动，识别花费大量时间的调查类型，并寻求将繁琐的任务自动化。\n每个任务都可以分配给给定的分析人员。团队成员也可以负责一项任务，而不必等待别人分配给他们。\n任务可能包含多个工作日志，贡献分析人员可以使用这些日志来描述他们要做什么、结果如何、附加一些证据或值得注意的文件等等。可以使用富文本编辑器或Markdown编写日志。\n三、行为\n每一种情况下都有一个、数百个或数千个可观测值，您可以从MISP事件或发送到平台的任何警报中直接创建或导入它们。快速分类和过滤。利用皮层和它的分析和反应的力量来获得宝贵的洞察力，加速你的调查和包含威胁。利用标签，旗标IOCs，目击和识别以前看到的可观察到的，以满足您的威胁情报。一旦调查完成，出口IOCs到一个或几个MISP实例。\n您可以在创建的每个案例中添加一个或数千个观察表。您还可以创建MISP事件的案例。TheHive可以很容易地链接到一个或多个MISP实例和MISP事件可以预览，以决定他们是否值得调查或不。如果准备进行调查，分析人员可以将事件添加到现有案例中，或者使用可自定义模板将其作为新案例导入。\n由于TheHive的Python API客户端TheHive4py，它可以向TheHive发送SIEM警报、网络钓鱼和其他可疑电子邮件以及其他安全事件。它们将与新的或更新的MISP事件一起出现在警报面板中，在这些事件中可以预览、导入案例或忽略它们。\n\nTheHive有能力自动识别在以前的案例中已经被观察到的可观察对象。可观察对象还可以与TLP和PAP以及使用标记提供或生成它们的源相关联。分析人员还可以很容易地将observables标记为IOCs，并隔离那些使用搜索查询的对象，然后导出它们，以便在SIEM或其他数据存储中进行搜索。\n根据您的OPSEC需求，分析人员可以在几次点击中分析上百个皮层实例，根据您的OPSEC需求，分析人员可以分析上百个皮层实例:DomainTools、VirusTotal、PassiveTotal、Joe Sandbox、geolocation、threat feed查找等。\n具有脚本编制技巧的安全分析人员可以很容易地将他们自己的分析程序添加到Cortex中，以便自动执行必须在observables或IOCs上执行的操作。他们还可以根据TLP决定分析程序的行为。例如，如果相关的TLP为白色或绿色，则可以将添加为observable的文件提交给VirusTotal。如果它是琥珀色的，则计算它的散列并将其提交给VT，但不提交文件。如果是红色，则不执行VT查找。\n四、响应\n分析人员可以利用Cortex响应器来控制事件、清除恶意软件和执行其他协调任务。例如，他们可以调用应答器来回复来自TheHive的可疑电子邮件通知，在代理级别阻塞URL，或者从被破坏的端点收集证据。\n五、体系结构\nTheHive是用Scala写的，使用的是ElasticSearch 5。x进行存储。它的REST API是无状态的，因此可以水平伸缩。前端使用AngularJS与Bootstrap。\n\n五、工作流\n下图展示了一个典型的工作流程:\n\n六、附加功能\n6.1身份验证\nTheHive支持多种认证方法:\nActive Directory\n    LDAP\n    API keys\n    X.509 SSO\n    OAuth 2\n    Local authentication\n6.2指示板\nTheHive提供了一个强大的、高度可配置的模块，允许你创建有意义的仪表板来驱动你的活动和支持你的预算请求。\n6.3案例合并\n如果您认为两个(或多个)案例与相同的威胁相关，或者有显著的可观察到的重叠，则很容易将它们合并在一起。\n6.4案例与观察滤波\n您可以非常容易地过滤案例和观察数据，只显示您感兴趣的数据。\n6.5MISP和Cortex\n可以将TheHive配置为使用各种过滤器(标签白名单、标签黑名单、组织黑名单、每个事件的最大属性……)从一个或多个MISP实例导入事件。您还可以使用TheHive将案例作为MISP事件导出到一个或多个MISP服务器。\nCortex是TheHive的完美伴侣。使用一个或多个来分析大规模的观察结果并对事件做出响应。\n6.6TheHive支持Alert Feeders\n七、相关截图\n\n图一创建案例\n手动创建案例，设置案例的严重性，信息共享方式（TLP），以及操作案例的方式（PAP）\n\n图2在案例中添加任务\n在案例中添加任务，好像只是一个文字记录过程，用于记录对这个案例进行分析的过程\n\n图3添加观察值  \n为案例添加相关观察值，该观察值可用于调查分析该案例\n  \n\n图4 添加后的案例列表\n选择左上角的action中的run analyzers可执行相关的分析，默认有Abuse_Finder_2_0等5种分析方式\n\n\n\n图5 分析结果列表  \n双击图4中的列表，会出现对应观察值的分析结果，以及相关的分析报告\n\n\n\n图6案例各种维度的统计分析\n可用仪表盘对案例的各种状态进行统计分析，并支持数据的下载和图片的保存\n\n图7job的各种维度统计\n对各种job进行统计分析\n\n\n图8对各种告警进行统计\n\n图10对观察值类型的定制\n\n图11案例模板的定制\n\n图12报告模板的定制\n\nhttps://thehive-project.org/\nhttps://www.circl.lu/misp-images/latest/MISP_v2.4.121@0f63223-VMware.zip\n","slug":"sec/MISP/一个4-in-1安全事件响应平台","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"安全运营","author_index":"安全书"},{"id":"6c0e4338384afddea47c090b9e1f3147","title":"MISP-开源威胁情报共享平台","content":"MISP-开源威胁情报共享平台MISP（核心软件） - 开源威胁情报和共享平台（以前称为恶意软件信息共享平台）\nMISP是一种开源软件解决方案，用于收集，存储，分发和共享有关网络安全事件分析和恶意软件分析的网络安全指标和威胁。 MISP由事件分析师，安全和ICT专业人员或恶意软件逆转器设计，以支持他们的日常运营，以有效地共享结构化信息。\nMISP的目标是促进安全社区和国外的结构化信息共享。 MISP提供支持信息交换的功能，但也提供网络入侵检测系统（NIDS），LIDS以及日志分析工具SIEM对所述信息的消费。\n交换信息可以更快地检测到目标攻击并提高检测率，同时减少误报。 我们还避免扭转类似的恶意软件，因为我们非常清楚其他团队或组织已经分析了特定的恶意软件。\nMISP 意软件信息共享平台和威胁共享平台的核心功能包括：\n\n高效的IOC和指标数据库，允许存储有关恶意软件样本，事件，攻击者和情报的技术和非技术信息。\n自动关联查找来自恶意软件，攻击活动或分析的属性和指标之间的关系。相关引擎包括属性之间的相关性和更高级的相关性，例如模糊散列相关（例如ssdeep）或CIDR块匹配。也可以启用相关性或按属性禁用事件。\n灵活的数据模型，可以表达复杂对象并将其链接在一起，以表达威胁情报，事件或连接元素。\n内置共享功能，可使用不同的分发模型简化数据共享。 MISP可以自动同步不同MISP实例之间的事件和属性。高级过滤功能可用于满足每个组织的共享策略，包括灵活的共享组容量和属性级别分配机制。\n直观的用户界面，供最终用户创建，更新和协作处理事件和属性/指标。一个图形界面，可以在事件及其相关性之间无缝导航。用于创建和查看对象与属性之间关系的事件图功能。高级过滤功能和警告列表，可帮助分析人员提供事件和属性，并限制误报风险。\n以结构化格式存储数据（允许自动使用数据库用于各种目的），同时广泛支持欺诈指标中的网络安全指标，如金融部门。\n导出：生成IDS，OpenIOC，纯文本，CSV，MISP XML或JSON输出以与其他系统集成（网络IDS，主机IDS，自定义工具），缓存格式（用于取证工具），STIX（XML和JSON）1和2，NIDS出口（Suricata，Snort和Bro / Zeek）或RPZ区域。可以通过misp-modules轻松添加许多其他格式。\n导入：批量导入，批量导入，从OpenIOC导入，GFI沙箱，ThreatConnect CSV，MISP标准格式或STIX 1.1 / 2.0。许多其他格式通过misp-modules轻松添加。\n灵活的自由文本导入工具，可简化非结构化报告与MISP的集成。\n一个温和的系统，用于协作处理事件和属性，允许MISP用户建议对属性/指标进行更改或更新。\n数据共享：使用MISP自动与其他方和信任组进行交换和同步。\n委托共享：允许一个简单的伪匿名机制将事件/指标的发布委托给另一个组织。\n灵活的API，可将MISP与您自己的解决方案集成。 MISP与PyMISP捆绑在一起，PyMISP是一个灵活的Python库，用于获取，添加或更新事件属性，处理恶意软件样本或搜索属性。详尽的restSearch API，可轻松搜索MISP中的指标，并以MISP支持的所有格式导出。\n可调整的分类法，根据您自己的分类方案或现有分类对事件进行分类和标记。分类法可以是您的MISP的本地分类，但也可以在MISP实例之间共享。\n智能词汇称为MISP galaxy，与现有的威胁演员，恶意软件，RAT，勒索软件或MITER ATT＆CK捆绑在一起，可以轻松地与MISP中的事件和属性相关联。\nPython中的扩展模块，可以使用您自己的服务扩展MISP或激活已有的misp-modules。\n瞄准支持以获得组织关于共享指标和属性的观察。瞄准可以通过MISP用户界面，API作为MISP文档或STIX目击文档来提供。\nSTIX支持：以STIX版本1和版本2格式导入和导出数据。\n通过GnuPG和/或S / MIME对通知进行集成加密和签名，具体取决于用户的首选项。\nMISP内的实时发布 - 订阅频道，以自动获取ZMQ（例如misp-dashboard）或Kafka发布中的所有更改（例如，新事件，指示符，目击或标记）。\n\n参考：\n恶意软件分析大合集\n","slug":"sec/MISP/MISP-开源威胁情报共享平台","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"MISP","author_index":"安全书"},{"id":"e8ef9943ac6094f4ceac1e5621ee5615","title":"为威胁情报和机器学习研究收集和策划IOC白名单","content":"为威胁情报和机器学习研究收集和策划IOC白名单在这篇文章中，我分享了我为威胁情报和机器学习研究建立和维护大量良性的IOCs(白名单)的经验。\n白名单在威胁情报关联中是一个有用的概念，因为它可以很容易地让良性观察进入威胁情报指示源，特别是来自开源供应商或供应商，他们不应该那么小心。如果这些威胁情报源被用于阻塞(例如，在防火墙或WAF设备中)或警报(例如，在SIEM或IDS中的日志关联)，良性条目进入安全控制的成本将非常高(浪费分析时间来筛选假阳性警报，或为被阻塞的合法网站损失业务生产力)。白名单通常用于过滤威胁情报源中的可观察信息，如果它们与事件日志(例如，bluecoat代理日志、防火墙日志等)相交，则几乎肯定会被标记为假阳性，并用于警报。白名单对于构建机器学习模型和丰富上下文信息所需的标记数据集也非常有用。\n良性观察的典型例子是8.8.8.8(谷歌发布的开放DNS解析器)。这已经在许多开源和商业威胁情报中错误地找到了它的方式，因为有时恶意软件使用这个IP来进行DNS解析，或者他们ping它来进行连接检查。由于威胁feed的派生/收集方式不同，通常会有许多其他可观察对象进入威胁feed。以下是威胁情报反馈中误报的主要来源的总结，以及识别这些来源以防止其使用的方法。如今，大多数商业威胁情报平台都很擅长识别这些信息，而占主导地位的开源威胁情报平台MISP在其警告列表方面也做得越来越好，但正如你将在下面的文章中发现的那样，还有一些改进的空间。\n一、良性入站观测值\n从分布式网络传感器(如蜜罐或防火墙日志)获得的威胁情报馈源中，通常会出现良性的入站观测数据。这些ip出现在防火墙日志中，通常是良性的，或者最多被认为是噪音。下面是几种常见的良性入站可观察类型。每一种类型都有推荐的数据源或收集技术，列在子项目中:\n（1）已知的网络爬虫：网络爬虫是服务器爬行的万维网和通过这个过程可能进入许多公司的网络或可能意外地击中蜜罐或防火墙。\n一旦确定了模式，可以使用RDNS + DNS分析批量枚举这些模式。下面是googlebots的一个示例模式。挖掘大量rdns数据集合可以揭示需要关注的其他模式。下面是一个例子，一个简单的PTR查找已知的googlebot IP。这将开始揭示可以编纂的模式，假设您可以访问像这里提供的(或者可以轻松生成)的大量RDNS数据。\n  \n\n（2）与高可见项目或安全公司(Shodan, Censys, Rapid7项目Sonar, ShadowServer等)相关的已知端口扫描器。\nRDNS + DNS分析可以批量枚举这些(假设供应商希望被识别)。例子:\n\n\n（3）邮件服务器——这些服务器发送电子邮件，有时会错误地被表示为威胁信息。\n为了列举这些，你需要一个流行的电子邮件域名列表。然后对该列表执行DNS TXT请求并解析SPF记录。可能需要多次查找，因为SPF允许重定向和包含。下面的示例显示了对gmail.com手动执行此操作所需的命令。返回的CIDR块是发送gmail电子邮件的IP空间。警告或封锁这些会导致糟糕的一天。\n\n（4）云PaaS提供商——大多数云提供商通过api或文档发布他们的IP空间。这些列表对于派生白名单很有用，但是需要进一步过滤。理想情况下，只白名单大量共享的云IP空间(如S3、CLOUDFRONT等)，而不是容易被坏人使用的IP空间，如EC2s。这些白名单不应用于排除解析到此IP空间的域名，而应用于警报的丰富或从这些IP范围禁用基于IOC的警报。\n亚马逊AWS IP范围：https://ip-ranges.amazonaws.com/ip-ranges.json\n谷歌云平台IP范围：https://gist.github.com/n0531m/f3714f6ad6ef738a3b0a\nAzure IP范围：https://www.microsoft.com/en-us/download/details.aspx?id=56519\n注:Greynoise是“反威胁”情报的商业提供商(也就是说，他们可以识别噪音和其他良性观察对象)。他们非常擅长识别上面列出的良性观测的类型，因为他们维护一个全球分布的传感器阵列，并且专门分析网络事件以识别良性活动。\n注意:misp -warning列表现在提供了许多这样的项目，但是它们可能已经过时了(它们的一些列表已经几个月没有更新了)。理想情况下，所有这些列表都是通过从权威来源自动收集而不是存储在github中的硬编码数据来保持最新的(除非这些数据经常自动更新)。更多提示请参见“建立/维护白名单数据”一节。\n二、良性的出站可见\n良性的出站观察经常出现在来自恶意软件沙箱、URL沙箱、出站web爬虫、电子邮件沙箱和其他类似的威胁信息中。下面是几种常见的良性出站可观察类型。每一种类型都有推荐的数据源或收集技术，列在子项目中:\n1、流行域名-流行域名可以结束威胁情报来源，特别是那些来自恶意软件沙箱，因为通常情况下，恶意软件使用良性域名作为连接检查和一些恶意软件，如那些执行点击欺诈行为更像网络爬虫，访问许多不同的良性网站。这些流行的域名经常出现在大多数公司网络中，而且本质上几乎都是良性的(注意:它们可以被破坏并用于托管恶意内容，所以在这里需要非常小心)。\n下面是一些流行域名的数据源。它们在衡量受欢迎程度的方式上略有不同(通过Web访问者的数量、Web爬行数据出现的频率、基于DNS查询的数量或组合)。这些列表不应该原样用于白名单;它们需要被过滤/精炼。请参阅下面的“构建/维护白名单数据”一节，了解关于优化建议的更多细节。\nAmazon Alexa top 1 Million\nCisco Umbrella Top 1 Million\nDomcop Top 10m Domains(data) - The top 10 million websites taken from the Open PageRank Initiative.\nMajestic Million Domains\nMoz’s list of the most popular 500 websites on the internet\nQuantcast Top 1 Million\nTranco: A Research-Oriented Top Sites Ranking Hardened Against Manipulation\nMISP-warninglists’dax30 websites,bank websites,university domains,url shorteners,whats-my-ip sites\n2、流行IP地址-流行IP与流行域名非常相似。它们无处不在，当它们放到威胁情报feed时，它们会造成大量的误报。流行IP列表可以通过解析流行域名列表生成。这些列表不应该原样用于白名单;它们需要被过滤/精炼。请参阅下面的“构建/维护白名单数据”一节，了解关于优化建议的更多细节。\n3、免费的电子邮件域-免费的电子邮件域偶尔会意外地出现在威胁情报feed，所以它是好的保持一个良好的列表，以防止误报。Hubspot提供了一份不错的清单。https://knowledge.hubspot.com/forms/what-domains-are-blocked-when-using-the-forms-email-domains-to-block-feature\n4、广告服务器——广告服务器经常出现在URL沙箱feed中，因为这些feed通常是通过访问许多网站并等待恶意攻击或反病毒警报来获得的。这些相同的服务器总是出现在良好的互联网流量中。Easylist提供了这类数据。https://easylist.to/\n**5、CDN IPs -**内容分发网络地理上分布式的缓存代理服务器或网络提供高可用性和高性能web内容分布。它们的服务器被大量共享以分发各种web内容。当来自CDNs的ip转化为威胁情报时，假阳性很快就会出现。下面是几个CDN IP和域源。\nWPO-Foundation CDN list (embedded in Python code)\nAWS IP Ranges- but filtered for cloudfront and S3 IP space.\nCloudflare IP Ranges\nFastly IP Ranges\nMaxCDN IP Ranges\n与识别已知的web爬虫非常相似，一旦识别出模式，可以使用DNS PTR-Lookup + DNS A-Lookup 分析批量枚举这些爬虫。\n6、证书撤销列表(CRL)和在线证书状态协议(OCSP)域/ url——当在恶意软件沙箱中执行二进制文件并且可执行文件已经签名时，将连接到CRL和OCSP服务器。正因为如此，这些经常错误地放入到威胁feed。\n抓取证书从Alexa顶级网站，提取OCSP URL。这个老的Alienvault 帖子描述了这个过程(以及另一种使用现已不存在的EFF SSL天文台的方法)，而这个github 存储地提供了实现这个过程的代码。在此应注意，因为对手可以影响以这种方式收集的数据。\nMISP-warninglists’ crl-ip-hostname\n7、NTP服务器——一些恶意软件调用NTP服务器进行连接检查或确定真实的日期/时间。正因为如此，NTP服务器经常会错误地获取来自恶意软件沙箱的威胁情报。\nWeb抓取NTP服务器列表(如NIST Internet Time服务器和NTP Pool Project服务器)，并执行DNS解析来导出每个区域负载均衡器背后的所有服务器。\n8、根名称服务器和TLD名称服务器\n对公共后缀列表中的每个域执行DNS NS-lookup，然后执行DNS A-lookup每个名称服务器域以获得它们的IP地址。\n9、邮件交换服务器\n获取流行电子邮件域的列表，然后对流行电子邮件域执行MX查找，以获得它们各自的邮件交换(MX)服务器。对MX服务器列表执行DNS A-lookup以获得它们的IP地址。\n10、NAT会话遍历工具(STUN)是一组标准化的方法，包括一个网络协议，用于在实时语音、视频、消息传递和其他交互通信应用中遍历网络地址转换器(NAT)网关。“通过https://en.wikipedia.org/wiki/STUN。下面是一些**STUN**服务器的来源(其中一些看起来很旧)。\nhttps://www.voip-info.org/stun//\nhttps://gist.github.com/mondain/b0ec1cf5f60ae726202e\nhttps://gist.github.com/zziuni/3741933\nhttp://enumer.org/public-stun.txt\n11、停车IPs - IPs作为 DNS-A的默认IP记录，用于新注册的域名。\nmaltrails parking_sites\n12、流行的开放DNS解析器\n公共递归名称服务器 (Wikipedia)——列出了最大和最流行的开放递归名称服务器。\n公共DNS服务器列表（Public DNS Server List）——维护一个公开的递归名称服务器的大列表，_可能对上下文有用，但不应该被白名单_。\n13、安全公司、安全博客和安全工具网站——这些网站经常出现在威胁邮件列表中，这些邮件列表有时会被当作威胁源而被错误地标记为恶意。\n刮掉所有与awesome-*安全相关的著名github存储点。这有点冒险，因为对手可能会将他们的域名添加到这些列表中。例子:\nawesome-security\nawesome-malware-analysis\nawesome-honeypots\nMISP-warninglists提供了一个看起来很不错的安全提供这博客帖子（https://github.com/MISP/misp-warninglists/tree/master/lists/security-provider-blogpost）和自动恶意软件分析列表（https://github.com/MISP/misp-warninglists/tree/master/lists/automated-malware-analysis）。\n14、Bit Torrent Trackers-github.com/ngosang/trackerslist\n15、跟踪域名-常用的著名的电子邮件营销公司。在威胁情报源经常出现在来自垃圾邮件或钓鱼邮件sinkhole。在实践中导致了高假阳性率。\nPDNS和/或域Whois分析是识别这些可观察到的模式的一种方法。下面是一个例子使用Whois数据为Marketo.com和确定所有其他Marketo电子邮件跟踪域使用Marketo的域名服务器。这个例子来自Whoisology，但批量Whois挖掘是首选方法。\n\n注意:mis- warning列表现在提供了其中的一些项目，但是它们可能已经过时了。理想情况下，通过从权威来源自动收集，所有这些列表都是最新的。更多提示请参见“建立/维护白名单数据”一节。\n三、良性的基于主机的可见指标\n善意的基于主机的可观察性指标在基于恶意软件沙箱的威胁情报源中非常常见。下面是一些可观察类型的示例。到目前为止，我只发现了一些不错的哈希列表(见下面)。\nFile hashes\nMutexes\nRegistry Keys\nFile Paths\nService names\n数据来源:\nNSRL hashset\nWindows-7/32 Diskprint\nNeo23x0 / fp-hashes.py\nMISP常见的IOC假阳性\n曼迪昂特红线白名单(镜像)-注意:这在我写这篇博客的时候已经5岁了。\nHashsets.com(商业)哈希列表\n在有关恶意软件检测的领先学术和行业研究中，通常使用Virustotal来构建带标签的训练数据。更多细节请看这篇文章。这些技术似乎非常适合用于训练数据创建，但不推荐用于操作使用的白名单，因为错误否定的可能性很高。\n注意:如果你的目标是在二进制文件上建立一个机器学习模型，你应该考虑Endgame的Ember。“数据集包括从1.1M二进制文件中提取的特征:900K训练样本(300K恶意，300K良性，300K未标记)和200K测试样本(100K恶意，100K良性)”。看到Ember:一个开放的数据集训练静态PE恶意软件的机器学习模型更多的细节。\n四、白名单排除\n有许多可观察到的东西，由于它们的受欢迎程度和重要性，我们永远不会想把它们列入白名单。这些应该在一个白名单排除列表(又称灰名单)中维护。下面是一些例子:\n共享主机域名和动态DNS域名-这些基本域名不应该被警告，因为许多在Alexa的前100万名单，将令人难以置信的噪音。_这些子域很容易引起警觉，因为它们很容易被对手控制和滥用。_下面是这些信息的一些来源，但是找出主要的供应商并抓取他们的网站或api将是保持这些信息新鲜的更好方法。\nShared Hosting-Maltrails free web hosting\nDynamic DNS-Maltrails DynDNS\nDNS Sinkhole IPs\nhttps://tisiphone.net/2017/05/16/consolidated-malware-sinkhole-list/\ngithub.com/brakmic/Sinkholes\nsinkdb.abuse.ch\nMISP warninglists sinkholes\n五、建立/维护白名单数据\n为了可维护，白名单的生成需要自动化。对于希望确保总是在白名单中的内容，这条规则可能有例外，但对于其他内容，理想情况下它们是从权威来源收集的，或者是基于可靠的分析技术生成的。您不能总是盲目地信任上面列出的每个数据源。对于某些情况，需要一些自动验证、过滤或分析。下面是一些有效的方法。\n1、白名单中的每个实体都应该被分类(这是什么类型的白名单条目?)和来源(这是从哪里来的?)以便我们确切地知道它是如何到达那里的(即什么数据源负责)，以及它是什么时候被添加/更新的。如果存在与白名单相关的问题，这将有助于解决问题的特定来源。\n2、从原始源站点检索白名单条目，并从那里解析/提取数据。尽可能避免一次转储白名单条目，因为它们很快就会过时。如果包含一次性转储，请确保保持它们的沿袭。\n3、一些大容量数据集对于分析扩展或筛选各种白名单非常有用。\n（1）批量活动DNS解析(A-lookups, MX-lookups, NS-lookups,和 TXT-lookups)。Adns在这方面可能很有用。\n（2）批量RDNS数据(从scans.io获取或自己收集)。\n（3）批量Whois数据-这可以从几个供应商购买。这里有一些:whoisxmlapi.com, iqwhois.com, jsonwhois.com, whoisdatabasedownload.com，和research.domaintools.com。\n（4）被动DNS (PDNS)数据可以从几个供应商购买，或者你可以使用自己的网络来收集和存储这些数据。以下是一些PDNS的供应商:farsightsecurity.com, deteque.com, circl.lu, riskiq.com, passivednsmnemonic.no和coresecurity.com(原Damballa)。\n4、Netblock所有权(Maxmind)查找/分析对于一些审查非常有用。\n5、白名单应该至少每天更新以保持新鲜。可能会有一些数据源比这更改得更频繁或更少。\n在刷新白名单时要小心。添加健全检查，以确保在替换旧白名单之前正确地生成了新白名单。白名单加载失败的代价将是大量的误报(不幸的是，我不得不以痛苦的方式吸取这个教训……)。\n6、流行域名列表不能从表面上看是良性的。恶意域名总是会进入这些列表。这里有一些解决方法:\n7、使用n天稳定top- x技术。例如，稳定6个月Alexa top 500k -创建一个衍生列表从顶级Alexa域名，你过滤的名单，只有域名已经在Alexa top 500k名单，在过去6个月每天。在恶意域检测文献中，常用该技术构建高质量的良性标记数据。它并不完美，可能需要根据白名单的使用情况进行调整。这种技术需要保存历史上流行的域名列表。Wayback机器似乎拥有Alexa top1m数据的巨大历史镜像，可能适合引导自己的收藏。\n8、这些列表的批量DNS解析对于生成流行的IP列表也很有用，但只有在使用n天稳定的top-X概念或在如何使用它们时才有用。\n9、使用白名单排除设置，以删除类别的域名/ ip，你永远不想白名单。白名单排除集也应通过权威来源的自动收集保持新鲜(例如，在可能的情况下，抓取动态DNS提供商和共享托管网站，PDNS / Whois分析也可以工作)。\n10、最后，在生成白名单时要小心，并考虑数据的哪些方面是被对手控制的。我们需要小心，不要盲目相信这些事情。一些例子:\nRDNS条目可能具有欺骗性，特别是当对手知道它们用于白名单时。例如，对手可以为他们拥有的IP地址空间创建PTR记录，与谷歌的googlebot RDNS或Shodan的census RDNS相同，但他们不能更改DNS记录，将该域名映射回他们的IP空间。对于这些，通常还需要正向查找或netblock所有权验证。\n总之，白名单对于在与事件数据关联之前从威胁情报列表中过滤出可观察的信息，为机器学习模型构建标记数据集，以及用上下文信息丰富威胁情报或警报非常有用。创建和维护这些列表需要大量的工作。要非常小心，不要走得太远，或者白名单域或ip很容易被对手控制。\nhttp://www.covert.io/\n","slug":"sec/MISP/为威胁情报和机器学习研究收集和策划IOC白名单","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"IOC","author_index":"安全书"},{"id":"33c279dddaa220a0eb336dbd68718677","title":"如何使用MISP的API","content":"如何使用MISP的APIWelcome back to this series on using MISP for threat intelligence!\nMISP (Malware Information Sharing Platform and Threat Sharing) is an open-source threat intelligence platform that allows you to share, collate, analyze, and distribute threat intelligence. It is used across industries and governments worldwide to share and analyze information about the latest threats. This series aims to give you the knowledge you need to get up and running with MISP as quickly as possible. \nIf you have followed this series, you will now have events and attributes (IOCs) in your MISP instance and know how to search through them. However, this can be clunky using the MISP web interface. Thankfully, MISP exposes an API we can use to perform any action we can do in the web interface in code!\nToday, you learn to use this API to make the most of your MISP instance. You will see how to get statistics about your MISP instance, search for attributes and events, and visualize data you’ve added to your instance.\nLet’s jump in and start using the API!\nWhat is an API?Before looking at MISP’s API, let’s have a quick refresher on what an API is and what it is used for. \nAn Application Programming Interface (API) is a set of protocols, routines, and tools for building software applications. It defines a set of rules that allow software applications to interact with each other to exchange data and services. They are a bridge between two applications that allows them to communicate with each other in a standard way. \nAPIs allow developers to access specific functionality or data from a service or application without requiring access to the underlying code. This makes it possible to integrate different software applications, databases, and services and build new applications on top of existing ones. \nThe most common APIs you are likely to interact with are web APIs, which allow you to interact with a web-based application in a programmable manner. APIs can be public (which anyone can use) or private (which are only accessible by authorized parties). Again, most of the time, you will use APIs requiring some form of authorization (username and password, token, etc.), which is the case with MISP’s API. \nThe Basics of the MISP APIMISP comes with a RESTful API, which you can use to query your MISP instance for data about itself (e.g., statistics) or data about the intelligence it holds (e.g., events and attributes) using HTTP GET requests. This data is returned to you in either JSON or XML format so you can easily parse it into the form you want to work with. You can also use HTTP POST, PUT, and DELETE requests to add, edit, or remove data from your MISP instance programmatically.\nInteracting with your MISP instance through its API saves you from going through MISP’s web interface to retrieve this data and increases the efficiency of your operations through the power of code and automation.\nInteracting with the MISP APITo interact with the MISP API, you must add an authentication key to authenticate your application with your MISP instance. You can do this by going to Administration in the top menu and selecting the List Auth Keys dropdown option.\n\nYou may not see this option if you do not have the appropriate privileges. To circumvent this, log in as the default admin user.\nThis will bring you to the Authentication Key Index, where you can click the Add authentication key button to create a new API key. \n\nClicking this button will bring up a popup window for you to fill out the details of the authentication key you are adding. Here, you can select the user account associated with the key, add a comment about what this key is used for, allowlist only specific IP addresses, and add an expiration date. All of these are optional. Click Submit when done.\n\nMake sure to save your authentication key in your password manager so you can use it later. This is very important. You won’t be able to see this key again in MISP, and you will have to generate a new one if you forget it. Click the I have noted down my key, take me back now button when done.\n\nYou will now see your authentication key appear on the Authentication Key Index page, and you can begin using it!\n\nThe Best Way to Use the MISP APIYou can interact with the MISP API through direct web requests to the MISP API endpoint. For instance, making a GET request to https://&lt;misp_ip&gt;/events to retrieve information about an event or a POST request to https://&lt;misp_ip&gt;/events/add to add an event. However, if you know a little bit of Python, there is an easier way. \nPyMISP is a Python library you can use to access MISP, make API requests, and automatically parse data returned into Python objects so you can manipulate them using standard Python methods and functions. You can install PyMISP using the Python package manager pip with the command pip3 install pymisp or use another installation method detailed on the PyMISP GitHub page.\nOnce installed, you can use PyMISP to create a Python script that acts as a wrapper for all your MISP API queries, allowing you to perform complex data analysis tasks easily. That said, skip the script. The best way to perform data analysis (and prototyping) is using a Jupyter Notebook. \nA Jupyter Notebook can serve two main purposes: \n\nCreating a mix of code and Markdown content that serves as “interactive documentation.” A user reads the Markdown content and executes the code as they work their way through the Notebook. \nFor prototyping code that you are building into a larger and more complex tool.\n\nYou can use Jupyter Notebooks for prototyping as you interact with the MISP API through Python code. To follow along, see Python Threat Hunting Tools: Part 10 — The Power of Jupyter Notebooks to learn how to create a Jupyter Notebook. Then, use the code examples shown below in your Jupyter Notebook, replacing the variables I use with those of your MISP instance. Add documentation so you remember what each code example does using Markdown cells.\nAuthenticationYou must first authenticate to send API requests to your MISP instance. You need two things to do this:\n\nAn authentication key to authenticate to the API (as discussed above). \nThe IP address or URL of your MISP instance.\n\nWith these in hand, you can use the code below to authenticate to the MISP API using Python:\nPython\n12345678# import PyMISP object from pymisp Python libraryfrom pymisp import PyMISP# url or IP address of MISP instanceMISP_URL = &#x27;&lt;misp_url&gt;&#x27;# your API authentication key, generated using your MISP instanceMISP_KEY = &#x27;&lt;api_key&gt;&#x27;# create MISP instance to interact with using Python methodsmisp = PyMISP(MISP_URL, MISP_KEY, ssl=False, debug=False)\n\nYou are now ready to begin interacting with the MISP API using Python. Let’s see how to retrieve statistics, search for attributes and events, and visualize data!\nThe ssl and debug options have been set to false to avoid unnecessary error messages when prototyping. \nRetrieving StatisticsYou can get data from the MISP API about general statistics, tags, and attributes related to your MISP instance. \nGeneral StatisticsTo retrieve general statistics, you can use the user_statistics() method associated with the misp object you created when authenticating.\nPython\n1response = misp.user_statistics()\n\nThis returns a Python dictionary, which you can query for information like total users, events, and attributes.\nPython\n1234567def general_stats():  res = misp.user_statistics()  print(f&quot;Total users: &#123;res[&#x27;stats&#x27;][&#x27;user_count&#x27;]&#125;&quot;)  print(f&quot;Total events: &#123;res[&#x27;stats&#x27;][&#x27;event_count&#x27;]&#125;&quot;)  print(f&quot;Total attributes: &#123;res[&#x27;stats&#x27;][&#x27;attribute_count&#x27;]&#125;&quot;)general_stats()\n\nTag StatisticsTo retrieve tag statistics, you can use the tag_statistics() method associated with the misp object you created.\nPython\n1response = misp.tag_statistics()\n\nThis returns a Python dictionary which you can query for information based on specific tags.\nPython\n1234567def tag_stats():  res = misp.tag_statistics()  print(f&quot;Total reports: &#123;res[&#x27;tags&#x27;][&#x27;cssa:origin=report&#x27;]&#125;&quot;)  print(f&quot;Total investigations: &#123;res[&#x27;tags&#x27;][&#x27;cssa:origin=manual_investigation&#x27;]&#125;&quot;)  print(f&quot;Total purple team exercises: &#123;res[&#x27;tags&#x27;][&#x27;custom:purple-team-exercise&#x27;]&#125;&quot;)general_stats()\n\nAttribute StatisticsTo retrieve statistics about attributes, you can use the attribute_statistics() method associated with the misp object you created. \nPython\n1response = misp.attribute_statistics()\n\nThis returns a Python dictionary, which you can query for information about specific attributes.\nPython\n123456789def attribute_stats():  res = misp.attributes_statistics()  print(f&quot;Total MD5 hashes: &#123;res[&#x27;md5&#x27;]&#125;&quot;)  print(f&quot;Total domains: &#123;res[&#x27;domains&#x27;]&#125;&quot;)  print(f&quot;Total IP addresses: &#123;res[&#x27;ip-dst&#x27;]&#125;&quot;)  print(f&quot;Total URLs: &#123;res[&#x27;url&#x27;]&#125;&quot;)  print(f&quot;Total email addresses: &#123;res[&#x27;email-src&#x27;]&#125;&quot;)  general_stats()\n\nSearching for Attributes and EventsYou can use the MISP API to search for Indicators of Compromise (IOCs) you uploaded to your MISP instance as attributes. Searching for them will return the MISP event they are associated with.\nTo learn more about attributes and events in MISP, read Threat Intelligence with MISP: Part 3 — Creating Events.\nThe code below searches for an IOC and uses the misp object’s search() method to query the MISP API for this IOC. MISP will search all the attributes it has stored in its database and return the event an attribute is associated with. The Python code saves the response returned by the API in a dictionary data structure and checks to see if it contains data using an if statement. If it does, this data is parsed using dictionary bracket notation to return key event information that is printed using Python f strings.\nPython\n123456789101112131415IOC = &quot;oxcdntech.com&quot;response = misp.search(value=IOC)if response:    print(&quot;--- Matching Event ---&quot;)    print(f&quot;Event ID: &#123;response[0][&#x27;Event&#x27;][&#x27;id&#x27;]&#125;&quot;)    print(f&quot;Event Info: &#123;response[0][&#x27;Event&#x27;][&#x27;info&#x27;]&#125;&quot;)    print(f&quot;Date Added: &#123;response[0][&#x27;Event&#x27;][&#x27;date&#x27;]&#125;&quot;)    print(f&quot;Tags: &#123;response[0][&#x27;Event&#x27;][&#x27;date&#x27;]&#125;&quot;)    for tag in response[0][&#x27;Event&#x27;][&#x27;Tag&#x27;]:        print(f&quot;- &#123;tag[&#x27;name&#x27;]&#125;&quot;)    print(&quot;-&quot; * 20)else:    print(f&quot;The IOC &#123;IOC&#125; is not in MISP&quot;)\n\nThe IOC in this example code is a domain name (oxcdntech.com). However, you can change this for any MISP attribute type, such as IP addresses, file hashes, hostnames, email addresses, etc.\nThe MISP API provides a quick and easy way to search your MISP instance for an IOC without going through the web interface. These searches can also be scripted, automated, and integrated into larger workflows. For instance, you can write a script to check an IOC against your MISP instance, VirusTotal, GreyNoise, and any other threat intelligence source that exposes an API for you to use, allowing you to produce a more complete picture. \nVisualizing DataThe examples so far, returning statistics and searching for IOCs, have been basic. Let’s now look at a more complex example of using the MISP API to visualize the most common techniques, tactics, and procedures (TTPs) within your threat intelligence data. \nWhenever you upload a new threat intelligence report, incident, or piece of research to MISP, you can include additional context by adding a galaxy cluster on the View Event page. This additional context allows you to use shared threat intelligence frameworks or standardized lingo to describe your event, helping others understand and use it.\nRead Threat Intelligence with MISP: Part 3 — Creating Events to learn about galaxy clusters.\nUsing the Attacker Pattern galaxy (under the mitre-attack), you can add data about the TTPs associated with an event. This is useful because it helps you track how threat actors attack systems and, by extension, how to defend against them.\n\nHowever, as defenders, our time and resources are usually limited, so we need to prioritize which TTPs we want to focus on defending against. A good starting point is finding what TTPs are most commonly used by threat actors targeting your organization and prioritizing those. You can use the MISP API to automate this by aggregating common TTPs and then visualizing the most common using the pandas Python data analysis library.\nThis approach is discussed in-depth in Threat Profiling: How to Understand Hackers and Their TTPs, where you can see how to perform common TTP aggregation and visualization manually using a spreadsheet.\nThe Python code below does the following:\n\nReturns all events in your MISP.\nCreates a Python dictionary containing MITRE ATT&amp;CK TTPs mapped to a count (redacted for brevity).\nLoops through all events and increases the count of the TTP in the dictionary. It uses dictionary bracket notation to parse galaxy cluster information.\nTransforms the Python dictionary into a pandas series object.\nPlots the series object using a horizontal bar graph so you can visualize the data. This code only plots TTPs that have a count greater than 9.\n\nPython\n1234567891011121314151617181920212223242526# (1) get all events in MISP instanceall = misp.search(controller=&quot;events&quot;)# (2) create dictionary containing MITRE ATT&amp;CK TTPs mapped to a countttps = &#123;  &quot;T1548&quot; : 0,  ...  &quot;T1220&quot; : 0,&#125;# (3) loop through all events and increase count of a TTP in dictionary if an event has that TTPfor i in all:    galaxies = i[&#x27;Event&#x27;][&#x27;Galaxy&#x27;]    for j in galaxies:        if j[&#x27;type&#x27;] == &#x27;mitre-attack-pattern&#x27;:            for k in j[&#x27;GalaxyCluster&#x27;]:                ttp = k[&#x27;meta&#x27;][&#x27;external_id&#x27;][0]                if ttp in ttps:                    ttps[ttp] += 1# (4) creating a pandas series objectttps_data = pd.Series(data=ttps, index=list(ttps.keys()))# (5) plotting the data in a horizontal bar graph(ttps_data    [lambda s: s&gt;9]    .plot.barh())\n\nOnce executed, you should see a nicely formatted horizontal bar graph in your Jupyter Notebook. This shows you the most common TTPs and, unlike a spreadsheet, will dynamically change when you add more events to your MISP instance.\n\nGoing a step further, you can also limit your collection of TTPs to specific MISP events. MISP allows you to add tags to events that allow you to classify and categorize your events. For instance, you could have a tag for external threat intelligence reports, a tag for incidents your organization has faced in the past, or a tag for research you’re performing. \nThe code below limits the TTPs it aggregates and visualizes to those with the tag “software-research.” I created this custom tag to add data to MISP about threat actors and malware I was researching, including the TTPs they use. The code lets me see the common TTPs in this research data.\nPython\n12345678910111213141516171819202122232425262728293031TAG = &quot;software-research&quot;# get all events in MISP instanceall = misp.search(controller=&quot;events&quot;)# create dictionary containing MITRE ATT&amp;CK TTPs mapped to a countttps = &#123;  &quot;T1548&quot; : 0,  ...  &quot;T1220&quot; : 0,&#125;# loop through all events and increase count of a TTP in dictionary if an event has that TTPfor i in all:    # check for a specific TAG    for tag in i[&#x27;Event&#x27;][&#x27;Tag&#x27;]:        if tag[&#x27;name&#x27;] == TAG:            galaxies = i[&#x27;Event&#x27;][&#x27;Galaxy&#x27;]        else:            continue        for j in galaxies:            if j[&#x27;type&#x27;] == &#x27;mitre-attack-pattern&#x27;:                for k in j[&#x27;GalaxyCluster&#x27;]:                    ttp = k[&#x27;meta&#x27;][&#x27;external_id&#x27;][0]                    if ttp in ttps:                        ttps[ttp] += 1# plotting datattps_data = pd.Series(data=ttps, index=list(ttps.keys()))(ttps_data    [lambda s: s&gt;11]    .plot.barh())\n\nSummaryCongrats! You now know the basics of the MISP API and how to leverage it to get statistics about your MISP instance, search for attributes and events, and visualize the threat intelligence you’ve added to it. The MISP API is an incredibly powerful tool that you should invest time into learning by building your own simple Python scripts and automations. \nIf you were unable to follow along, don’t worry. I will add all these code examples to a Jupyter Notebook you can use. You can find it on my GitHub page, and I will write up how to use it in Python Threat Hunting Tools: Part 11 — A Jupyter Notebook for MISP. \nThe next installment in this series explores how to export attributes from your MISP instance as IOCs to use with your security solutions to detect and block the latest threats. You will see how to do this through the web interface and the MISP API. Stay tuned!\nDiscover more in the Threat Intelligence with MISP series!\n\nStay up-to-date whenever we release articles, tips, and guided tutorials. Don’t miss a thing and signup to get notified of new content.\nInteresting in Learning More?\nLearn the dark arts of red teamingCheck out these courses offered by Zero-Point Security. They will teach you all things red teaming from creating exploits, writing your own C2 framework, and emulating real-world threat actors.\nIf you want more of a challenge, take on one of their certification exams and land your next job in cyber:\n\nRed Team Ops\nRed Team Ops II\n\n\nLearn more cyber security skillsCheck out The All-Access Membership Pass by TCM Academy. for courses on hacking/pentesting, malware analysis, digital forensics, programming/scripting, GRC, and more!\nIf you’re looking to level up your skills even more, have a go at one of their certifications:\n\nPractical Network Penetration Tester\nPractical Junior Malware Researcher\nPractical Career-Ready Professional\n\n","slug":"sec/MISP/如何使用MISP的API","date":"2024-03-14T06:15:59.765Z","categories_index":"安全","tags_index":"MISP,API","author_index":"安全书"},{"id":"88a39baca0bf4d65eac517bd912a0a45","title":"Redis调用Lua代码测试","content":"Redis调用Lua代码测试写一段用Redis执行Lua代码的例子\n以下是一个使用Redis执行Lua代码的示例：\n12345678910111213141516171819import redis# 连接到Redis服务器r = redis.Redis(host=&#x27;localhost&#x27;, port=6379, db=0)# 定义Lua脚本script = &quot;&quot;&quot;local key = KEYS[1]local value = ARGV[1]redis.call(&#x27;SET&#x27;, key, value)return redis.call(&#x27;GET&#x27;, key)&quot;&quot;&quot;# 执行Lua脚本result = r.eval(script, 1, &#x27;mykey&#x27;, &#x27;myvalue&#x27;)# 打印结果print(result)\n\n在上面的示例中，我们首先通过redis.Redis()函数连接到Redis服务器。然后，我们定义了一个简单的Lua脚本，该脚本接受一个键（KEYS[1]）和一个值（ARGV[1]），并将该键值对存储在Redis中。最后，我们使用r.eval()方法来执行Lua脚本，并传递键和值作为参数。\n执行完Lua脚本后，我们可以通过打印result变量来查看结果。在这个例子中，结果是存储在Redis中的值（即键为’mykey’的值）。\n请注意，在实际使用中，请根据您的具体需求修改Lua脚本，并根据您的实际情况设置正确的主机、端口和数据库号码。\n123for i = 1, 100000000 do\tredis.call(&#x27;SET&#x27;, &#x27;key&#x27; .. i, i)end\n\n\n1redis-cli EVAL &quot;$(cat test.lua)&quot; 0\n\n\n\nlua中如何查看Lua的版本号\n在Lua中，可以使用全局变量 _VERSION 来查看Lua的版本号。在Lua的交互式环境中输入 _VERSION 即可查看当前Lua的版本号。例如：\n12&gt; print(_VERSION)Lua 5.3\n\n\n\n\n如何在Redis-cli执行脚本，返回redis-cli支持lua的版本。\n要在Redis-cli中执行Lua脚本并获取Redis-cli支持的Lua版本，您可以按照以下步骤操作：\n\n打开终端并启动Redis-cli。\n在Redis-cli中输入EVAL &quot;return redis.call(&#39;info&#39;,&#39;server&#39;)[&#39;redis_version&#39;]&quot; 0。\n按Enter键执行该命令。\nRedis-cli将返回一个包含服务器版本号的字符串。\n\n请注意，这个命令使用了Redis的EVAL命令来执行Lua脚本。脚本中的redis.call(&#39;info&#39;,&#39;server&#39;)将返回有关服务器的信息，并使用[‘redis_version’]来提取服务器版本号。\nEVAL “return redis.call(‘info’,’server’)[‘redis_version’]” 0\n在redis-cli中返回， redis server支持的Lua的编译器版本\n在redis-cli中可以通过以下命令返回redis server支持的Lua的编译器版本号：\n1EVAL &quot;return redis.replicate_commands()&quot; 0\n\n这个命令会执行一个简单的Lua脚本，其中调用了redis.replicate_commands()函数。如果该函数存在，则表示Redis服务器支持Lua脚本。\n在redis-cli中可以通过以下命令返回redis server支持的Lua的编译器版本号：\n1redis-cli info | grep lua_version\n\n该命令会返回类似以下的结果：\n1lua_version:5.1\n\n这表示Redis server支持Lua编译器的版本号为5.1。\n1redis-cli EVAL &quot;$(cat ver.lua)&quot; 0\nver.lua\n12print(_VERSION)return _VERSION\n\n\n\n","slug":"redis/Redis调用Lua代码测试","date":"2024-03-14T06:15:59.764Z","categories_index":"Lua,Redis","tags_index":"Redis","author_index":"安全书"},{"id":"bcb7c4b98ca2fe3fe924416317ff59aa","title":"Syslog-NG-Kakfa","content":"Syslog-NG-Kakfa12345678910111213141516171819202122232425262728293031323334353637destination d_kafka &#123;channel &#123;rewrite &#123;set(&quot;$&#123;HOST&#125;&quot; value(&quot;.eventv1.host&quot;));set(&quot;1&quot; value(&quot;.eventv1.@version&quot;));set(&quot;$&#123;ISODATE&#125;&quot; value(&quot;.eventv1.@timestamp&quot;) condition(&quot;$&#123;.eventv1.@timestamp&#125;&quot; eq &quot;&quot;));set(&quot;$&#123;MESSAGE&#125;&quot; value(&quot;.eventv1.message&quot;) condition(&quot;$&#123;.eventv1.message&#125;&quot; eq &quot;&quot;));set(&quot;$&#123;MSG&#125;&quot; value(&quot;.eventv1.message&quot;) condition(&quot;$&#123;.eventv1.message&#125;&quot; eq &quot;&quot;));set(&quot;generic&quot; value(&quot;.eventv1.type&quot;) condition(&quot;$&#123;.eventv1.type&#125;&quot; eq &quot;&quot;));&#125;;destination &#123;kafka-c(config(metadata.broker.list(&quot;localhost:9092&quot;)queue.buffering.max.ms(&quot;1000&quot;))topic(&quot;test&quot;)message(&quot;$(format-json --key .eventv1.* --rekey .eventv1.* --shift 9)&quot;));&#125;;&#125;;&#125;;\n\n\n\n\n\n","slug":"redis/Syslog-NG-Kakfa","date":"2024-03-14T06:15:59.764Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"869a6190793366537b039507409bd457","title":"启动 Redis服务","content":"启动 Redis服务如何从Linux命令执行Redis-Server\n要从Linux命令行执行Redis服务器，可以按照以下步骤：\n\n首先，确保已经安装了Redis服务器。如果没有安装，请使用适合您的Linux发行版的包管理器来安装它。例如，在Ubuntu上，可以使用以下命令进行安装：\n1sudo apt-get install redis-server\n安装完成后，您可以使用以下命令来启动Redis服务器：\n1redis-server\n如果您希望在后台运行Redis服务器，可以使用以下命令：\n1redis-server --daemonize yes\nRedis服务器将以默认配置文件redis.conf中定义的参数启动。如果您希望指定不同的配置文件，请使用--config选项：\n1redis-server --config /path/to/redis.conf\n在启动Redis服务器后，您可以使用Redis客户端与服务器进行交互。打开新的终端窗口，并输入以下命令以连接到Redis服务器：\n1redis-cli\n现在，您可以在Redis客户端中执行各种Redis命令了。\n\n\n请注意，这些步骤可能因为您所使用的Linux发行版或具体配置而有所不同。确保参考适用于您系统的文档或官方指南以获取准确信息。\nRedis服务提示下面这句话是什么意思？Error: Profile must be specified\n这句话的意思是在使用Redis服务时必须指定配置文件。\nredis的下面这个问题怎么解决Error: Can’t found libredis\n这个错误通常表示系统无法找到所需的libredis库文件。\n有几种可能的解决方法：\n\n检查是否已正确安装了redis。确保已经按照正确的方式安装了redis，并且所有依赖项也已经安装。\n\n检查libredis库文件是否存在。确认libredis库文件是否存在于系统的正确位置。你可以使用以下命令来查找库文件：\n1find / -name libredis.so\n更新动态链接器缓存。如果你已经在正确的位置上有libredis库文件，但是系统仍然无法找到它，尝试更新动态链接器缓存：\n1sudo ldconfig\n确保路径设置正确。检查LD_LIBRARY_PATH环境变量是否包含了libredis库文件所在的路径。如果没有，请将其添加到环境变量中：\n1export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/libredis\n重新编译应用程序。如果以上方法都无效，可能是因为应用程序对于libredis版本有特定要求，而你所使用的版本不兼容。尝试重新编译应用程序以适应当前的libredis版本。\n\n\n如果以上方法都无效，可以提供更多关于你的操作系统、Redis和问题环境的详细信息，以便更好地帮助你解决问题。\nNo libredis specified, exit now…\n下面这是什么问题，怎么解决？[1164109] 03 Jan 13:45:54 # Error creating tmp file ./libredis.6fI2dF: No such file or directory\ncreating temp copy of libredis fail\n这个问题是在创建一个临时文件时出现了错误，错误信息是”No such file or directory”，即找不到该文件或目录。\n要解决这个问题，可以尝试以下几种方法：\n\n检查文件路径：确保指定的文件路径是正确的，并且存在于系统中。如果路径有误，可以修正它。\n\n检查权限：确保当前用户有足够的权限来创建临时文件。如果没有足够的权限，可以尝试以管理员身份运行程序或修改文件权限。\n\n清理临时文件：有时候临时文件可能已经存在但无法使用。可以尝试删除旧的临时文件，并重新运行程序以创建新的临时文件。\n\n检查磁盘空间：确保磁盘上有足够的可用空间来创建临时文件。如果磁盘空间不足，可以清理不必要的文件或扩大磁盘容量。\n\n更新软件版本：如果问题仍然存在，可能是由于软件本身存在bug导致的。尝试更新到最新版本或联系软件开发者以获取支持和修复。\n\n\n如果以上方法都无法解决问题，建议提供更多上下文和详细错误信息以便更好地帮助你解决这个问题。\n","slug":"redis/启动 Redis服务","date":"2024-03-14T06:15:59.764Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"76f43e596a4b0521c7e8a04facad5994","title":"mac m1安装pyaudio","content":"mac m1安装pyaudio下面这个问题什么原因，如何解决DEPRECATION: –build-option and –global-option are deprecated. pip 24.0 will enforce this behaviour change. A possible replacement is to use –config-settings. Discussion can\nbe found at https://github.com/pypa/pip/issues/11859\nWARNING: Implying –no-binary=:all: due to the presence of –build-option / –global-option.\n这个问题的原因是，–build-option 和 –global-option 这两个参数在 pip 24.0 版本中被弃用，并且在未来版本中将不再被支持。pip 建议使用 –config-settings 参数作为替代方案。这个问题的讨论可以在 https://github.com/pypa/pip/issues/11859 找到。\n要解决这个问题，你可以尝试使用 –config-settings 参数来替代 –build-option 和 –global-option 参数。例如，你可以将原来的命令：\npip install package_name –build-option=some_option\n替换为：\npip install package_name –config-settings=some_option\n这样就可以避免出现警告信息并继续正常安装包。请注意，具体的解决方法可能会因你的实际情况而有所不同，建议参考相关讨论和文档以获得更准确的解决方案。\nWARNING: Implying –no-binary=:all: due to the presence of –build-option / –global-option.这句话什么意思\n这句话的意思是警告存在 –build-option / –global-option，因此暗示使用 –no-binary=:all:。\n如何将这里的python3 -m pip install pyaudio –global-option=”build_ext” –global-option=”-I/opt/homebrew/include” –global-option=”-L/opt/homebrew/lib”   中的–global-option  –build-option 换成 –no-binary=:all的形式\n要将–global-option和–build-option换成–no-binary=:all的形式，可以按照以下步骤进行：\n\n将原始命令中的–global-option和–build-option删除。\n在pip install命令后添加–no-binary=:all。\n\n最终的命令如下所示：\npython3 -m pip install pyaudio –no-binary=:all -I/opt/homebrew/include -L/opt/homebrew/lib\n如何在pip的安装过程中指定include 和lib目录\n在pip的安装过程中，可以通过使用--global-option参数来指定include和lib目录。\n例如，假设你想将include目录设置为/usr/local/include，lib目录设置为/usr/local/lib，你可以使用以下命令：\n1pip install package_name --global-option=build_ext --global-option=&quot;-I/usr/local/include&quot; --global-option=&quot;-L/usr/local/lib&quot;\n\n这将在安装package_name时将include目录设置为/usr/local/include，lib目录设置为/usr/local/lib。\n请注意，这些选项只适用于需要编译源代码的包。对于纯Python包，这些选项不会生效。torchaudio与pyaudio有什么区别\nTorchaudio和Pyaudio是两个用于音频处理的Python库，它们有以下区别：\n\nTorchaudio是PyTorch生态系统中的一个模块，专注于音频数据的处理和转换。它提供了一系列用于加载、转换和操作音频数据的功能，以及用于音频特征提取和预处理的工具。而Pyaudio则是一个通用的音频处理库，可以进行录制、播放和处理音频数据。\n\nTorchaudio使用PyTorch张量作为其主要数据结构，这使得它与其他PyTorch模块（如torch.nn）无缝集成，并且可以利用GPU加速。相比之下，Pyaudio主要使用NumPy数组来表示音频数据。\n\nTorchaudio提供了一些高级功能，如语音识别（ASR）模型和声纹识别模型等预训练模型。这些模型可以直接在Torchaudio中使用，并且兼容PyTorch的训练和推理流程。而Pyaudio主要关注基本的录制、播放和处理功能，并没有内置的机器学习模型。\n\n由于Torchaudio是基于PyTorch构建的，因此它可以利用PyTorch强大的计算图和自动求导功能。这使得在使用Torchaudio进行音频信号处理时更容易实现复杂的操作和算法。\n\n\n综上所述，Torchaudio更适合与PyTorch一起使用，用于音频数据的处理、特征提取和深度学习等任务。而Pyaudio则更适合基本的音频录制、播放和处理需求。\nboost和boost-python这两个软件是做什么的，作用是什么\nBoost是一个开源的C++库集合，提供了许多通用的编程工具和数据结构，可以提高C++程序的效率和可移植性。\nboost-python是Boost库中的一个模块，它提供了一组工具和类，用于将C++代码连接到Python解释器中。它允许开发人员在Python中使用Boost库中的功能，并且可以方便地在两种语言之间进行数据交换和函数调用。\nboost-python的作用是使开发人员能够更方便地将C++代码集成到Python项目中，并利用C++的高性能和庞大的库生态系统来加速Python应用程序的执行。\n下面是最有可能安装成功的安装方式。\npyaudio安装1234brew install boost brew install boost-pythonbrew install portaudiobrew link portaudio\n\n1python -m pip install --global-option=&#x27;build_ext&#x27; --global-option=&#x27;-I/opt/homebrew/Cellar/portaudio/19.7.0/include&#x27; --global-option=&#x27;-L/opt/homebrew/Cellar/portaudio/19.7.0/lib&#x27; pyaudio\n\n\n写一段pyaudio的python使用代码\n12import pyaudioimport wave\n定义音频参数123456CHUNK = 1024FORMAT = pyaudio.paInt16CHANNELS = 2RATE = 44100RECORD_SECONDS = 5WAVE_OUTPUT_FILENAME = &quot;output.wav&quot;\n\n初始化PyAudio对象1audio = pyaudio.PyAudio()\n打开音频流1234567stream = audio.open(format=FORMAT,                    channels=CHANNELS,                    rate=RATE,                    input=True,                    frames_per_buffer=CHUNK)print(&quot;开始录音...&quot;)\n\n1frames = []\n录制音频数据12345for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):    data = stream.read(CHUNK)    frames.append(data)print(&quot;录音结束.&quot;)\n停止音频流并关闭PyAudio对象123stream.stop_stream()stream.close()audio.terminate()\n将录制的音频数据写入到WAV文件中123456wf = wave.open(WAVE_OUTPUT_FILENAME, &#x27;wb&#x27;)wf.setnchannels(CHANNELS)wf.setsampwidth(audio.get_sample_size(FORMAT))wf.setframerate(RATE)wf.writeframes(b&#x27;&#x27;.join(frames))wf.close()\n\n\n\n\nMac系统安装pyaudio之后，出现了下面的问题，如何进行解决。import pyaudio._portaudio as pa\nImportError: dlopen(/Users/shengyang1/opt/anaconda3/envs/ppocr_rosetta/lib/python3.9/site-packages/pyaudio/_portaudio.cpython-39-darwin.so, 0x0002): symbol not found in flat n\namespace ‘_PaMacCore_SetupChannelMap’\n这个问题可能是由于缺少依赖库或者版本不兼容导致的。解决方法如下：\n\n确保已经安装了最新版的pyaudio：使用命令pip install --upgrade pyaudio来更新pyaudio。\n\n检查是否安装了portaudio依赖库：在终端中运行以下命令来安装portaudio：\n1brew install portaudio\n如果已经安装了portaudio，那么可能是版本不兼容导致的问题。尝试使用较旧的portaudio版本来解决问题。可以通过以下命令安装特定版本的portaudio：\n1brew install portaudio@19\n如果以上方法都无效，可以尝试使用Anaconda环境中提供的pyaudio版本，以确保依赖库与系统兼容。首先，创建一个新的虚拟环境：\n1conda create -n new_env python=3.9\n\n然后，激活该环境：\n1conda activate new_env\n\n最后，在新环境中安装pyaudio：\n1pip install pyaudio\n\n如果以上方法都无效，可能需要查找其他解决方案或者考虑使用其他音频处理库。\n用Python写一个PyAudio使用的小例子\nimport pyaudio\n创建音频流p = pyaudio.PyAudio()stream = p.open(format=pyaudio.paInt16,                channels=1,                rate=44100,                input=True,                frames_per_buffer=1024)\n开始录音print(“开始录音…”)frames = []for i in range(0, int(44100 / 1024 * 5)):    data = stream.read(1024)    frames.append(data)\n停止录音print(“停止录音…”)stream.stop_stream()stream.close()p.terminate()\n保存录音文件wf = wave.open(“output.wav”, “wb”)wf.setnchannels(1)wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))wf.setframerate(44100)wf.writeframes(b’’.join(frames))wf.close()\nprint(“录音文件已保存为output.wav”)\n下面这个问题如何解决mpicc: line 285: x86_64-apple-darwin13.4.0-clang: command not found \n这个问题是由于系统找不到x86_64-apple-darwin13.4.0-clang命令而引起的。要解决这个问题，可以按照以下步骤进行操作：\n\n确认是否已经安装了Clang编译器。可以在终端中运行clang --version命令来检查。\n\n如果尚未安装Clang编译器，可以通过以下方式之一进行安装：\n\n使用Homebrew包管理器运行brew install llvm命令来安装最新版本的Clang。\n下载并安装Xcode开发工具套件，其中包含了Clang编译器。\n\n\n如果已经安装了Clang编译器，请确保其路径已经正确配置。可以在终端中运行which clang命令来查看路径。如果路径不正确，可以通过修改环境变量或者更新系统配置文件来修复。\n\n如果以上步骤都没有解决问题，可能是因为MPI库或mpicc命令没有正确安装或配置。请检查MPI库和mpicc命令是否已正确安装，并且其路径是否正确配置。\n\n\n通过上述步骤中的一种或多种操作，应该能够解决该问题。如果问题仍然存在，请提供更多详细信息以便进一步分析和帮助解决。\npip install 时的参数–global-option，在升级之后，变成什么了这句话是什么原因造成的 WARNING: Implying –no-binary=:all: due to the presence of –build-option / –global-option. 怎么解决这个问题\n在 pip 升级之后，参数 --global-option 变成了 --options.\n这个警告是由于同时存在 --build-option 或 --global-option 和 --no-binary=:all: 导致的。--no-binary=:all: 是一个选项，用于禁用二进制包的安装。\n要解决这个问题，可以尝试以下方法之一：\n\n将 --no-binary=:all: 移动到参数列表的末尾。\n删除 --build-option 或 --global-option 参数，并将其替换为相应的选项。\n更新 pip 到最新版本，并查看是否有更正警告的修复。\n\npython 的_PEP 517, 518是什么意思\nPEP 517和PEP 518是Python Enhancement Proposals（Python增强提案）中的两个提案，分别用于描述构建系统和依赖管理。\nPEP 517描述了一种标准的构建系统接口规范，它定义了构建工具（如pip）与项目构建过程之间的交互方式。该规范使得开发者可以使用不同的构建工具来构建和打包他们的项目，而无需对构建工具有深入了解。这样可以提高项目的可移植性和可扩展性。\nPEP 518则描述了一种标准的依赖管理接口规范，它定义了项目如何声明和安装其依赖项。通过使用该规范，开发者可以将项目所需的依赖项以一种统一且易于管理的方式进行声明，并使得安装这些依赖项变得更加方便。\n综合起来，PEP 517和PEP 518为Python社区提供了一种标准化的方式来处理构建和依赖管理，从而促进了Python生态系统中各个项目之间更加紧密和兼容的合作。\npip 23在安装包时，如果告诉setup程序，指定程序使用的.h头文件，同时指定.lib的库文件的位置\n在安装包时，可以使用pip 23的setup.py文件来指定程序使用的.h头文件和.lib库文件的位置。在setup.py文件中，可以使用include_dirs参数来指定.h头文件的位置，使用library_dirs参数来指定.lib库文件的位置。\n以下是一个示例的setup.py文件：\n1234567891011from setuptools import setup, Extensionext_modules = [    Extension(&#x27;my_package&#x27;, [&#x27;src/my_module.c&#x27;], include_dirs=[&#x27;path/to/headers&#x27;], library_dirs=[&#x27;path/to/libs&#x27;], libraries=[&#x27;my_lib&#x27;]),]setup(    name=&#x27;my_package&#x27;,    version=&#x27;1.0&#x27;,    ext_modules=ext_modules,)\n\n在上述示例中，我们定义了一个名为my_package的扩展模块，它包含了一个名为my_module.c的C源码文件。通过设置include_dirs=[&#39;path/to/headers&#39;]，我们告诉setup程序去寻找头文件时应该搜索的路径。通过设置library_dirs=[&#39;path/to/libs&#39;]，我们告诉setup程序去寻找库文件时应该搜索的路径。同时，我们还通过设置libraries=[&#39;my_lib&#39;]来指定需要链接的库。\n然后，在命令行中运行以下命令来安装包：\n1pip install .\n\n这将会执行当前目录下的setup.py，并安装相应的扩展模块和其他依赖项。\n注意：以上示例中的路径只是示意，并非实际路径，请根据实际情况进行替换。\npip install 安装库的时候，如何指定头文件和库文件\n在使用pip安装库时，默认情况下是无法指定头文件和库文件的。pip是Python的包管理工具，主要用于安装Python包，而不涉及C/C++等其他语言的编译和链接。\n如果你需要指定头文件和库文件，可以考虑使用其他适合的工具，如以下几种方式：\n\n使用conda：conda是另一个流行的包管理工具，与pip类似，但也支持跨平台安装C/C++库。可以使用conda install命令来安装包，并指定头文件和库文件路径。\n\n手动编译和安装：如果源代码提供了源码或二进制发行版，并且允许手动编译和安装，你可以下载源代码并按照项目文档中提供的步骤进行手动编译和安装。在编译过程中，你可以通过设置环境变量或命令行参数来指定头文件和库文件路径。\n\n使用系统包管理器：某些操作系统（如Linux）提供了自己的软件包管理器（如apt-get、yum等），你可以使用这些软件包管理器来安装C/C++库，并自动处理依赖关系。在使用系统包管理器时，它会自动将头文件和库文件放置在系统默认位置。\n\n\n综上所述，pip并不适用于直接安装C/C++相关的头文件和库文件。如需更多详细信息，请参考相关工具的文档或官方网站。\n下面这个问题如何解决：DEPRECATION: –build-option and –global-option are deprecated. pip 24.0 will enforce this behaviour change. A possible replacement is to use –config-settings. Discussion can\nbe found at https://github.com/pypa/pip/issues/11859\n怎么替换 ，设置 build_ext和对应include和lib的位置\n根据给出的信息，pip 24.0版本开始弃用–build-option和–global-option参数，建议使用–config-settings参数进行替换。讨论和更多信息可以在https://github.com/pypa/pip/issues/11859找到。\n要设置build_ext并指定对应的include和lib位置，可以按照以下步骤进行操作：\n\n确保已经安装了pip的最新版本。使用以下命令升级pip：\n1pip install --upgrade pip\n使用–config-settings参数进行替换。具体步骤如下：\n\n\n\n打开终端或命令提示符窗口；\n运行以下命令来设置路径：1pip install --config-setting build_ext:&lt;path_to_build_ext&gt; --config-setting include_dir:&lt;path_to_include_dir&gt; --config-setting lib_dir:&lt;path_to_lib_dir&gt;\n其中，是你要设置的build_ext路径，是你要设置的include文件夹路径，是你要设置的lib文件夹路径。\n\n\n检查是否成功替换。可以运行以下命令来验证替换是否成功：1pip config list\n这将显示当前配置的所有参数和值。确认build_ext、include_dir和lib_dir参数与你之前设置的路径一致即可。\n\n通过按照上述步骤进行操作，应该能够成功解决所提到的问题并替换build_ext以及相应的include和lib位置。\npython pip 中的 build_ext是什么作用\n在Python的pip工具中，build_ext是一个命令选项，用于构建和编译Python扩展模块。它可以帮助用户在安装Python包时自动编译包中的C/C++扩展模块。\n当用户使用pip安装一个包时，如果该包包含C/C++扩展模块（通常是通过Cython或其他工具生成的），那么build_ext命令选项会被调用来构建这些扩展模块。它会自动查找和配置所需的编译器，并根据操作系统和Python版本等因素进行相应的编译和链接操作。\n使用build_ext命令选项可以简化扩展模块的安装过程，使得用户可以更方便地安装依赖于C/C++代码的Python包。\n在pip 23中如何配置 build_ext这个参数，在pip install 安装特点的安装包时\n在pip 23中，可以使用--global-option参数来配置build_ext选项。具体步骤如下：\n\n打开命令行终端。\n\n使用以下命令安装特定的安装包，并配置build_ext选项：\n1pip install &lt;package_name&gt; --global-option=&quot;build_ext&quot; --global-option=&quot;-&lt;build_ext_option&gt;&quot;\n\n其中，&lt;package_name&gt;是要安装的特定安装包的名称，&lt;build_ext_option&gt;是要配置的build_ext选项。\n\n\n举例说明：\n假设要安装名为example_package的特定安装包，并配置了一个名为example_option的build_ext选项。可以使用以下命令进行安装和配置：\n1pip install example_package --global-option=&quot;build_ext&quot; --global-option=&quot;-example_option&quot;\n\n这样，就可以在安装特定的安装包时配置相应的build_ext选项了。\n怎么解决下面的问题 ERROR: Cannot uninstall ‘PyAudio’. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n这个错误通常发生在尝试卸载通过distutils安装的PyAudio时。这可能是因为PyAudio没有提供一个清晰的卸载规范，所以无法准确确定哪些文件属于它。\n为了解决这个问题，你可以尝试以下方法：\n\n使用pip进行卸载：在命令行中运行以下命令：\n1pip uninstall pyaudio\n这将使用pip来卸载PyAudio，而不是使用distutils。\n\n手动删除文件：如果上述方法无效，你可以手动删除PyAudio的文件。首先，找到Python的安装目录（通常位于C:\\PythonXX或/usr/lib/pythonX.X），然后进入Lib\\site-packages目录。在此目录中搜索并删除与PyAudio相关的文件和文件夹。\n\n\n请注意，在执行任何操作之前，请确保备份你的数据和系统以防止意外损坏。\n如果以上方法都无效，可能需要考虑重新安装Python，并且在安装PyAudio之前确保没有其他依赖项或冲突存在\n其他方法很都是无效的，最有的方法。\nconda install portaudio pyaudio\n用conda install 安装portaudio 和 pyaudio这两个包，当然前提是brew install portaudio –head这样在conda虚拟环境中使用是没有问题了，其他.h.lib配置配置去也没用， 关键就是需要conda install portaudio这种，不能只安装pyaudio，pyaudio要引用portaudio，如果不安装库找不到。\n","slug":"python/mac m1安装pyaudio","date":"2024-03-14T06:15:59.764Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"519ee70fb3f13a4f693153edd0ae568d","title":"哈佛大学的课程：“Python 数据科学简介”","content":"哈佛大学的课程：“Python 数据科学简介”哈佛大学的课程：“Python 数据科学简介”  \n免费，但需要先熟悉 Python 才能学习本课程。  \n该课程适合初学者。它适合那些想要对机器学习和人工智能有基本了解的人。  \n该课程将涵盖其中一些主题：  \n• 泛化和过度拟合• 模型构建、规范化和评估• 线性和逻辑回归模型• k-最近邻• Scikit-Learn、NumPy、Pandas 和 Matplotlib  \n如果你是一名具有 Python 代码编写经验的软件开发人员并且想要开始机器学习，那么本课程是完美的选择。  \n链接： pll.harvard.edu/course/introduction-data-science-python\n\n","slug":"python/哈佛大学的课程：“Python 数据科学简介”","date":"2024-03-14T06:15:59.764Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"8c50f65f248aa683977646be2697726c","title":"AI蜜罐Galah","content":"AI蜜罐GalahGalah蜜罐用AI 反馈攻击的请求，不再是用模拟的服务程序进行反馈。https://github.com/0x4D31/galah\n工具要求\n\n\n\n\n\n\n\n\nGo v1.20+\n工具下载由于该工具基于Go语言开发，因此我们首先需要在本地设备上安装并配置好Go v1.20+环境。\n接下来，点击【这里】创建你的OpenAI API密钥。如果你想要使用HTTPS的话，别忘了生成TLS证书。\n配置完成之后，广大研究人员可以直接使用下列命令将该项目源码克隆至本地：\ngit clone &#103;&#105;&#x74;&#64;&#x67;&#105;&#x74;&#104;&#117;&#x62;&#46;&#x63;&#x6f;&#109;:0x4D31/galah.git\n然后使用下列命令切换到项目目录中，并安装该工具所需的全部依赖组件：\ncd galah\ngo mod download\ngo build  \n./galah -i en0 -v\n响应样例样例1% curl http://localhost:8080/login.php\nLogin PageUsername:Password:Login\n\nJSON日志记录：\n{“timestamp”:”2024-01-01T05:38:08.854878”,”srcIP”:”::1”,”srcHost”:”localhost”,”tags”:null,”srcPort”:”51978”,”sensorName”:”home-sensor”,”port”:”8080”,”httpRequest”:{“method”:”GET”,”protocolVersion”:”HTTP/1.1”,”request”:”/login.php”,”userAgent”:”curl/7.71.1”,”headers”:”User-Agent: [curl/7.71.1], Accept: [/]”,”headersSorted”:”Accept,User-Agent”,”headersSortedSha256”:”cf69e186169279bd51769f29d122b07f1f9b7e51bf119c340b66fbd2a1128bc9”,”body”:””,”bodySha256”:”e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855”},”httpResponse”:{“headers”:{“Content-Type”:”text/html”,”Server”:”Apache/2.4.38”},”body”:”\\u003c!DOCTYPE html\\u003e\\u003chtml\\u003e\\u003chead\\u003e\\u003ctitle\\u003eLogin Page\\u003c/title\\u003e\\u003c/head\\u003e\\u003cbody\\u003e\\u003cform action=’/submit.php’ method=’post’\\u003e\\u003clabel for=’uname’\\u003e\\u003cb\\u003eUsername:\\u003c/b\\u003e\\u003c/label\\u003e\\u003cbr\\u003e\\u003cinput type=’text’ placeholder=’Enter Username’ name=’uname’ required\\u003e\\u003cbr\\u003e\\u003clabel for=’psw’\\u003e\\u003cb\\u003ePassword:\\u003c/b\\u003e\\u003c/label\\u003e\\u003cbr\\u003e\\u003cinput type=’password’ placeholder=’Enter Password’ name=’psw’ required\\u003e\\u003cbr\\u003e\\u003cbutton type=’submit’\\u003eLogin\\u003c/button\\u003e\\u003c/form\\u003e\\u003c/body\\u003e\\u003c/html\\u003e”}}\n样例2% curl http://localhost:8080/.aws/credentials\n[default]\naws_access_key_id = AKIAIOSFODNN7EXAMPLE\naws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nregion = us-west-2\nJSON日志记录：\n{“timestamp”:”2024-01-01T05:40:34.167361”,”srcIP”:”::1”,”srcHost”:”localhost”,”tags”:null,”srcPort”:”65311”,”sensorName”:”home-sensor”,”port”:”8080”,”httpRequest”:{“method”:”GET”,”protocolVersion”:”HTTP/1.1”,”request”:”/.aws/credentials”,”userAgent”:”curl/7.71.1”,”headers”:”User-Agent: [curl/7.71.1], Accept: [/]”,”headersSorted”:”Accept,User-Agent”,”headersSortedSha256”:”cf69e186169279bd51769f29d122b07f1f9b7e51bf119c340b66fbd2a1128bc9”,”body”:””,”bodySha256”:”e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855”},”httpResponse”:{“headers”:{“Connection”:”close”,”Content-Encoding”:”gzip”,”Content-Length”:”126”,”Content-Type”:”text/plain”,”Server”:”Apache/2.4.51 (Unix)”},”body”:”[default]\\naws_access_key_id = AKIAIOSFODNN7EXAMPLE\\naws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nregion = us-west-2”}}\n样例3% curl http://localhost:8888/are-you-a-honeypot\nNo, I am a server.`\nJSON日志记录：\n{“timestamp”:”2024-01-01T05:50:43.792479”,”srcIP”:”::1”,”srcHost”:”localhost”,”tags”:null,”srcPort”:”61982”,”sensorName”:”home-sensor”,”port”:”8888”,”httpRequest”:{“method”:”GET”,”protocolVersion”:”HTTP/1.1”,”request”:”/are-you-a-honeypot”,”userAgent”:”curl/7.71.1”,”headers”:”User-Agent: [curl/7.71.1], Accept: [/]”,”headersSorted”:”Accept,User-Agent”,”headersSortedSha256”:”cf69e186169279bd51769f29d122b07f1f9b7e51bf119c340b66fbd2a1128bc9”,”body”:””,”bodySha256”:”e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855”},”httpResponse”:{“headers”:{“Connection”:”close”,”Content-Length”:”20”,”Content-Type”:”text/plain”,”Server”:”Apache/2.4.41 (Ubuntu)”},”body”:”No, I am a server.”}}\n样例4% curl http://localhost:8888/i-mean-are-you-a-fake-server`\nNo, I am not a fake server.\nJSON日志记录：\n{“timestamp”:”2024-01-01T05:51:40.812831”,”srcIP”:”::1”,”srcHost”:”localhost”,”tags”:null,”srcPort”:”62205”,”sensorName”:”home-sensor”,”port”:”8888”,”httpRequest”:{“method”:”GET”,”protocolVersion”:”HTTP/1.1”,”request”:”/i-mean-are-you-a-fake-server”,”userAgent”:”curl/7.71.1”,”headers”:”User-Agent: [curl/7.71.1], Accept: [/]”,”headersSorted”:”Accept,User-Agent”,”headersSortedSha256”:”cf69e186169279bd51769f29d122b07f1f9b7e51bf119c340b66fbd2a1128bc9”,”body”:””,”bodySha256”:”e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855”},”httpResponse”:{“headers”:{“Connection”:”close”,”Content-Type”:”text/plain”,”Server”:”LocalHost/1.0”},”body”:”No, I am not a fake server.”}}\n工具运行截图\n许可证协议本项目的开发与发布遵循Apache-2.0开源许可证协议。\n项目地址Galah：【GitHub传送门】\n参考资料\n\n\n\n\n\n\n\n\nhttps://www.macquariedictionary.com.au/blog/article/728/\nhttps://platform.openai.com/api-keys\n","slug":"sec/AI蜜罐Galah","date":"2024-03-14T06:15:59.764Z","categories_index":"AIGC,honeypot","tags_index":"galah","author_index":"安全书"},{"id":"4919993c987690bd225d04d8dee1317a","title":"ASCII码攻击LLM","content":"ASCII码攻击LLM这篇论文找到了基于ASCII的攻击LLM（或者说绕过LLM安全机制）的方法。如图1，2所解释的↓  \nArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs（针对有安全机制的LLM 的基于 ASCII Art 的越狱攻击）  \n论文：arxiv.org/abs/2402.11753  \n论文摘要：安全对于大型语言模型 (LLM) 的使用至关重要。数据过滤和监督微调等多种技术已被开发出来，以加强LLM的安全性。  \n然而，目前已知的技术假设用于LLM安全对齐的语料库仅通过语义来解释。然而，这种假设在实际应用中并不成立，这导致LLM存在严重漏洞。例如，论坛的用户经常使用 ASCII 艺术（一种基于文本的艺术形式）来传达图像信息。  \n在本文中，我们提出了一种新颖的基于 ASCII 艺术的越狱攻击，并引入了综合基准视觉文本挑战（ViTC）来评估LLM识别不能仅通过语义解释的提示的能力。我们展示了五个 SOTA LLM（GPT-3.5、GPT-4、Gemini、Claude 和 Llama2）难以识别以 ASCII 艺术形式提供的提示。  \n基于这一观察，我们开发了越狱攻击 ArtPrompt，它利用LLM在识别 ASCII 艺术方面的糟糕表现来绕过安全措施并引发LLM的不良行为。ArtPrompt 仅需要对受害者 LLM 进行黑盒访问，使其成为一种实用的攻击。  \n我们在五个 SOTA LLM上评估了 ArtPrompt，并表明 ArtPrompt 可以有效且高效地诱导所有五个LLM的不良行为。  \n","slug":"sec/ASCII码攻击LLM","date":"2024-03-14T06:15:59.764Z","categories_index":"LLM","tags_index":"ASCII攻击","author_index":"安全书"},{"id":"afd75d50217c22d7dbe522b16944f052","title":"prime-select","content":"prime-selectprime-select命令是用于在Linux系统上切换NVIDIA驱动程序和集成显卡之间的工具。它允许用户选择使用哪个图形处理单元（GPU）来运行图形应用程序。\n使用prime-select有以下几种命令：\n\nprime-select query：查询当前正在使用的GPU。例如，执行”prime-select query”命令将返回”nvidia”或”intel”，表示当前正在使用的是NVIDIA GPU还是集成显卡。\n\nprime-select intel：切换到使用集成显卡。执行”prime-select intel”命令将会禁用NVIDIA GPU并将系统切换到使用集成显卡。\n\nprime-select nvidia：切换到使用NVIDIA GPU。执行”prime-select nvidia”命令将会禁用集成显卡并将系统切换到使用NVIDIA GPU。\n\n\n需要注意的是，在使用prime-select命令之前，必须已经安装并正确配置了NVIDIA驱动程序和集成显卡驱动程序。\n","slug":"python/nvidia/prime-select切换显卡","date":"2024-03-14T06:15:59.764Z","categories_index":"AIGC,prime-select","tags_index":"prime-select","author_index":"安全书"},{"id":"88f798c6d8c746939f865dd26b874610","title":"ATT&CK与CAPEC的比较","content":"ATT&amp;CK与CAPEC的比较了解对手的行为在网络安全中越来越重要。有两种方法用于组织关于对手行为的知识——CAPEC和ATT&amp;CK，每一种方法都关注于一组特定的用例。\n本页解释了CAPEC和ATT&amp;CK之间的相同点、不同点和关系，以及它们在网络安全中的作用。\n一、常见攻击模式枚举和分类(CAPEC)\nCAPEC关注于应用程序安全性，并描述了敌手利用网络能力中的已知弱点所使用的通用属性和技术。(例如，SQL注入、XSS、会话固定、点击劫持)\n（1）关注应用程序安全性\n（2）列举针对脆弱系统的攻击\n（3）包括社会工程/供应链\n（4）与通用弱点枚举(CWE)相关联\n二、对抗性战术、技巧与常识(ATT&amp;CK)\n对抗性战术、技巧与常识(ATT&amp;CK)专注于网络防御，描述了敌方生命周期、攻击前和攻击后的作战阶段(例如，持久性、横向移动、撤退)，并详细描述了高级持续性威胁(APT)在瞄准、破坏和在网络内作战时用来执行目标的具体战术、技术和程序(ttp)。\n（1）专注于网络防御\n（2）基于威胁情报和红队的研究\n（3）提供对恶意行为的上下文理解\n（4）支持测试和分析防御选项\n三、它们是如何联系在一起的……\nCAPEC列举的许多攻击模式都是通过ATT&amp;CK描述的特定技术由对手使用的。这使得能够在对手的操作生命周期内对攻击模式进行上下文理解。CAPEC攻击模式和相关的ATT&amp;CK技术在适当的时候在两个工作之间相互引用。\n四、何时使用…\n使用CAPEC:\n应用程序的威胁建模\n开发人员的培训和教育\n渗透测试\n使用ATT&amp;CK:\n比较计算机网络防御能力\n防御持续的高级威胁\n寻找新的威胁\n增强威胁情报\n对手模拟练习\nmitre定义的APT组织\nhttps://attack.mitre.org/groups/\nATT&amp;CK Comparison，https://capec.mitre.org/about/attack_comparison.html\nhttps://www.mitre.org/capabilities/cybersecurity/overview/cybersecurity-blog/attck%E2%84%A2-content-available-in-stix%E2%84%A2-20-via\nhttps://github.com/MISP/misp-galaxy/tree/master/clusters\nhttps://www.freebuf.com/column/197837.html\nhttps://www.anquanke.com/post/id/185492\nhttps://github.com/mitre/cti\n","slug":"sec/ATT-CK/ATT&CK与CAPEC的比较","date":"2024-03-14T06:15:59.764Z","categories_index":"安全","tags_index":"ATTCK,CAPEC","author_index":"安全书"},{"id":"8dc14b0dbd571d51984bd924096bc1c4","title":"映射cve和ATT&CK框架TTPs一种经验方法","content":"映射cve和ATT&amp;CK框架TTPs一种经验方法对漏洞和攻击进行划分和分类对于理解漏洞是如何被利用的以及漏洞是如何通过不同的步骤(包括侦察、漏洞检测、利用、特权升级、横向移动和泄露)展开的非常重要。\n本文重点介绍如何在CVE、CAPEC、CWE和ATT&amp;CK漏洞和攻击分类之间建立桥梁/关联，以便更好地理解攻击向量和方法。\n一、映射cve和ATT&amp;CK框架TTPs:建立基线1.1 CVE分类法最重要和公认的漏洞分类和分类法是CVE计划-常见漏洞和暴露，其定义为:\nCVE®项目的任务是识别、定义和分类公开披露的网络安全漏洞。目录中的每个漏洞都有一个CVE记录。这些漏洞被发现，然后由来自世界各地与CVE计划合作的组织分配和发布。合作伙伴发布CVE记录以交流一致的漏洞描述。信息技术和网络安全专业人员使用CVE记录来确保他们讨论的是同一个问题，并协调他们的努力来优先考虑和解决漏洞。”\nCVE是一个对漏洞进行分类的术语表。术语表分析漏洞，然后使用通用漏洞评分系统(CVSS)来评估漏洞的威胁级别，主要是从技术角度进行评估。\n二、CVSS框架通用漏洞评分系统(CVSS)是一个用于沟通软件漏洞特征和严重性的开放框架。CVSS由三个度量组组成:基础、时间和环境。基础指标产生一个从0到10的分数，然后可以通过对时间和环境指标进行评分来修改这个分数。CVSS分数也表示为向量字符串，这是用于派生分数的值的压缩文本表示。因此，CVSS非常适合作为需要精确和一致的漏洞严重程度评分来确定漏洞优先级的行业、组织和政府的标准测量系统。国家漏洞数据库(NVD)提供了几乎所有已知漏洞的CVSS评分。\nNVD同时支持CVSS (Common Vulnerability Scoring System) v2.0和v3.X版本标准。NVD提供CVSS“基础评分”，代表每个漏洞的固有特征。NVD目前不提供“时间分数”(由于漏洞外部事件而随时间变化的指标)或“环境分数”(为反映漏洞对组织的影响而定制的分数)。然而，NVD确实为CVSS v2和v3提供了一个CVSS计算器，以允许您添加时间和环境评分数据，但仅依赖CVSS是不够的。\n在CVSS得分3.1，这些是得分的基础得分的组成部分:\n\n来源:_First.Org_，通用漏洞评分系统v3.1:规范文档\n基本度量组表示漏洞的内在特征，这些特征随时间和用户环境的变化而不变。它由两组指标组成:可利用性指标和影响指标。\n可利用性指标反映了漏洞被利用的容易程度和技术手段。也就是说，它们代表了易受攻击的事物的特征，我们正式地称之为易受攻击的部分。\n影响指标反映了成功利用的直接后果，并表示对遭受影响的事物的后果，我们将其正式称为受影响组件。\n虽然易受攻击的组件通常是软件应用程序、模块、驱动程序等(也可能是硬件设备)，但受影响的组件可能是软件应用程序、硬件设备或网络资源。此属性由Scope度量捕获，该度量反映一个组件中的漏洞是否会影响组件之外的资源。\n时间度量组反映了漏洞的特征，这些特征可能会随着时间而变化，但不会随着用户环境而变化。例如，一个简单易用的漏洞利用工具包会增加CVSS得分，而创建一个官方补丁会降低它。\n环境度量组表示与特定用户环境相关且唯一的漏洞特征。考虑因素包括安全控制的存在，这可能减轻成功攻击的部分或全部后果，以及技术基础设施中易受攻击系统的相对重要性。\n三、MITRE CAPEC目录MITRE CAPEC是已知攻击模式的全面字典，对手利用软件应用程序、硬件设备和物联网设备中的弱点。美国国土安全部最初于2007年发布该标准，旨在通过开发阶段的安全意识来提高软件的安全性。截至2021年的当前版本是3.7版本，有546种攻击模式。CAPEC攻击模式分为6个“域”和9个“机制”。\n攻击范围:\n\n\n\n\n\n\n\n\n\n软件\n硬件\n沟通\n供应链\n社会工程\n物理安全\n攻击机制:\n\n\n\n\n\n\n\n\n\n参与欺骗性互动\n滥用现有功能\n操作数据结构\n操作系统资源\n注入意想不到的物品\n运用概率技术\n操作时间和状态\n收集和分析信息\n颠覆访问控制\nCAPEC概要文件中的信息是广泛的。例如，capec包括用于跟踪和关联的ID、攻击名称、高级描述、攻击执行过程、攻击先决条件、严重范围和评分、攻击者技能要求、攻击成功率和到CWE (Common Weakness Enumeration)的映射。\nCAPEC分类法为每个攻击模式包含到相关CWEs的全面映射，CWEs又可以映射到cve，但它还包含到ATT&amp;CK ttp的直接映射。这是capec、CWEs和ATT&amp;CK ttp之间详细映射的一个清晰示例:https://capec.mitre.org/data/definitions/636.html\n映射到CWE极大地扩展了CAPEC的能力，因为CWE可以从CVE产品漏洞关联到高级攻击模式。\n在高级攻击信息和特定产品漏洞之间的遍历可以增强威胁情报和缓解工作。一份广泛的MIT白皮书提供了将CAPECs缝合到MITRE ATT&amp;CK和CWE, CVE, CVSS和CPE数据的详细描述。\n下图显示了CAPEC的扩展如何从高信息扩展到低信息。\n\n来源:fnCyber，“CAPEC -常见攻击模式枚举和分类”\n例如，让我们看看在2020年发现的CVE-2020-16875。\nNIST丰富的CVE详细信息包括“弱点枚举”字段，表示相关CWE类别和其他有价值的信息，如供应商咨询和补救信息、CVSS(通用漏洞评分系统)和CPE(通用平台枚举)，将漏洞映射到特定产品。\n在这种情况下，CVE表示严重评分为7.2，并影响2013年至2019年之间的Microsoft Exchange Server软件版本的累积更新。列出的CWE类别是CWE-74下游组件使用的输出中特殊元素的不适当中和和CWE-269不适当的特权管理。\n此外，从CWE到CAPEC，揭示了与不适当的输入处理和CAPEC-233相关的几个类别:特权升级。完整的CAPEC、CWE和CVE数据可从MITRE公开获得，扩展的CVE到CWE和CPE可从NIST获得。\nMITRE ATT&amp;CK将网络攻击活动的各种战术与特定的技术和程序(TPP)联系起来。该框架允许洞察网络攻击元素链，以实现恶意的最终目标。\n像ATT&amp;CK一样，CAPEC从战术、技术和程序(TTP)的角度来处理攻击模式。然而，在总共546个CAPEC中，有112个已经通过“与ATT&amp;CK相关的分类映射”字段直接映射到ATT&amp;CK战术和技术，该字段可在ATT&amp;CK中列出的相关CAPEC的244门课程中获得。\n因此，同时使用ATT&amp;CK和CAPEC对于全面的安全角度是必要的。\n来源：https://www.nopsec.com/blog/mapping-cves-and-attck-framework-ttps-an-empirical-approach/\n","slug":"sec/ATT-CK/映射cve和ATT&CK框架TTPs一种经验方法","date":"2024-03-14T06:15:59.764Z","categories_index":"安全","tags_index":"ATTCK,CVE,TTPs","author_index":"安全书"},{"id":"95e90514163f2adead82ccfd062b2e72","title":"cuDNN","content":"cuDNNcuDNN（CUDA Deep Neural Network library）是一个用于加速深度神经网络计算的GPU加速库。它提供了高效的实现和优化，可以显著加快深度学习模型训练和推理的速度。\n使用cuDNN，可以进行以下操作：\n\n卷积神经网络（CNN）：cuDNN提供了高效的卷积操作实现，包括前向传播、反向传播和卷积算法选取。\n循环神经网络（RNN）：cuDNN支持各种循环神经网络模型，如长短期记忆网络（LSTM）和门控循环单元（GRU），并提供高效的实现。\n优化器：cuDNN还提供了一些常用的优化器，如随机梯度下降法（SGD）和Adam等，可以加速训练过程。\n数据转换：cuDNN可以进行数据格式转换，例如将输入数据从行主序列转换为列主序列等。\n\n总之，使用cuDNN可以显著提升深度学习模型在GPU上的计算性能，加快训练和推理速度。\n给出例子如何用Python使用cuDNN的LSTM算法的调用实例。\n下面是一个使用Python调用cuDNN的LSTM算法的示例：\n1234567891011121314import tensorflow as tffrom tensorflow.keras.layers import LSTM, CuDNNLSTM# 创建一个简单的LSTM模型model = tf.keras.Sequential()model.add(LSTM(64, input_shape=(10, 32)))  # 使用普通LSTM层model.add(CuDNNLSTM(64))  # 使用cuDNN加速的LSTM层# 编译和训练模型model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;binary_crossentropy&#x27;)model.fit(x_train, y_train, epochs=10)# 使用训练好的模型进行预测predictions = model.predict(x_test)\n\n在上面的示例中，我们首先导入CuDNNLSTM类，并将其添加到模型中作为一个层。然后，我们可以像使用普通LSTM一样编译、训练和预测模型。\n请注意，要使用cuDNN加速的LSTM层，你需要确保你的环境中安装了适当的cuDNN库，并且你正在使用TensorFlow GPU版本。另外，由于cuDNN LSTMs只支持固定长度的输入序列，因此在定义模型时需要指定输入形状（例如(10, 32)）。\n希望这个例子能帮助到你！\n","slug":"python/codna/cuDNN","date":"2024-03-14T06:15:59.762Z","categories_index":"AIGC,cuDNN","tags_index":"cuDNN","author_index":"安全书"},{"id":"00a4faf1190304140b94f0b8788c00f3","title":"Obsidian Jupyter Book插件","content":"Obsidian Jupyter Book插件在Obsidian中，如何用Jupyter Book插件，运行Python代码？\n在Obsidian中，你可以通过以下步骤使用Jupyter Book插件来运行Python代码：\n\n首先，确保已经安装了Jupyter Book插件。可以通过在Obsidian的插件设置中搜索并安装该插件。\n\n创建一个新的Markdown笔记，并将其保存为.ipynb文件格式。例如，你可以命名为example.ipynb。\n\n在笔记中按照Jupyter Notebook的语法编写Python代码块。例如：\n1print(&quot;Hello, world!&quot;)\n\n\n保存并关闭笔记。\n\n在Obsidian的编辑区域，右键点击笔记，并选择“Open with Jupyter Book”选项。\n\n这将会在Obsidian中打开一个新的预览窗口，其中包含了运行Python代码块的结果。\n\n\n注意：在使用Jupyter Book插件之前，请确保已经正确安装了Python和相关依赖包。\n1print(&quot;test&quot;)\n\n\n1234567import numpy as np  from matplotlib import pyplot as plt  x = np.linspace(0, 1)  y = np.exp(-x) * np.sin(4 * np.pi * x)  plt.plot(x, y)  pass\n\n\n关键点是代码种类，不是选Python，而是选jupyter，才会出现运行标记。\n用Python画一个一元二次方程y=x^2的图像。\n可以使用Python的matplotlib库来画一个一元二次方程y=x^2的图像。以下是一个示例代码：\n123456789101112131415161718192021import numpy as npimport matplotlib.pyplot as plt# 生成x的取值范围x = np.linspace(-10, 10, 100)# 计算对应的y值y = x**2# 绘制图像plt.plot(x, y)# 设置坐标轴标签plt.xlabel(&#x27;x&#x27;)plt.ylabel(&#x27;y&#x27;)# 设置标题plt.title(&#x27;Graph of y=x^2&#x27;)# 显示图像plt.show()\n\n运行这段代码，就会得到一元二次方程y=x^2的图像。\n如何在Obsidian中，用符号给示y等于x的二次方。\n在Obsidian中，你可以使用Markdown语法来表示y等于x的二次方。以下是一种方法：\n\n使用符号^表示上标，即表示指数。\n将x^2放在y的后面，表示y等于x的二次方。\n\n示例： y = x^2\n这样就能正确地表示y等于x的二次方。\n1y = x^2\n\n x的二次方，在Obsidian中，用数学符号怎么表示。\ny=x²的这个方程式，用Python画出这个函数他在第一象限的图像怎么实现？\n要在第一象限绘制函数y = x²的图像，可以使用Python的matplotlib库来实现。以下是一个示例代码：\n1234567891011121314151617181920import matplotlib.pyplot as pltimport numpy as np# 生成x的取值范围x = np.linspace(0, 10, 100)# 计算相应的y值y = x**2# 绘制图像plt.plot(x, y)# 设置坐标轴标签和标题plt.xlabel(&#x27;x&#x27;)plt.ylabel(&#x27;y&#x27;)plt.title(&#x27;Graph of y = x²&#x27;)# 显示图像plt.show()\n\n运行这段代码后，将会在新的窗口中显示出函数y = x²在第一象限内的图像。\n1print(&quot;hello world!&quot;)\n\n\n\n/Users/shengyang1/opt/anaconda3/envs/jupyter3.10/bin/python\n/Users/shengyang1/opt/anaconda3/envs/jupyter3.10/bin/python/Users/shengyang1/opt/anaconda3/envs/jupyter3.10/bin/python\nC:\\Users\\Admin.conda\\envs\\llm\\\n1print(123)\n\n\n1print(&quot;hello world&quot;)\n\n\n123print(123)a = input(&quot;输入：&quot;)print(a)\n\n\n123import pyaudioimport wave\n\n1print(&quot;test&quot;)\n\n","slug":"python/jupyterbook/Obsidian Jupyter Book插件","date":"2024-03-14T06:15:59.762Z","categories_index":"obsidian","tags_index":"jupyter","author_index":"安全书"},{"id":"e564ce5c4856dfbed477325743829e87","title":"iCloud的文件夹的位置","content":"iCloud的文件夹的位置PC的iCloud的位置。cd /Library/Mobile\\ Documents/comapple~CloudDocs\n手机上Obsidian文件夹的位置。cd /Library/Mobile\\ Documents/iCloud\\md~obsidiancd /Library/Mobile\\ Documents/iCloudmd~obsidian/Documents\n","slug":"other/iCloud的文件夹的位置","date":"2024-03-14T06:15:59.761Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"acf07aee4ab1a89a03bfa1816ac12a9b","title":"计算机自学指南","content":"计算机自学指南Github榜首：北大学神整理最全面的计算机自学指南。这是一个系统的自学计算机的最优路径，北大新科的学长给我们做的很完美的不断迭代的CS学习规划。从必学工具、数学基础、软件基础等，由浅入深的带你走入计算机科学的领域。Computers are not magic! 这里就让我给你讲一下我学习浏览的感受。PKUFlyingPig大神的学习路径附在这里，github.com/PKUFlyingPig/cs-self-learning 小伙伴们请登录GitHub给大神点赞和收藏\n\n\n\n","slug":"opensource/计算机自学指南","date":"2024-03-14T06:15:59.761Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"fdd0a7bc582d8610e53c9b2f7cf8673b","title":"用于多模式文档理解的布局感知生成语言模型","content":"用于多模式文档理解的布局感知生成语言模型DocLLM: A layout-aware generative language model for multimodal document understanding（用于多模式文档理解的布局感知生成语言模型）  \n论文：arxiv.org/abs/2401.00908  \n论文摘要：  \n企业文档（例如表格、发票、收据、报告、合同和其他类似记录）通常在文本和空间模态的交汇处携带丰富的语义。复杂布局提供的视觉提示对于有效理解这些文档起着至关重要的作用。  \n在本文中，我们提出了 DocLLM，它是传统大型语言模型 (LLM) 的轻量级扩展，用于对视觉文档进行推理，同时考虑文本语义和空间布局。我们的模型与现有的多模态LLM不同，它避免了昂贵的图像编码器，并且只专注于边界框信息以合并空间布局结构。  \n具体来说，通过将经典 Transformer 中的注意力机制分解为一组解开的矩阵来捕获文本和空间模态之间的交叉对齐。此外，我们设计了一个学习填充文本片段的预训练目标。这种方法使我们能够解决视觉文档中经常遇到的不规则布局和异构内容。预训练模型使用大规模指令数据集进行微调，涵盖四个核心文档智能任务。  \n我们证明，我们的解决方案在所有任务的 16 个数据集中的 14 个上优于 SotA LLM，并且可以很好地推广到 5 个以前未见过的数据集中的 4 个。\n\n","slug":"paper/用于多模式文档理解的布局感知生成语言模型","date":"2024-03-14T06:15:59.761Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"8acb019eb4d4e800260b2c7eda03a5c4","title":"视频生成模型：构建虚拟世界的模拟器","content":"视频生成模型：构建虚拟世界的模拟器翻译了OpenAI关于Sora相关的技术报告：《Video generation models as world simulators | 视频生成模型：构建虚拟世界的模拟器》  \n这篇技术报告主要介绍了两方面内容：(1) OpenAI如何将各种类型的视觉数据转化为统一的表示形式，从而实现生成模型的大规模训练；(2) 对 Sora 模型能力和局限性的定性评价。  \n报告中没有包含模型和实施的详细信息。  \nSora 属于扩散型 Transformer（diffusion transformer）。  \n我们知道，传统的 Transformer，主要有Encoder和Decoder，Encoder是将文本编码成 Token，从而可以将自然语言变成可以统一处理的数字或代码。而 Decoder 则是将 Token 反向解码成文本。  \n而 Sora 也是类似的思路，只不过它编码的结果不是Token，报告里面叫 Patches（中文暂译做补片），Encoder 将视频压缩为低维潜空间，再将其分解为 Patches。同样 Sora 也能从 Patches 反向解码成视频图像。（参考图一）  \nSora 同时还是一种扩散模型，能将有噪声的图像块，基于 Prompt 还原出清晰的图像。（参考图二）  \n另外，报告中特地提到了：“我们的研究显示，扩展视频生成模型的规模是向着创建能够模拟物理世界的通用工具迈出的有前途的一步。”  \n据说微软前一段时间给OpenAI搞了五千亿个视频用于训练。\n原文：\nhttps://openai.com/research/video-generation-models-as-world-simulators?continueFlag=2c6d842b1332338a289515b10241db55\n","slug":"paper/视频生成模型：构建虚拟世界的模拟器","date":"2024-03-14T06:15:59.761Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"fe1448a608eca318d1350f71f4be1e8e","title":"Python加密库缺失","content":"测试一下Obsidian\n12cryptography is required for sha256_password or caching_sha2_password\n\n原因是缺失了一个库。\n12pip3 install setuptools_rustpip3 install cryptography\n问题出现在 Django用PyMSQL调用MySQL相关的函数引起 。\n如果Python使用加密解密库，还有一人比较常用的库。\n1pip3 install pycryptodome==3.15.0\n\n∏\nmac下obsidian如何显示console控制台的快捷键\n在mac下，要显示Obsidian的控制台，您可以按照以下步骤操作：\n\n打开Obsidian应用程序。\n点击菜单栏中的”帮助”选项。\n在下拉菜单中，选择”开发者工具”。\n这将打开一个新窗口，其中包含Obsidian的控制台。\n\n请注意，控制台窗口可能会显示一些警告、错误或其他信息。如果您遇到了任何问题或错误，请将这些信息提供给Obsidian的开发者以获取帮助。\n　mac下obsidian如何显示console控制台的快捷键\n在Mac下，你可以使用以下快捷键来显示Obsidian的控制台：\n\n按下Command + Option + I 打开开发者工具。这将打开一个新的窗口，其中包含控制台选项卡。\n在控制台选项卡中，你可以查看Obsidian的日志和错误消息。\n\n请注意，这些快捷键是在默认设置下生效的。如果你修改了快捷键设置，那么可能需要使用不同的组合来打开控制台。\n","slug":"python/2023-09-28-Python加密库缺失","date":"2024-03-14T06:15:59.761Z","categories_index":"python,加密库","tags_index":"python","author_index":"安全书"},{"id":"02ac3d01366c7a352094c19df12c098f","title":"Python显示request请求的响应时间戳","content":"Python显示request请求的响应时间戳Python显示request请求的响应时间戳\n要显示Python的request请求的响应时间戳，可以使用time模块来获取请求开始和结束的时间，并计算它们之间的差异。以下是一个示例代码：\n1234567891011121314151617import requestsimport time# 发送请求前记录开始时间start_time = time.time()# 发送请求response = requests.get(&#x27;http://example.com&#x27;)# 请求结束后记录结束时间end_time = time.time()# 计算响应时间response_time = end_time - start_time# 打印响应时间print(&#x27;Response Time:&#x27;, response_time)\n\n在上述代码中，我们使用了time.time()函数来获取当前时间的时间戳。在发送请求之前记录了开始时间，并在请求结束后记录了结束时间。然后，通过计算两个时间戳之间的差异来得到响应时间。\n注意：这只是一个基本示例，实际中可能需要考虑更多因素，如网络延迟、服务器响应速度等。\npython中 time.time()返回的时间是什么单位\ntime.time()函数返回的时间是以秒为单位的浮点数。\n这句话什么意思， 怎么解决这个问题UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly. To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()return self.fget.get(instance, owner)()\n这句话是一个警告，意思是TypedStorage已被弃用，将来会被移除，只有UntypedStorage会保留作为唯一的存储类。如果你在直接使用storages，那么这个警告对你来说才有意义。要直接访问UntypedStorage，请使用tensor.untyped_storage()代替tensor.storage()。\n要解决这个问题，你可以按照警告中的建议，在代码中将tensor.storage()替换为tensor.untyped_storage()来访问UntypedStorage。这样可以避免在将来版本中出现问题。\n用python计算time的时间差， 并按时间戳的格式输出\n在Python中，可以使用datetime模块来计算时间差，并按照时间戳的格式输出。下面是一个示例代码：\n123456789101112from datetime import datetime# 定义起始时间和结束时间start_time = datetime(2022, 1, 1, 12, 0, 0)end_time = datetime(2022, 1, 1, 13, 30, 0)# 计算时间差time_diff = end_time - start_time# 输出时间差并按照时间戳的格式输出print(f&quot;Time difference: &#123;time_diff&#125;&quot;)print(f&quot;Time difference in seconds: &#123;time_diff.total_seconds()&#125;&quot;)\n\n运行以上代码，将输出如下结果：\n12Time difference: 1:30:00Time difference in seconds: 5400.0\n\n在输出中，Time difference显示了时间差为1小时30分钟，而Time difference in seconds显示了以秒为单位的时间差，即5400秒。这两个值可以根据需要进行进一步处理或格式化。\npython 输出时间戳， 定时取当前时间time.time(),格式按正常时间戳格式输出，精确到到毫秒\n可以使用time模块中的time()函数来获取当前时间戳，并使用datetime模块中的strftime()函数将其格式化为正常时间戳格式，精确到毫秒。\n以下是一个示例代码：\n12345678910111213import timefrom datetime import datetime# 获取当前时间戳timestamp = time.time()# 将时间戳转换为datetime对象dt_object = datetime.fromtimestamp(timestamp)# 格式化为正常时间戳格式，精确到毫秒formatted_timestamp = dt_object.strftime(&#x27;%Y-%m-%d %H:%M:%S.%f&#x27;)print(formatted_timestamp)\n\n运行以上代码，将输出类似于以下格式的时间戳：\n12022-01-01 12:34:56.789012\n\n注意，由于time()函数返回的是从1970年1月1日午夜开始经过的秒数，所以如果想要精确到毫秒，则需要使用datetime模块来进行转换和格式化。\n将两个time.time()调用，返回的时间差的结果，输出的时间转算成用了多少分钟和毫秒\n以下是将两个time.time()调用的结果转换为分钟和毫秒的方法：\n12345678910111213141516171819import time# 第一个time.time()调用start_time = time.time()# 执行一些操作# 第二个time.time()调用end_time = time.time()# 计算时间差time_difference = end_time - start_time# 转换为分钟和毫秒minutes = int(time_difference / 60)milliseconds = int((time_difference % 60) * 1000)# 输出结果print(&quot;时间差为：&#123;&#125; 分钟 &#123;&#125; 毫秒&quot;.format(minutes, milliseconds))\n\n在这个例子中，我们首先记录了第一个time.time()调用的结果作为起始时间start_time，然后执行一些操作，最后记录第二个time.time()调用的结果作为结束时间end_time。然后，我们计算两个时间之间的差异，并将其转换为分钟和毫秒。最后，我们使用print()函数输出结果。\n59.92it/s这是一个什么单位？具体含义是什么，在大语言训练的过程，数据嵌入\n59.92it/s 是一个单位表示每秒处理的信息数量。这里的 “it” 可能代表 “iterations”，即迭代次数。具体含义可能是在大语言训练的过程中，每秒进行59.92次迭代操作。数据嵌入指将数据嵌入到模型中进行训练或处理的过程。\n","slug":"python/Python显示request请求的响应时间戳","date":"2024-03-14T06:15:59.761Z","categories_index":"AIGC,python","tags_index":"python","author_index":"安全书"},{"id":"05b362c6dec32eeac664da3321842b99","title":"SD安装失败的总结","content":"SD安装失败的总结sd 安装过程\n1.下载webuigit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git\n2.安装包下载太慢,可以指定清华源  -i http://pypi.tuna.tsinghua.edu.cn/simple –trusted-host pypi.tuna.tsinghua.edu.cn –timeout=3000\n2.安装问题  1.Cannot locate TCMalloc (improves CPU memory usage)    yum install gperftools gperftools-devel\n  2.一直卡着clip安装    修改stable-diffusion-webui/modules目录下的launch_utils.py文件，在https://github.com前面加上https://ghproxy.com/，不然国内服务器很容易下载失败\n例如：https://ghproxy.com/https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip\n  3.git Unknown option: -C    因为git版本比较低，需要大于1.8.5\n\nMax retries exceeded with url: /openai/clip-vit-large-patch14/resolve/main/vocab.json (Caused by ConnectTimeoutError下载clip-vit-large-patch14 文件到本地  g解压后到stable diffusion 根目录 openai/clip-vit-large-patch14/**\n配置端口和host./webui.sh –xformers –listen –port 7860–listen 将监听 0.0.0.0,保证别的机器可以访问本机\n\n","slug":"python/SD安装失败的总结","date":"2024-03-14T06:15:59.761Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"c8f9ef0ce429539720d45bd27158e7b0","title":"Conda设置参数设置","content":"Conda设置参数设置 在conda中如何设置.cache文件夹位置为/data0\n要将conda中的.cache文件夹位置设置为/data0，可以按照以下步骤操作：\n\n打开终端或命令提示符。\n\n输入以下命令，将当前用户的~/.condarc文件复制到主目录下（如果该文件不存在则跳过此步骤）：\n1cp ~/.condarc ~\n使用文本编辑器打开~/.condarc文件，例如使用vim编辑器：\n1vim ~/.condarc\n在打开的.condarc文件中，添加或修改以下行：\n12345678envs_dirs:  - /data0/conda/envs  - /opt/anaconda3/envs  - /home/user_name/.conda/envspkgs_dirs:  - /data0/conda/pkgs  - /opt/anaconda3/pkgs  - /home/user_name/.conda/pkgs\n保存并关闭.condarc文件。\n\n\n现在，你已经成功将conda中的.cache文件夹位置设置为/data0。请注意替换指定路径中的”user_name”为你的用户名。\n如何配置.condarc文件，里面有那些参数设置。\n如果查看CUDA的具体版本号\n可以通过以下步骤查看CUDA的具体版本号：\n\n打开终端或命令提示符窗口。\n运行以下命令：nvcc --version。\n终端或命令提示符会显示CUDA的版本号信息。\n\n另外，如果你是在Windows操作系统上使用CUDA，你还可以通过以下步骤查看CUDA的版本号：\n\n打开开始菜单，并搜索“NVIDIA Corporation”文件夹。\n在该文件夹中，找到并打开“NVIDIA Control Panel”应用程序。\n在NVIDIA Control Panel窗口左侧的面板中，选择“帮助”&gt; “关于NVIDIA Control Panel”。\n在弹出的对话框中，你将看到CUDA驱动程序的版本号。\n\n无论在哪种操作系统上使用CUDA，以上方法都可以帮助你查看具体的CUDA版本号。\napt install 如何不考虑依赖， 强行安装一个软件\n要在Linux系统中强行安装一个软件而不考虑依赖关系，可以使用以下命令：\nsudo apt-get –no-install-recommends install &lt;软件包名称&gt;\n请注意，强行安装软件可能会导致系统不稳定或产生其他问题。确保你了解可能的后果并谨慎操作。\napt  install 一个软件，不考虑过程中的警告\n要在终端中安装软件并忽略警告，可以使用以下命令：\n1apt install &lt;软件名称&gt; -y\n这将自动回答任何确认提示，以便安装过程不会被暂停等待用户输入。请注意，忽略警告可能会导致潜在的问题，因此请谨慎使用。\n如何用Tar解压zip文件\n要使用tar解压缩zip文件，首先需要将zip文件转换为tar文件，然后再使用tar命令解压缩。\n以下是使用tar解压缩zip文件的步骤：\n\n首先，确保系统上已安装tar命令。如果没有安装，请先安装tar命令。\n\n打开终端或命令提示符。\n\n使用以下命令将zip文件转换为tar文件：\n1$ unzip filename.zip -d dirname\n\n其中，filename.zip是要解压缩的zip文件的名称，dirname是要创建的目标目录的名称。该命令将在当前目录下创建一个名为dirname的目录，并将zip文件解压缩到该目录中。\n\n然后，进入目标目录：\n1$ cd dirname\n最后，使用以下命令使用tar解压缩tar文件：\n1$ tar -xvf filename.tar\n\n其中，filename.tar是要解压缩的tar文件的名称。该命令会将tar文件中的内容提取到当前目录中。\n\n\n完成后，您可以在当前目录中查看已解压缩的文件和文件夹。\n注意：在某些情况下，您可能需要提供完整路径来执行上述操作。\n下面的问题， 是什么原因造成的，有什么好的方法吗Preparing to unpack …/nvidia-kernel-common-535_535.129.03-0ubuntu1_amd64.deb …\nUnpacking nvidia-kernel-common-535 (535.129.03-0ubuntu1) over (535.104.12-0ubuntu1) …\ndpkg: error processing archive /var/cache/apt/archives/nvidia-kernel-common-535_535.129.03-0ubuntu1_amd64.deb (–unpack):\ntrying to overwrite ‘/lib/firmware/nvidia/535.129.03/gsp_ga10x.bin’, which is also in package nvidia-firmware-535-535.129.03 535.129.03-0ubuntu0.22.04.1\ndpkg-deb: error: paste subprocess was killed by signal (Broken pipe)\nErrors were encountered while processing:\n/var/cache/apt/archives/nvidia-kernel-common-535_535.129.03-0ubuntu1_amd64.deb\nneedrestart is being skipped since dpkg has failed\n这个错误是由于在安装nvidia-kernel-common-535时，发生了文件冲突导致的。具体来说，系统中已经安装了nvidia-firmware-535-535.129.03包，并且它包含了与nvidia-kernel-common-535相同的文件’/lib/firmware/nvidia/535.129.03/gsp_ga10x.bin’。\n解决这个问题的一个好方法是执行以下步骤：\n\n打开终端并输入以下命令以删除已安装的nvidia-firmware-535-535.129.03包：sudo apt-get remove nvidia-firmware-535-535.129.03\n\n输入以下命令以清除未完成的安装：sudo dpkg –configure -a\n\n接下来，再次尝试安装nvidia-kernel-common-535：sudo apt-get install nvidia-kernel-common-535\n\n\n这样应该可以解决文件冲突并成功完成安装。\n下面这句话的含义和作用是什么sudo update-initramfs -u\n这句命令的含义是使用sudo权限更新initramfs（initial RAM file system）并重新生成引导文件。作用是在Linux系统中更新初始化内存文件系统，以确保系统能够正确引导。通过此命令，可以更新内核镜像和相关配置文件，以便在启动时加载正确的驱动程序和模块。\nnouveau是什么？他的作用是什么？\nnouveau是一个开源的图形驱动程序，用于Linux操作系统中的图形处理单元（GPU）。\nnouveau的作用是提供对NVIDIA显卡的支持，使得用户能够在Linux系统中使用NVIDIA显卡进行图形渲染和计算任务。它提供了与NVIDIA官方闭源驱动类似的功能，包括3D加速、视频解码、双显示器支持等。\n与闭源驱动相比，nouveau具有一些优势和不同之处。首先，它是开源的，可以由任何人进行修改和改进，并且可以与Linux内核及其其他组件进行集成。其次，nouveau提供了一些实验性的功能和调试选项，使得开发人员能够更好地理解和调试显卡硬件。此外，nouveau还致力于改善电源管理和性能优化等方面。\n总体而言，nouveau为Linux用户提供了一个免费、开放和可定制的选择来使用NVIDIA显卡，并在Linux环境下获得高质量的图形性能。\n安装Nivida驱动的时候为什么要禁用nouveau\n在安装Nvidia驱动程序时，需要禁用nouveau驱动程序是因为nouveau是一个开源的图形驱动程序，它可以与Nvidia显卡进行通信并提供基本的图形功能。然而，当安装官方的Nvidia专有驱动程序时，它与nouveau驱动程序可能会发生冲突，导致系统稳定性问题或无法正常启动。\n禁用nouveau驱动程序可以确保系统只使用官方的Nvidia驱动程序，以获得更好的图形性能和兼容性。这样做可以防止冲突，并确保正确加载和使用专有驱动程序所需的所有功能和优化。\n禁用nouveau驱动程序有多种方法，例如修改Linux内核参数、编辑GRUB引导配置文件或使用命令行选项。具体步骤可能因操作系统版本和配置而有所不同，请根据您的操作系统和需求选择适当的方法。\n如何查看torch的版本\n要查看torch的版本，可以使用以下代码：\n123import torchprint(torch.__version__)\n\n运行这段代码将打印出当前安装的torch版本。\nNVIDIA-SMI 535.129.03 Driver Version: 535.129.03 CUDA Version: 12.2\n翻译下面这句英文Depends: nvidia-kernel-common-535 (= 535.129.03-0ubuntu1) but 535.104.12-0ubuntu1 is to be installed\n依赖于nvidia-kernel-common-535（= 535.129.03-0ubuntu1），但要安装的是535.104.12-0ubuntu1。\n  如何查看本机看装了nvidia的那些驱动\n要查看本机是否安装了NVIDIA驱动程序，可以按照以下步骤进行操作：\n\n打开终端或命令提示符窗口。\n输入以下命令并按Enter键执行：1nvidia-smi\n如果安装了NVIDIA驱动程序，将显示与GPU相关的信息，包括驱动程序版本和GPU使用情况。\n\n另外，你还可以通过以下方法之一来检查本机是否安装了NVIDIA驱动程序：\n\n在Windows操作系统中，你可以打开“设备管理器”，然后展开“显示适配器”类别，查看是否存在NVIDIA的显卡驱动。\n在Linux操作系统中，你可以使用lsmod | grep nvidia命令来检查是否加载了NVIDIA内核模块。\n在Mac操作系统中，你可以打开“关于本机”菜单，并选择“系统报告”，然后在左侧面板中选择“图形/显示”类别，在右侧窗口中查看显卡信息。\n\n","slug":"python/codna/Conda设置参数设置","date":"2024-03-14T06:15:59.761Z","categories_index":"AIGC,conda","tags_index":"conda","author_index":"安全书"},{"id":"e610e4d512d51105e5370a7afc95aadf","title":"conda init bash指令的作用","content":"conda init bash指令的作用conda init bash这条指令的作用是什么，conda init bash，对那些文件做了处理了变化，有没有对.bashrc文件添加了什么内容？\n“conda init bash”命令的作用是将conda命令添加到bash shell的初始化配置文件中，以便在每次打开新的终端时自动激活conda环境。\n执行”conda init bash”命令后，会对.bashrc文件进行修改。它会在.bashrc文件末尾添加一段脚本，用于初始化conda。具体内容可能因系统和conda版本而有所不同，但一般情况下会包含以下内容：\n1234567891011121314# &gt;&gt;&gt; conda initialize &gt;&gt;&gt;# !! Contents within this block are managed by &#x27;conda init&#x27; !!__conda_setup=&quot;$(&#x27;/path/to/anaconda3/bin/conda&#x27; &#x27;shell.bash&#x27; &#x27;hook&#x27; 2&gt; /dev/null)&quot;if [ $? -eq 0 ]; then    eval &quot;$__conda_setup&quot;else    if [ -f &quot;/path/to/anaconda3/etc/profile.d/conda.sh&quot; ]; then        . &quot;/path/to/anaconda3/etc/profile.d/conda.sh&quot;    else        export PATH=&quot;/path/to/anaconda3/bin:$PATH&quot;    fifiunset __conda_setup# &lt;&lt;&lt; conda initialize &lt;&lt;&lt;\n\n注意：上述内容中的”/path/to/anaconda3”应替换为实际安装Anaconda或Miniconda的路径。\n这段脚本会在每次打开新的终端时执行，以确保Conda环境被正确激活。\n","slug":"python/codna/conda init bash指令的作用","date":"2024-03-14T06:15:59.761Z","categories_index":"python,conda","tags_index":"conda","author_index":"安全书"},{"id":"cff8a50c65a7fc50daa4abbaa8022cfe","title":"shutter-encoder免费视频转换","content":"shutter-encoder免费视频转换#开源项目推荐#：paulpacifico/shutter-encoder  \nShutter Encoder是一款开源免费的视频压缩编辑软件，支持windows和Mac。  \n主要功能包括：修剪和剪辑视频优化图片强大的裁剪支持生成和烧录剪辑信息字幕嵌入和烧录添加水印内置字幕编辑器等等\nhttps://www.shutterencoder.com/en/\nhttps://github.com/paulpacifico/shutter-encoder?continueFlag=ee66df50d8b2c452419ecff089efadc7\n\n","slug":"opensource/shutter-encoder免费视频转换","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"787f9d6e258fa139dbc5ec7521b6fde6","title":"《动手学深度学习》","content":"《动手学深度学习》推荐收藏（要学习哦）《动手学深度学习》  \nzh.d2l.ai  \n每个章节都是可以直接运行的 Jupyter 记事本，可以在本地直接运行，也可以克隆到 Google Colab 在云端运行。\n推荐收藏（要学习哦）《动手学深度学习》  \nzh.d2l.ai  \n每个章节都是可以直接运行的 Jupyter 记事本，可以在本地直接运行，也可以克隆到 Google Colab 在云端运行。\n\n","slug":"opensource/《动手学深度学习》","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"2c1dca5ce015e081c739168114db673d","title":"学家Maxime Labonne将微软的“小模型”Phi改造成了专家模型版本","content":"学家Maxime Labonne将微软的“小模型”Phi改造成了专家模型版本J.P.摩根的科学家Maxime Labonne将微软的“小模型”Phi，改造成了专家模型版本2x2_8版本：huggingface点co/mlabonne/phixtral-2x2_842x2_8版本：huggingface点co/mlabonne/phixtral-4x2_8 ​​​\n\n","slug":"opensource/学家Maxime Labonne将微软的“小模型”Phi改造成了专家模型版本","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"6d7ca311841c5ed9556ad896492f84ec","title":"开源的一个文档管理系统 Paperless-ngx","content":"开源的一个文档管理系统 Paperless-ngx它能够将你的纸质文档转换成在线可搜索的文档，并进行分类和索引，方便随时搜索查阅。  \nGitHub：github.com/paperless-ngx/paperless-ngx  \n主要有如下特性：  \n\n通过 OCR 技术自动扫描处理文档，同时能添加可搜索和可选文本。  \n能够利用标签、类型等多种方式来管理和分类文档，可利用机器学习技术自动分类。  \n文档保存为 PDF 格式，并同时保留未更改的原始文件。  \n支持识别超过 100 多种语言。  \n支持多种文件类型，如 PDF 文档、图像、纯文本文件或各类办公文档等。  \n界面美观、提供全文搜索功能、邮件处理功能。  \n有强大的多用户权限系统，支持全局权限和针对单独文档设置权限。\n\n\n","slug":"opensource/开源的一个文档管理系统 Paperless-ngx","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"5e193373dce27cd04399c0aebd29e85f","title":"模型生成语音","content":"模型生成语音Pinokio已经支持在本地使用MyShell 的 OpenVoice语音模型生成语音了。https://pinokio.computer/?continueFlag=22d463803a5e9fe20c66258db2d14df1\n","slug":"opensource/music/模型生成语音","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"ed5f36c345eb120dc9b9124931f35856","title":"开源TTS（文本生成语音）模型集合","content":"开源TTS（文本生成语音）模型集合开源TTS（文本生成语音）模型集合  \nXTTS - https://huggingface.co/coqui/XTTS-v2?continueFlag=22d463803a5e9fe20c66258db2d14df1\nYourTTS -   https://github.com/Edresson/YourTTS?continueFlag=22d463803a5e9fe20c66258db2d14df1\nFastSpeech2 - https://github.com/DigitalPhonetics/IMS-Toucan?continueFlag=22d463803a5e9fe20c66258db2d14df1\nVITS - https://huggingface.co/docs/transformers/model_doc/vits?continueFlag=22d463803a5e9fe20c66258db2d14df1\nTorToiSe - https://github.com/neonbjb/tortoise-tts?continueFlag=22d463803a5e9fe20c66258db2d14df1\nPheme - https://github.com/PolyAI-LDN/pheme?continueFlag=22d463803a5e9fe20c66258db2d14df1\nEmotiVoice - https://github.com/netease-youdao/EmotiVoice?continueFlag=22d463803a5e9fe20c66258db2d14df1\nStyleTTS 2 - https://github.com/yl4579/StyleTTS2?continueFlag=22d463803a5e9fe20c66258db2d14df1\npflowtts_pytorch - https://github.com/p0p4k/pflowtts_pytorch?continueFlag=22d463803a5e9fe20c66258db2d14df1\nVALL-E - https://github.com/enhuiz/vall-e?continueFlag=22d463803a5e9fe20c66258db2d14df1\n\n","slug":"opensource/music/开源TTS（文本生成语音）模型集合","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,TTS","tags_index":"TTS","author_index":"安全书"},{"id":"5e544af8f21f59746eb792b85e5b6db2","title":"WhisperSpeech文本转语音","content":"WhisperSpeech文本转语音很多人都听说过OpenAI开源的Whisper，是一个语音转文本的库。最近有个很火的开源项目叫WhisperSpeech，是将Whisper反向操作，就变成了一个文本转语音的库，效果还不错。\nhttps://github.com/collabora/WhisperSpeech?continueFlag=22d463803a5e9fe20c66258db2d14df1\n\n\n","slug":"opensource/sound/WhisperSpeech文本转语音","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,WhisperSpeech","tags_index":"WhisperSpeech","author_index":"安全书"},{"id":"eb7ff1a1c10025a2663883c2cd4d7e49","title":"AnimateAnyone","content":"AnimateAnyone刚发现摩尔线程前几天复原了阿里的单图跳舞项目并且已经开源训练代码，你可以训练自己的AnimateAnyone模型。有个基于摩尔线程开源的版本制作了 ComfyUI 节点，并且提供了基础的工作流。现在可以在ComfyUI中非常简单的让单图跳舞了。\nhttps://github.com/chaojie/ComfyUI-Moore-AnimateAnyone\n\n","slug":"opensource/video/AnimateAnyone","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,AnimateAnyone","tags_index":"AnimateAnyone","author_index":"安全书"},{"id":"dde64d8630e6c5550acf06dbe60b7085","title":"SonicVisionLM视频生成音效","content":"SonicVisionLM视频生成音效SonicVisionLM 可以为视频生成音效。它使用视觉语言模型 (VLM) 来识别视频中的事件并生成与视频内容匹配的声音。  \n戳视频听听音效↓  \n项目：yusiissy.github.io/SonicVisionLM.github.io  \nSonicVisionLM: Playing Sound with Vision Language Models（用视觉语言模型播放声音）  \n论文摘要：人们对为无声视频生成声音的任务越来越感兴趣，主要是因为它在简化视频后期制作方面的实用性。然而，现有的视频声音生成方法试图直接从视觉表示创建声音，由于难以将视觉表示与音频表示对齐，这可能具有挑战性。  \n在本文中，我们提出了SonicVisionLM，这是一种新颖的框架，旨在通过利用视觉语言模型生成各种声音效果。我们没有直接从视频生成音频，而是使用强大的视觉语言模型 (VLM) 的功能。  \n当提供无声视频时，我们的方法首先使用 VLM 识别视频中的事件，以建议与视频内容匹配的可能声音。这种方法的转变将图像和音频对齐的挑战性任务转变为通过流行的扩散模型对齐图像到文本和文本到音频的更深入研究的子问题。  \n为了提高LLM的音频推荐质量，我们收集了一个广泛的数据集，将文本描述映射到特定的声音效果，并开发了时间控制的音频适配器。  \n我们的方法超越了当前将视频转换为音频的最先进方法，从而增强了与视觉效果的同步并改善了音频和视频组件之间的对齐。\n","slug":"opensource/sound/SonicVisionLM视频生成音效","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC,SonicVisionLM","tags_index":"SonicVisionLM","author_index":"安全书"},{"id":"b47d7593669fa330c65584f3449adde6","title":"WhisperFusion","content":"WhisperFusion通过语音与AI进行对话https://github.com/collabora/WhisperFusion/blob/main/README.md\n","slug":"opensource/sound/WhisperFusion","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC","tags_index":"WhisperFusion","author_index":"安全书"},{"id":"4a024021a60f470787d8b42e3b1651ad","title":"Luna AI","content":"Luna AILuna AI：全自动的 AI 直播系统，由ChatterBot / GPT / Claude / langchain 本地 or 云端 / chatglm / text-generation-webui / 讯飞星火 / 智谱AI 做为 大脑 驱动的虚拟主播 Live2D / Vtube Studio / UE5 + Audio2Face ，可以在 Bilibili / 抖音 / 快手 / 斗鱼 直播中与观众实时互动 或者 直接在本地和您进行聊天，使用自然语言处理和文本转语音技术 Edge-TTS / VITS-Fast / elevenlabs / bark-gui / VALL-E-X 生成对观众问题的回答并可以通过 so-vits-svc / DDSP-SVC 变声，另外还可以通过特定指令协同 Stable Diffusion 进行画图展示。并且可以自定义文案进行循环播放】’Luna AI - Luna AI’ GitHub: github.com/0x648/luna-ai\n","slug":"opensource/zhibo/Luna AI","date":"2024-03-14T06:15:59.760Z","categories_index":"AIGC","tags_index":"Luna","author_index":"安全书"},{"id":"5c042704720d576a36ac14be2ca61bc2","title":"Prompting Guide","content":"Prompting GuidePrompting Guide\n项目：www.promptingguide.aiGit：github.com/dair-ai  \n最近的更新：  \n\n在 GitHub 有 40K ⭐️  \n全球超过 250 万学习者  \n添加了 Gemini、Mistral 7B 和 Phi-2 的全面提示指南  \nPrompt chaining技术的新指南  \n函数调用的新指南  \n用于 RAG、函数调用和其他提示技术入门的 Python notebooks  \n宣布设立一个新章节来记录和发现新的LLM研究成果；这是一项正在进行的工作，未来几周会有大更新  \n现在有 13 种翻译版本  \n\n\n\n\n","slug":"opensource/Prompting Guide","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,prompting guide","tags_index":"Prompting Guide","author_index":"安全书"},{"id":"f8565fffcb4c0199e69072e808bcc1bc","title":"Portkey-AI gateway","content":"Portkey-AI gateway在 GitHub 上有一个称之为 “AI Gateway（AI 网关）” 的工具。  \n通过统一简单的 API，让你轻松快速接入 100 多种大语言模型，如 OpenAI、Anthropic、Mistral、LLama2、Google Gemini 等。  \nGitHub：github.com/Portkey-AI/gateway  \n具有如下特点：  \n\n占用空间极小，仅仅约 45kb，但其处理速度极快，达到快 9.9 倍。  \n可以同时连接多个模型，并能处理多个模型、服务提供商和密钥之间的负载平衡。  \n设置故障转移机制，当一个模型出现无法使用情况，可自动切换到可用模型，确保你的应用持续稳定运行。  \n默认配置自动重试，并采用指数回退策略，进一步提高请求的稳定性。  \n可根据需求添加中间件，满足你个性化需求。  \n已经在超过 100B Tokens 上进行了实战测试。\n\n\n","slug":"opensource/Portkey-AI gateway","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,AI gateway","tags_index":"AI gateway","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"网易有道开源了一款名为 QAnything 的知识库问答引擎，可实现一键部署！  \n不仅可调用云端大模型服务，还可实现纯本地部署。但官方建议在配备 NVIDIA 3090 16GB 显存以上的电脑上进行本地部署。  \n支持导入 PDF、Word（doc/docx）、PPT、Markdown 等多种格式的文档，即可像与 GPT 对话那样，提供准确、快速、可靠的问答体验。  \nGitHub：github.com/netease-youdao/QAnything  \n主要有如下特点：  \n\n数据安全：支持全程断网安装与使用。  \n跨语种问答：无缝切换中英文问答，不限文件语种。  \n海量数据处理：采用两阶段向量排序，有效解决大规模数据检索问题，数据越多效果越好。  \n高性能生产级系统：适用于企业应用的直接部署。  \n易用性：无需繁琐的配置，一键安装部署，拿来就用。  \n多知识库问答：支持选择多个知识库进行问答。\n\n\n","slug":"opensource/QAnything 知识库问答引擎","date":"2024-03-14T06:15:59.759Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"bf743a7e33155e28f37ac5a1a08296ec","title":"Quiver云大脑","content":"Quiver云大脑【Quiver：一个设计成在云中作为您的“第二大脑”，用于轻松存储和检索非结构化信息的工具，其功能类似于 Obsidian，但由生成式 AI 提供支持，可以直接和存储的资料进行对话】’Quiver - Dump all your files and thoughts into your GenerativeAI brain and chat with it’ Stan Girard GitHub: github.com/StanGirard/quiver\n","slug":"opensource/Quiver云大脑","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,Quiver","tags_index":"Quiver","author_index":"安全书"},{"id":"d197d6a5586b959dab8a9b3896756513","title":"WeChatMsg 微信聊天管理工具","content":"WeChatMsg 微信聊天管理工具【WeChatMsg —— 微信聊天管理工具】项目地址：https://gitee.com/lc044/WeChatMsg\nWeChatMsg 是一款开源的微信聊天管理工具。🍉功能：还原微信聊天界面● 🗨文本✅● 🏝图片✅● 🐻‍❄️表情包✅● 拍一拍等系统消息✅导出聊天记录● sqlite 数据库✅● HTML (文本、图片、视频、表情包、语音、文件、系统消息)✅● CSV 文档✅● TXT 文档✅● Word 文档✅分析聊天数据，做成可视化年报 (急需前端大佬提供优质模板)\n","slug":"opensource/WeChatMsg 微信聊天管理工具","date":"2024-03-14T06:15:59.759Z","categories_index":"gitee","tags_index":"gitee","author_index":"安全书"},{"id":"4b4ad76e40a6aec8ebb922b2fb9d3aaa","title":"GPT-SoVITS","content":"GPT-SoVITS在 GitHub 上刚开源的一款适用于中文语音克隆的工具：GPT-SoVITS。  \n仅需提供 5 秒语音样本，1 分钟完成声音克隆并训练出高质量的 TTS 模型！  \nGitHub：github.com/RVC-Boss/GPT-SoVITS  \n目前已获得 1.1k Star，看到很多人对其评价为目前最强中文语音克隆工具。\n特征：★ 零样本 TTS：输入 5 秒语音样本并体验即时文本到语音转换。  \n★ Few-shot TTS：仅用 1 分钟的训练数据即可微调模型，以提高语音相似度和真实感。  \n★ 跨语言支持：用与训练数据集不同的语言进行推理，目前支持英语、日语和中文。  \n★ WebUI工具：集成工具包括语音伴奏分离、自动训练集分割、中文ASR和文本标注，帮助初学者创建训练数据集和GPT/SoVITS模型。\n","slug":"opensource/music/GPT-SoVITS","date":"2024-03-14T06:15:59.759Z","categories_index":"github","tags_index":"github","author_index":"安全书"},{"id":"03979614022b99854c743327dde93925","title":"AIGC 生成音乐","content":"AIGC 生成音乐宇航员骑马奔驰，配什么BGM比较飒？这活交给AI试试！  \n输入文本“宇航员骑大马”，秒速生成一段1分钟的音频：  \nemmm……听起来好动感！  \n是的没错，AI可以基于文字提示生成音乐！  \n上面这段演示视频，基于Deforum Stable Diffusion的Colab页面代码修改而来。  \n这只新项目的名字叫Mubert API，已在Github开源，获得1000多的标星。  \n推特上也有不少人已经用Mubert API生成音频，来给自己的视频配乐了。  \nMubert API大概的工作流程是这样的：  \n音乐人谱曲后上传→AI进行风格分类→用户输入文本→AI用demo组曲→生成个性化音乐  \n也就是说，虽然Mubert API在进行text-to-music的工作，但是AI负责的部分，只有两个步骤：  \n分类demo + 根据提示文本组合demo成曲。  \n简而言之，最后生成的音乐，是由真人谱曲、AI组曲。\nAIGC音乐","slug":"opensource/music/AIGC 生成音乐Mubert API","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,music,Mubert API","tags_index":"music,Mubert API","author_index":"安全书"},{"id":"423fff7e035377580959d9c4577a1325","title":"Amphion","content":"AmphionAmphion：一个开源的音频、音乐和语音生成整合工具包。  \n支持如下功能：  \n\n文本转语音（TTS）：高性能，支持主流模型及架构，可生成自然的声音。  \n歌声转换（SVC）：可将某人歌声转换成其他人歌声，内置张学友、陈奕迅、王菲等已训练好的声音。  \n文本转音频（TTA）：可通过文本提示，生成逼真的声效、语音以及音乐，类似于 AudioLDM。  \n\nGitHub：github.com/open-mmlab/Amphion  \n以上功能均可在 HuggingFace 上使用。  \n地址：huggingface.co/amphion\n\ndemo https://huggingface.co/spaces/amphion/singing_voice_conversion\n","slug":"opensource/music/Amphion","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,Amphion","tags_index":"Amphion","author_index":"安全书"},{"id":"868e3cd853e2fb25fbbd3b9fcb1e1038","title":"Meta开源了AI 音频生成工具 AudioCraft","content":"Meta开源了AI 音频生成工具 AudioCraftAudioCraftMeta开源了AI 音频生成工具 AudioCraft，包含 3 个模型：  \n\nMusicGen 文本生成音乐  \nAudioGen 文本生成音频  \nEnCodec 损失更少的音频压缩  \n\nAudioGen的demo：felixkreuk.github.io/audiogen  \nMusicGen在🤗HuggingFace 上的测试地址（在线Demo）：https://huggingface.co/spaces/facebook/MusicGen?continueFlag=22d463803a5e9fe20c66258db2d14df1\nAIGC音乐","slug":"opensource/music/Meta开源了AI 音频生成工具 AudioCraft","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,AudioCraft","tags_index":"AudioCraft","author_index":"安全书"},{"id":"28aee948305f9d40f822e6bd2d04fbce","title":"OpenVoice：多功能即时声音克隆技术","content":"OpenVoice：多功能即时声音克隆技术OpenVoice is a multi-functional real-time voice cloning technology developed by the MyShell team. It can clone the voice of the original speaker and generate speech in various languages by providing a short audio sample.\nIt has the following advantages:\n\nHigh-precision voice cloning:It can highly restore the reference voice, supporting speech generation in multiple languages and accents.\n\nFlexible voice style control:It allows fine adjustments to the emotions and accents of the voice, as well as control over rhythm, pauses, and intonation.\n\nCross-language voice cloning without sample:Both the reference voice and generated voice can be in any language outside of large-scale multilingual datasets.\n\n\nGitHub: github.com/myshell-ai/OpenVoice\nI tested it, and the effect for Chinese is not very good. The MyShell team is aware of this issue and has expressed that they are working on optimizing it.OpenVoice：多功能即时声音克隆技术。  \n这是由 MyShell 团队开发的一项技术，只需提供一段简短的音频样本，就能克隆出原发言者的声音，并能以此生成各种语言的语音。  \n它具有如下优势：  \n1）高精度音色克隆能够高度还原参考音色，支持多语种和多种口音的语音生成。  \n2）灵活的声音风格调控可以对声音的情感、口音进行精细调整，还可以控制节奏、停顿和语调等多种声音风格。  \n3）无需样本的跨语言声音克隆无论是参考声音还是生成的声音，都可以是大型多语种数据集之外的任何语言。  \nGitHub：github.com/myshell-ai/OpenVoice  \n测试了下，中文效果不是很好， 对此 MyShell 团队也清楚并表示正在优化处理。\n\n","slug":"opensource/music/OpenVoice：多功能即时声音克隆技术","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,github","tags_index":"github","author_index":"安全书"},{"id":"a8dc2259290df507e7a1ee1a8b7e6436","title":"WavJourney根据文本提示生成音频","content":"WavJourney根据文本提示生成音频【WavJourney：根据文本提示生成音频，可生成引人入胜的音频故事情节、个性化的声音、逼真的演讲、情感共鸣的音乐作品和身临其境的音效】《WavJourney - a Hugging Face Space by Audio-AGI》\ndemohttps://huggingface.co/spaces/Audio-AGI/WavJourney?continueFlag=22d463803a5e9fe20c66258db2d14df1\nGithub: github.com/Audio-AGI/WavJourne\nAIGC音乐","slug":"opensource/music/WavJourney根据文本提示生成音频","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,audio,WavJourney","tags_index":"WavJourney","author_index":"安全书"},{"id":"f380b05117d4b8eb3944fcca3840bb7a","title":"Riffusion：基于Stable Diffusion的实时音乐生成","content":"Riffusion：基于Stable Diffusion的实时音乐生成【Riffusion：基于Stable Diffusion的实时音乐生成，输入歌词和声音提示即可创作音乐】”Riffusion - Stable diffusion for real-time music generation”\nhttps://www.riffusion.com/?continueFlag=22d463803a5e9fe20c66258db2d14df1\n","slug":"opensource/music/Riffusion：基于Stable Diffusion的实时音乐生成","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,Riffusion","tags_index":"Riffusion","author_index":"安全书"},{"id":"9752557ebe590527728adfa25fc43406","title":"在线生成音乐的项目和工具","content":"在线生成音乐的项目和工具AIGC与声音和音乐相关的在线Demo\n歌手换声 A的声音换成B歌手的。https://huggingface.co/spaces/amphion/singing_voice_conversion\n根据提示词生成音乐， 基于Stable Diffusionhttps://www.riffusion.com/?continueFlag=22d463803a5e9fe20c66258db2d14df1\n根据提示词生成音乐https://huggingface.co/spaces/Audio-AGI/WavJourney?continueFlag=22d463803a5e9fe20c66258db2d14df1\nMeta facebook 公司的根据提示词生成音乐https://huggingface.co/spaces/facebook/MusicGen?continueFlag=22d463803a5e9fe20c66258db2d14df1\n","slug":"opensource/music/在线生成音乐的项目和工具","date":"2024-03-14T06:15:59.759Z","categories_index":"AIGC,music","tags_index":"music","author_index":"安全书"},{"id":"876cf66625c49b0d0aaed601604f1e57","title":"AI神器及下载地址","content":"AI神器及下载地址\n","slug":"opensource/AI神器及下载地址","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"eb7ff1a1c10025a2663883c2cd4d7e49","title":"AnimateAnyone","content":"AnimateAnyoneAnimateAnyone（http://t.cn/A6lLddEA）的开源实现Moore-AnimateAnyone，可以了解一下↓ 项目：github.com/MooreThreads/Moore-AnimateAnyone 这是一个非常初步的版本，旨在接近AnimateAnyone中显示的性能（在我们的测试下大约为 80%） 当前版本还存在以下缺陷： → 当参考图像具有干净的背景时，背景可能会出现一些伪影 → 当参考图像和关键点之间存在比例不匹配时，可能会出现次优结果。该版本尚未实现论文中提到的预处理技术。 → 当运动序列微妙或场景静止时，可能会出现一些闪烁和抖动。 当然，作者还在持续优化，些问题将在不久的将来得到解决和改善。 附：另一个实现在这里github.com/guoqincode/Open-AnimateAnyone\n","slug":"opensource/AnimateAnyone","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"7e0343734d8fb32cb6aa2171358da2ec","title":"AnyText(AI生成或者编辑图片中的文字)","content":"AnyText(AI生成或者编辑图片中的文字)阿里发布的AnyText了解一下！可以用AI生成或者编辑图片中的文字，且与图片风格保持一致。支持中文（毕竟自己人的研究）  \nAnyText: Multilingual Visual Text Generation And Editing（多语言视觉文本生成和编辑）  \n项目：github.com/tyxsspa/AnyText论文：arxiv.org/abs/2311.03054演示：modelscope.cn/studios/damo/studio_anytext  \n论文摘要：  \n基于扩散模型的文本到图像最近取得了令人瞩目的成就。尽管当前的图像合成技术非常先进，能够生成高保真度的图像，但当聚焦于生成图像中的文本区域时，仍然可能会泄露出真相。  \n为了解决这个问题，我们引入了 AnyText，一种基于扩散的多语言视觉文本生成和编辑模型，专注于在图像中渲染准确且连贯的文本。  \nAnyText 包含一个具有两个主要元素的扩散管道：辅助潜在模块和文本嵌入模块。前者使用文本字形、位置和蒙版图像等输入来生成用于文本生成或编辑的潜在特征。后者采用 OCR 模型将笔划数据编码为嵌入，与标记生成器中的图像标题嵌入混合，生成与背景无缝集成的文本。我们采用文本控制扩散损失和文本感知损失进行训练，以进一步提高书写准确性。AnyText 可以用多种语言编写字符，  \n据我们所知，这是第一个解决多语言视觉文本生成问题的工作。值得一提的是，AnyText 可以插入社区现有的扩散模型中，以准确地渲染或编辑文本。  \n经过广泛的评估实验，我们的方法明显优于所有其他方法。此外，我们还贡献了第一个大规模多语言文本图像数据集 AnyWord-3M，其中包含 300 万个带有多种语言 OCR 注释的图像文本对。基于AnyWord-3M数据集，我们提出了AnyText-benchmark来评估视觉文本生成的准确性和质量。\n","slug":"opensource/AnyText(AI生成或者编辑图片中的文字)","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,github","tags_index":"github","author_index":"安全书"},{"id":"4ba2544bec456336ced726313887dd49","title":"Apache Answer开源问题社区","content":"Apache Answer开源问题社区\nVisActor（图一）：字节推出的前端数据可视化方案。网页链接  \npaint-board（图二）：开源画板，提供各种笔触。网页链接  \nApache Answer（图三）：开源问答平台软件，帮你快速建立问答社区。网页链接  \nYazi（图四）：运行在终端里面的文件管理器，跨平台。网页链接\n\n","slug":"opensource/Apache Answer开源问题社区","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"aa4fa1b6f96947cce8be62bd4b2776f0","title":"Jan.ai桌面AI","content":"Jan.ai桌面AI一个类似于ChatGPT的替代品，可以在个人电脑上100%离线运行。\nhttps://github.com/janhq/jan?continueFlag=ee66df50d8b2c452419ecff089efadc7\nhttps://jan.ai/\n\n","slug":"opensource/Jan.ai桌面AI","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"650765578b5bfd5d725692c13a51e1b9","title":"LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力","content":"LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力  \nLARP能让游戏角色像真人一样和玩家对话，同时能够理解游戏中复杂的情境、记住过去的互动。并根据这些信息做出合理的反应。  \n它能让游戏角色的行为更加真实和有深度，从而提升玩家的游戏体验。  \nLARP的工作原理是通过先进的认知架构和环境交互模块，结合后处理方法，使得游戏中的AI代理能够以更真实、更有深度的方式与玩家互动，从而提升整个游戏的体验。  \n认知架构：能够模拟人类的认知过程，包括记忆处理和决策制定。  \n环境交互模块：与游戏环境互动，学习和适应环境变化。  \n主要功能：  \n\n更自然的对话：它能让游戏中的角色以更自然、更流畅的方式与你对话。你可以用自然语言向它们提问，它们也能以类似真人的方式回答。  \n角色有自己的记忆和个性：这些角色不仅能记住你之前的互动，还会根据它们的“个性”做出反应。比如，一个友好的商人可能会记得你上次帮助他，而一个狡猾的盗贼可能会试图欺骗你。  \n更丰富的游戏体验：这些代理能够根据游戏中发生的事件做出反应，提供更多样化的游戏体验。例如，如果游戏中发生了一场战斗，这些角色可能会对此做出评论或提供帮助。  \n更深入的角色扮演：由于游戏角色能够提供更具深度和变化的互动，你作为玩家可以更深入地投入到角色扮演中，体验一个更加丰富和真实的游戏世界。  \n\n项目地址：miao-ai-lab.github.io/LARP/论文：arxiv.org/abs/2312.17653GitHub：github.com/MiAO-AI-Lab/LARP\n","slug":"opensource/LARP：一个开放世界游戏代理，赋予游戏角色真实的语言和认知能力","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"4f8f7da3ab9de307d7967ad3cdc3c644","title":"MobileVLM：一种快速、可复现且强大的适用于移动设备的视觉语言助手。","content":"MobileVLM：一种快速、可复现且强大的适用于移动设备的视觉语言助手。MobileVLM：一种快速、可复现且强大的适用于移动设备的视觉语言助手。  \n论文摘要：  \n我们向您介绍MobileVLM。这是一款专为移动设备打造的、出色的多模态视觉语言模型（MMVLM）。  \nMobileVLM混合了各种面向移动设备的架构设计和技术。这其中包括一套从零开始训练的大规模语言模型（参数达到14亿和27亿），一个使用CLIP方法预训练的多模态视觉模型，以及一个高效的投射器，可实现跨模式交互。  \n我们使用了几种典型的VLM基准测试来评估MobileVLM。结果表明，我们的模型与一些大模型相比，表现相当出色。我们在Qualcomm Snapdragon 888 CPU和NVIDIA Jeston Orin GPU上测量了推理速度。  \n令人兴奋的是，我们取得了21.5个和65.3个 Token 每秒的推理速度，这在业界属于领先水平。  \n论文地址：https://arxiv.org/abs/2312.16886https://weibo.cn/sinaurl?u=https%3A%2F%2Farxiv.org%2Fabs%2F2312.16886)  \n项目地址：https://github.com/Meituan-AutoML/MobileVLM?continueFlag=48c6ac337ec997382068a1426679b2ec\n️️️测试一下\n","slug":"opensource/MobileVLM：一种快速、可复现且强大的适用于移动设备的视觉语言助手。","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"76809eb8e705b8ffe77ac47cfe901bb0","title":"NoMask文本到人体动作","content":"NoMask文本到人体动作AI除了有文本到图像、视频，还有文本到动作↓  \nMoMask是文本到人体动作的新研究方向，生成的动画可以导入Blender和其他CG软件中。  \n项目：huggingface.co/spaces/MeYourHint/MoMask论文：arxiv.org/abs/2312.00063  \nMoMask: Generative Masked Modeling of 3D Human Motions（3D 人体运动的生成蒙版建模）  \n论文摘要：我们介绍 MoMask，这是一种新颖的蒙版建模框架，用于文本驱动的 3D 人体运动生成。  \n在 MoMask 中，采用分层量化方案将人体运动表示为具有高保真细节的多层离散运动标记。  \n从基础层开始，利用通过矢量量化获得的运动令牌序列，导出递增阶的剩余令牌并将其存储在层次结构的后续层中。因此，后面是两个不同的双向Transformer。对于基础层运动标记，指定了一个 Masked Transformer 来预测以训练阶段的文本输入为条件的随机掩蔽运动标记。  \n在生成（即推理）阶段，从空序列开始，我们的 Masked Transformer 迭代地填充缺失的标记；随后，残差变换器学习根据当前层的结果逐步预测下一层标记。  \n大量实验表明，MoMask 在文本到运动生成任务上优于最先进的方法，在 HumanML3D 数据集上的 FID 为 0.045（相对于 T2M-GPT 的 0.141），在 KIT 上的 FID 为 0.228（相对于 0.514） -ML，分别。MoMask 还可以无缝应用于相关任务，无需进一步模型微调，例如文本引导的时间修复。\n","slug":"opensource/NoMask文本到人体动作","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"48a53ce5cdc72b30cd8a8705eac92978","title":"Open Interpreter","content":"Open InterpreterOpen Interpreter 这项目强的离谱啊，想玩玩了。\n作者给了他一张有，温度传感器、LCD面板和Arduino的照片。他就自己打开Arduino的编辑器写了代码让LCD面板现实温度传感器读取的温度。  \nOpen Interpreter（开放解释器） 可以让大语言模型（LLMs）在本地运行代码（比如 Python、JavaScript、Shell 等）。安装后，在终端上运行 $ interpreter 即可通过类似 ChatGPT 的界面与 Open Interpreter 聊天。在代码运行前都会要求你批准执行代码。  \nOpen Interpreter（开放解释器）通过在本地环境中运行。它可以完全访问互联网，不受运行时间或是文件大小的限制，也可以使用任何软件包或库。  \n项目地址：https://github.com/KillianLucas/open-interpreter/?continueFlag=22d463803a5e9fe20c66258db2d14df1\n","slug":"opensource/Open Interpreter","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"91385f1fab7da7d056f09d474ac1f71b","title":"OpenAI官方的撰写提示秘籍","content":"OpenAI官方的撰写提示秘籍官网：platform.openai.com/docs/guides/prompt-engineering/six-strategies-for-getting-better-results  \n▶策略1：清晰的指令情景：用户想要在Excel中计算一列数字的总和。  \n较差的提问：”如何在Excel中加数字？”更好的提问：”如何在Excel中自动计算一列金额的总和，并将总数显示在名为‘总计’的右侧列中？”  \n说明：第二个提问更清晰、具体，使模型能够提供更精确的回答。  \n▶策略2：使用外部工具情景：用户需要计算一个复杂的数学问题。  \n传统方法：直接问模型这个数学问题的答案。改进方法：指导模型使用Python代码来计算答案，例如使用三个反引号（```）包围Python代码。  \n说明：使用外部工具（如Python代码执行）可以提高计算的准确性。  \n▶策略3：分解复杂任务情景：用户需要对一篇长文档进行总结。  \n传统方法：直接要求模型一次性总结整个文档。改进方法：将文档分成多个部分，逐个总结，然后将这些小总结合并成一个完整的总结。  \n说明：将复杂任务分解成多个简单的子任务，可以提高处理的效率和质量。  \n▶策略4：模型思考时间情景：用户询问关于历史事件的复杂问题。  \n传统方法：直接要求模型回答。改进方法：首先要求模型提出一个推理过程，然后再给出答案。  \n说明：让模型先进行思考，可以帮助它提供更深入、更准确的答案。  \n▶策略5：系统性测试变化情景：开发者想改善聊天机器人的性能。  \n传统方法：根据个别案例调整指令。改进方法：创建一个包含多种测试案例的套件，系统性地评估每次改动对性能的影响。  \n说明：系统性地测试改动可以确保每次调整都真正提升了性能。  \n▶策略6：指导模型使用引用文本情景：用户对某个专业领域的问题寻求详细且准确的答案。  \n传统方法：直接向模型提问。改进方法：提供相关领域的参考文献或文章，并指导模型根据这些文献来回答问题。  \n说明：通过提供参考文献，可以引导模型提供更准确、更有根据的答案，减少错误或虚构信息的出现。\n\n\n\n\n","slug":"opensource/OpenAI官方的撰写提示秘籍","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,提示词秘籍","tags_index":"提示词秘籍","author_index":"安全书"},{"id":"0e12fc59bb4e5c0819fe2a5d3602bf14","title":"ollama的indexing这个API是什么作用？","content":"ollama的indexing这个API是什么作用？ollama的/indexing这个API是什么作用？\nollama的/indexing这个API是一种用于数据搜索和分析的工具，可以帮助开发者更好地理解和利用数据。该API提供了一系列的功能，包括数据挖掘、数据可视化、数据分析等。通过使用/indexing API，开发者可以更好地理解和利用数据，从而提高他们的工作效率和决策能力。️\n用python举例 ollama 的/indexing这个API的使用1. 首先，需要安装python和requests库。可以使用pip命令进行安装：\n1pip install python requests\n\n然后，可以使用以下代码来调用Ollama的/indexingAPI：12345678910111213141516import requests# 设置API地址和请求参数url = &quot;https://api.ollama.com/v1/indexing&quot;params = &#123;    &quot;api_key&quot;: &quot;YOUR_API_KEY&quot;,&#125;# 发送请求并获取响应response = requests.post(url, data=params)# 如果请求成功，则输出响应内容if response.status_code == 200:    print(&quot;请求成功！&quot;)else:    print(&quot;请求失败！&quot;)\n在上述代码中，YOUR_API_KEY是您需要设置的Ollama API密钥。建议您在代码中使用环境变量来存储这个密钥，以便在不同的环境下重复使用相同的API密钥。\n如果您需要更多的信息或指导，请查看Ollama API文档。️\n\n","slug":"ollama/ollama的indexing这个API是什么作用？","date":"2024-03-14T06:15:59.758Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"6f9969d6703cdfb337efc9fb77db60f7","title":"TinyLlama","content":"TinyLlamaTinyLlama\nMac下高速跑LLM  \nTinyLlama ultra fast on M3 Max cores: 4E+12P+40GPU with  \n\nQ4_0: 207 tokens/s  \nQ5_K_M: 197 tokens/s  \nFP16: 119 tokens/s ​​​\n\nhttps://ollama.ai/library/tinyllama?continueFlag=ee66df50d8b2c452419ecff089efadc7\nhttps://github.com/jzhang38/TinyLlama\nhttps://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.6\n\n\n","slug":"ollama/TinyLlama","date":"2024-03-14T06:15:59.757Z","categories_index":"AIGC,ollama","tags_index":"ollama","author_index":"安全书"},{"id":"00031c756df5944ae03766354a37e479","title":"Lua的变量","content":"变量变量就是给一块内存区域赋予的一个名字。变量使得在程序中就可以修改或读取相应的内存区域中的内容。它可以代表各种不同类型的值，包括函数与表。 \n变量的名字由字母、数字与下划线组成。它必须是字母或下划线开头。由于 Lua 是字母大小写敏感的，所以大写字母与小写字母是不一样的。Lua 中有八种基本值类型： \n在 Lua 语言中，虽然我们没有变量数据类型，但是依据变量的作用域我们可以将变量分为三类： \n\n    全局变量：除非显示的声明一个局部变量，否则所有的变量都被默认当作全局变量。\n    局部变量：如果我们将一个变量定义为局部变量，那么这么变量的作用域就被限制在函数内。\n    表字段：这种特殊的变量可以是除了 nil 以外的所有类型，包括函数。\n\n\nLua 变量定义一个变量定义就意味着告诉解释器在什么地方创建多大的一块存储空间。一个变量定义包括一个可选的类型( type )以及该类型的一个或多个变量名的列表，如下所示：  \n12345type variable_list;```  其中，type 是可以选择指定为 local 或者不指定使用默认值 global，variable_list 是包含一个或多个由逗号分隔的标识符名字。下面是合法变量定义的示例：  \nlocal    i, jlocal    ilocal    a,c\n12345local i,j 声明定义了两个变量 i 与 j；它命令解释器创建两个名称分别为 i,j 的变量，并且将其作用域限制在局部。  在声明变量的时候可以同时初始化变量（为变量赋初值）。在变量名后跟上等号和一个常量表达式就可以初始化变量。如下所示：  \ntype variable_list = value_list;\n123一些例子如下：  \nlocal d , f = 5 ,10 –声明局部变量 d，f。d , f = 5, 10;      –声明全局变量 d，f。d, f = 10           –[[声明全局变量 d，f，其中 f 的值是 nil–]]\n12345678910111213如果只是定义没有初始化，则静态存储变量被隐式初始化为 nil。  ## Lua 变量声明  正如在上面例子看到的那样，为多个变量赋值就是在变量列表后跟上值列表。例子 local d，f = 5，10 中,变量列表是 d，f，值列表是 5，10。  Lua 赋值时会将第一个值赋给第一个变量，第二个值赋给第二个变量，依次类推。所以，d 的值是 5,f 的值是 10。  ## 示例  下面的示例中，变量被声明在顶部，但是它们在主函数中定义和初始化:  \n– 变量定义:local a, b– 初始化a = 10b = 30print(“value of a:”, a)print(“value of b:”, b)– 交换变量的值b, a = a, bprint(“value of a:”, a)print(“value of b:”, b)f = 70.0/3.0print(“value of f”, f)\n123上面的代码被编译生成和执行后，会产生如下的结果：  \nvalue of a:    10value of b:    30value of a:    30value of b:    10value of f    23.333333333333\n12345678910## Lua 中的左值与右值  Lua　中有两种表达式：  &lt;ul&gt;\t&lt;li&gt;左值：引用内存位置的表达式被称之为左值表达式。左值表达式既可以出现在赋值符号的左边也可以出现在赋值符号的右边。&lt;/li&gt;\t&lt;li&gt;右值：术语“右值”指存在内存某个位置的数据值。我们不能为右值表达式赋值，也就是说右值表达式只可能出现在赋值符号的右边，而不可能出现在赋值符号的左边。&lt;/li&gt;&lt;/ul&gt;变量属于左值表达式，所以它可以现在赋值符号的左边。数值常量属于右值表达式，它不能被赋值也不能出现在赋值符号的左边。下面是合法的语句：  \ng = 20\n123但是，下面的语句是非法的，它会产生生成时错误：  \n10 = 20 \n123在 Lua 语言中，除了上面讲的这种赋值，还允许在一个赋值语句中存在多个左值表达式与多个右值表达式。如下所示：  \ng,l = 20,30\n\n在这个语句中，g 被赋值为 20，l 被赋值为 30。\n\n","slug":"old-lua/2016-06-01-variables","date":"2024-03-14T06:15:59.732Z","categories_index":"lua_guide,LUA教程","tags_index":"LUA教程","author_index":"安全书"},{"id":"7132dce4b61373adb37dd9650b6cc624","title":"Lua的while循环","content":"Lua while 循环在 Lua 语言中，只要 while 循环条件为真，while 语句就会一直执行，直到 while 循环条件为假为止。  \n语法Lua 语言中 while 循环的语法如下所示：  \n1234while(condition)do   statement(s)end\n\n其中，statement(s) 可能只是一条语句也可能是一个语句块。条件可以是任何表达式，若表达式结果为真，则循环继续。循环为假时，程序结束 while 循环，执行 while 后面的代码。  \n流程图  \n请注意，while 循环的关键点在于循环可能根本不会执行。当检测条件为假是，程序会跳过 while 循环体而直接执行 while 后的第一条语句。  \n示例123456a=10while( a &lt; 20 )do   print(&quot;value of a:&quot;, a)   a = a+1end\n\n执行上面的代码，将会得到如下的结果：  \n12345678910value of a:\t10value of a:\t11value of a:\t12value of a:\t13value of a:\t14value of a:\t15value of a:\t16value of a:\t17value of a:\t18value of a:\t19\n\n\n\n\n","slug":"old-lua/2016-06-01-while","date":"2024-03-14T06:15:59.732Z","categories_index":"lua_guide,LUA教程","tags_index":"LUA教程","author_index":"安全书"},{"id":"26bfa2ece82537ab5f6962e2d31968f1","title":"Lua中的for循环","content":"Lua 中的 for 循环for 循环控制结构可以让你高效地写出需要执行特定次数的循环代码。  \n语法Lua 语言中 for 循环的语法如下：  \n1234for init,max/min value, incrementdo   statement(s)end\n\n下面是 for 循环执行的流程：  \n\n    init 首先执行并且只执行一次。在这一步骤中，你需要声明并初始化循环控制变量。\n    \n    接下来，max/min 是循环结束的条件。程序中将 init 与 最大值或最小值进行比较，条件为真则继续执行循环，否则结束循环。\n    \n    循环体执行后，程序跳转至递增或递减语句( increment/descrement )。此语句中，我们可以更新我们的控制变量。\n    \n    再次检查条件。如果条件为真，则执行循环并重复过程（执行循环体，递增运算，再检查条件）。当条件为假时，结束循环。\n    \n\n\n流程图  \n示例1234for i=10,1,-1 do    print(i) end\n\n执行上面的代码后，将得到如下的输出结果：  \n1234567891010987654321\n","slug":"old-lua/2016-06-11-for","date":"2024-03-14T06:15:59.732Z","categories_index":"lua_guide,lua教程","tags_index":"LUA,abc,basic","author_index":"安全书"},{"id":"0498ed7eca93166bac9cec9951eb31df","title":"Lua元表","content":"Lua 元表正如其名，元表也是表。不过，将元表与表相关联后，我们就可以通过设置元表的键和相关方法来改变表的行为。元方法的功能十分强大，使用元方法可以实现很多的功能，比如：  \n\n    修改表的操作符功能或为操作符添加新功能（译注：如果您学过 C++ 之类的面向对象的语言，应该比较好理解，其实它实现的是操作的重载）。\n    使用元表中的 __index 方法，我们可以实现在表中查找键不存在时转而在元表中查找键值的功能。\n  \n\nLua 提供了两个十分重要的用来处理元表的方法，如下：  \n\n    setmetatable(table,metatable):此方法用于为一个表设置元表。\n    getmetatable(table)：此方法用于获取表的元表对象。\n  \n\n首先，让我们看一下如何将一个表设置为另一个表的元表。示例如下：  \n1234567mytable = &#123;&#125;mymetatable = &#123;&#125;setmetatable(mytable,mymetatable)```  上面的代码可以简写成如下的一行代码：  \nmytable = setmetatable({},{})\n12345## __index  下面的例子中，我们实现了在表中查找键不存在时转而在元表中查找该键的功能：  \nmytable = setmetatable({key1 = “value1”}, {  __index = function(mytable, key)    if key == “key2” then      return “metatablevalue”    else      return mytable[key]    end  end})\nprint(mytable.key1,mytable.key2)\n123运行上面的程序，我们可以得到如下的输出结果：  \nvalue1    metatablevalue\n1234567891011接下来逐步解释上面例子运行的过程：  &lt;ul&gt;\t&lt;li&gt;表 mytable 为 &#123;key = &quot;values1&quot;&#125;&lt;/li&gt;\t&lt;li&gt;为 mytable 设置了一个元表，该元表的键 __index 存储了一个函数，我们称这个函数为元方法。&lt;/li&gt;\t&lt;li&gt;这个元方法的工作也十分简单。它仅查找索引 “key2”,如果找到该索引值，则返回 &quot;metatablevalue&quot;,否则返回 mytable 中索引对应的值。&lt;/li&gt;&lt;/ul&gt;上面的程序同样可以简化成如下的形式：  \nmytable = setmetatable({key1 = “value1”}, { __index = { key2 = “metatablevalue” } })print(mytable.key1,mytable.key2)\n12345## __newindex  为元表添加 __newindex 后，当访问的键在表中不存在时，此时添加新键值对的行为将由此元方法（__newindex）定义。下面的例子中，如果访问的索引在表中不存在则在元表中新加该索引值（注意，是添加在另外一个表 mymetatable 中而非在原表 mytable 中。），具体代码如下(译注：请注意此处 __newindex 的值并非一个方法而是一个表。)：  \nmymetatable = {}mytable = setmetatable({key1 = “value1”}, { __newindex = mymetatable })\nprint(mytable.key1)\nmytable.newkey = “new value 2”print(mytable.newkey,mymetatable.newkey)\nmytable.key1 = “new  value 1”print(mytable.key1,mymetatable.newkey1)\n123执行上面的程序，我们可以得到如下的输出结果：  \nvalue1nil    new value 2new  value 1    nil\n1234可以看出，在上面的程序中，如果键存在于主表中，只会简单更新相应的键值。而如果键不在表中时，会在另外的表 mymetatable 中添加该键值对。  在接下来这个例子中，我们用 rawset 函数在相同的表（主表）中更新键值，而不再是将新的键添加到另外的表中。代码如下所示：  \nmytable = setmetatable({key1 = “value1”}, {  __newindex = function(mytable, key, value)        rawset(mytable, key, “&quot;“..value..”&quot;“)\n  end})\nmytable.key1 = “new value”mytable.key2 = 4\nprint(mytable.key1,mytable.key2)\n123执行上面的程序，我们可以得到如下的输出结果：  \nnew value    “4”\n1234567rawset 函数设置值时不会使用元表中的 __newindex 元方法。同样的，Lua 中也存的一个 rawget 方法，该方法访问表中键值时也不会调用 __index 的元方法。  ## 为表添加操作符行为  使用 + 操作符完成两个表组合的方法如下所示（译注：可以看出重载的意思了）：  \nmytable = setmetatable({ 1, 2, 3 }, {  __add = function(mytable, newtable)    for i = 1, table.maxn(newtable) do      table.insert(mytable, table.maxn(mytable)+1,newtable[i])    end    return mytable  end})\nsecondtable = {4,5,6}\nmytable = mytable + secondtablefor k,v in ipairs(mytable) doprint(k,v)end\n123执行上面的的程序，我们可以得到如下的输出结果：  \n1    12    23    34    45    56    6\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354元表中 __add 键用于修改加法操作符的行为。其它操作对应的元表中的键值如下表所示。  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;键&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__add&lt;/td&gt;\t\t&lt;td&gt;改变加法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__sub&lt;/td&gt;\t\t&lt;td&gt;改变减法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__mul&lt;/td&gt;\t\t&lt;td&gt;改变乘法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__div&lt;/td&gt;\t\t&lt;td&gt;改变除法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__mod&lt;/td&gt;\t\t&lt;td&gt;改变模除操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__unm&lt;/td&gt;\t\t&lt;td&gt;改变一元减操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__concat&lt;/td&gt;\t\t&lt;td&gt;改变连接操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__eq&lt;/td&gt;\t\t&lt;td&gt;改变等于操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__lt&lt;/td&gt;\t\t&lt;td&gt;改变小于操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__le&lt;/td&gt;\t\t&lt;td&gt;改变小于等于操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;  ## __call  使用 __call 可以使表具有像函数一样可调用的特性。下面的例子中涉及两个表，主表 mytable 和 传入的实参表结构 newtable，程序完成两个表中值的求和。\nmytable = setmetatable({10}, {  __call = function(mytable, newtable)    sum = 0    for i = 1, table.maxn(mytable) do        sum = sum + mytable[i]    end    for i = 1, table.maxn(newtable) do        sum = sum + newtable[i]    end    return sum  end})newtable = {10,20,30}print(mytable(newtable))\n123运行上面的代码，我们可以得到如下的输出结果：  \n70\n12345## __tostring  要改变 print 语句的行为，我们需要用到 __tostring 元方法。下面是一个简单的例子：  \nmytable = setmetatable({ 10, 20, 30 }, {  __tostring = function(mytable)    sum = 0    for k, v in pairs(mytable) do        sum = sum + v    end    return “The sum of values in the table is “ .. sum  end})print(mytable)\n123运行上面的代码，我们可以得到如下的输出结果：  \nThe sum of values in the table is 60\n```  \n如果你完全掌握了元表的用法，你就可以实现很多看上面很复杂的操作。如果不使用元表，就不仅仅是看上去很复杂了，而是真的非常复杂。所以，多做一些使用元表的练习，并熟练掌握所有元表的可选项，这会让你受益匪浅。\n","slug":"old-lua/2016-06-01-metatables","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"LUA教程","author_index":"安全书"},{"id":"795dd91f8815508a13e65b7151fdf68c","title":"Lua模块","content":"Lua 模块什么是模块？Lua 中的模块与库的概念相似，每个模块都有一个全局唯一名字，并且每个模块都包含一个表。使用一个模块时，可以使用 require 加载模块。模块中可以包括函数和变量，所有这些函数和变量被表存储于模块的表中。模块中的表的功能类似于命名空间，用于隔离不同模块中的相同的变量名。在使用模块的时候，我们应该遵守模块定义的规范，在 require 加载模块时返回模块中的包含函数和变量的表对象。  \nLua 模块的特别之处模块中表的使用使得我们可在绝大多数情况下可以像操作其它表一样操作模块。由于 Lua 语言允许对模块本身进行操作，所以 Lua 也就具备了许多其它语言需要特殊机制才能实现的特殊性质。例如，这种自由的表操作机制使得编程人员可以用多种方法调用模块中的函数。下面的例子演示了其中的一些方法：  \n1234567891011121314151617181920212223242526-- 假设我们有一个板块 printFormatter-- 该模块有一个函数 simpleFormat(arg)-- 方法 1require &quot;printFormatter&quot;printFormatter.simpleFormat(&quot;test&quot;)-- 方法 2local formatter = require &quot;printFormatter&quot;formatter.simpleFormat(&quot;test&quot;)-- 方法 3require &quot;printFormatter&quot;local formatterFunction = printFormatter.simpleFormatformatterFunction(&quot;test&quot;)```  从上面的例子中可以看出，Lua 不需要任何额外的代码就可以实现非常灵活的编程技巧。  ## require 函数  Lua 提供了一个高层次抽象的函数 require，使用这个函数可以加载所有需要的模块。在设计之初，这个函数就被设计的尽可能的简单，以避免加载模块时需要太多的模块信息。require 函数加载模块时把所有模块都只当作一段定义了变量的代码（事实上是一些函数或者包含函数的表）而已，完全不需要更多的模块信息。  ## 示例  让我们看一下面这个例子。在这个例子中，我们定义了模块 mymath,在这个模块中定义一些数学函数，并将该模块存储于 mymath.lua 文件中。具体内容如下：  \nlocal mymath =  {}function mymath.add(a,b)   print(a+b)end\nfunction mymath.sub(a,b)   print(a-b)end\nfunction mymath.mul(a,b)   print(a*b)end\nfunction mymath.div(a,b)   print(a/b)end\nreturn mymath\n123接下来，我们在另一个文件　moduletutorial.lua 文件中访问这个模块。具体代码如下所示：  \nmymathmodule = require(“mymath”)mymathmodule.add(10,20)mymathmodule.sub(30,20)mymathmodule.mul(10,20)mymathmodule.div(30,20)\n123运行这段代码这前，我们需要将两个 lua 源代码文件放在同一目录下，或者把模块代码文件放在包路径下（这种情况需要额外的配置）。运行上面的代码，可以得到如下的输出结果：  \n30102001.5\n12345678910111213## 注意事项  &lt;ul&gt;\t&lt;li&gt;把模块和待运行的文件放在相同的目录下。&lt;/li&gt;\t&lt;li&gt;模块的名称与文件名称相同。&lt;/li&gt;\t&lt;li&gt;为 require 函数返回模块（在模块中使用 return 命令返回存储了函数和变量的表）。尽管有其它的模块实现的方式，但是建议您使用上面的实现方法。&lt;/li&gt;&lt;/ul&gt;  ## 更老的实现模块的方法 下面，我们将用 package.seall 这种比较老的方法重新实现上面的例子。这种实现方法主要用于 Lua 5.1 或 5.2 版本。使用这种方式实现模块的代码如下所示：  \nmodule(“mymath”, package.seeall)\nfunction mymath.add(a,b)   print(a+b)end\nfunction mymath.sub(a,b)   print(a-b)end\nfunction mymath.mul(a,b)   print(a*b)end\nfunction mymath.div(a,b)   print(a/b)end\n123使用此模块的代码如下所示：  \nrequire(“mymath”)mymath.add(10,20)mymath.sub(30,20)mymath.mul(10,20)mymath.div(30,20)\n```  \n当我们运行这段代码，我们会得到与前面相同的输出结果。但是建议你不要使用这种方式，因为普遍认为这种方式不及新的方法安全。许多用到 Lua 语言的 SDK 都已经不再使用这种方式定义模块，例如, Corna SDK。\n","slug":"old-lua/2016-06-01-modules","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"5244c371e170ba321efd30c500d79562","title":"Lua中的嵌套 if 语句","content":"#Lua 中的嵌套 if 语句  \n在 Lua 语言中，你可以合法的嵌套使用 if-else 语句。这也就是说，你可以在一个 if 或 if-else 语句内再使用一个　if 或 if-else 语句。  \n##语法  \n嵌套 if 语句的语法规则如下：  \n1234567891011121314if( boolean_expression 1)then   --[ 如果布尔表达式 1 为真，则执行此处代码。 --]   if(boolean_expression 2)   then      --[ 如果布尔表达式 2 为真（注：布尔表达式 1 为真），则执行此处代码）。 --]   endend```  你也可以像嵌套使用 if 语句那样使用嵌套使用 else if...else 语句。  ##示例  \n–[ 定义局部变量 –]a = 100;b = 200;–[ 检查条件真假 –]if( a == 100 )then   –[ 如果前面的条件为真，再检查下面的条件。 –]   if( b == 200 )   then      –[ 如果条件为真，则输出如下内容 –]      print(“Value of a is 100 and b is 200” );   endendprint(“Exact value of a is :”, a );print(“Exact value of b is :”, b );\n123执行上面的代码，可以得到如下的输出结果：  \nValue of a is 100 and b is 200Exact value of a is :    100Exact value of b is :    200```\n","slug":"old-lua/2016-06-01-nested-if-statement","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"a1b21463fc87d45dd3b0b4f9d1ff1b21","title":"Lua面向对象","content":"Lua 面向对象面向对象概述面向对象编程技术是目前最常用的编程技术之一。目前大量的编程语言都支持面向对象的特性： \n\n    C++\n    Java\n    Objective-C\n    Smalltalk\n    C#\n    Ruby\n\n\n面向对象的特征\n    类（class）：类是可以创建对象，并为状态（成员变量）提供初值及行为实现的可扩展模板。\n    对象（objects）：对象是类的实例，每个对象都有独立的内存区域。\n    继承（inheritance）：继承用于描述一个类的变量和函数被另一个类继承的行为。\n    封装（encapsulation）：封装是指将数据和函数组织在一个类中。外部可以通过类的方法访问内中的数据。封装也被称之为数据抽象。\n\n## Lua 中的面向对象  \n\n在 Lua 中，我们可以使用表和函数实现面向对象。将函数和相关的数据放置于同一个表中就形成了一个对象。继承可以用元表实现，它提供了在父类中查找存在的方法和变量的机制。Lua 中的表拥有对象的特征，比如状态和独立于其值的标识。两个有相同值的对象（表）是两个不同的对象，但是一个对象在不同的时间可以拥有不同的值。与对象一样，表拥有独立于其创建者和创建位置的生命周期。  \n一个真实世界的例子面向对象已经是一个广泛使用的概念，但是你需要正确清楚地理解它。让我们看一个数学方面的例子。我们经常需要处理各种形状，比如圆、矩形、正方形。这些形状有一个共同的特征——面积。所以，所有其它的形状都可以从有一个公共特征——面积的基类扩展而来。每个对象都可以有它自己的特征和函数，比如矩阵有属性长、宽和面积，printArea 和 calculateArea 方法。  \n创建一个简单的类下面例子实现了矩阵类的三个属性：面积、长和宽。它还同时实现了输出面积的函数 printArea。  \n1234567891011121314151617181920212223242526272829303132-- 元类Rectangle = &#123;area = 0, length = 0, breadth = 0&#125;-- 继承类的方法 newfunction Rectangle:new (o,length,breadth)  o = o or &#123;&#125;  setmetatable(o, self)  self.__index = self  self.length = length or 0  self.breadth = breadth or 0  self.area = length*breadth;  return oend-- 继承类的方法 printAreafunction Rectangle:printArea ()  print(&quot;The area of Rectangle is &quot;,self.area)end```  ### 创建对象  创建对象即是为类的实例分配内存空间的过程。每个对象都有自己独立的内存区域，同时还会共享类的数据。  ```luar = Rectangle:new(nil,10,20)```  ### 访问属性我们可以使用点操作符访问类中属性。  \nprint(r.length)\n\n### 访问成员方法  \n\n使用冒号操作符可以访问对象的成员方法，如下所示：  \n\n```lua\nr:printArea()\n\n初始化阶段，调用函数为对象分配内存同时设置初值。这与其它与面向对象的语言中的构造器很相似。其实，构造器本身也就和上面的初始化代码一样，并没有什么特别之处。  \n完整的例子让我们一起看一个 Lua 实现面向对象的完整例子。  \n-- 元类\nShape = &#123;area = 0&#125;\n\n-- 基类方法 new\nfunction Shape:new (o,side)\n  o = o or &#123;&#125;\n  setmetatable(o, self)\n  self.__index = self\n  side = side or 0\n  self.area = side*side;\n  return o\nend\n\n-- 基类方法 printArea\nfunction Shape:printArea ()\n  print(&quot;The area is &quot;,self.area)\nend\n\n-- 创建对象\nmyshape = Shape:new(nil,10)\n\nmyshape:printArea()\n\n运行上面的程序，我们可以得到如下的输出结果：  \nThe area is     100\n\nLua 中的继承继承就是从基对象扩展的过程，正如从图形扩展至矩形、正方形等等。在现实世界中，常用来共享或扩展某些共同的属性和方法。让我们看一个简单的类扩展的例子。我们有如下的类：  \n -- 元类\nShape = &#123;area = 0&#125;\n-- 基类方法 new\nfunction Shape:new (o,side)\n  o = o or &#123;&#125;\n  setmetatable(o, self)\n  self.__index = self\n  side = side or 0\n  self.area = side*side;\n  return o\nend\n-- 基类方法 printArea\nfunction Shape:printArea ()\n  print(&quot;The area is &quot;,self.area)\nend\n\n我们从上面的类中扩展出正方形类，如下所示：  \nSquare = Shape:new()\n-- 继承类方法 new\nfunction Square:new (o,side)\n  o = o or Shape:new(o,side)\n  setmetatable(o, self)\n  self.__index = self\n  return o\nend\n\n重写基类的函数继承类可以重写基类的方法，从而根据自己的实际情况实现功能。示例代码如下所示：  \n-- 继承方法 printArea\nfunction Square:printArea ()\n  print(&quot;The area of square is &quot;,self.area)\nend\n\n继承的完整示例在元表的帮助下，我们可以使用新的 new 方法实现类的扩展（继承）。子类中保存了所有基类的成员变量和方法。  \n-- Meta class\nShape = &#123;area = 0&#125;\n-- Base class method new\nfunction Shape:new (o,side)\n  o = o or &#123;&#125;\n  setmetatable(o, self)\n  self.__index = self\n  side = side or 0\n  self.area = side*side;\n  return o\nend\n-- Base class method printArea\nfunction Shape:printArea ()\n  print(&quot;The area is &quot;,self.area)\nend\n\n-- Creating an object\nmyshape = Shape:new(nil,10)\nmyshape:printArea()\n\nSquare = Shape:new()\n-- Derived class method new\nfunction Square:new (o,side)\n  o = o or Shape:new(o,side)\n  setmetatable(o, self)\n  self.__index = self\n  return o\nend\n\n-- Derived class method printArea\nfunction Square:printArea ()\n  print(&quot;The area of square is &quot;,self.area)\nend\n\n-- Creating an object\nmysquare = Square:new(nil,10)\nmysquare:printArea()\n\nRectangle = Shape:new()\n-- Derived class method new\nfunction Rectangle:new (o,length,breadth)\n  o = o or Shape:new(o)\n  setmetatable(o, self)\n  self.__index = self\n  self.area = length * breadth\n  return o\nend\n\n-- Derived class method printArea\nfunction Rectangle:printArea ()\n  print(&quot;The area of Rectangle is &quot;,self.area)\nend\n\n-- Creating an object\nmyrectangle = Rectangle:new(nil,10,20)\nmyrectangle:printArea()\n\n运行上面的程序，我们可以得到如下的输出结果：  \nThe area is     100\nThe area of square is     100\nThe area of Rectangle is     200\n\n上面的例子中，我们继承基类 Shape 创建了两个子类 Rectange 与 Square。在子类中可以重写基类提供的方法。在这个例子中，子类重写了 printArea 方法。\n","slug":"old-lua/2016-06-01-object-oriented","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"690a2272c904046df2d9d8b8e3328a46","title":"Lua操作系统工具库","content":"Lua 操作系统工具库在很多应用中，我们都需要访问到操作系统级别的函数，操作系统库就给我们提供了这样的工具。下面的列表给出操作系统工具包提供的方法：  \n\n    \n        S.N.\n        函数与功能\n    \n    \n        1\n        os.clock()：以秒为单位返回程序运行所用 CPU 时间的近似值。\n    \n    \n        2\n        os.date([format[,time]])：返回时间字符串或包含时间的表，时间按指定格式格式化。\n    \n    \n        3\n        os.difftime(t2,t1)：返回从 t1 时刻至 t2 时刻经历的时间。在 POSIX，windows，及其它某些系统中，该值就是 t2-t1。\n    \n    \n        4\n        os.execute([command])：该函数等价于 ANSI C 中的 system 函数。传递的参数 command 由操作系统的 shell 执行。如果命令成功结束，则返回的第一个值为 true，否则为 nil。\n    \n    \n        5\n        os.exit([code[,close]])：调用 ANSI C 的 exit 函数，结束程序。如果 code 为　true, 则返回状态为 EXIT_SUCESS；若 code 为 false,则返回状态为 EXIT_FAILURE。如果 code 为数值，则返回状态也就为该数值。\n    \n    \n        6\n        os.getenv(varname)：返回进程的环境变量 varname 的值，如果此环境变量没有定义则返回 nil。\n    \n    \n        7\n        os.remove(filename)：删除文件（或 POSIX 系统中的空目录）。如果函数失败，则返回 nil 以及描述错误的字符串与错误代码。\n    \n    \n        8\n        os.rename(oldname,newname)：重命名文件或目录。如果函数失败，则返回 nil 以及描述错误的字符串与错误代码。\n    \n    \n        9\n        os.setlocale(locale[,category])：设置程序当前的地区（locale），locale 是一个与操作系统相关的字符串。category 是一个可选的字符串，描述设置更改的范围，包括: all，collate，ctype，monetary，numeric，time。默认为 all。函数返回新地区的名称，如果函数调用失败则返回 nil。\n    \n    \n        10\n        os.time([table])：无参数时，返回当前时间；传入参数时，则返回指定参数表示的日期和时间。传入的参数必须包含以下的域:年、月、日。时（默认 12）、分（默认 0）、秒（默认 0）、isdst（默认 nil） 四个域是可选的。\n    \n    \n        11\n        os.tmpname()：返回一个可作为临时文件名的字符串。这个临时文件必须显式地打开，使用结束时也必须显式地删除。\n    \n\n\n常用的 OS 函数示例如下：  \n12345678910111213141516171819-- 格式化日期io.write(&quot;The date is &quot;, os.date(&quot;%m/%d/%Y&quot;),&quot;\\n&quot;)-- 日期与时间io.write(&quot;The date and time is &quot;, os.date(),&quot;\\n&quot;)-- 时间io.write(&quot;The OS time is &quot;, os.time(),&quot;\\n&quot;)-- 等待一段时间for i=1,1000000 doend-- Lua 启动的时长io.write(&quot;Lua started before &quot;, os.clock(),&quot;\\n&quot;)```  执行上面的程序，我们可以得到如下的输出结果： \nThe date is 01/25/2014The date and time is 01/25/14 07:38:40The OS time is 1390615720Lua started before 0.013\n\n上面的例子只是简单的说明了一下操作系统相关函数的使用，实际开发过程中，可以根据实际情况使用所有函数。可以多做一些练习熟悉上面所列出的函数。\n\n","slug":"old-lua/2016-06-01-operating-system-facilities","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"67d9d5e60b37525bc4954f8a5bb0acb9","title":"操作符","content":"操作符操作符是用于告诉解释器执行特定的数学或逻辑运算的符号。Lua 语言有丰富的内置操作符，主要包括以下几类：  \n\n    算术运算操作符\n    关系运算操作符\n    逻辑运算操作符\n    其它操作符\n\n这篇教程将会依次介绍以上四类操作符。  \n\n算术去处操作符下面的表中列出了所有 Lua 语言支持的算术运算操作符。假设 A 变量的值为 10，B 变量的值为 20，则：  \n\n    \n        操作符\n        描述\n        示例\n    \n    \n        +\n        两个操作数据相加\n        A + B = 30\n    \n    \n        -\n        第一个操作数减去第二个操作数据\n        A - B = 10\n    \n    \n        *\n        两个操作数相乘\n        A * B = 200\n    \n    \n        %\n        模除操作符\n        A % B = 0\n    \n    \n        ^\n        幂运算符\n        A ^ 2 = 100\n    \n    \n        -\n        一元减操作符用于取反\n        -A = -10\n    \n\n\n关系运算符下面的表列出了 Lua 支持的所有关系运算符。假设 A 的值为 10，B 的值为 20，则：  \n\n    \n        操作符\n        描述\n        示例\n    \n    \n        ==\n        判断两个操作数是否相等，若相等则条件为真，否则为假。\n        (A == B) 为假。\n    \n    \n        ~=\n        判断两个操作数是否相等，若不相等则条件为真，否则为假。\n        (A ~= B) 为真。\n    \n    \n        >\n        如果左操作数大于右操作数则条件为真，否则条件为假。\n        (A > B) 为假。\n    \n    \n        \n        如果左操作数小于右操作数则条件为真，否则条件为假。\n        (A \n    \n    \n        >=\n        如果左操作数大于或等于右操作数则条件为真，否则条件为假。\n        (A >= B) 为假。\n    \n    \n        \n        如果左操作数小于或等于右操作数则条件为真，否则条件为假。\n        (A \n    \n    \n\n\n逻辑运算符下面的表列出了 Lua 支持的所有逻辑运算符。假设 A 的值为 真（非零），B 的值为 假（零），则： \n\n    \n        操作符\n        描述\n        示例\n    \n    \n        and\n        逻辑与运算符。如果两个操作数都非零，则条件为真。\n        (A and B) 为假。\n    \n    \n        or\n        逻辑或运算符。如果两个操作数中其中有一个非零，则条件为真。\n        (A or B) 为真。\n    \n    \n        not\n        逻辑非运算符。翻转操作数的逻辑状态。如果条件是真，则逻辑非运算符会将其变成假。\n        !(A and B) 为真。\n    \n\n\n其它操作符Lua 语言还支持另外两个操作符：\n\n    \n        操作符\n        描述\n        示例\n    \n    \n        ..\n        连接两个字符串。\n        若 a 为 \"Hello\"，b 为 \"World\",则 a..b 返回 \"Hello World\"。\n    \n    \n        #\n        一元运算符，返回字符串或者表的长度。\n        #\"Hello\" 返回 5。\n    \n\n\n\n操作符优先级操作符的优先级将决定表达式中的项如何组合。这会影响到表达式的求值。一些操作符比另外一些操作符有更高的优先级。例如，乘法操作符优先级比加法操作符更高。 \n例如 x = 7 +3*2，这里 x 的值为 13，而不是 20。这是因为操作符 * 优级级比操作符 + 优先级更高，所以先得到 3*2 的乘积，然后再加上 7。  \n下面的表中，从上到下优先级递减。在每个表达式中，高优先级操作数先运算。  \n\n    \n        分类\n        操作数\n        结合性\n    \n    \n        一元运算符类\n        not # -\n        从右至左\n    \n    \n        连接运算符\n        ..\n        从右至左\n    \n    \n        乘除运算符类\n        * / %\n        从左至右\n    \n    \n        加减运算符类\n        + - \n        从左至右\n    \n    \n        关系运算符类\n         = == ~=\n        从左至右\n    \n    \n        等于运算符类\n        == ~=\n        从左至右\n    \n    \n        逻辑与运算符\n        and\n        从左至右\n    \n    \n        逻辑或运算符\n        or\n        从左至右\n    \n\n","slug":"old-lua/2016-06-01-operators","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"2656993cf43ed1aa35c9954d6baa5550","title":"概述","content":"概述Lua 是用 C 语言开发的可扩展的轻量级编程语言。它起源于 1993 年由 Roberto lerusalimschy,Luiz Henrique de Figueiredo 与 Waddemar Celes 领导的一个内部项目。设计者的初衷是希望 Lua 可以成为一款整合 C 语言代码以及其它传统语言代码的软件。这种整合会带来很多好处，它让你不需要重复做 C 语言已经做的很好的工作，而专注于提供那些 C 语言不擅长的特性：提供更高的抽象（离硬件更远）、动态结构、无冗余、易于测试与调试。为了提供这些特性，Lua 提供了安全的环境、动态内存管理，以及擅长处理字符串和其它动态大小数据结构的工具。  \n特点Lua 有着许多自身的特点使得它与其它编程语言不同。主要包括：  \n\n可扩展性  \n简单  \n高效  \n跨平台  \n自由与开放  \n  \n\n示例代码print(&quot;Hello World!&quot;)\n\nLua 是如何实现的Lua 主要包括两个部分：Lua 解释器部分以及运行软件系统。  运行软件系统是真正解释执行由 Lua 语言编写的程序的应用程序（译注：此处 Lua 翻译器部分用于将 Lua　代码编译成中间字节码，运行软件系统指 Lua 虚拟机，而一般我们所说 Lua 解释器包括这两部分）。 Lua 解释器是由 ANSI C 编写的，因此它有很好的可移植性，可以运行各种各运的设备上，无论是大型网络服务器还是小型移动设备。  \n无论 Lua 语言还是 Lua 解释器都已经是非常成熟的、同时还兼备体积小，运行速度非常快的特点。小体积的特性也使得 Lua 可以运行在很多只有少量内存的小型设备中。\n学习 Lua学习 Lua 语言最重要的一点是把注意力放在它的概念上，千万不要迷失在语言的技术细节中。学习 Lua 的目的是成为一个更好的程序人员。也就是说，学习 Lua 可以帮助您在设计与实现新系统，或者维护旧系统的时候变得更加的高效。  \nLua 的应用场景\n游戏开发  \n开发单机应用  \n网站开发  \n扩展数据库或者为数据库开发插件，比如，MySQL 代理或 MySQL WorkBench  \n开发安全系统，如入侵检测系统（IDS）  \n  \n\n","slug":"old-lua/2016-06-01-overview","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"17f717e08ff041fef49c1fa8a71c5669","title":"repeat...until 循环","content":"#repeat…until 循环  \n与 for 和 while 循环中先检测条件再决定是否执行循环不同，repeat…until 先执行循环再检测条件判断是否再次执行。除了 repeat…until 循环一定会执行一次之外，repeat…until 与 while 循环很相似。  \n##语法  \nLua 语言中 repeat…until 循环的语法如下：  \n123456789101112repeat   statement(s)until( condition )```  请注意，条件表达式出现在循环的结束处，所以在检查条件之前，循环体中语句 statement(s) 已经执行了一次。  如果条件为假，则控制回到循环开始再次执行循环体。这个过程一直重复到条件为真时结束。##流程图  ![](images/repeat_until_loop.jpg)##示例  \n–[ 局部变量定义 –]local a = 10–[ 重复循环执行 –]repeat   print(“value of a:”, a)   a = a + 1until( a &gt; 15 )\n12执行上面的代码，将会得到如下的结果：  \nvalue of a:    10value of a:    11value of a:    12value of a:    13value of a:    14value of a:    15\n\n\n","slug":"old-lua/2016-06-01-repeat-until","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"fa374b256846497ad36372533ba9888a","title":"Lua标准库","content":"Lua 标准库Lua 标准库利用 C 语言 API 实现并提供了丰富的函数，它们内置于 Lua 语言中。该标准库不仅可以提供 Lua 语言内服务，还能提供外部服务，比如文件或数据库的操作。  \n这些标准库使用标准的 C API 接口实现，它们作为独立的 C 语言模块提供给使用者。主要包括以下的内容：\n\n    基本库，包括协程子库\n    模块库\n    字符串操作\n    表操作\n    数学计算库\n    文件输入与输出\n    操作系统工具库\n    调试工具库\n\n\n基本库在本教程中，我们已经在很多地方都使用了基本库的内容。下面的表中列出了相关的函数与链接。  \n\n    \n        S.N.\n        库或者方法\n    \n    \n        1\n        错误处理库，包括错误处理函数，比如 assert，error等，详见错误处理。\n    \n    \n        2\n        内存管理，包括与垃圾回收相关的自动内存管理的内容，详见垃圾回收。\n    \n    \n        3\n        dofile([filename])，打开指定文件，并将文件内容作为代码执行。如果没有传入参数，则函数执行标准输入的内容。错误会传递至函数调用者。\n    \n    \n        4\n        _G，全局变量，它存储全局的环境。Lua 本身不使用此变量。\n    \n    \n        5\n        getfenv([f])，返回指定函数使用的当前环境（作用域），可以通过函数名或栈深度值指定函数。 1 表示调用 getfenv 的函数。如果传入的参数不是函数或者 f 为 0,则返回全局环境。f 的默认值为 1。\n    \n    \n        6\n        getmetatable(object)：如果对象没有元表，则返回 nil。如果对象的元表有 __metable 域，则返回该值；否则返回对象的元表。\n    \n    \n        7\n        ipairs(t)，用于遍历表，此函数返回三个值：next 函数，表 t, 以及 0。\n    \n    \n        8\n        load(func[,chunkname])，使用函数 func 加载一个块（代码块），每次调用func必须返回与先前的结果连接后的字符串\n    \n    \n        9\n        loadfile([filename]),与 load 函数相似，此函数从文件中或标准输入（没指定文件名时）读入代码块。\n    \n    \n        10\n        loadstring(string,[,chunkname])，与 load 类似，从指定字符串中获得代码块。\n    \n    \n        11\n        next(table[,index])，此函数用于遍历表结构。第一参数为表，第二个参数是一个索引值。返回值为指定索引的下一个索引与相关的值。\n    \n    \n        12\n        pairs(t),用于遍历表，此函数返回三个值：next 函数，表 t, 以及 nil。\n    \n    \n        13\n        print(...)，打印输出传入参数。\n    \n    \n        14\n        rawequal(v1,v2)，判断 v1 与 v2 是否相等，不会调用任何元方法。返回布尔值。\n    \n    \n        15\n        rawget(table,index)，返回 table[index]，不会调用元方法。table 必须是表，索引可以是任何值。\n    \n    \n        16\n        rawset(table,index,value)，等价于 table[index] = value，但是不会调用元方法。函数返回表。\n    \n    \n        17\n        select(index,...)，如果 index 为数字n,那么 select 返回它的第 n 个可变实参，否则只能为字符串 \"#\",这样select会返回变长参数的总数。\n    \n    \n        18\n        setfenv(f,table)，设置指定函数的作用域。可以通过函数名或栈深度值指定函数。 1 表示调用 setfenv 的函数。返回值为指定函数。特别地，如果 f 为 0，则改变当前线程的运行环境，这时候函数无返回值。\n    \n    \n        19\n        setmetatable(table,metatable)，设置指定表的元表（不能从 Lua 中改变其它类型的元表，其它类型的元表只能从 C 语言中修改）。如果 metatable 为 nil，则删除表的元表；如果原来的元表有 __metatable 域，则出错。函数返回 table。 \n    \n    \n        20\n        tonumber(e[,base])，将参数转换为数值。如果参数本身已经是数值或者是可以转换为数值的字符串，则 tonumber 返回数值，否则返回 nil。\n    \n    \n        21\n        tostring(e)，将传递的实参以合理的格式转换为字符串。精确控制字符串的转换可以使用 string.format 函数。\n    \n    \n        22\n        type(v)，以字符串的形式返回输入参数的类型。该函数的返回值可以取字符串：nil，number，string，boolean，table，function，thread，userdata。\n    \n    \n        23\n        unpack(list[,i[,j]])，从指定的表中返回元素。\n    \n    \n        24\n        _VERSION，存储当前解释器版本信息的全局变量。该变量当前存储的内容为：Lua 5.1。（译注：与解释器版本有关）\n    \n    \n        25\n        协程库，包括协程相关的函数，详见协程\n    \n\n\n模块库模块库提供了加载模块的基本函数。它在全局作用域内提供了 require 函数。其它的函数都是通过包管理的模块库提供的。详细内容请参见模块。\n字符串操作库详细内容请参见字符串。\n表操作库详细内容请参见表。\n数学函数库详细内容请参见数学函数库。 \n文件 IO 库详细内容请参见文件 IO。 \n操作系统工具库详细内容请参见操作系统工具库。 \n调试工具库详细内容请参见调试。 \n","slug":"old-lua/2016-06-01-standard-libraries1","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"cce4b5e763b43300a4fad206fcb6b9e4","title":"Lua循环嵌套","content":"#Lua 循环嵌套  \nLua 编程语言允许使用循环嵌套。接下来这一节中将用例子来说嵌套循环的使用方法：  \n##语法  \nfor 循环嵌套的语法如下：  \n1234567891011for init,max/min value, incrementdo   for init,max/min value, increment   do      statement(s)   end   statement(s)end```  while 循环嵌套的语法如下：  \nwhile(condition)do   while(condition)   do      statement(s)   end   statement(s)end\n123repeat...until  循环嵌套的语法如下：  \nrepeat   statement(s)   repeat      statement(s)   until( condition )until( condition )\n1234567需要注意的是，在任何外层循环类型内可以使用任何内层循环类型。  ##示例  下面的例子中使用了嵌套循环：  \nj =2for i=2,10 do   for j=2,(i/j) , 2 do      if(not(i%j))      then         break      end      if(j &gt; (i/j))then         print(“Value of i is”,i)      end   endend\n123运行上面的代码，可以得到如下的输出结果：　　\nValue of i is    8Value of i is    9Value of i is    10\n\n\n","slug":"old-lua/2016-06-01-nested-loop","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"cedbdf206a63ba0896535fb39f386996","title":"Lua字符串","content":"Lua 字符串字符串就是一个由字符或控制字符组成的序列。字符串可以用以下三种方式任意一种进行初始化。\n\n    单引号字符串\n    双引号字符串\n    [[和]]之间的字符串\n  \n\n上面三种初始化方式的示例如下：  \n1234567891011string1 = &quot;Lua&quot;print(&quot;\\&quot;String 1 is\\&quot;&quot;,string1)string2 = &#x27;Tutorial&#x27;print(&quot;String 2 is&quot;,string2)string3 = [[&quot;Lua Tutorial&quot;]]print(&quot;String 3 is&quot;,string3)```  运行上面的程序，我们可以得到如下的输出结果：  \n“String 1” is    LuaString 2 is    TutorialString 3 is    “Lua Tutorial”\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115字符串中转义字符用于改变字符的一般正常的解释。在上面的例子中，输出双引号（&quot;&quot;）的时候，我们使用的是 \\&quot;。下表列出了转义序列及相应的使用方法：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;转义序列&lt;/th&gt;\t\t&lt;th&gt;用法&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\a&lt;/td&gt;\t\t&lt;td&gt;响铃&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\b&lt;/td&gt;\t\t&lt;td&gt;退格&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\f&lt;/td&gt;\t\t&lt;td&gt;换页&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\n&lt;/td&gt;\t\t&lt;td&gt;换行&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\r&lt;/td&gt;\t\t&lt;td&gt;回车&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\t&lt;/td&gt;\t\t&lt;td&gt;制表符&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\v&lt;/td&gt;\t\t&lt;td&gt;垂直制表符&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\\\&lt;/td&gt;\t\t&lt;td&gt;反斜线&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\&quot;&lt;/td&gt;\t\t&lt;td&gt;双引号&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\&#x27;&lt;/td&gt;\t\t&lt;td&gt;单引号&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\[&lt;/td&gt;\t\t&lt;td&gt;左方括号&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\]&lt;/td&gt;\t\t&lt;td&gt;右方括号&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;## 字符串操作  Lua 支持如下的字符串操作方法：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;S.N.&lt;/th&gt;\t\t&lt;th&gt;函数及其功能&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;1&lt;/td&gt;\t\t&lt;td&gt;string.upper(argument):将输入参数全部字符转换为大写并返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;2&lt;/td&gt;\t\t&lt;td&gt;string.lower(argument):将输入参数全部字符转换为小写并返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;3&lt;/td&gt;\t\t&lt;td&gt;string.gsub(maingString,findString,replaceString):将 mainString 中的所有 findString 用 replaceString 替换并返回结果。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;4&lt;/td&gt;\t\t&lt;td&gt;string.strfind(mainString,findString,optionalStartIndex,optionalEndIndex):在主字符串中查找 findString 并返回 findString 在主字符串中的开始和结束位置，若查找失败则返回 nil。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;5&lt;/td&gt;\t\t&lt;td&gt;string.reverse(arg):将输入字符串颠倒并返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;6&lt;/td&gt;\t\t&lt;td&gt;string.format(...):返回格式化后的字符串。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;7&lt;/td&gt;\t\t&lt;td&gt;string.char(arg) 和 string.byte(arg):前者返回输出参数的所代表的字符，后者返回输入参数（字符）的数值。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;8&lt;/td&gt;\t\t&lt;td&gt;string.len(arg):返回输入字符串的长度。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;9&lt;/td&gt;\t\t&lt;td&gt;string.rep(string,n): 将输入字符串 string 重复 n　次后的新字符串返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;10&lt;/td&gt;\t\t&lt;td&gt;..:连接两个字符串。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;接下来我们用一些例子来讲解如何使用上面这些函数。  ## 大小写操作函数  下面的代码将字符串中字符全部转换成大写或小写：  \nstring1 = “Lua”;print(string.upper(string1))print(string.lower(string1))\n123执行上面的代码可以得到如下的输出结果：  \nLUAlua\n12345## 替换子串  用一个字符串替换字符串的某子串的示例代码如下：  \nstring = “Lua Tutorial”– 替换字符串newstring = string.gsub(string,”Tutorial”,”Language”)print(“The new string is”,newstring)\n123执行上面的代码可以得到如下的输出结果：  \nThe new string is    Lua Language\n12345## 查找与颠倒  查找一个子串的索引与颠倒一个字符串函数的示例代码如下所示：  \nstring = “Lua Tutorial”– 替换字符串print(string.find(string,”Tutorial”))reversedString = string.reverse(string)print(“The new string is”,reversedString)\n123执行上面的代码可以得到如下的输出结果：  \n5    12The new string is    lairotuT auL\n12345## 格式化字符串  在编程过程中，我们经常需要将字符串以某种格式输出。此时，你就可以使用 string.format 函数格式化你的输出内容。如下所示：  \nstring1 = “Lua”string2 = “Tutorial”number1 = 10number2 = 20– 基本字符串格式print(string.format(“Basic formatting %s %s”,string1,string2))– 日期格式化date = 2; month = 1; year = 2014print(string.format(“Date formatting %02d/%02d/%03d”, date, month, year))– 符点数格式化print(string.format(“%.4f”,1/3))\n123执行上面的代码可以得到如下的输出结果：  \nBasic formatting Lua TutorialDate formatting 02/01/20140.3333\n12345## 字符与字节表示  字节表示函数用于将字符的内部表示转换为字符表示，而字符表示函数正好相反。 示例代码如下：  \n– 字节转换– 第一个字符print(string.byte(“Lua”))– 第三个字符print(string.byte(“Lua”,3))– 倒数第一个字符print(string.byte(“Lua”,-1))– 第二个字符print(string.byte(“Lua”,2))– 倒数第二个字符print(string.byte(“Lua”,-2))\n– 内部 ASCII 字值转换为字符print(string.char(97))\n123执行上面的代码可以得到如下的输出结果：  \n769797117117a\n12345## 其它常用函数  其它常用的字符串处理函数包括字符串连接，字符串长度函数以及重复字符串多次的函数。它们的使用方法示例如下：  \nstring1 = “Lua”string2 = “Tutorial”– 用 .. 连接两个字符串print(“Concatenated string”,string1..string2)\n– 字符串的长度print(“Length of string1 is “,string.len(string1))\n– 重复字符串repeatedString = string.rep(string1,3)print(repeatedString)\n123执行上面的代码可以得到如下的输出结果：  \nConcatenated string    LuaTutorialLength of string1 is     3LuaLuaLua``` \n","slug":"old-lua/2016-06-01-strings","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"038bf88a1c7598385fc79ad2a48f60ba","title":"Lua表","content":"Lua 表在 Lua 语言中，表是唯一可以用来创建不同数据类型的数据结构，比如常见的数组和字典都是用表来创建的。 Lua 语言中经常到关联数组这种数据类型，它不仅可以用数值作为索引值，除了 nil 以外的字符串同样可以作为其索引。表没有固定的大小，当数据量增加时表会自动增大。  \nLua 语言中的各种结构表示都用到了表，包括包（package）的表示。当我们使用方法 string.format 时，我们用到的其实是包 string 中的方法 format。  \n使用表表被称之为对象，它既不是值也不是变量。Lua 用构造表达式 {} 创建一个空表。需要注意的是，在存储表的变量和表本身之间没有什么固定的对应关系（译注：一个表可以被不同的变量引用，一个变量也可以随时改变其所引用的表对象）。  \n123456789101112131415--简单的表初始化mytable = &#123;&#125;--简单的表赋值mytable[1]= &quot;Lua&quot;--移除引用mytable = nil-- lua 的垃圾回收机制负责回收内存空间```  当我们有一个拥有一系列元素的表时，如果我们将其赋值给 b。那么 a 和 b 都会引用同一个表对象(a 先引用该表)，指向相同的内存空间。而不会再单独为 b 分配内存空间。即使给变量 a 赋值 nil，我们仍然可以用变量 b 访问表本身。如果已经没有变量引用表时，Lua　语言垃圾回收机制负责回收不再使用的内存以被重复使用。  下面的示例代码使用到了上面提到的表的特性。　　\n– 声明空表mytable = {}print(“Type of mytable is “,type(mytable))\nmytable[1]= “Lua”mytable[“wow”] = “Tutorial”print(“mytable Element at index 1 is “, mytable[1])print(“mytable Element at index wow is “, mytable[“wow”])\n– alternatetable 与 mytable 引用相同的表alternatetable = mytable\nprint(“alternatetable Element at index 1 is “, alternatetable[1])print(“mytable Element at index wow is “, alternatetable[“wow”])\nalternatetable[“wow”] = “I changed it”\nprint(“mytable Element at index wow is “, mytable[“wow”])\n– 只是变量被释放，表本身没有被释放alternatetable = nilprint(“alternatetable is “, alternatetable)\n– mytable 仍然可以访问print(“mytable Element at index wow is “, mytable[“wow”])\nmytable = nilprint(“mytable is “, mytable)\n123执行上面的代码，我们可以得到如下的输出结果：  \nType of mytable is     tablemytable Element at index 1 is     Luamytable Element at index wow is     Tutorialalternatetable Element at index 1 is     Luamytable Element at index wow is     Tutorialmytable Element at index wow is     I changed italternatetable is     nilmytable Element at index wow is     I changed itmytable is     nil\n12345678910111213141516171819202122232425262728293031323334353637## 表的操作函数  下面的表中列出了 Lua 语言内置的表操作函数，具体内容如下所示：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;S.N.&lt;/th&gt;\t\t&lt;th&gt;方法与作用&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;1&lt;/td&gt;\t\t&lt;td&gt;table.concat(table[, sep [, i[,j]]]): 根据指定的参数合并表中的字符串。具体用法参考下面的示例。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;2&lt;/td&gt;\t\t&lt;td&gt;table.insert(table,[pos,]value):在表中指定位置插入一个值。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;3&lt;/td&gt;\t\t&lt;td&gt;table.maxn(table)：返回表中最大的数值索引。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;4&lt;/td&gt;\t\t&lt;td&gt;table.remove(table[,pos]):从表中移出指定的值。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;5&lt;/td&gt;\t\t&lt;td&gt;table.sort(table[,comp]):根据指定的（可选）比较方法对表进行排序操作。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;  让我们一起看一些上述函数使用的例子。  ### 表连接操作  我们可以使用表连接操作连接表中的元素，如下所示。  \nfruits = {“banana”,”orange”,”apple”}– 返回表中字符串连接后的结果print(“Concatenated string “,table.concat(fruits))\n–用字符串连接print(“Concatenated string “,table.concat(fruits,”, “))\n–基于索引连接 fruitsprint(“Concatenated string “,table.concat(fruits,”, “, 2,3))\n123执行上面的代码，我们可以得到如下的输出结果：  \nConcatenated string     bananaorangeappleConcatenated string     banana, orange, appleConcatenated string     orange, apple\n12345### 插入与移出操作  插入和移除表中元素是对表最常见的操作。使用方法如下所示：  \nfruits = {“banana”,”orange”,”apple”}\n– 在 fruits 的末尾插入一种水果table.insert(fruits,”mango”)print(“Fruit at index 4 is “,fruits[4])\n– 在索引 2 的位置插入一种水果table.insert(fruits,2,”grapes”)print(“Fruit at index 2 is “,fruits[2])\nprint(“The maximum elements in table is”,table.maxn(fruits))\nprint(“The last element is”,fruits[5])table.remove(fruits)print(“The previous last element is”,fruits[5])\n123执行上面的代码，我们可以得到如下的输出结果：  \nFruit at index 4 is     mangoFruit at index 2 is     grapesThe maximum elements in table is    5The last element is    mangoThe previous last element is    nil\n12345### 表排序操作  在程序开发过程中，常常有对表排序的需求。 sort 函数默认使用字母表对表中的元素进行排序（可以通过提供比较函数改变排序策略）。示例代码如下：  \nfruits = {“banana”,”orange”,”apple”,”grapes”}for k,v in ipairs(fruits) doprint(k,v)endtable.sort(fruits)print(“sorted table”)for k,v in ipairs(fruits) doprint(k,v)end\n123执行上面的代码，我们可以得到如下的输出结果：  \n1    banana2    orange3    apple4    grapessorted table1    apple2    banana3    grapes4    orange```  \n","slug":"old-lua/2016-06-01-tables","date":"2024-03-14T06:15:59.731Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"1c92a7bccc4e1c860aee5220573c9c25","title":"Lua运行环境","content":"Lua 运行环境本地环境搭建在本地搭建 Lua 编程语言的开发运行环境，你需要在你的计算机上安装如下三个软件：(1) 文本编辑器。(2)  Lua 解释器。（3）Lua 编译器。  \n文本编辑器文本编辑器用来编辑你的程序代码。有如下几款常用的文本编辑器软件：Windows notepad、Brief、Epsilon、EMACS、vim/vi。\n在不同的操作系统中有各自不同的编辑器，而且编辑器的版本不一样。例如，Notepad 主要用在 Windows 系统中，vim/vi 不仅可以用于 Windows 系统也可以用于 Linux 和 UNIX 操作系统。 \n用文本编辑器编辑的文件被称为源文件。源文件中包含程序的源代码。Lua 程序的源文件经常以 .lua　作为其后缀名。\n开始编写程序之前，请确保您已经安装好一个文本编辑软件，并且曾经有过写代码，将其存入文件，生成并执行的经验。  \nLua 解释器Lua 解释器是一个能让您输入 Lua　命令并立即执行的小程序。它在执行一个　Lua 文件过程中，一旦遇到错误就立即停止执行，而不像编译器会执行完整个文件。  \nLua 编译器如果将 Lua 扩展到其它语言或者应用中时，我们需要一个软件开发工具箱以及 Lua 应用程序接口兼容的编译器。  \n在 Windows 系统安装 Lua在 Windows 系统环境可以安装一个叫 SciTE 的 Lua 开发 IDE (集成开发环境)。它可以在这儿下载：http://code.google.com/p/luaforwindows。\n运行下载的可执行程序就可安装 Lua 语言的 IDE 了。  \n在这个 IDE 上，你可以创建并生成 Lua 代码。\n如果你希望在命令行模式下安装 Lua，你则需要安装 MinGW 或者 Cygwin，然后在 Ｗindows 系统中编译安装 Lua。  \n在 Linux 系统安装 Lua使用下面的命令下载并生成 Lua 程序：\n12345678910$ wget http://www.lua.org/ftp/lua-5.2.3.tar.gz$ tar zxf lua-5.2.3.tar.gz$ cd lua-5.2.3$ make linux test```  在其它系统上安装 Lua 时，比如 aix，ansi，bsd，generic，linux，mingw，posix，solaris，你需要将 make linux test 命令中的 linux 替换为相应的系统平台名称。 假设我们已经有一个文件 helloWord.lua ，文件内容如下：   \nprint(“Hello World!”)\n123我们先使用 cd 命令切换至 helloWord.lua　文件所在的目录，然后生成并运行该文件：　　\n$ lua helloWorld\n123执行上面的命令，我们可以看到如下的输出：  \nhello world\n12345## 在 Mac OS X 系统安装 Lua  使用下面的命令可以在 Mac OS X 系统生成并测试 Lua：  \n$ curl -R -O http://www.lua.org/ftp/lua-5.2.3.tar.gz$ tar zxf lua-5.2.3.tar.gz$ cd lua-5.2.3$ make macosx test\n123456如果你没有安装 Xcode 和命令行工具，那么你就不能使用 make 命令。你先需要从 mac 应用商店安装 Xcode，然后在 Xcode 首选项的下载选项中安装命令行工具组件。完成上面的步骤后，你就可以使用 make 命令了。  make macosx test 命令并不是非执行不可的。即使你没有执行这个命令，你仍可以在你的 Mac OS X 系统中使用 Lua。  假设我们已经有一个文件 helloWord.lua ，文件内容如下：  \nprint(“Hello World!”)\n123我们先使用 cd 命令切换至 helloWord.lua　文件所在的目录，然后生成并运行该文件：　　\n$ lua helloWorld\n123执行上面的命令，我们可以看到如下的输出：  \nhello world\n```  \nLua IDE正如前面提到的那样，Windows 系统中 SciTE 是 Lua 创始团队提供的默认的 Lua 集成开发环境（IDE)。 此外，还有一款名叫 ZeroBrane 的 IDE。 它具有跨平台的特性，支持 Windows、Mac 与 Linux。同时，许多 eclipse 插件使得 eclipse 能成为 Lua 的 IDE。IDE 中像代码自动补全等诸多特性使得开发变得简单了很多，因此建议你使用 IDE 开发 Lua 程序。同样，IDE 也能像 Lua 命令行版本那样提供交互式编程功能。\n","slug":"old-lua/2016-06-01-environment","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"8fa5391aad4ba0aa8b3b2333eb0ffb7d","title":"Lua错误处理","content":"Lua 错误处理为什么需要错误处理机制在真实的系统中程序往往非常复杂，它们经常涉及到文件操作、数据库事务操作或网络服务调用等，这个时候错误处理就显得非常重要。不关注错误处理可能在处理诸如涉密或金融交易这些业务时造成重大的损失。无论什么时候，程序开发都要求小心地做好错误处理工作。在 Lua 中错误可以被分为两类：  \n\n    语法错误\n    运行时错误\n\n\n语法错误语法错误是由于不正确的使用各种程序语法造成的，比如错误的使用操作符或表达式。下面即是一个语法错误的例子：  \n12345a == 2```  正如你知道的那样，单个等号与双等号是完全不一样的。二者之间随意的替换就导致语法错误。一个等号表示的是赋值，而双等号表示比较。类似地，下面这一小段代码中也存在语法错误：  \nfor a= 1,10   print(a)end\n123执行上面的这段程序，我们会得到如下的输出结果：  \nlua: test2.lua:2: ‘do’ expected near ‘print’\n1234567语法错误相比于运行时错误更容易处理，因为 Lua 解释器可以更精确的定位到语法错误的位置。由上面的错误，我们可以容易就知道，在 print 语句前添加 do 语句就可以了，这是 Lua 语法结构所要求的。  ## 运行时错误  对于运行时错误，虽然程序也能成功运行，但是程序运行过程中可能因为错误的输入或者错误的使用函数而导致运行过程中产生错误。下面的例子显示了运行时错误如何产生的：  \nfunction add(a,b)   return a+bend\nadd(10)\n123当我们尝试生成(build)上面的程序，程序可以正常的生成和运行。但是一旦运行后，立马出现下面的运行时错误。  \nlua: test2.lua:2: attempt to perform arithmetic on local ‘b’ (a nil value)stack traceback:    test2.lua:2: in function ‘add’    test2.lua:5: in main chunk    [C]: ?\n1234567这个运行时错误是由于没有正确的为 add 函数传入参数导致的，由于没有为 b 传入值，所有 b 的值为 nil 从而导致在进行加法运算时出错。  ## Assert and Error 函数  我们经常用到 assert 和 error 两个函数处理错误。下面是一个简单的例子。  \nlocal function add(a,b)   assert(type(a) == “number”, “a is not a number”)   assert(type(b) == “number”, “b is not a number”)   return a+bendadd(10)\n123执行上面的程序，我们会得到如下的输出结果：  \nlua: test2.lua:3: b is not a numberstack traceback:    [C]: in function ‘assert’    test2.lua:3: in function ‘add’    test2.lua:6: in main chunk    [C]: ?\n12345678error(message [,level]) 函数会结束调用自己的函数，并将 message 作为错误信息返回调用者(译注:保护模式下才会返回调用者，一般情况会结束程序运行并在控制终端输出错误信息)。error 函数本身从不返回。一般地，error 函数会在消息前附上错误位置信息。级别(level) 参数指定错误发生的位置。若其值为 1(默认值)，返回的错误的位置是 error 函数被调用的位置。若为 2, 返回的错误位置为调用 error 函数的函数被调用的位置，依次类推。将 level 参数的值设为 0 就不再需要在消息前增加额外的位置信息了。  ## pcall 与 xpcall　　在 Lua 中，为了避免使用抛出错误和处理错误，我们需要用到 pcall 和 xpcall 函数来处理异常。  使用 pcall(f,arg1,...) 函数可以使用保护模式调用一个函数。如果函数 f 中发生了错误， 它并不会抛出一个错误，而是返回错误的状态。使用的 pcall 函数的方法如下所示：  \nfunction myfunction ()   n = n/nilend\nif pcall(myfunction) then   print(“Success”)else    print(“Failure”)end\n123执行上面的程序，我们可以得到如下的输出结果：  \nFailure\n123xpcall(f,err) 函数调用函数 f 同时为其设置了错误处理方法 err，并返回调用函数的状态。任何发生在函数 f 中的错误都不会传播，而是由 xpcall 函数捕获错误并调用错误处理函数 err，传入的参数即是错误对象本身。xpcall 的使用示例如下：  \nfunction myfunction ()   n = n/nilend\nfunction myerrorhandler( err )   print( “ERROR:”, err )end\nstatus = xpcall( myfunction, myerrorhandler )print( status)\n123执行上面的程序，我们可以得到如下的输出结果：  \nERROR:    test2.lua:2: attempt to perform arithmetic on global ‘n’ (a nil value)false\n\n作为程序开发人员，在程序中正确合理地处理错误是非常重要的。正确地处理错误可以保证发生意外情况不会影响到程序用户的使用。\n\n","slug":"old-lua/2016-06-01-error-handling","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"7cdf9755b9d268215aaceca81f7a3596","title":"Lua文件I/O","content":"Lua 文件 I/OLua 的 IO 库用于读取或操作文件。Lua IO 库提供两类文件操作，它们分别是隐式文件描述符(implict file descriptors)和显式文件描述符(explicit file descriptors)。\n在接下来的例子的，我们会用到一个示例文件 test.lua，文件内容如下：  \n123456-- sample test.lua-- sample2 test.lua```  简单的打开文件操作可以用如下的语句完成。  \nfile = io.open (filename [, mode])\n1234567891011121314151617181920212223242526272829303132333435363738可选的打开文件的模式如下表所示。  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;模式&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;r&quot;&lt;/td&gt;\t\t&lt;td&gt;只读模式，这也是对已存在的文件的默认打开模式。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;w&quot;&lt;/td&gt;\t\t&lt;td&gt;可写模式，允许修改已经存在的文件和创建新文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;a&quot;&lt;/td&gt;\t\t&lt;td&gt;追加模式，对于已存的文件允许追加新内容，但不允许修改原有内容，同时也可以创建新文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;r+&quot;&lt;/td&gt;\t\t&lt;td&gt;读写模式打开已存的在文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;w+&quot;&lt;/td&gt;\t\t&lt;td&gt;如果文件已存在则删除文件中数据；若文件不存在则新建文件。读写模式打开。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;a+&quot;&lt;/td&gt;\t\t&lt;td&gt;以可读的追加模式打开已存在文件，若文件不存在则新建文件。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;## 隐式文件描述符  隐式文件描述符使用标准输入输出模式或者使用单个输入文件和输出文件。使用隐匿文件描述符的示例代码如下：  \n– 只读模式打开文件file = io.open(“test.lua”, “r”)\n– 将 test.lua 设置为默认输入文件io.input(file)\n–打印输出文件的第一行print(io.read())\n– 关闭打开的文件io.close(file)\n– 以追加模式打开文件file = io.open(“test.lua”, “a”)\n– 将 test.lua 设置为默认的输出文件io.output(file)\n– 将内容追加到文件最后一行io.write(“– End of the test.lua file”)\n– 关闭打开的文件io.close(file)\n123执行上面的程序，我们可以看到输出了 test.lua 文件的第一行。在本例中，输出的结果为：  \n\nSample test.lua123456789101112131415161718192021222324252627282930313233343536373839404142输出的内容是 test.lua 文件中的第一行。“-- End of the test.lua file” 他会被追加到 test.lua 文件的最后一行。  从上面的例子中，你可以看到隐式的描述述如何使用 io.&quot;x&quot;  方法与文件系统交互。上面的例子使用 io.read() 函数时没有使用可选参数。此函数的可选参数包括：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;模式&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*n&quot;&lt;/td&gt;\t\t&lt;td&gt;从文件当前位置读入一个数字，如果该位置不为数字则返回 nil。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*a&quot;&lt;/td&gt;\t\t&lt;td&gt;读入从当前文件指针位置开始的整个文件内容。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*i&quot;&lt;/td&gt;\t\t&lt;td&gt;读入当前行。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;number&lt;/td&gt;\t\t&lt;td&gt;读入指定字节数的内容。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;另外一些常用的方法：&lt;ul&gt;\t&lt;li&gt;io.tmpfile():返回一个可读写的临时文件，程序结束时该文件被自动删除。&lt;/li&gt;\t&lt;li&gt;io.type(file):检测输入参数是否为可用的文件句柄。返回 &quot;file&quot; 表示一个打开的句柄；“closed file” 表示已关闭的句柄；nil 表示不是文件句柄。&lt;/li&gt;\t&lt;li&gt;io.flush():清空输出缓冲区。&lt;/li&gt;\t&lt;li&gt;io.lines(optional file name): 返回一个通用循环迭代器以遍历文件，每次调用将获得文件中的一行内容,当到文件尾时，将返回nil。若显示提供了文件句柄，则结束时自动关闭文件；使用默认文件时，结束时不会自动关闭文件。&lt;/li&gt;&lt;/ul&gt;  ## 显示文件描述符  我们也会经常用到显示文件描述符，因为它允许我们同时操作多个文件。这些函数与隐式文件描述符非常相似，只不过我们在这儿使用 file:function_name 而不是使用 io.function_name 而已。下面的例子使用显示文件描述符实现了与前面例子中完全相同的功能。  　\n\n只读模式打开文件file = io.open(“test.lua”, “r”)\n\n\n\n– 输出文件的第一行print(file:read())\n– 关闭打开的文件file:close()\n– 以追加模式打开文件file = io.open(“test.lua”, “a”)\n– 添加内容到文件的尾行file:write(“–test”)\n– 关闭打开的文件file:close()\n123执行上面的程序，我们可以得到与前面使用隐式文件描述符类似的输出结果：  \n– Sample test.lua\n12345678910在显式文件描述符中，打开文件的描述与读文件时的参数与隐式文件描述中的完全相同。另外的常用方法包括：&lt;ul&gt;\t&lt;li&gt;file:seek(option whence,option offset)：此函数用于移动文件指针至新的位置。参数 whence 可以设置为 “set”，&quot;cur&quot;,&quot;end&quot;，offset 为一个偏移量值，描述相对位置。如果第一个参数为 &quot;set&quot;，则相对位置从文件开始处开始计算；如果第一个参数为 &quot;cur&quot;，则相对位置从文件当前位置处开始计算； 如果第一个参数为 &quot;end&quot;，则相对位置从文件末尾处开始计算。函数的参数默认值分别为 &quot;cur&quot; 和 ０，因此不传递参数调用此函数可以获得文件的当前位置。&lt;/li&gt;\t&lt;li&gt;file:flush()：清空输出缓冲区。&lt;/li&gt;\t&lt;li&gt;io.lines(optional file name)：提供一个循环迭代器以遍历文件，如果指定了文件名则当遍历结束后将自动关闭该文件；若使用默认文件，则遍历结束后不会自动关闭文件。&lt;/li&gt;&lt;/ul&gt;下面的例子演示 seek 函数的使用方法。它将文件指针从文件末尾向前移动 25。并使用 read 函数从该位置出输出剩余的文件内容。  \n– Opens a file in readfile = io.open(“test.lua”, “r”)\nfile:seek(“end”,-25)print(file:read(“*a”))\n– closes the opened filefile:close()\n12执行上的面的程序，你可以得到类似下面的输出结果：  \n sample2 test.lua–test\n\n你还可以尝试不同的参数了解更多的 Lua 文件操作方法。\n\n","slug":"old-lua/2016-06-01-file-io","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"7cdf9755b9d268215aaceca81f7a3596","title":"Lua文件I/O","content":"Lua 文件 I/OLua 的 IO 库用于读取或操作文件。Lua IO 库提供两类文件操作，它们分别是隐式文件描述符(implict file descriptors)和显式文件描述符(explicit file descriptors)。\n在接下来的例子的，我们会用到一个示例文件 test.lua，文件内容如下：  \n123456-- sample test.lua-- sample2 test.lua```  简单的打开文件操作可以用如下的语句完成。  \nfile = io.open (filename [, mode])\n1234567891011121314151617181920212223242526272829303132333435363738可选的打开文件的模式如下表所示。  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;模式&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;r&quot;&lt;/td&gt;\t\t&lt;td&gt;只读模式，这也是对已存在的文件的默认打开模式。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;w&quot;&lt;/td&gt;\t\t&lt;td&gt;可写模式，允许修改已经存在的文件和创建新文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;a&quot;&lt;/td&gt;\t\t&lt;td&gt;追加模式，对于已存的文件允许追加新内容，但不允许修改原有内容，同时也可以创建新文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;r+&quot;&lt;/td&gt;\t\t&lt;td&gt;读写模式打开已存的在文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;w+&quot;&lt;/td&gt;\t\t&lt;td&gt;如果文件已存在则删除文件中数据；若文件不存在则新建文件。读写模式打开。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;a+&quot;&lt;/td&gt;\t\t&lt;td&gt;以可读的追加模式打开已存在文件，若文件不存在则新建文件。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;## 隐式文件描述符  隐式文件描述符使用标准输入输出模式或者使用单个输入文件和输出文件。使用隐匿文件描述符的示例代码如下：  \n– 只读模式打开文件file = io.open(“test.lua”, “r”)\n– 将 test.lua 设置为默认输入文件io.input(file)\n–打印输出文件的第一行print(io.read())\n– 关闭打开的文件io.close(file)\n– 以追加模式打开文件file = io.open(“test.lua”, “a”)\n– 将 test.lua 设置为默认的输出文件io.output(file)\n– 将内容追加到文件最后一行io.write(“– End of the test.lua file”)\n– 关闭打开的文件io.close(file)\n123执行上面的程序，我们可以看到输出了 test.lua 文件的第一行。在本例中，输出的结果为：  \n\nSample test.lua123456789101112131415161718192021222324252627282930313233343536373839404142输出的内容是 test.lua 文件中的第一行。“-- End of the test.lua file” 他会被追加到 test.lua 文件的最后一行。  从上面的例子中，你可以看到隐式的描述述如何使用 io.&quot;x&quot;  方法与文件系统交互。上面的例子使用 io.read() 函数时没有使用可选参数。此函数的可选参数包括：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;模式&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*n&quot;&lt;/td&gt;\t\t&lt;td&gt;从文件当前位置读入一个数字，如果该位置不为数字则返回 nil。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*a&quot;&lt;/td&gt;\t\t&lt;td&gt;读入从当前文件指针位置开始的整个文件内容。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*i&quot;&lt;/td&gt;\t\t&lt;td&gt;读入当前行。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;number&lt;/td&gt;\t\t&lt;td&gt;读入指定字节数的内容。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;另外一些常用的方法：&lt;ul&gt;\t&lt;li&gt;io.tmpfile():返回一个可读写的临时文件，程序结束时该文件被自动删除。&lt;/li&gt;\t&lt;li&gt;io.type(file):检测输入参数是否为可用的文件句柄。返回 &quot;file&quot; 表示一个打开的句柄；“closed file” 表示已关闭的句柄；nil 表示不是文件句柄。&lt;/li&gt;\t&lt;li&gt;io.flush():清空输出缓冲区。&lt;/li&gt;\t&lt;li&gt;io.lines(optional file name): 返回一个通用循环迭代器以遍历文件，每次调用将获得文件中的一行内容,当到文件尾时，将返回nil。若显示提供了文件句柄，则结束时自动关闭文件；使用默认文件时，结束时不会自动关闭文件。&lt;/li&gt;&lt;/ul&gt;  ## 显示文件描述符  我们也会经常用到显示文件描述符，因为它允许我们同时操作多个文件。这些函数与隐式文件描述符非常相似，只不过我们在这儿使用 file:function_name 而不是使用 io.function_name 而已。下面的例子使用显示文件描述符实现了与前面例子中完全相同的功能。  　\n\n只读模式打开文件file = io.open(“test.lua”, “r”)\n\n\n\n– 输出文件的第一行print(file:read())\n– 关闭打开的文件file:close()\n– 以追加模式打开文件file = io.open(“test.lua”, “a”)\n– 添加内容到文件的尾行file:write(“–test”)\n– 关闭打开的文件file:close()\n123执行上面的程序，我们可以得到与前面使用隐式文件描述符类似的输出结果：  \n– Sample test.lua\n12345678910在显式文件描述符中，打开文件的描述与读文件时的参数与隐式文件描述中的完全相同。另外的常用方法包括：&lt;ul&gt;\t&lt;li&gt;file:seek(option whence,option offset)：此函数用于移动文件指针至新的位置。参数 whence 可以设置为 “set”，&quot;cur&quot;,&quot;end&quot;，offset 为一个偏移量值，描述相对位置。如果第一个参数为 &quot;set&quot;，则相对位置从文件开始处开始计算；如果第一个参数为 &quot;cur&quot;，则相对位置从文件当前位置处开始计算； 如果第一个参数为 &quot;end&quot;，则相对位置从文件末尾处开始计算。函数的参数默认值分别为 &quot;cur&quot; 和 ０，因此不传递参数调用此函数可以获得文件的当前位置。&lt;/li&gt;\t&lt;li&gt;file:flush()：清空输出缓冲区。&lt;/li&gt;\t&lt;li&gt;io.lines(optional file name)：提供一个循环迭代器以遍历文件，如果指定了文件名则当遍历结束后将自动关闭该文件；若使用默认文件，则遍历结束后不会自动关闭文件。&lt;/li&gt;&lt;/ul&gt;下面的例子演示 seek 函数的使用方法。它将文件指针从文件末尾向前移动 25。并使用 read 函数从该位置出输出剩余的文件内容。  \n– Opens a file in readfile = io.open(“test.lua”, “r”)\nfile:seek(“end”,-25)print(file:read(“*a”))\n– closes the opened filefile:close()\n12执行上的面的程序，你可以得到类似下面的输出结果：  \n sample2 test.lua–test\n\n你还可以尝试不同的参数了解更多的 Lua 文件操作方法。\n\n","slug":"old-lua/2016-06-01-file-io1","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"4b8da2e6835e8f700ba371a83ecbe6ab","title":"Lua函数","content":"Lua 函数函数用于将一组语句组合起来完成一个任务。你可以将你的代码分割到不同的函数中。如何将你的代码分到不同的函数中完全由你自己决定，不过一般会按照逻辑功能进行划分，每个函数都执行一个特定的任务。 \n在 Lua 中提供了大量的内置函数供我们使用。例如，print() 函数用于将输入的参数输出到终端。 \n函数往往也被称作方法，子例程或过程等等。  \n函数定义Lua 中函数定义的语法如下所示：　　\n1234567891011121314151617181920optional_function_scope function function_name( argument1, argument2, argument3..., argumentn)function_bodyreturn result_params_comma_separatedend```  Lua 中函数定义包括函数头和函数名两部分。如下列出函数的所有部分：  &lt;ul&gt;\t&lt;li&gt;可选的函数作用域：你可以使用关键字 local 限制函数的作用域，你也可以忽略此部分而使用默认值。函数作用域默认是全局。&lt;/li&gt;\t&lt;li&gt;函数名：函数的真正名称。函数名与函数的参数列表一起被称为函数签名。&lt;/li&gt;\t&lt;li&gt;参数：一个参数就一个占位符一样。函数调用时，把值传递给参数。这个值被称之为实际参数或直参数。参数列表指参数的类型，顺序与数量。参数是可选的，一个函数可以没有参数。&lt;/li&gt;\t&lt;li&gt;函数体：函数体是代码语句集合，定义了函数的功能。&lt;/li&gt;\t&lt;li&gt;返回：在 Lua 中，可以使用 return 关键字同时返回多返回值，每个返回值之间使用逗号分隔。&lt;/li&gt;&lt;/ul&gt;  ## 示例  下面是函数 max() 源代码。此函数接受两个参数 num1 与 num2，返回两个输入参数的最大值。  \n–[[ function returning the max between two numbers –]]function max(num1, num2)\n   if (num1 &gt; num2) then      result = num1;   else      result = num2;   end\n   return result;end\n123456789101112131415## 函数参数  如果函数需要用到参数，则它必须声明接受参数值的变量。这些被声明的变量被称为函数的形式参数或简称形参。  函数的形参与函数中其它局部变量一样，在函数的入口处被创建，函数结束时被销毁。  ## 调用函数  创建函数的时候，我们已经定义了函数做什么。接下来，我们就可以调用函数来完成已定义的任务或功能。  当程序中调用一个函数时，程序的控制转移到被调用的函数中。被调用的函数执行定义的任务；当 return 语句被执行或者到达函数末尾时，程序的控制回到主程序中。   调用函数的方法很简单，你只需要将函数要求的参数传递给函数就可以实现函数的调用。如果函数有返回值，你也可以将函数的返回值存储下来。如下如示：  \nfunction max(num1, num2)   if (num1 &gt; num2) then      result = num1;   else      result = num2;   end\n   return result;end\n– 调用函数print(“The maximum of the two numbers is “,max(10,4))print(“The maximum of the two numbers is “,max(5,6))\n123执行上面的代码，可以得到如下的输出结果：  \nThe maximum of the two numbers is     10The maximum of the two numbers is     6\n12345## 赋值与传递函数  在 Lua 语言中，我们可以将函数赋值给一个变量，也可以将函数作为参数传递给另外一个函数。下面是赋值传递函数的一个例子：  \nmyprint = function(param)   print(“This is my print function -   ##”,param,”##”)end\nfunction add(num1,num2,functionPrint)   result = num1 + num2   functionPrint(result)endmyprint(10)add(2,5,myprint)\n123执行上面的代码，可以得到如下的输出结果：  \nThis is my print function -   ##    10    ##This is my print function -   ##    7    ##\n12345## 变参函数  在 Lua 语言中，使用 ... 作为参数可以创建参数个数可变的函数，即变参函数。我们可以使用下面的这个例子来理解变参函数的概念。下面的这个例子中函数返回输入参数的平均值：  \nfunction average(…)   result = 0   local arg={…}   for i,v in ipairs(arg) do      result = result + v   end   return result/#argend\nprint(“The average is”,average(10,5,3,4,5,6))\n123执行上面的代码，可以得到如下的输出结果：  \nThe average is    5.5``` \n","slug":"old-lua/2016-06-01-functions","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"0574a789cafc1558adcaaf40b641bfb0","title":"Lua游戏开发","content":"Lua 游戏开发Lua 语言因其结构和语法的简洁性而在各类游戏引擎中被广泛使用。游戏对图形画面要求非常苛刻，这无疑需消耗大量的内存空间，而这些内存空间的管理是非常棘手的问题。Lua 语言有自动的垃圾回收机制，这种自动化的内存管理机制也使得 Lua 受到游戏引擎开发者的青睐。著名的 Lua 游戏引擎主要包括：  \n\n    Cornoa SDK\n    Gideros Mobile\n    ShiVa3D\n    Moai SDK\n    LOVE\n    CryEngine\n\n\n上面每一个游戏引擎都是基于 Lua 的，并且每一个都提供了丰富的 API。我们下面看一下每一款游戏引擎的特点。  \nCorna SDK这是一款支持 iPhone，iPad，Android 平台的移动设备游戏引擎。它提供了一个免费版本的 SDK, 不过该免费版本的功能也受到限制。你可以在需要的时候升级到其它版本。\nGorona SDK 提供了如下的特征：  \n\n    物理与冲突处理接口\n    Web 和网络接口\n    游戏网络接口\n    广告接口\n    数据分析接口\n    数据库和文件处理接口\n    加密和数学计算接口\n    音频和多媒体接口\n\n\n相比于使用 iOS 或 Android 系统原生 API， 使用上面的接口可以让我们的开发效率更高。  \nGideros MobileGideros 提供 iOS 和 Android 跨平台的软件开发工具包（SDK）。它是一个免费的游戏引擎，其主要的优点包括：  \n\n    集成开发环境：它提供一套集成开发环境，使用应用开发变得容易许多。\n    即时测试：在游戏开发过程中，通过 wifi 在 1 秒之内就可以在真实设备上测试应用。为开发者省去了导出和部署应用的时间。\n    插件：支持使用插件的方式扩展。导入的代码（C, C++, Java，Obje-C），Lua　可以直接解释执行。目前网络上已有了大量的开源插件可供使用。\n    面向对象编程：Gideros 提供了自己的类系统，支持 OOP 标准，开发可以开发干净的 OOP 代码。\n    原生速度：基于 C/C++ 和 openGL,应用可以以原生的运行，完全利用 CPU 和 GPU 的处理能力。\n\n\nShiVa3D这一款 3D 的游戏引擎，它提供了图形化的编辑器，可以为 Web、终端、移动设备开发应用或游戏。它支持多个平台，包括：Windows，Mac，Linux，iOS，Android，BlackBerry，Palm OS，Wii，WebOS。\n它主要的特点包括：  \n\n    标准插件\n    网格修改接口\n    集成开发环境\n    内置 Terrain，Ocean 与 动画编辑器\n    支持 ODE 物理引擎\n    完全的光线映射控制\n    实时预览\n    Collada 交换格式的支持\n\n\nShiVa3D 的 Web 版本是免费的，但其它的版本是收费版本。  \nMoai SDKMoai SDK 是跨平台的移动游戏开发引擎，它支持 iPhone，iPad 以及 Android 系统。Moai　平台包括　Moai SDK，开源的引擎，以及 Moai 云。 Moai 云是一个 SaaS 平台，提供游戏部署的服务。不过，Moai 云平台已经关闭，现在只有游戏引擎是可用的。  \nLOVELOVE 是一个开源的 2D 游戏的开始框架，它支持 Windows，Mac OS X 以及 Linux 多个平台。\n它主要提供以下的开发接口：  \n\n    音频接口\n    文件系统接口\n    键盘和操纵杆接口\n    数据计算 API\n    窗口和鼠标接口\n    物理接口\n    系统和定时器接口\n\n\nCryEngineCryEngine 是由德国的游戏引擎开发商 Cryteck 开发的游戏引擎。到目前为止，它已由第一代引擎发展到了第四代，是一个高级的游戏开发解决方案。它目前支持 PC，Xbox 360，PlayStation3，以及 WiiU。\n它主有以下的优点：  \n\n    视觉效果就像自然光线，态柔和阴影，实时动态全局光照，光传输容量控制，颗粒底纹，镶嵌等。\n    角色动画系统与人物个性化系统。\n    参数骨骼动画和独特的专用人脸动画编辑器。\n    人工智能系统如多层导航网格战术角度系统。还提供了设计师友好的 AI 编辑系统。\n    游戏混合及分析，数据驱动的音响系统的动态声音和互动音乐等。\n  \n\n结束语每个款游戏引擎都有着自己的优势以及不足之处。正确的选择游戏引擎会让你的开发变得容易和有趣得多。所以，在选择之前，请先仔细斟酌你的需求，分析哪一款游戏引擎真正的适合你，然后再决定使用它。\n","slug":"old-lua/2016-06-01-game-programming","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"a34942b7e84e08a52441ea25cc5475d6","title":"Lua垃圾回收机制","content":"Lua 垃圾回收机制Lua 通过特定算法的垃圾回收机制实现自动内存管理。由于自动内存管理机制的存在，作为程序开发人员：  \n\n    不需要关心对象的内存分配问题。\n    不再使用对象时，除了将引用它的变量设为 nil，不需要主动释放对象。\n  \nLua 的垃圾回收器会不断运行去收集不再被 Lua 程序访问的对象。  \n所有的对象，包括表、userdata、函数、线程、字符串等都由自动内存管理机制管理它们空间的分配和释放。Lua 实现了一个增量式标记清除垃圾收集器。它用两个数值控制垃圾回收周期，垃圾收集器暂停时间（garbage-collector pause） 和垃圾收集器步长倍增器（garbage-collector step multiplier）。其数值是以百分制计数的，即数值 100 内部表示 1。  \n\n垃圾收集器暂停时间该数值被用于控制垃圾收集器被 Lua 自动内存管理再次运行之前需要的等待时长。当其小于 100 时意味着收集器在新周期开始前不再等待。其值越大垃圾回收器被运行的频率越低，越不主动。当其值 200 时，收集器在总使用内存数量达到上次垃圾收集时的两倍时再开启新的收集周期。因此，根据程序不同的特征，可以通过修改该值使得程序达到最佳的性能。  \n垃圾收集器步长倍增器步长倍增器用于控制了垃圾收集器相对内存分配的速度。数值越大收集器工作越主动，但同时也增加了垃圾收集每次迭代步长的大小。值小于 100 可能会导致垃圾器一个周期永远不能结束，建议不要这么设置。默认值为 200，表示垃圾收集器运行的速率是内存分配的两倍。\n垃圾回收器相关函数作为开发人员，我们可能需要控制 Lua 的自动内存管理机制，可以使用下面的这些方法：  \n\n    collectgarbage(\"collect\")：运行一个完整的垃圾回收周期。\n    collectgarbage(\"count\")：返回当前程序使用的内存总量，以 KB 为单位。\n    collectgarbage(\"restart\")：如果垃圾回收器停止，则重新运行它。\n    collectgarbage(\"setpause\")：设置垃圾收集暂停时间变量的值，值由第二个参数指出（第二参数的值除以 100 后赋予变量）。稍后，我们将详细讨论它的用法。\n    collectgarbage(\"setsetmul\")：设置垃圾收集器步长倍增器的值，第二个参数的含义与上同。\n    collectgarbage(\"step\")：进行一次垃圾回收迭代。第二个参数值越大，一次迭代的时间越长；如果本次迭代是垃圾回收的最后一次迭代则此函数返回 true。\n    collectgarbage(\"stop\")：停止垃圾收集器运行。\n\n\n下面的示例代码中使用了垃圾收集器相关函数，如下所示：  \n123456789101112131415mytable = &#123;&quot;apple&quot;, &quot;orange&quot;, &quot;banana&quot;&#125;print(collectgarbage(&quot;count&quot;))mytable = nilprint(collectgarbage(&quot;count&quot;))print(collectgarbage(&quot;collect&quot;))print(collectgarbage(&quot;count&quot;))```  运行上面的程序，我们可以得到如下的输出结果。请注意，输出结果与操作系统类型与 Lua 自动内存管理都有关，所以可能实际运行的结果与下面不相同。  \n20.956054687520.9853515625019.4111328125\n```  \n从上面的程序，我们可以看出，一旦垃圾回收运行后，使用的内存量立即就减少了。但是，我们并不需要主动去调用它。因为，即使我们不调用此函数，Lua 也会按配置的周期自动的调用垃圾回收器。显然，如果需要，我们可以用上面的这些函数调整垃圾回收器的行为。这些函数帮且程序开发人员处理更加复杂的场景。根据开发的不同程序的内存需求，我们可以使用到这些方法来提高程序的性能。虽然大部分情况下，我们都不会用到这些函数，但是了解这些方法可以帮助我们调试程序，以免应用上线后带来的损失。 \n译注：更多垃圾回收器的内容请参考官网或者此博客。\n","slug":"old-lua/2016-06-01-garbage-collection","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"90762206aba1aa8a729d07e471d48c2c","title":"Lua中的 if...else 语句","content":"#Lua 中的 if…else 语句  \n如果 if 语句后面跟上 else 语句，那么条件为假时就执行 else 语句的代码。  \n##语法  \nLua 语言中 if…else 语句的语法如下所示：  \n1234567891011121314151617if(boolean_expression)then   --[ 如何条件为真，则执行此处代码。 --]else   --[ 如何条件为假，则执行此处代码。 --]end```  当布尔表达式为真时，执行 if 语句的代码块；如果条件为假时，则执行 else 语句的代码块。  Lua 语言中所有布尔真与非 nil 的组合的结果被当作真，而布尔假与 nil 组合被当作假。值得注意的是，Lua 中零被当作真，这一点与其它大部分语言不一样。##流程图  ![](http://www.tutorialspoint.com/lua/images/if_else_statement.jpg)  ##示例  \n–[ 定义局部变量 –]a = 100;–[ 检查条件 –]if( a &lt; 20 )then   –[ 如果条件为真，则输出如下内容 –]   print(“a is less than 20” )else   –[ 如果条件为假，则输出如下内容 –]   print(“a is not less than 20” )endprint(“value of a is :”, a)\n123执行上面的代码则可以得到如下的输出结果：  \na is not less than 20value of a is :    100\n123456789101112131415##if...else if...else 语句  if 语句后可以选择跟上 else if...else 语句。该语句对于检测多个条件时非常有用。  使用 if，else if 以及 else 时，请注意以下三点：  &lt;ul&gt;\t&lt;li&gt;if 语句后面至多可以有一个 else 语句。如果有　else if,则此 else 语句必须在 else if 语句之后。&lt;/li&gt;\t&lt;li&gt;if 语句之后可以有多零个或多个 else if，但是这些 else if 必须在　else 语句之前。&lt;/li&gt;\t&lt;li&gt;如果一个 if 语句的条件为真时，其后的所有剩余的 else 和 else if 的都不会再执行，也不会测试它们的条件真假。&lt;/li&gt;&lt;/ul&gt;  ##语法  Lua 中 if...else if...else 语句的语法规则如下：  \nif(boolean_expression 1)then   –[ 如果布尔表达式 1 为真时，则执行此处代码。–]\nelse if( boolean_expression 2)   –[ 如果布尔表达式 2 为真时，则执行此处代码。 –]\nelse if( boolean_expression 3)   –[ 如果布尔表达式 3为真时，则执行此处代码。 –]else   –[ 当上面所有布尔表达式条件都为假时执行此处代码。–]end\n123##示例  \n–[ 定义局部变量 –]a = 100–[ 检查布尔条件 –]if( a == 10 )then   –[ 条件为真时输出如下内容 –]   print(“Value of a is 10” )elseif( a == 20 )then   –[ if else if 条件为真时 –]   print(“Value of a is 20” )elseif( a == 30 )then   –[ if else if 条件为真时 –]   print(“Value of a is 30” )else   –[ 如果上述条件全部为假时 –]   print(“None of the values is matching” )endprint(“Exact value of a is: “, a )\n123  执行上面的代码将得到如下的输出结果：  \nNone of the values is matchingExact value of a is:    100\n\n\n","slug":"old-lua/2016-06-01-if-else-if-statement","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"eacf32e453764fca08d4d96ce1e78183","title":"Lua迭代器","content":"Lua 迭代器迭代器是用于遍历集合或容器中元素的一种结构。在 Lua 语言中，集合往往指的是可以用来创建各种数据结构的表。比如，数组就是用表来创建的。  \n通用迭代器通用迭代器可以访问集合中的键值对。下面是通用迭代器的一个简单例子：  \n12345678910array = &#123;&quot;Lua&quot;, &quot;Tutorial&quot;&#125;for key,value in ipairs(array) do   print(key, value)end```  执行的上面的代码，我们可以得到如下的输出结果：  \n1  Lua2  Tutorial\n12345678910111213141516上面的例子中使用了 Lua 提供的默认迭代器函数 ipairs。  在 Lua 语言中，我们使用函数表示迭代器。根据是否在迭代器函数中是否维护状态信息，我们将迭代器分为以下两类：  &lt;ul&gt;\t&lt;li&gt;无状态迭代器&lt;/li&gt;  \t&lt;li&gt;有状态迭代器&lt;/li&gt;&lt;/ul&gt;  ## 无状态迭代器  由此迭代器的名称就可以看出来，这一类的迭代器函数中不会保存任何中间状态。  让我们一起来看一下下面这个例子。在这个例子中，我们用一个简单的函数创建了一个自己的迭代器。这个迭代器用以输出 n 个数的平方值。  \nfunction square(iteratorMaxCount,currentNumber)   if currentNumber&lt;iteratorMaxCount   then      currentNumber = currentNumber+1   return currentNumber, currentNumber*currentNumber   endend\nfor i,n in square,3,0do   print(i,n)end\n123执行上面的代码，我们可以得到如下的输出结果：  \n1    12    43    9\n123我们可以稍微的修改一下上面的代码，使得此迭代器可以像 ipairs 那样工作。如下所示：  \nfunction square(iteratorMaxCount,currentNumber)   if currentNumber&lt;iteratorMaxCount   then      currentNumber = currentNumber+1   return currentNumber, currentNumber*currentNumber   endend\nfunction squares(iteratorMaxCount)   return square,iteratorMaxCount,0end  \nfor i,n in squares(3)do    print(i,n)end\n12执行上面的代码，我们可以得到如下的输出结果：  \n1    12    43    9\n1234567## 有状态迭代器  前面的例子使用的迭代器函数是不保存状态的。每次调用迭代器函数时，函数基于传入函数的第二个变量访问集合的下一个元素。在 Lua 中可以使用闭包来存储当前元素的状态。闭包通过函数调用得到变量的值。为了创建一个新的闭包，我们需创建两个函数，包括闭包函数本身和一个工厂函数，其中工厂函数用于创建闭包。  下面的示例中，我们将使用闭包来创建我们的迭代器。  \narray = {“Lua”, “Tutorial”}\nfunction elementIterator (collection)   local index = 0   local count = #collection   – 返回闭包函数   return function ()      index = index + 1      if index &lt;= count      then         – 返回迭代器的当前元素         return collection[index]      end   endend\nfor element in elementIterator(array)do   print(element)end\n123执行上面的代码，我们可以得到如下的输出结果：  \nLuaTutorial\n```  \n上面的例子中我们可以看到，在　elementIterator 函数内定义了另外一个匿名函数。此匿名函数中使用了一个外部变量 index (译注：此变量在匿名函数之外，elementIterator 函数内)。每次内部的匿名函数被调用时，都会将 index 的值增加 1，并统计数返回的每个元素。 \n我们可以参照上面的方法使用闭包创建一个迭代器函数。每次我们使用迭代器遍历集合时，它都可以返回多个元素。\n","slug":"old-lua/2016-06-01-iterators","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"50b76913de0a7e15924d6b0f0dac6bf2","title":"LUA的Loop循环","content":"循环　虽然一般情况下，语句都是顺序执行的：函数内的第一条语句先执行，然后是第二条，依次类推。  但是还是可能存在需要执行一段代码多次的情况。\n为此编程语言提供各式各样的控制结构实现复杂的程序执行路径。\n其中，循环语句可以让我们可以执行一条或一组语句多次。下图中所描述的是大多数语言中循环语句的形式：  \n  \nLua 语言提供了如下几种循环结构语句。点击链接可查看详细说明。  \n\n    \n        循环类型\n        描述\n    \n    \n        while 循环\n        先检测条件，条件为真时再执行循环体，直到条件为假时结束。\n    \n    \n        for 循环\n        执行一个语句序列多次，可以简化管理循环变量的代码。\n    \n        \n        repeat...until 循环\n        重复执行一组代码语句，直到 until 条件为真为止。\n    \n    \n        嵌套循环\n        可以在一个循环语句中再使用一个循环语句。\n        \n  \n\n循环控制语句循环控制语句改变循环正常的执行顺序。当离开一个作用域时，在该作用域内自动创建的对象都会被自动销毁。\nLua 支持如下所示的循环控制语句。点击下面的链接查看详细内容：  \n\n    \n        循环控制语句\n        描述\n    \n        \n        break\n        break 语句结束循环，并立即跳转至循环或 switch 语句后的第一条语句处开始执行。\n        \n\n\n无限循环如果循环条件永远不可能为假，则此循环为无限循环。while 语句经常被当作无限循环语句使用。因为我们可以直接将其条件设置为真，这样 while 就会一直循环下去。在无限循环中，可以使用 break 跳出循环。  \n1234while( true )do   print(&quot;This loop will run forever.&quot;)end\n\n","slug":"old-lua/2016-06-01-loop","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"LUA教程","author_index":"安全书"},{"id":"3f4bda6307129cf6a3004f8fe27cd085","title":"Lua数学函数库","content":"Lua 数学函数库在科学计算与工程计算领域，我们都需要用到大量的数学函数。在 Lua 的数学库提供了大量的数学函数，如下表所示：  \n\n    \n        S.N.\n        函数与功能\n    \n    \n        1\n        math.abs(x)：返回 x 的绝对值。\n    \n    \n        2\n        math.acos(x)：返回 x 的反余弦值（弧度）。\n    \n    \n        3\n        math.asin(x)：返回 x 的反正弦值（弧度）。\n    \n    \n        4\n        math.atan(x)：返回 x 的反正切值（弧度）。\n    \n    \n        5\n        math.atan2(y,x)，返回 y/x 的反正切值，使用两个参数的符号查找象限（ x 为 0 时也能正确的处理）。\n    \n    \n        6\n        math.ceil（x）:返回大于或等于 x 的最小整数。\n    \n    \n        7\n        math.cos(x)：返回 x 的余弦值（x 以弧度为单位）。\n    \n    \n        8\n        math.cosh(x)：返回 x 的双曲余弦值。\n    \n    \n        9\n        math.deg(x)：返回 x　的角度值（ｘ为弧度）。\n    \n    \n        10\n        math.exp(x)：返回 e 的 x 次幂。\n    \n    \n        11\n        math.floor(x)：返回小于或等于 x 的最大整数。\n    \n    \n        12\n        math.fmod(x,y): 返回 x%y。\n    \n    \n        13\n        math.frexp(x)：返回两个值 m，e，满足 x = m*2^e。其中，e 是整数，m 的绝对值属于区间 [0.5,1)。\n    \n    \n        14\n        math.huge：最大值，不小于任何其它数值。\n    \n    \n        15\n        math.ldexp(m,e)：返回 m*2^e(e 为整数)。\n    \n    \n        16\n        math.log(x)：计算自然对数。\n    \n    \n        17\n        math.log10(x)：计数以 10 为底的对数。\n    \n    \n        18\n        math.max(x,...)：返回输入参数的最大值。\n    \n    \n        19\n        math.min(x,...)：返回输入参数的最小值。\n    \n    \n        20\n        math.modf(x)：返回 x 的整数部分与小数部分。\n    \n    \n        21\n        math.pi：数值 PI。\n    \n    \n        22\n        math.pow(x,y)：等价于 x^y。\n    \n    \n        23\n        math.rad(x)：返回角度 x 的弧度值。\n    \n    \n        24\n        math.random([m,[n]])：该函数直接调用 ANSI C 的伪随机生成函数。无参数时，生成 [0,1) 区间的均匀分布的随机值；只传入参数 m 时，函数生成一个位于区间 [1,m] 的均匀分布伪随机值；同时传入参数 m,n 时，生成位于区间 [m,n] 的均匀分布伪随机值。\n    \n    \n        25\n        math.randomseed(x)：初始化伪随机数生成器种子值。\n    \n    \n        26\n        math.sin(x)：返回 x 的正弦值。\n    \n    \n        27\n        math.sinh(x)：返回 x 的双曲正弦值。\n    \n    \n        28\n        math.sqrt(x)：返回 x 的平方根。\n    \n    \n        29\n        math.tan(x)：返回 x 的正切值。\n    \n    \n        30\n        math.tanh(x)：返回 x 的双曲正切值。\n    \n\n\n三角函数三角函数的使用方法示例如下：  \n123456789101112131415161718radianVal = math.rad(math.pi / 2)io.write(radianVal,&quot;\\n&quot;)-- Sin value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.sin(radianVal)),&quot;\\n&quot;)-- Cos value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.cos(radianVal)),&quot;\\n&quot;)-- Tan value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.tan(radianVal)),&quot;\\n&quot;)-- Cosh value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.cosh(radianVal)),&quot;\\n&quot;)-- Pi Value in degreesio.write(math.deg(math.pi),&quot;\\n&quot;)```  运行上面的程序，我们可以得到如下的输出结果：  \n0.0274155677808040.01.00.01.0180\n123## 另外一些常用的数学函数  \n– Floorio.write(“Floor of 10.5055 is “, math.floor(10.5055),”\\n”)– Ceilio.write(“Ceil of 10.5055 is “, math.ceil(10.5055),”\\n”)– Square rootio.write(“Square root of 16 is “,math.sqrt(16),”\\n”)– Powerio.write(“10 power 2 is “,math.pow(10,2),”\\n”)io.write(“100 power 0.5 is “,math.pow(100,0.5),”\\n”)– Absoluteio.write(“Absolute value of -10 is “,math.abs(-10),”\\n”)–Randommath.randomseed(os.time())io.write(“Random number between 1 and 100 is “,math.random(),”\\n”)–Random between 1 to 100io.write(“Random number between 1 and 100 is “,math.random(1,100),”\\n”)–Maxio.write(“Maximum in the input array is “,math.max(1,100,101,99,999),”\\n”)–Minio.write(“Minimum in the input array is “,math.min(1,100,101,99,999),”\\n”)\n123运行上面的程序，我们可以得到如下的输出结果：  \nFloor of 10.5055 is 10Ceil of 10.5055 is 11Square root of 16 is 410 power 2 is 100100 power 0.5 is 10Absolute value of -10 is 10Random number between 1 and 100 is 0.22876674703207Random number between 1 and 100 is 7Maximum in the input array is 999Minimum in the input array is 1\n\n上面的例子只是给出了数学函数一些简单的使用方法，在实际中我们可以根据自己的需要进行选择和使用。通过更多的练习可以对这些函数更加的熟悉。\n\n","slug":"old-lua/2016-06-01-math-library","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"15a63bcbcc45ec73313b8b26fa940570","title":"Lua中的if语句","content":"#Lua 中的 if 语句  \nif　语句包括一个布尔表达式和一个或多个语句。　　\n##语法  \nLua 语言 if 语句的语法如下：  \n123456789101112131415if(boolean_expression)then   --[如果布尔表达式为真，statement(s) 执行。--]end```  如果布尔表达式计算结果为真，则 if 语句内的代码块执行；如果布尔表达式计算结果为假，跳过 if 语句中的代码直接执行 if 语句后面的代码。  Lua 语言中所有布尔真与非 nil 的组合的结果被当作真，而布尔假与 nil 组合被当作假。值得注意的是，Lua 中零被当作真，这一点与其它大部分语言不一样：  ##流程图  ![](http://www.tutorialspoint.com/lua/images/if_statement.jpg)##示例  \n–[ 局部变量定义 –]a = 10;–[ 检查 if　语句使用的布尔条件 –]if( a &lt; 20 )then   –[ 如果条件为真则输出如下内容　–]   print(“a is less than 20” );endprint(“value of a is :”, a);\n123执行上面的代码可以得到如下的结果：　　\na is less than 20value of a is : 10\n\n\n","slug":"old-lua/2016-06-01-if-statement","date":"2024-03-14T06:15:59.730Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"\nlua 基础 \n概述permalink: /lua_guide/TOC/\n运行环境\n基本语法\n变量\n日期类型\n操作符\n循环\n决策\n函数\n字符串\n数组\n迭代器\n表\n模块 \n元表  \n协程 \n文件 I/O\n错误处理\n\n\nlua 进阶\n调试\n垃圾回收机制\n面向对象\nWeb 编程\n数据库访问\n游戏开发\n标准库\n\n\n\n","slug":"old-lua/2016-06-01-TOC","date":"2024-03-14T06:15:59.729Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Lua 中文指南permalink: /lua_guide/README/Lua 语言是基于 C 语言之上的开源编程语言。它的价值在于其跨平台的特性，从大型服务器系统到小型移动应用都可以看到它的身影。\n这篇教程不仅包括 Lua 编程语言的基本知识，还包括 Lua 语言在各类应用场景中的应用。  \n适用人群这篇教程主要是为 Lua 语言的初学者准备的。不过，其中也包含了既适合初学者也适合高级用户的主题。  \n学习前途建议您在开始学习这篇教程之前先掌握一些计算机编程的基本概念。但是这篇教程本身是自包含的，即使您是完全的初始者，您也能够学习到大量的 Lua 语言的编程概念。您只需有一些基本的文本编辑与命令行的知识即可。  \n官方英文原版：http://www.tutorialspoint.com/lua/index.htm \n","slug":"old-lua/2016-06-01-README","date":"2024-03-14T06:15:59.729Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"e16187d7a3c490f96b788338bdd79d24","title":"数组","content":"Lua 数组数组是一组有序的对象排列，既可以是一维的也可以是多维的。  \n在 Lua 语言中，数组是用整数索引表实现的。数组的大小并不固定，随着数组元素的增加，它可以动态地增加内存空间大小。  \n一维数组一维数组可以使用一个简单的表结构表示。可以通过一个简单循环初始化数组或者读取数组中数据。示例代码如下所示：  \n123456789array = &#123;&quot;Lua&quot;, &quot;Tutorial&quot;&#125;for i= 0, 2 do   print(array[i])end```  执行上面的代码可以得到如下的输出结果：  \nnilLuaTutorial\n123从上面的例子中可以看出，当我们尝试着访问数组中一个不存在的索引时，会得到 nil 值。 Lua 语言与 C 语言不同，Lua 数组的索引是从 1 开始的，而 C 语言中索引是从 0 开始的。不过呢，你也可以在索引值为 0 或小于 0 的位置创建对象。下面的代码演示了如何使用负索引值创建并初始化数组：  \narray = {}\nfor i= -2, 2 do   array[i] = i *2end\nfor i = -2,2 do   print(array[i])end\n123执行上面的代码可以得到如下的输出结果：  \n-4-2024\n1234567891011## 多维数组  多维数组有以下两种实现方式：  &lt;ol&gt;\t&lt;li&gt;数组的数组（译注：数组的每一个元素是一个数组）。&lt;/li&gt;\t&lt;li&gt;修改一维数组的索引值（译注：将多维数组映射到一维数组中）。&lt;/li&gt;&lt;/ol&gt;  使用方法一创建 3x3 的二维数组：  \n– 初始化数组array = {}for i=1,3 do   array[i] = {}      for j=1,3 do         array[i][j] = i*j      endend\n– 访问数组元素for i=1,3 do   for j=1,3 do      print(array[i][j])   endend\n123执行上面的代码可以得到如下的输出结果：  \n123246369\n123通过修改数组的的索引值实现 3x3 的二维数组，示例代码如下:  \n– 初始化数组array = {}maxRows = 3maxColumns = 3for row=1,maxRows do   for col=1,maxColumns do      array[rowmaxColumns +col] = rowcol   endend\n– 访问数组元素for row=1,maxRows do   for col=1,maxColumns do      print(array[row*maxColumns +col])   endend\n123执行上面的代码可以得到如下的输出结果：  \n123246369\n```  \n正如从上面例子中所看到的那样，数组中数据是基于索引存储的。这使得数组可以以稀疏的方式存储，这也是 Lua 矩阵的存储方式。正是因为 Lua 中不会存储 nil 值，所以 Lua　不需要使用任何特殊的技术就可以节约大量的空间，这一点在其它语言中是做不到的。\n","slug":"old-lua/2016-06-01-arrays","date":"2024-03-14T06:15:59.729Z","categories_index":"Lua,Arrays","tags_index":"Arrays","author_index":"安全书"},{"id":"9b97fd5c58ceb41de2e73474e4dfb1f8","title":"Lua基本语法","content":"基本语法Lua 学起来非常简单。现在，让我们开始创建我们的第一个 Lua 程序吧！  \n第一个 Lua 程序Lua 提供交互式编程模式。在这个模式下，你可以一条一条地输入命令，然后立即就可以得到结果。你可以在 shell 中使用 lua -i 或者 lua 命令启动。输入命令后，按下回车键，就启动了交互模式，显示如下:\n123$ lua -i $ Lua 5.1.4  Copyright (C) 1994-2008 Lua.org, PUC-Rioquit to end; cd, dir and edit also available\n\n\n\n\n你可以使用如下命令打印输出：  \n1$&gt; print(&quot;test&quot;)\n\n\n按下回车键后，你会得到如下输出结果：  \n1&#x27;test&#x27;\n\n默认模式编辑使用 Lua 文件做为解释器的参数启动解释器,然后开始执行文件直到文件结束。当脚本执行结束后，解释器就不在活跃了。 \n让我们写一个简单的 Lua 程序。所有的 Lua　文件都扩展名都是.lua。因此，将下面的源代码放到 test.lua 文件中。  \n1print(&quot;test&quot;)\n\n假如你已经设置好 Lua 程序的环境，用下面的命令运行程序：  \n1$ lua test.lua\n\n我们会得到如下的输出结果：  \n1test\n\n让我们尝试使用另外的方式运行 Lua 程序。下面是修改后的 test.lua 文件：  \n12#!/usr/local/bin/luaprint(&quot;test&quot;)\n\n这里，我们假设你的 Lua 解释器程序在 /usr/local/bin/lua 目录下。test.lua 文件中第一行由于以 # 开始而被解释器忽略，运行这个程序可以得到如下的结果：  \n12$ chmod a+rx test.lua$./test.lua\n\n我们会得到如下的的输出结果：  \n1test\n\n接下来让我们看一下 Lua 程序的基本结构。这样，你可以更容易理解 Lua 编程语言的基本结构单元。  \nLua 中的符号Lua 程序是由大量的符号组成的。这些符号可以分为关键字、标识符、常量、字符串常量几类。例如，下面的 Lua 语句中包含三个符号：  \n1io.write(&quot;Hello world, from &quot;,_VERSION,&quot;!\\n&quot;)\n\n这三个符号分别是:  \n1234io.write(&quot;Hello world, from &quot;,_VERSION,&quot;!\\n&quot;)\n\n注释注释就是 Lua 程序中的帮助文档，Lua 解释器会自动忽略它们。所有注释都以 –[[ 开始，并以 –]]结束。如下所示：  \n1--[[ my first program in Lua --]]\n\n标识符Lua 中标识符是识别变量、函数或者其它用户自定义项的名字。标符识总是以字母或者下划线开始，其后可以是零个或多个字母、下划线或数字。Lua 标识符中不允许出现任何标点符号，比如，@，$ 或者 %。Lua 是大小写敏感的语言，因此 Manpower 和 manpower 是 Lua 中两个不同的标识符。下面所列的是一些合法标识符的例子。  \n12mohd         zara      abc     move_name    a_123myname50     _temp     j       a23b9        retVal\n\n关键字下面列表中所示的是 Lua 中一小部分保留字。这些保留字不能用作常量、变量以及任何标识符的名字。  \n\n    \n    and\n    break\n    do\n    else\n    \n    \n    elseif\n    end\n    false\n    for\n    \n    \n    function\n    if\n    in\n    local\n    \n    \n    nil\n    not\n    or\n    repeat\n    \n    \n    return\n    then\n    true\n    until\n    \n    \n    while\n    \n    \n    \n    \n\n\nLua 中的空白符如果 Lua 程序中某一行只包含空格或者注释，那么这样的一行被称之为空行。 Lua 解释器将完全忽略这一行。在 Lua 中，空白是用来描述空格、制表符、换行符和注释的术语。空白符用于将语句中的一部分与其它部分区分开，使得解释器可以语句中的一个元素，比如 int，何处结束，以及另一个元素从何处开始。因此，在下面的语句中：  \n1local age\n\n在 local 与 age 之间至少有一个空白符（通常是空格）,这个空白符使得解释器可以将 local 与 age 区分开。另一方面，在下面的语句中：  \n1fruit = apples + oranges   --get the total fruit\n\nfruit 与 = 之间以及 = 与 apples 之间的空白符都是可以没有的。但是为了程序的可读性目的，建议你在它们之间使用空白符。\n","slug":"old-lua/2016-06-01-basic-syntax","date":"2024-03-14T06:15:59.729Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"1e07952645adeb0063307933aff99e35","title":"Break语句","content":"break 语句程序在解释执行过程中，在循环内遇到 break 语句时，循环将立即结束。程序将循环语句的下一条语句开始执行。如果你是在嵌套循环（即，一个循环内还有一个循环语句）内使用 break 语句，break 只结束内层循环，并从该代码块后的第一条语句处开始执行。  \n语法break 语句的语法如下所示：  \n1234567891011121314151617181920212223break;```  ## 流程图：  ![](images/break.jpg)  ## 示例  ```lua--[ 局部变量定义--]a = 10--[ 执行 while 循环--]while( a &lt; 20 )do   print(&quot;value of a:&quot;, a)   a=a+1   if( a &gt; 15)   then      --[ terminate the loop using break statement --]      break   endend\n\n执行上面的代码可以得到如下的结果：  \n123456value of a:\t10value of a:\t11value of a:\t12value of a:\t13value of a:\t14value of a:\t15\n\n\n\n","slug":"old-lua/2016-06-01-break","date":"2024-03-14T06:15:59.729Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"bce3027296f15638c976f1ebef15c96b","title":"Lua协程","content":"Lua 协程概述协程具有协同的性质，它允许两个或多个方法以某种可控的方式协同工作。在任何一个时刻，都只有一个协程在运行，只有当正在运行的协程主动挂起时它的执行才会被挂起（暂停）。 \n上面的定义可能看上去比较模糊。接下来让我讲得很清楚一点，假设我们有两个方法，一个是主程序方法，另一个是一个协程。当我们使用 resume 函数调用一个协程时，协程才开始执行。当在协程调用 yield 函数时，协程挂起执行。再次调用 resume 函数时，协程再从上次挂起的地方继续执行。这个过程一直持续到协程执行结束为止。  \n协程中可用的函数下面的表中列出 Lua 语言为支持协程而提供的所有函数以及它们的用法。  \n\n    \n        S.N.\n        方法和功能\n    \n    \n        1\n        coroutine.create(f):用函数 f 创建一个协程，返回 thread 类型对象。\n    \n    \n        2\n        coroutine.resume(co[,val1,...]): 传入参数（可选），重新执行协程 co。此函数返回执行状态，也可以返回其它值。\n    \n    \n        3\n        coroutine.running():返回正在运行的协程，如果在主线程中调用此函数则返回 nil。\n    \n    \n        4\n        coroutine.status(co):返回指定协程的状态，状态值允许为：正在运行(running)，正常(normal)，挂起(suspended)，结束(dead)。\n    \n    \n        5\n        coroutine.wrap(f):与前面 coroutine.create 一样，coroutine.wrap 函数也创建一个协程，与前者返回协程本身不同，后者返回一个函数。当调用该函数时，重新执行协程。\n    \n    \n        6\n        coroutine.yield(...):挂起正在执行的协程。为此函数传入的参数值作为执行协程函数 resume 的额外返回值（默认会返回协程执行状态）。\n    \n\n\n示例让我们通过下面的例子来理解一下协程这个概念。  \n1234567891011121314151617181920co = coroutine.create(function (value1,value2)   local tempvar3 =10   print(&quot;coroutine section 1&quot;, value1, value2, tempvar3)   local tempvar1 = coroutine.yield(value1+1,value2+1)   tempvar3 = tempvar3 + value1   print(&quot;coroutine section 2&quot;,tempvar1 ,tempvar2, tempvar3)   local tempvar1, tempvar2= coroutine.yield(value1+value2, value1-value2)   tempvar3 = tempvar3 + value1   print(&quot;coroutine section 3&quot;,tempvar1,tempvar2, tempvar3)   return value2, &quot;end&quot;end)print(&quot;main&quot;, coroutine.resume(co, 3, 2))print(&quot;main&quot;, coroutine.resume(co, 12,14))print(&quot;main&quot;, coroutine.resume(co, 5, 6))print(&quot;main&quot;, coroutine.resume(co, 10, 20))```  执行上面的程序，我们可以得到如下的输出结果：  \ncoroutine section 1    3    2    10main    true    4    3coroutine section 2    12    nil    13main    true    5    1coroutine section 3    5    6    16main    true    2    endmain    false    cannot resume dead coroutine\n123456789101112131415161718## 上面的例子到底做了些什么呢？  和前面说到的一样，在例子中我们使用 resume 函数继续执行协程，用 yield 函数挂起协程。同样，从例子中也可以看出如何为执行协程的 resueme 函数返回多个值。下面我将逐步解释上面的代码。  &lt;ul&gt;\t&lt;li&gt;首先，我们创建了一个协程并将其赋给变量 co。此协程允许传入两个参数。&lt;/li&gt;\t&lt;li&gt;第一次调用函数 resume 时，协程内局部变量 value1 和 value2 的值分别为 3 和 2。&lt;/li&gt;\t&lt;li&gt;为了便于理解，我们使用了局部变量 tempvar3 该变量被初始化为 10。由于变量 value1 的值为3，所以 tempvar3 在随后的协程调用过程中被先后更新为 13 和 16。&lt;/li&gt;\t&lt;li&gt;第一次调用 coroutine.yield 时，为 resume 函数返回了值 4 和 3，这两个值是由传入的参数 3，2 分别加 1 后的结果，这一点可以从 yield 语句中得到证实。除了显示指定的返回值外，resume 还收到隐式的返回值 true，该值表示协程执行的状态，有 true 和 false 两个可能取值。&lt;/li&gt;\t&lt;li&gt;上面的例子中，我们还应该关注在下一次调用 resume 时如何为协程传入参数。从例子中可以看到，coroutine.yield 函数返回后为两个变量赋值，该值即是第二次调用 resume 时传入的参数。这种参数传递的机制让可以结合前面传入的参数完成很多新的操作。&lt;/li&gt;\t&lt;li&gt;最后，协程中所有语句执行完后，后面的调用就会返回 false 状态，同时返回 &quot;cannot resume dead coroutine&quot;消息。&lt;/li&gt;&lt;/ul&gt;## 另一个协程的示例  下面这例子中的协程使用 yield 函数和 resume 函数依次返回数字 1 到 5。示例中，如果没有协程对象或对象已结束（dead），则重新创建一个新的协程对象；若协程已经存在，则执行已经存在的协程。  \nfunction getNumber()   local function getNumberHelper()      co = coroutine.create(function ()      coroutine.yield(1)      coroutine.yield(2)      coroutine.yield(3)      coroutine.yield(4)      coroutine.yield(5)      end)      return co   end   if(numberHelper) then      status, number = coroutine.resume(numberHelper);      if coroutine.status(numberHelper) == “dead” then         numberHelper = getNumberHelper()         status, number = coroutine.resume(numberHelper);      end      return number   else      numberHelper = getNumberHelper()      status, number = coroutine.resume(numberHelper);      return number   endendfor index = 1, 10 do   print(index, getNumber())end\n12执行上述的程序，我们可以得到如下的输出结果：  \n1    12    23    34    45    56    17    28    39    410    5\n```\n大家经常会把协程和多线程编程语言中的线程进行对比，但我们要明白，协程有着与线程类似的特性，但是协程与线程的区别在于协程不能并发，任意时刻只会有一个协程执行，而线程允许并发的存在。（译注：译者认为本质上协程其是就是线程，不过是用户态的线罢了，它将调度问题交由程序开发人员手动完成。）  \n我们通过控制程序执行顺序以满足获取某些临时信息的需求。配合全局变量的使用，协和会变得更加的灵活方便。\n","slug":"old-lua/2016-06-01-coroutines","date":"2024-03-14T06:15:59.729Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"5593d949c022c9556ceb62d288c587d5","title":"Lua数据库访问","content":"Lua 数据库访问简单的数据操作，我们用文件就可以处理。但是，某些时候文件操作存在性能、扩展性等问题。这时候，我们就需要使用数据库。LuaSQL 是一个提供数据库操作的库，它支持多种 SQL 数据库的操作。包括：  \n\n    SQLite\n    MySQL\n    ODBC\n  \n在本教程中，我们会讲解用 Lua 语言对 MySQL 数据库与 SQLite 数据库进行操作。这些操作具有一般性，它们也可以移植到其它类型 SQL 数据库中。首先让我们看一下如何操作 MySQL 数据库。  \n\nMySQL 数据库环境设置为了下面的例子可以正确演示，我们需要首先初始化数据库设置。我们假设你已经完成了如下的工作：  \n\n    安装 MySQL 数据库，使用默认用户名 root， 默认密码为： 123456。\n    已经创建数据库 test。\n    已经阅读过关于 MySQL 的基本教程，并掌握了 MySQL 的基本知识。\n  \n\n导入 MySQL假设你已经安装配置正确了，那么我们可以使用 require 语句导入 sqlite 库。安装过程中会产生一个存储数据相关文件的目录 libsql。  \n123456789mysql = require &quot;luasql.mysql&quot;```  我们可以通过 mysql 变量访问 luasql.mysql 中的 mysql 表，该表中存存储数据库操作相关的函数。### 建立连接 先初始化 MySQL 的环境，再建立一个连接。如下所示：  \nlocal env  = mysql.mysql()local conn = env:connect(‘test’,’root’,’123456’)\n1234567上面的程序会与已存在的 MySQL 数据库 test 建立连接。### 执行函数LuaSQL 库中有一个 execute 函数，此函数可以完成所有数据加操作，包括创建、插入、更新等操作。其语法如下所示：  \nconn:execute([[ ‘MySQLSTATEMENT’ ]])\n1234567执行上面的语句这前，我们需要保证与 MySQL 数据库的连接 conn 是打开的，同时将 MySQLSTATEMENT 更改为合法的 SQL 语句。  ### 创建表下面的示例演示如何创建一个数据库表。例子中为表创建了两个属性分别为 id 和 name，其类型分别为整数和 vchar。  \nmysql = require “luasql.mysql”\nlocal env  = mysql.mysql()local conn = env:connect(‘test’,’root’,’123456’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample2 (id INTEGER, name TEXT);]])print(status,errorString )\n123运行上面的程序后，数据库中创建了一个表 sample，该表有两列，属性名分别为 id 和 name。\nMySQL environment (004BB178)    MySQL connection (004BE3C8)0    nil\n123如果发生错误，则函数将返回一个错误消息，成功执行则返回 nil。下面是错误消息的一个例子：  \nLuaSQL: Error executing query. MySQL: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘“id INTEGER, name TEXT)’ at line 1\n12345### 插入语句  ＭySQL 插入语句的示例如下所示：  \n conn:execute([[INSERT INTO sample values(‘11’,’Raj’)]])\n12345### 更新语句  ＭySQL 更新语句的示例如下所示：  \nconn:execute([[UPDATE sample3 SET name=’John’ where id =’12’]])\n12345### 删除语句  ＭySQL 删除语句的示例如下所示：  \nconn:execute([[DELETE from sample3 where id =’12’]])\n12345### 查找语句   成功查找返回后，我们需要循环遍历返回的所有行以取得我们需要的数据。查找语句的示例如下：  \ncursor,errorString = conn:execute([[select * from sample]])row = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  – reusing the table of results  row = cursor:fetch (row, “a”)end\n1234567上面的代码中，我们先打开了一个 MySQL 连接。通过 execute 函数返回的游标(cursor)，我们可以使用游标遍历返回的表，取得我们查找的数据。### 完整示例  下面这个例子用到了所有上面提到的数据的操作函数，请看下面这个完整的例子：  \nmysql = require “luasql.mysql”\nlocal env  = mysql.mysql()local conn = env:connect(‘test’,’root’,’123456’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample3 (id INTEGER, name TEXT)]])print(status,errorString )\nstatus,errorString = conn:execute([[INSERT INTO sample3 values(‘12’,’Raj’)]])print(status,errorString )\ncursor,errorString = conn:execute([[select * from sample3]])print(cursor,errorString)\nrow = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  row = cursor:fetch (row, “a”)end– close everythingcursor:close()conn:close()\n123运行上面的程序，我们可以得到如下的输出结果：  \nMySQL environment (0037B178)    MySQL connection (0037EBA8)0    nil1    nilMySQL cursor (003778A8)    nilId: 12, Name: Raj\n12345678910111213141516## 执行事务  事务是数据库中保证数据一致性的一种机制。事务有以下四个性质：  &lt;ul&gt;\t&lt;li&gt;原子性：一个事务要么全部执行要么全部不执行。&lt;/li&gt;\t&lt;li&gt;一致性：事务开始前数据库是一致状态，事务结束后数据库状态也应该是一致的。&lt;/li&gt;\t&lt;li&gt;隔离性：多个事务并发访问时，事务之间是隔离的，一个事务的中间状态不能被其它事务可见。&lt;/li&gt;\t&lt;li&gt;持久性： 在事务完成以后，该事务所对数据库所做的更改便持久的保存在数据库之中，并不会被回滚。&lt;/li&gt;\t&lt;/ul&gt;事务以 START_TRANSACTION 开始，以 提交（commit）或 回滚（rollback）语句结束。  ### 事务开始  为了初始化一个事务，我们需要先打开一个 MySQL 连接，再执行如下的语句：  \nconn:execute([[START TRANSACTION;]])\n12345### 事务回滚  当需要取消事务执行时，我们需要执行如下的语句回滚至更改前的状态。\nconn:execute([[ROLLBACK;]])\n12345### 提交事务  开始执行事务后，我们需要使用 commit 语句提交完成的修改内容。\nconn:execute([[COMMIT;]])\n1234567前面我们已经了解了 MySQL 的基本知识。接下来，我们将解释一下基本的  SQL 操作。请记住事务的概念，虽然我们在 SQLite3 中我们不在解释它，但是它的概念在 SQLite3 中同样适用。  ## 导入 SQLite 假设你已经安装配置正确了，那么就可以使用 require 语句导入 sqlite 库。安装过程中会产生一个存储数据相关文件的目录 libsql。  \n sqlite3 = require “luasql.sqlite3”\n1234567通过 sqlite3 变量可以访问提供的所有数据库操作相关函数。  ### 建立连接  我们先初始化 sqlite 环境，然后为该环境创建一个连接。语法如下：  \nlocal env  = sqlite3.sqlite3()local conn = env:connect(‘mydb.sqlite’)\n1234567上面的代码会与一个 sqlite 文件建立连接，如果文件不存在则创建新的 sqlite 文件并与该新文件建立连接。  ### 执行函数  LuaSQL 库中有一个 execute 函数，此函数可以完成所有数据加操作，包括创建、插入、更新等操作。其语法如下所示：  \nconn:execute([[ ‘SQLite3STATEMENT’ ]])\n1234567执行上面的语句这前，我们需要保证与 MySQL 数据库的连接 conn 是打开的，同时将 SQLite3STATEMENT 更改为合法的 SQL 语句。  ### 创建表下面的示例演示如何创建一个数据库表。例子中为表创建了两个属性分别为 id 和 name，其类型分别为整数和 vchar。  \nsqlite3 = require “luasql.sqlite3”\nlocal env  = sqlite3.sqlite3()local conn = env:connect(‘mydb.sqlite’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample (‘id’ INTEGER, ‘name’ TEXT)]])print(status,errorString )\n123运行上面的程序后，数据库中创建了一个表 sample，该表有两列，属性名分别为 id 和 name。\nSQLite3 environment (003EC918)    SQLite3 connection (00421F08)0    nil\n123如果发生错误，则函数将而一个错误消息；若成功执行则返回 nil。下面是错误消息的一个例子：  \nLuaSQL: unrecognized token: “”‘id’ INTEGER, ‘name’ TEXT)”\n12345### 插入语句  插入语句的示例如下所示：  \n conn:execute([[INSERT INTO sample values(‘11’,’Raj’)]])\n12345### 查找语句   查找返回后，我们需要循环遍历每行以取得我们需要的数据。查找语句的示例如下：  \ncursor,errorString = conn:execute([[select * from sample]])row = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  – reusing the table of results  row = cursor:fetch (row, “a”)end\n12345678上面的代码中，我们先打开了一个 sqlite3 连接。通过 execute 函数返回的游标(cursor)，我们可以遍历返回的表，以取得我们查找的数据。### 完整示例  下面这个例子用到了所有上面提到的数据的操作函数，请看下面这个完整的例子： \nsqlite3 = require “luasql.sqlite3”\nlocal env  = sqlite3.sqlite3()local conn = env:connect(‘mydb.sqlite’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample (‘id’ INTEGER, ‘name’ TEXT)]])print(status,errorString )\nstatus,errorString = conn:execute([[INSERT INTO sample values(‘1’,’Raj’)]])print(status,errorString )\ncursor,errorString = conn:execute([[select * from sample]])print(cursor,errorString)\nrow = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  row = cursor:fetch (row, “a”)end– close everythingcursor:close()conn:close()env:close()\n123运行上面的程序，我们可以得到如下的输出结果：  \nSQLite3 environment (005EC918)    SQLite3 connection (005E77B0)0    nil1    nilSQLite3 cursor (005E9200)    nilId: 1, Name: Raj\n\n使用 libsql 库我们可以执行所有的数据库操作。所以，看完这些例子后，请自己多做一些练习。\n\n","slug":"old-lua/2016-06-01-database-access","date":"2024-03-14T06:15:59.729Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"374513b04e64d95f7bc41ddb08581b8d","title":"Lua调试","content":"Lua 调试Lua 提供一个调试库，这个库中提供了创建自己的调试器所需的所有原语函数。虽然，Lua 没有内置调试器，但是开发者们为 Lua 开发了许多的开源调试器。 \nLua 调试库包括的函数如下表所示。\n\n    \n        S.N.\n        方法和描述\n    \n    \n    1\n        debug():进入交互式调试模式，在此模式下用户可以用其它函数查看变量的值。\n    \n    \n        2\n        getfenv(object):返回对象的环境。\n    \n    \n        3\n        gethook(optional thread)：返回线程当前的钩子设置，总共三个值：当前钩子函数、当前的钩子掩码与当前的钩子计数。\n    \n    \n        4\n        getinfo(optional thread,function or stack leve,optional flag)：返回保存函数信息的一个表。你可以直接指定函数，或者你也可以通过一个值指定函数，该值为函数在当前线程的函数调用栈的层次。其中，0 表示当前函数（getinfo 本身）；层次 1 表示调用 getinfo 的函数，依次类推。如果数值大于活跃函数的总量，getinfo 则返回 nil。\n    \n    \n        5\n        getlocal(optional thread,stack level,local index)：此函数返回在 level 层次的函数中指定索引位置处的局部变量和对应的值。如果指定的索引处不存在局部变量，则返回 nil。当 level 超出范围时，则抛出错误。\n    \n    \n        6\n        getmetatable(value)：返回指定对象的元表，如果不存在则返回 nil。\n    \n    \n        7\n        getregistry()：返回寄存器表。寄存器表是一个预定义的用于 C 代码存储 Lua 值的表。\n    \n    \n        8\n        getupvalue(func function,upvalue index)：根据指定索引返回函数 func 的 upvalue 值（译注：upvalue 值与函数局部变量的区别在于，即使函数并非活跃状态也可能有 upvalue 值，而非活跃函数则不存在局部变量，所以其第一个参数不是栈的层次而是函数）。如果不存在，则返回 nil。\n    \n    \n        9\n        setfenv(function or thread or userdata,environment table)：将指定的对象的环境设置为 table,即改变对象的作用域。\n    \n    \n        10\n        sethook(optional thread,hook function,hook mask string with \"c\" and/or \"r\" and/or \"l\",optional instruction count)：把指定函数设置为钩子。字符串掩码和计数值表示钩子被调用的时机。这里，c 表示每次调用函数时都会执行钩子；r 表示每次从函数中返回时都调用钩子；l 表示每进入新的一行调用钩子。\n    \n    \n        11\n        setlocal(optional thread,stack level,local index,value):在指定的栈深度的函数中，为 index 指定的局部变量赋予值。如果局部变量不存在，则返回 nil。若 level 超出范围则抛出错误；否则返回局部变量的名称。\n    \n    \n        12\n        setmetatable(value,metatable):为指定的对象设置元表，元表可以为 nil。\n    \n    \n        13\n        setupvalue(function,upvalue index,value):为指定函数中索引指定的 upvalue 变量赋值。如果 upvalue 不存在，则返回 nil。否则返回此 upvalue 的名称。\n    \n    \n        14\n        traceback(optional thread,optional meesage string,opitona level argument)：用 traceback 构建扩展错误消息。\n    \n\n\n上面的表中列出了 Lua 的全部调试函数，我们经常用到的调试库都会用到上面的函数，它让调试变得非常容易。虽然提供了便捷的接口，但是想要用上面的函数创建一个自己的调试器并不是件容易的事。无论怎样，我们可以看一下下面这个例子中怎么使用这些调试函数的。  \n12345678function myfunction ()print(debug.traceback(&quot;Stack trace&quot;))print(debug.getinfo(1))print(&quot;Stack trace end&quot;)\treturn 10endmyfunction ()print(debug.getinfo(1))\n\n执行上面的程序，我们可以得到如下的栈轨迹信息：  \n123456789101112131415Stack tracestack traceback:\ttest2.lua:2: in function &#x27;myfunction&#x27;\ttest2.lua:8: in main chunk\t[C]: ?table: 0054C6C8Stack trace end```  上面的例子中，我们使用 debug.trace 函数输出了栈轨迹。 debug.getinfo 函数获得函数的当前表。  ## 示例二  在调试过程中，我们常常需要查看或修改函数局部变量的值。因此，我们可以用 getupvalue 获得变量的值，用 setupvalue 修改变量的值。示例如下：  \nfunction newCounter ()  local n = 0  local k = 0  return function ()    k = n    n = n + 1    return n    endend\ncounter = newCounter ()print(counter())print(counter())\nlocal i = 1\nrepeat  name, val = debug.getupvalue(counter, i)  if name then    print (“index”, i, name, “=”, val)    if(name == “n”) then        debug.setupvalue (counter,2,10)    end    i = i + 1  end – ifuntil not name\nprint(counter())\n123运行上面的程序，我们可以得到如下面的输出结果：  \n12index    1    k    =    1index    2    n    =    211\n```  \n在这个例子中，每次调用 counter 都会更新该闭包函数。我们可以通过 getupvalue 查看其当前的局部变量值。随后，我们更新局部变量的值。在为 n 设置新值之前，其值为 2。调用 setupvalue 后，n 被设置为 10。再调用 counter 时，它就会返回值 11 而不再是 3。  \n调试类型\n    命令行调试\n    图形界面调试\n\n\n命令行调试工具命令行调试就是使用命令行命令和 print 语句来调试程序。已经有许多现成的 Lua 命令行调试工具，下面列出了其中的一部分：\n\nRemDebug：RemDebug 是一个远程的调试器，它支持 Lua 5.0 和 5.1 版本。允许远程调试 Lua 程序，设置断点以及查看程序的当前状态。同时，它还能调试 CGILua 脚本。\nclidebugger：此调试器是用纯 Lua 脚本开发的命令行调试工具，支持 Lua 5.1。除了 Lua 5.1 标准库以外，它不依赖于任何其它的 Lua 库。虽然它受到了 RemDebug 影响而产生的，但是它没有远程调试的功能。\nctrace：跟踪 Lua API 调用的小工具。\nxdbLua：windows 平台下的 Lua 命令行调试工具。\nLuaInterface - Debuger：这个项目是 LuaInterface 的扩展，它对 Lua 调试接口进行进一步的抽象，允许通过事件和方法调用的方式调试程序。\nRIdb：使用套接字的远程 Lua 调试器，支持 Linux 和 Windows 平台。它的特性比任何其它调试器都丰富。\nModDebug：允许远程控制另外一个 Lua　程序的执行、设置断点以及查看程序的当前状态。\n\n图形界面调试工具图形界面的调试工具往往和集成开发环境（IDE）打包在一起。它允许在可视环境下进行调试，比如查看变量值，栈跟踪等。通过 IDE 的图形界面，你可以设置断点单步执行程序。  \n下面列出了几种图形界面的调试工具。  \n\n    SciTE：Windows 系统上默认的 Lua 集成开发环境，它提供了丰富的调试功能，比如，断点、单步、跳过、查看变量等等。\n    Decoda：一个允许远程调试的图形界面调试工具。\n    ZeroBrane Studio：一个 Lua 的集成开发环境，它集成了远程调试器、栈视图、远程控制终端、静态分析等诸多功能。它兼容各类 Lua 引擎，例如 LuaJIT,Love2d,Moai等。支持 Windows, OSX, Linux；开源。\n    akdebugger：eclipse 的 Lua 调试器和编辑器插件。\n    luaedit：支持运程调试、本地调试、语法高亮、自动补完、高级断点管理（包括有条件地触发断和断点计数）、函数列表、全局和本地变量列表、面对方案的管理等。\n","slug":"old-lua/2016-06-01-debugging","date":"2024-03-14T06:15:59.729Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"a760ef6d11a2d6078a812f5bc31cf898","title":"数据类型","content":"数据类型Lua 是动态类型编程语言，变量没有类型，只有值才有类型。值可以存储在变量中，作为参数传递或者作为返回值。尽管在 Lua 中没有变量数据类型，但是值是有类型的。下面的列表中列出了数据类型： \n\n    \n        值类型\n        描述\n    \n    \n        nil\n        用于区分值是否有数据，nil 表示没有数据。\n    \n    \n        boolean\n        布尔值，有真假两个值，一般用于条件检查。\n    \n    \n        number\n        数值，表示实数(双精度浮点数)。\n    \n    \n        string\n        字符串。\n    \n    \n        function\n        函数，表示由 C 或者 Lua 写的方法。\n    \n    \n        userdata\n        表示任意 C 数据。\n    \n    \n        thread\n        线程，表示独立执行的线程，它被用来实现协程。\n    \n    \n        table\n        表，表示一般的数组，符号表，集合，记录，图，树等等，它还可以实现关联数组。它可以存储除了 nil 外的任何值。\n    \n \n \ntype 函数Lua　中有一个 type　函数，它可以让我们知道变量的类型。下面的代码中给出了一些例子：　　\n123456789101112print(type(&quot;What is my type&quot;))   --&gt; stringt=10print(type(5.8*t))               --&gt; numberprint(type(true))                --&gt; booleanprint(type(print))               --&gt; functionprint(type(type))                --&gt; functionprint(type(nil))                 --&gt; nilprint(type(type(ABC)))           --&gt; string```  在 Linux 系统中运行上面的代码可以得到如下的结果：  \nstringnumberfunctionfunctionbooleannilstring\n\n默认情况下，在被初始化或赋值前，所有变量都指向 nil。 Lua 中空字符串和零在条件检查时，都被当作真。所以你在使用布尔运算的时候要特别注意。在下一章中，我们会了解到更多关于这些类型的知识。\n\n","slug":"old-lua/2016-06-01-data-types","date":"2024-03-14T06:15:59.729Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"d6286a3606fee451e0f5f2e41e7f6205","title":"Lua判断","content":"决策决策结构要求程序开发人员设置一个或多测试或计算条件。如果条件计算结果为真，则执行一个或多个语句；如果条件为假，则执行另外的语句。 \n下面是大多数程序语言中的决策结构的一般形式：  \n  \nLua 语言中所有布尔真和非 nil 值都当作真；把所有的布尔假和 nil 作为假。请注意，Lua 中的零会被当作真，而其它大部分语言会将零当作假。\nLua 语言提供了如下几类决策语句。点击下面的链接查看详细内容。\n\n    \n        语句\n        描述\n    \n    \n        if 语句\n        if 语句中包括一个布尔表达式和一个或多个语句。\n    \n    \n        if...else 语句\n        if 语句也可以选择和 esle 语句一起使用。当条件为假时，则执行 else 语句。\n    \n    \n        嵌套 if 语句\n        在 if 语句或者 else if 语句内使用　if 或者 else if。\n    \n","slug":"old-lua/2016-06-01-decision-making","date":"2024-03-14T06:15:59.729Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"5489aee09b1e0d4c387a202c68b698a4","title":"Obsidian插件实现","content":"Obsidian插件实现Obsidian插件是用什么语言编写的 ，如何写一个简单的Obsidian插件?\nObsidian插件是用JavaScript编写的。下面是一个简单的Obsidian插件的示例：\n\n创建一个新文件夹，命名为”my-plugin”（你可以使用任何你喜欢的文件夹名称）。\n在该文件夹中创建一个名为”main.js”的文件。\n在main.js中添加以下代码：\n\n12345678module.exports = &#123;    onload: function() &#123;        console.log(&#x27;Hello from my plugin!&#x27;);    &#125;,    onunload: function() &#123;        console.log(&#x27;Goodbye from my plugin!&#x27;);    &#125;&#125;;\n\n\n创建一个名为”manifest.json”的文件，并添加以下内容：\n\n12345678&#123;  &quot;id&quot;: &quot;my-plugin&quot;,  &quot;name&quot;: &quot;My Plugin&quot;,  &quot;version&quot;: &quot;0.1.0&quot;,  &quot;description&quot;: &quot;A simple Obsidian plugin.&quot;,  &quot;author&quot;: &quot;Your Name&quot;,  &quot;main&quot;: &quot;./main.js&quot;&#125;\n\n\n打开Obsidian应用程序，在设置中启用开发者模式。\n在Obsidian侧边栏中找到“Community plugins”选项并点击。\n点击“开发人员设置”按钮，然后点击“加载插件”按钮。\n在弹出的对话框中选择你所创建的插件文件夹（即”my-plugin”）。\n插件将被加载并执行，在控制台中应该会打印出”Hello from my plugin!”。\n每次你在main.js中进行更改之后，都需要重新加载插件才能看到更新。\n\n这只是一个简单的示例，你可以根据自己的需求在main.js中编写更复杂的逻辑。你还可以在manifest.json中定义其他属性，如图标、依赖项等。要了解更多关于Obsidian插件开发的详细信息，请参阅官方文档。\n写一个Obsidian的Hello World的插件\n要编写一个Obsidian的Hello World插件，你需要按照以下步骤进行操作：\n\n创建一个新的文件夹，作为插件项目的根目录。\n在该文件夹中创建一个名为main.js的JavaScript文件，作为插件的入口点。\n在main.js中编写以下代码：\n\n12345module.exports = &#123;    activate: function() &#123;        console.log(&quot;Hello World!&quot;);    &#125;&#125;\n\n\n在根目录中创建一个名为manifest.json的JSON文件，用于描述插件的元数据信息。在该文件中编写以下代码：\n\n12345678&#123;    &quot;id&quot;: &quot;hello-world&quot;,    &quot;name&quot;: &quot;Hello World&quot;,    &quot;version&quot;: &quot;1.0.0&quot;,    &quot;description&quot;: &quot;A Hello World plugin for Obsidian.&quot;,    &quot;author&quot;: &quot;Your Name&quot;,    &quot;main&quot;: &quot;./main.js&quot;&#125;\n\n\n打开Obsidian，在设置中启用开发者模式。然后点击“开发者工具”菜单。\n在开发者工具中，点击“加载插件”按钮，并选择插件项目根目录。\n插件将被加载，并在控制台输出“Hello World!”。\n\n这样就成功创建了一个简单的Hello World插件。你可以根据自己的需求进一步扩展和定制该插件。\n如何看Obsidian的控制台，还有插件输出的调试信息？\n要查看Obsidian的控制台，可以按下键盘上的Ctrl + Shift + I，这将打开开发者工具。然后，点击面板上的”Console”选项卡，你就可以看到控制台输出的信息了。\n如果你使用的是插件，并且希望查看插件输出的调试信息，可以在控制台中输入以下命令：\n1app.plugins.enableDevMode()\n\n这将启用插件的开发者模式，并显示插件输出的更多详细信息。然后，你就可以在控制台中查看插件输出的调试信息了。\n请注意，如果你遇到任何问题或错误，请将相关的调试信息包含在报告中，以便开发人员更好地理解并解决问题。\n在实行Obsidian插件的时候，显示下面的话是什么意思？app.js:1 Plugin failure: candylab-plugin TypeError: l is not a constructor\n为什么，如何解决这个问题\n这个错误通常表示在加载Obsidian插件时出现了问题。具体来说，这个错误说明了在加载插件”candylab-plugin”时发生了一个类型错误，其中l不是一个构造函数。\n要解决这个问题，你可以尝试以下几步：\n\n更新插件：检查是否有可用的更新版本，如果有，请尝试更新插件以查看是否能够解决该问题。\n\n插件兼容性：确保插件与当前版本的Obsidian兼容。某些插件可能不支持最新的Obsidian版本，因此你可以尝试禁用该插件或寻找其他替代方案。\n\n重新安装插件：有时，重新安装插件可以修复加载问题。通过在Obsidian中禁用并重新启用该插件来尝试重新安装它。\n\n寻求帮助：如果上述步骤都无法解决问题，你可以考虑向插件开发者寻求帮助。在Obsidian论坛或相关的社区中提问，并提供更详细的错误信息和步骤，以便其他人能够更好地帮助你解决问题。\n\n\n请注意，这只是一些常见的解决步骤，并不能保证对所有情况都有效。具体问题可能需要进一步调查和定位才能找到最佳解决方案。\nhttps://luhaifeng666.github.io/obsidian-plugin-docs-zh/zh2.0/events.html\n：写一个.ts语言实现的obsidian插件\n下面是一个简单的 TypeScript 语言实现的 Obsidian 插件示例：\n123456789101112131415161718192021222324252627282930import &#123; Plugin, MarkdownView, EditorPosition &#125; from &#x27;obsidian&#x27;;export default class MyPlugin extends Plugin &#123;    async onload() &#123;        console.log(&#x27;My plugin loaded&#x27;);        // 注册一个命令，用于在当前光标位置插入文本        this.addCommand(&#123;            id: &#x27;insert-text&#x27;,            name: &#x27;Insert Text&#x27;,            callback: () =&gt; &#123;                const activeView = this.app.workspace.getActiveViewOfType(MarkdownView);                if (activeView) &#123;                    const editor = activeView.editor;                    const cursor = editor.getCursor();                    editor.replaceRange(&#x27;Hello, World!&#x27;, cursor);                &#125;            &#125;        &#125;);        // 在文档加载完成后执行一些操作        this.registerEvent(this.app.workspace.on(&#x27;markdown:file-open&#x27;, (file) =&gt; &#123;            console.log(`Markdown file opened: $&#123;file.path&#125;`);        &#125;));    &#125;    onunload() &#123;        console.log(&#x27;My plugin unloaded&#x27;);    &#125;&#125;\n\n这个示例插件实现了两个功能：\n\n注册了一个命令 insert-text，当执行该命令时，在当前光标位置插入文本 “Hello, World!”。\n在文档加载完成后打印日志信息。\n\n要使用这个插件，你需要在 Obsidian 的插件设置中启用开发者模式，并将该 TypeScript 文件放置在你的插件目录下。然后重新加载 Obsidian 插件即可使用。\nhttps://forum-zh.obsidian.md/t/topic/19904\nhttps://github.com/thmed/obsidian-vue-sample-plugin/tree/main\n","slug":"obsidian/Obsidian插件实现","date":"2024-03-14T06:15:59.728Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"5f58f8177c391899cad1f2d5f235d2b7","title":"Obsidian的Dataview和Database插件","content":"Obsidian的Dataview和Database插件Obsidian的两个很有多的插件：Dataview和Database。\n这两个插件可以做相反的两个操作。\nA).Dataview插件提供了一种类似SQL的功能，可以用类似SQL语言， 让不是计算机专业的人，通过类似SQL的结构化查询语言对各种文章进行查询，其中有一个功能就是把符合某一条件的文件列出一个表格。\n例如下面的这句Dataview的QL描述：\n123table title,tags,categorieswhere contains(categories,&quot;AIGC&quot;)\n\n\nB).Database插件， 是在你所在当前目录创建一个数据库， 创建一个二维关系表，如果当前文件夹没有文件，那表格是空格， 在表格上创建一行， 就在当前目录生成一个markdown文件。\n如果有文件在当前文件夹， 创建数据库的时候， 就会把这些文件作为记录行，自动显示在表格里。\nDataview可以通过QL把文件显示成表， Database可以创建一个表，对应生成很多的文件对应名称的文件。\nDataview插件、是一个让Obsidian强大的检索系统。Database插件、让Obsidian笔记的组织更方便，超越了简单目录管理。\n#obsidian[超话]# \n","slug":"obsidian/Obsidian的Dataview和Database插件","date":"2024-03-14T06:15:59.728Z","categories_index":"obsidian","tags_index":"dataview,database","author_index":"安全书"},{"id":"211df99c937bc699c0f7bf5b7ef17ea0","title":"将AI功能引入Obsidian：提供强大的语义搜索和生成式问答功能","content":"将AI功能引入Obsidian：提供强大的语义搜索和生成式问答功能【Obsidian AI：将AI功能引入Obsidian，提供强大的语义搜索和生成式问答功能】’Obsidian AI - Adding powerful semantic search, generative answers, and other AI tools to Obsidian, using Supabase + OpenAI.’ Sudharshan GitHub: github.com/solderneer/obsidian-ai-tools\nObsidian+Zotero 通过插件整合，这个workflow 很优雅。用习惯了后读 PDF 应该更高效，从语言学习的角度看，来回跳转加导出注释也可以加强记忆。比如读每期的 TE，边读边做笔记，然后把笔记同步到 Obsidian。每周读完再整理这些笔记注释，遇到一些 recall 费劲的地方就一键定位到原文，用语境辅助加强记忆。\n","slug":"obsidian/将AI功能引入Obsidian：提供强大的语义搜索和生成式问答功能","date":"2024-03-14T06:15:59.728Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Lua基础教程permalink: /lua_guide/Home/\n","slug":"old-lua/2016-06-01-Home","date":"2024-03-14T06:15:59.728Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"70e37000c4501be47c28421aeabc9737","title":"templater插件startup template","content":"templater插件startup templateObsidian的templater插件中的startup template的作用是什么？\n在Obsidian的templater插件中，startup template是指在创建新的笔记时自动应用的模板。它的作用是为用户提供一个默认的笔记结构和内容，以便快速开始工作。通过设置startup template，用户可以定义自己想要的笔记格式，并在创建新笔记时自动应用该模板，节省了手动设置每个笔记格式的时间和精力。这样可以提高效率，并确保所有笔记都具有一致性和结构性。\n","slug":"obsidian/templater插件startup template","date":"2024-03-14T06:15:59.728Z","categories_index":"obsidian","tags_index":"templater","author_index":"安全书"},{"id":"0b3bcfb42c003daa901d515f506140a6","title":"Clickhouse在Mac M1 MBP上安装","content":"Clickhouse在Mac M1 MBP上安装sudo su -cd /opt\n要下载ARM64版本的安装程序，才可能苹果M1笔记本上安装。\ncurl -O ‘https://builds.clickhouse.com/master/macos-aarch64/clickhouse&#39;     &amp;&amp; chmod a+x ./clickhouse./clickhouse install\n./clickhouse install –binary-path=/usr/local/bin\nClickHouse has been successfully installed.\nStart clickhouse-server with:\nsudo clickhouse start\nStart clickhouse-client with:\nclickhouse-client –password\n指定目录安装clickhouse install –binary-path=/usr/local/bin\n指定目录启动clickhouse start –binary-path=/usr/local/bin\n这样在M1笔记本上半Mac最方便的，比Docker和本地编辑Clickhouse的CPP版本都方便。\nPS：https://djcurtis.me/installing-clickhouse-on-an-m1-mac.htmlhttps://clickhouse.com/docs/en/install\n","slug":"obsidian/database/Clickhouse在Mac M1 MBP上安装","date":"2024-03-14T06:15:59.728Z","categories_index":"database","tags_index":"ClickHouse","author_index":"安全书"},{"id":"ee05b15db07ec905bf57ae6a80e0b3db","title":"database插件","content":"database插件LLMMeta 70B的大模型\nhttps://labs.perplexity.ai/?continueFlag=b4666e2398caed8b0b3874d42e9b49b2\n","slug":"obsidian/database/database插件","date":"2024-03-14T06:15:59.728Z","categories_index":"obsidian","tags_index":"插件","author_index":"安全书"},{"id":"b1741c411ff3533be8f96d1741185264","title":"Clickhouse的SQL","content":"Clickhouse的SQLselect * from xxx_main_all where date=’2024-02-04’ limit 10\n","slug":"obsidian/database/Clickhouse的SQL","date":"2024-03-14T06:15:59.728Z","categories_index":"database","tags_index":"clickhouse","author_index":"安全书"},{"id":"cb5fe6c2b1cfab8a63443052c075ad8b","title":"Perplexity宣布B轮7360万美元融资","content":"Perplexity宣布B轮7360万美元融资AI搜索工具Perplexity宣布B轮7360万美元融资，估值达到5.2亿美元。 \n下面是这轮融资的一些信息：  \nPerplexity的月活跃用户增长到了1000万，并在2023年处理了超过50亿次查询。iOS和Android应用安装量超过100万。  \n投资者包括NEA、Elad Gil、Nat Friedman和Databricks的支持，以及新的投资者NVIDIA、Jeff Bezos（通过Bezos Expeditions Fund）、Tobi Lutke、Bessemer Ventures、Naval Ravikant等。  \nB轮7360万美元融资，估值达到5.2亿美元，总融资已经达到了1亿美元。\nhttps://blog.perplexity.ai/blog/perplexity-raises-series-b-funding-round?continueFlag=8c6b6dc8b4c21a95d8200f5093660247\n","slug":"news/Perplexity宣布B轮7360万美元融资","date":"2024-03-14T06:15:59.727Z","categories_index":"AIGC,news","tags_index":"news","author_index":"安全书"},{"id":"72c18236192225748cd4bbf4416994df","title":"《纯数学课程》-哈代 LaTeX 代码下载","content":"《纯数学课程》-哈代 LaTeX 代码下载发布于 2023-12-30 23:19:07\nA Course of Pure Mathematics（纯数学课程）是英国数学家G. H. Hardy和E. M. Wright合著的一部数学教科书，首次出版于1934年。这本书涵盖了纯数学的基础内容，包括集合论、代数、几何和分析。\nA Course of Pure Mathematics是一部经典的数学教材，被广泛使用于世界各地的大学和研究机构。这本书的特点是内容全面、逻辑严密、语言简洁明了。书中还包含了大量练习题，帮助读者巩固所学知识。\nA Course of Pure Mathematics的结构如下：\n\n第一卷：集合论、代数和函数论\n第二卷：几何\n第三卷：分析\n\n第一卷介绍了数学的基础概念，包括集合、函数、代数式和函数方程。\n第二卷介绍了几何的基础概念，包括点、线、平面、空间、图形和几何体。\n第三卷介绍了分析的基础概念，包括实数、复数、微积分和积分。\nA Course of Pure Mathematics是一本难度适中的数学教材，适合有一定数学基础的读者学习。这本书可以帮助读者建立起纯数学的基础知识，为进一步学习高等数学奠定基础。\n其电子书放在 Project Gutenberg，这是一个非营利组织，致力于使世界各地的人们能够自由访问文化和知识。\n电子书的地址：https://gutenberg.org/ebooks/38769\n提供了其电子书和 21 M 的电子书对应的 LaTeX 代码，真正是超级福利了。有兴趣可以下载观瞻观瞻。Happy LaTeXing！~\n\n","slug":"math/《纯数学课程》-哈代 LaTeX 代码下载","date":"2024-03-14T06:15:59.727Z","categories_index":"AIGC,math","tags_index":"weibo","author_index":"安全书"},{"id":"d7ccd0a2fc5b38ef8ee1737116d9945c","title":"函数","content":"函数用Python画出一个一元二次方程的坐标图像\n要画出一个一元二次方程的坐标图像，首先需要导入matplotlib库，并定义方程。然后，生成x轴的数值范围，并根据方程计算对应的y轴数值。最后，使用plot函数将x和y轴的数值绘制成图像。下面是一个示例代码：\n123456789101112131415import matplotlib.pyplot as pltimport numpy as npdef quadratic_equation(x):    return x**2 + 2*x + 1x = np.linspace(-10, 10, 100)y = quadratic_equation(x)plt.plot(x, y)plt.xlabel(&#x27;x&#x27;)plt.ylabel(&#x27;y&#x27;)plt.title(&#x27;Quadratic Equation&#x27;)plt.grid(True)plt.show()\n\n这段代码会画出一条抛物线形状的图像，表示一元二次方程y = x^2 + 2x + 1。\n用Python画出一个一元二次方程的坐标图像，并求两点都大于的0的两点的导数，画出图像。\n下面是用Python绘制一元二次方程的坐标图像的代码：\n12345678910111213141516171819import numpy as npimport matplotlib.pyplot as pltdef quadratic_equation(x, a, b, c):    return a*x**2 + b*x + ca = 1  # 二次项系数b = -2  # 一次项系数c = -3  # 常数项x = np.linspace(-10, 10, num=100)  # x轴取值范围为-10到10，总共100个点y = quadratic_equation(x, a, b, c)plt.plot(x, y)plt.xlabel(&#x27;x&#x27;)plt.ylabel(&#x27;y&#x27;)plt.title(&#x27;Quadratic Equation&#x27;)plt.grid(True)plt.show()\n\n运行上述代码，将得到一元二次方程的坐标图像。\n要求两点都大于0的两点的导数，我们需要先求出该一元二次方程的导函数。对于一元二次方程 $y = ax^2 + bx + c$，导函数为 $y’ = 2ax + b$。\n接下来，我们可以使用上述导函数来计算两个满足条件的点，并绘制出这两个点及其切线。以下是相应的代码：\n12345678910111213141516171819202122232425def derivative(x, a, b):    return 2*a*x + bx1 = 1.0x2 = -1.0y1 = quadratic_equation(x1, a, b, c)y2 = quadratic_equation(x2, a, b, c)dy_dx_1 = derivative(x1, a, b)dy_dx_2 = derivative(x2, a, b)tangent_line_1 = dy_dx_1 * (x - x1) + y1tangent_line_2 = dy_dx_2 * (x - x2) + y2plt.plot(x, y)plt.plot(x, tangent_line_1, linestyle=&#x27;--&#x27;, color=&#x27;red&#x27;)plt.plot(x, tangent_line_2, linestyle=&#x27;--&#x27;, color=&#x27;green&#x27;)plt.scatter([x1,x2], [y1,y2], color=&#x27;black&#x27;)plt.xlabel(&#x27;x&#x27;)plt.ylabel(&#x27;y&#x27;)plt.title(&#x27;Quadratic Equation with Tangent Lines&#x27;)plt.grid(True)plt.legend([&#x27;Quadratic Equation&#x27;,&#x27;Tangent Line at x=1&#x27;,&#x27;Tangent Line at x=-1&#x27;])plt.show()\n\n运行上述代码，将得到一元二次方程的坐标图像，并且在两个满足条件的点上绘制了切线。\n用python画一个一元一次方程的切线\nimport numpy as npimport matplotlib.pyplot as plt\n定义一元一次方程 y = kx + bk = 2b = 3\n定义切点的 x 坐标x0 = 4\n计算切点的 y 坐标y0 = k * x0 + b\n定义切线斜率为 k，截距为 b 的函数def line(x):    return k * x + b\n定义横坐标范围x = np.linspace(0, 10, 100)\n计算对应的纵坐标值y = line(x)\n绘制方程图像和切线plt.plot(x, y, label=’y = {}x + {}’.format(k, b))plt.plot(x0, y0, ‘ro’, label=’Tangent Point’)plt.plot(x, line(x0) + k*(x - x0), ‘r–’, label=’Tangent Line’)plt.xlabel(‘x’)plt.ylabel(‘y’)plt.title(‘Tangent Line of a Linear Equation’)plt.legend()plt.grid(True)plt.show()\n如何求一元一次方程的切线斜率\n一元一次方程的一般形式为y = mx + c，其中m为斜率，c为截距。\n求一元一次方程的切线斜率的步骤如下：\n\n将方程表示为y = f(x)，其中f(x)是一个关于x的函数。\n求出f(x)的导数f’(x)。\n将x值代入f’(x)得到对应的斜率。\n\n例如，对于方程y = 2x + 3，我们可以将其表示为函数f(x) = 2x + 3。然后，求出f(x)的导数f’(x)，在这个例子中，由于导数是常数2，所以切线斜率就是2。\n因此，对于任意给定的一元一次方程y = mx + c，其切线斜率就是m。\n用python代码画出一元一次方程斜率的函数坐图像。\n下面是一个简单的例子，用Python代码绘制一元一次方程 $y = ax + b$ 的图像，其中 $a$ 是斜率，$b$ 是截距。\n123456789101112131415161718import numpy as npimport matplotlib.pyplot as pltdef plot_linear_equation(a, b):    x = np.linspace(-10, 10, 100)    y = a*x + b    plt.plot(x, y)    plt.xlabel(&#x27;x&#x27;)    plt.ylabel(&#x27;y&#x27;)    plt.title(f&#x27;Linear Equation: y = &#123;a&#125;x + &#123;b&#125;&#x27;)    plt.grid(True)    plt.axhline(0, color=&#x27;black&#x27;,linewidth=0.5)    plt.axvline(0, color=&#x27;black&#x27;,linewidth=0.5)    plt.show()# 示例：绘制斜率为2，截距为3的直线图像plot_linear_equation(2, 3)\n\n运行以上代码将绘制出斜率为2、截距为3的直线图像。你可以根据需要修改参数 a 和 b 来绘制不同的方程图像。\n函数y = 2x + 3如何求导数，给出代入求导数公式的计算过程\n根据求导的定义，对于函数y = 2x + 3，其中y是关于x的函数，导数可以通过计算函数的斜率来得到。代入求导数公式的计算过程如下：\n\n将函数表示为一元一次方程形式：y = 2x + 3\n根据求导数公式，对于一元一次方程 f(x) = ax + b 的导数为 a。\n因此，对于函数 y = 2x + 3 的导数，结果就是斜率2。\n所以，函数 y = 2x + 3 的导数为 dy/dx = 2。\n\n用Python画出函数y = 2x + 3的图像\n可以使用matplotlib库来画出函数的图像。下面是一个示例代码：\n12345678910111213141516import matplotlib.pyplot as pltimport numpy as npx = np.linspace(-10, 10, 100)  # 创建一个包含-10到10之间100个点的数组y = 2 * x + 3plt.plot(x, y)  # 绘制函数图像plt.xlabel(&#x27;x&#x27;)  # 设置x轴标签plt.ylabel(&#x27;y&#x27;)  # 设置y轴标签plt.title(&#x27;Graph of y = 2x + 3&#x27;)  # 设置图像标题plt.grid(True)  # 添加网格线plt.axhline(0, color=&#x27;black&#x27;, linewidth=0.5)  # 添加x轴参考线plt.axvline(0, color=&#x27;black&#x27;, linewidth=0.5)  # 添加y轴参考线plt.show()  # 显示图像\n\n运行这段代码后，会弹出一个窗口显示函数y = 2x + 3的图像。\nplt.plot(x, y)函数是根据什么数据画图像的\nplt.plot(x, y)函数是根据x和y的数据画图像的。其中，x表示横轴上的数据点，y表示纵轴上的数据点。这个函数将根据提供的x和y数据点之间的关系绘制出一条曲线或折线图。\n","slug":"math/函数","date":"2024-03-14T06:15:59.727Z","categories_index":"数学","tags_index":"函数","author_index":"安全书"},{"id":"ac01f7e97a697c6edaad9a52a52d8a36","title":"平方和公式","content":"平方和公式平方和公式是什么， 用Python如何求（a+b)的平方的结果。\n平方根公式是指对于任意实数a和b，有以下公式成立：\n(a + b)² = a² + 2ab + b²\n要用Python求(a+b)的平方，可以使用以下代码：\n123456a = 3b = 4result = (a + b) ** 2print(result)\n\n运行这段代码，输出结果为49。\n平方差公式是什么， 用Python如何求（a-b)的平方的结果。\n平方差公式指的是两个数的平方差可以表示为两个数的平方和减去两倍乘积。具体表达式如下：\n(a - b)² = a² - 2ab + b²\n在Python中，可以使用以下代码来求(a - b)的平方结果：\n123456a = 5b = 3result = (a - b) ** 2print(result)\n\n输出结果为：4\n","slug":"math/平方和公式","date":"2024-03-14T06:15:59.727Z","categories_index":"数学","tags_index":"平方和公式","author_index":"安全书"},{"id":"948829d08bf40a6cd0d39eba1af93cc8","title":"周髀算经","content":"周髀算经周髀算经中是否有和微积分类似内容？\n在《周髀算经》中，虽然没有明确涉及微积分类似的内容，但其中包含了一些与微积分类似的数学方法和思想。《周髀算经》是中国古代数学著作之一，主要讨论了算术和几何方面的问题。\n在几何方面，书中提到了类似于求曲线面积和体积的问题。例如，在第三篇中，《周髀算经》提到了如何计算圆形田地的面积，以及如何计算圆桶的体积。这些问题涉及到了曲线和曲面的测量，与微积分类似。\n此外，《周髀算经》还引入了一种近似求解平方根的方法，这也与微积分类似。书中介绍了通过逼近法来求解平方根，并给出了一个求解平方根近似值的公式。\n尽管《周髀算经》中没有显式提到微分和积分等概念，但其中所涉及到的数学思想和方法与微积分类似，可以看作是中国古代对微积概念进行初步探索和应用的一种表现。\n《周髀算经》中对取曲面面积的原文是什么\n《周髀算经》中对取曲面面积的原文是：“凡求曲面之法，以长乘广为之。”\n《周髀算经》是那个朝代出现的\n《周髀算经》是出现在中国东汉末年的朝代，也就是公元3世纪。\n","slug":"math/周髀算经","date":"2024-03-14T06:15:59.727Z","categories_index":"AIGC,math","tags_index":"math","author_index":"安全书"},{"id":"a2e094343c4f55dec920488e061c5184","title":"张量","content":"张量如何将URL字符串转换成张量，并转转成对应的Python数据结构类型\n要将URL字符串转换为张量，您需要执行以下步骤：\n\n导入必要的库：\n\n12import torchimport urllib\n\n\n使用urllib库中的urlopen()函数打开URL并读取数据：\n\n12url = &#x27;your_url_string&#x27;data = urllib.request.urlopen(url).read()\n\n\n将数据转换为张量：\n\n1tensor_data = torch.from_numpy(data)\n\n请注意，这只适用于二进制数据。如果您要处理文本数据，可以使用urlopen().read().decode(&#39;utf-8&#39;)将字节数据解码为字符串。\n要将张量转换回Python数据结构类型，可以使用.tolist()方法。例如，如果要将张量转换为Python列表，请执行以下操作：\n1list_data = tensor_data.tolist()\n\n这样，您就可以将URL字符串转换为张量并将其转换回对应的Python数据结构类型。\n张量和向量的区别\n张量和向量是线性代数中的概念，它们之间有一些区别。\n\n维度：向量是一维的，即只有一个维度。而张量可以是多维的，可以有多个维度。\n\n元素个数：向量只包含一个元素组成的序列。而张量可以包含多个元素组成的序列。\n\n表示方式：向量通常用列向量或行向量表示。而张量可以用矩阵、数组等方式表示。\n\n运算规则：在线性代数中，向量与标量的乘法和加法是定义过的。而对于张量来说，除了与标量的乘法和加法外，还有更复杂的运算规则，如张量积、外积等。\n\n\n总之，张量是对向量概念的扩展和推广，它可以表示更高维度、更复杂结构的数据。\n张量的定义\n张量的定义是一个多维数组或矩阵的扩展，它可以用于表示向量、矩阵和更高维度的数组。在数学和物理学中，张量是一种具有多个索引的对象，可以根据不同的变换规则进行运算。在机器学习和深度学习领域，张量是存储和处理数据的主要数据结构。\n张量可以有任意多个维度，每个维度可以有任意大小。例如，一个二维矩阵可以被视为一个2阶张量，其中第一个维度表示行数，第二个维度表示列数。一个三维数组可以被视为一个3阶张量，其中第一个维度表示高度，第二个维度表示行数，第三个维度表示列数。\n在机器学习和深度学习中，张量通常用来表示输入数据、权重和输出数据。通过对这些张量进行运算，我们可以构建神经网络模型，并进行训练和预测。\n总之，张量是一种多维数组或矩阵的扩展，在数学、物理学以及机器学习和深度学习中都具有重要的应用价值。\n用python计算一个曲线函数的导数\n要计算一个曲线函数的导数，可以使用Python中的数值微分方法或符号计算方法。\n\n数值微分方法：数值微分是通过计算函数在给定点附近的差商来近似求解导数。常见的数值微分方法包括前向差分、后向差分和中心差分。\n\n前向差分：定义函数f(x)，则f’(x) ≈ (f(x+h) - f(x)) / h12def derivative(f, x, h):    return (f(x + h) - f(x)) / h\n后向差分：定义函数f(x)，则f’(x) ≈ (f(x) - f(x-h)) / h12def derivative(f, x, h):    return (f(x) - f(x - h)) / h\n中心差分：定义函数f(x)，则f’(x) ≈ (f(x+h) - f(x-h)) / (2h)12def derivative(f, x, h):    return (f(x + h) - f(x - h)) / (2 * h)\n\n\n符号计算方法：符号计算是使用符号代数进行导数计算，可以利用Python中的符号计算库（如SymPy）实现。\n12345from sympy import symbols, diffdef derivative(f, x):    x = symbols(&#x27;x&#x27;)    return diff(f, x)\n\n在使用符号计算方法时，需要先定义一个符号变量x，并使用diff函数对函数f进行求导。\n\n\n示例：假设要计算函数f(x) = x^2 + 3x - 2在x=2处的导数，可以使用中心差分方法进行数值微分计算。\n12345678910def f(x):    return x**2 + 3*x - 2def derivative(f, x, h):    return (f(x + h) - f(x - h)) / (2 * h)x = 2h = 0.001result = derivative(f, x, h)print(result)\n\n输出结果为：7.000000000000002\n用Python求得一个函数的导数\n用LSTM算法实现对恶意URL的判断。\nLSTM（Long Short-Term Memory）是一种递归神经网络（RNN）的变体，它在处理序列数据时具有记忆功能。在恶意URL判断问题中，可以使用LSTM算法进行建模和分类。\n下面是一个使用Python和Keras库实现恶意URL判断的例子：\n\n数据预处理：首先，将URL数据集划分为训练集和测试集。然后，对URL进行标记化处理，将每个字符映射为一个整数，并对长度不足的URL进行填充。\n\nLSTM模型构建：使用Keras库构建一个包含嵌入层、LSTM层和全连接层的神经网络模型。嵌入层用于将整数映射到向量表示，LSTM层用于学习序列信息，并最终通过全连接层输出分类结果。\n\n模型训练：使用训练集对构建好的LSTM模型进行训练。可以选择合适的损失函数（如交叉熵）、优化器（如Adam）和评估指标（如准确率）。\n\n模型评估：使用测试集对训练好的LSTM模型进行评估。计算模型在测试集上的准确率、精确率、召回率等指标来评估其性能。\n\n模型应用：将新的URL输入到训练好的LSTM模型中，根据输出进行恶意URL的判断。\n\n\n这只是一个简单的实现例子，具体的实现过程还需要根据具体的数据集和需求进行调整和优化。\n给出一段用Python用LSTM实现恶意URL分析有代码\n下面是一个使用Python和LSTM来实现恶意URL分析的示例代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import numpy as npfrom keras.models import Sequentialfrom keras.layers import LSTM, Dense, Embeddingfrom keras.preprocessing.sequence import pad_sequencesfrom sklearn.model_selection import train_test_split# 加载数据集def load_data():    urls = []    labels = []    # 从文件中读取URL和标签，将其添加到urls和labels列表中    with open(&#x27;data.txt&#x27;, &#x27;r&#x27;) as file:        for line in file:            url, label = line.strip().split(&#x27;,&#x27;)            urls.append(url)            labels.append(int(label))    return urls, labels# 创建词汇表（字符级别）def create_vocab(urls):    chars = set()    for url in urls:        chars.update(url)    char2idx = &#123;char: idx+1 for idx, char in enumerate(chars)&#125;    return char2idx# 将URL转换为字符索引序列def encode_urls(urls, char2idx):    encoded_urls = []    for url in urls:        encoded_url = [char2idx[char] for char in url]        encoded_urls.append(encoded_url)    return encoded_urls# 填充序列到固定长度def pad_sequences(encoded_urls, max_length):    padded_urls = pad_sequences(encoded_urls, maxlen=max_length, padding=&#x27;post&#x27;)    return padded_urls# 构建LSTM模型def build_model(vocab_size, max_length):    model = Sequential()    model.add(Embedding(vocab_size+1, 32))  # 将字符索引映射为32维向量表示    model.add(LSTM(64))    model.add(Dense(1, activation=&#x27;sigmoid&#x27;))    model.compile(loss=&#x27;binary_crossentropy&#x27;, optimizer=&#x27;adam&#x27;, metrics=[&#x27;accuracy&#x27;])    return model# 加载数据集urls, labels = load_data()# 创建词汇表（字符级别）char2idx = create_vocab(urls)# 将URL转换为字符索引序列encoded_urls = encode_urls(urls, char2idx)# 填充序列到固定长度max_length = max(len(url) for url in urls)padded_urls = pad_sequences(encoded_urls, max_length)# 划分训练集和测试集X_train, X_test, y_train, y_test = train_test_split(padded_urls, labels, test_size=0.2)# 构建模型model = build_model(len(char2idx), max_length)# 训练模型model.fit(X_train, y_train, epochs=10, batch_size=64)# 评估模型loss, accuracy = model.evaluate(X_test, y_test)print(&#x27;Test loss:&#x27;, loss)print(&#x27;Test accuracy:&#x27;, accuracy)\n\n请注意，此示例仅提供了一个基本的框架，您可能需要根据自己的数据和需求进行适当的调整和修改。\n给出一段用Python用LSTM实现恶意URL分析有代码，并判断某个URL是不是恶意URL，还是正常URL\n以下是一个使用Python和LSTM模型实现恶意URL分析的代码示例：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import numpy as npfrom keras.models import Sequentialfrom keras.layers import LSTM, Dense, Embeddingfrom keras.preprocessing.sequence import pad_sequences# 定义LSTM模型def create_model(vocab_size):    model = Sequential()    model.add(Embedding(vocab_size, 32))    model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))    model.add(Dense(1, activation=&#x27;sigmoid&#x27;))    model.compile(loss=&#x27;binary_crossentropy&#x27;, optimizer=&#x27;adam&#x27;, metrics=[&#x27;accuracy&#x27;])    return model# 加载训练数据和标签def load_data(filename):    with open(filename, &#x27;r&#x27;) as f:        lines = f.readlines()    urls = []    labels = []    for line in lines:        url, label = line.strip().split(&#x27;,&#x27;)        urls.append(url)        labels.append(int(label))    return urls, labels# 构建词汇表并将URL转化为数字序列def build_vocab(urls):    vocab = set()    for url in urls:        vocab.update(url)    vocab = sorted(list(vocab))    char_to_idx = &#123;char: idx + 1 for idx, char in enumerate(vocab)&#125;        sequences = []    for url in urls:        sequence = [char_to_idx[char] for char in url]        sequences.append(sequence)        return sequences# 加载训练数据和标签train_urls, train_labels = load_data(&#x27;train.csv&#x27;)# 构建词汇表并将URL转化为数字序列sequences = build_vocab(train_urls)# 对URL进行填充，使得所有序列长度相同max_len = max(len(seq) for seq in sequences)padded_sequences = pad_sequences(sequences, maxlen=max_len)# 将标签转化为numpy数组train_labels = np.array(train_labels)# 训练LSTM模型model = create_model(len(char_to_idx) + 1)model.fit(padded_sequences, train_labels, epochs=10, batch_size=32)# 加载测试数据test_urls, test_labels = load_data(&#x27;test.csv&#x27;)# 将测试URL转化为数字序列并进行填充test_sequences = build_vocab(test_urls)padded_test_sequences = pad_sequences(test_sequences, maxlen=max_len)# 预测测试数据的标签pred_labels = model.predict_classes(padded_test_sequences)# 判断某个URL是恶意URL还是正常URLdef predict_malicious(url):    sequence = [char_to_idx[char] for char in url]    padded_sequence = pad_sequences([sequence], maxlen=max_len)    pred_label = model.predict_classes(padded_sequence)[0][0]    if pred_label == 1:        return &quot;恶意URL&quot;    else:        return &quot;正常URL&quot;url_to_predict = &#x27;http://www.example.com&#x27;prediction_result = predict_malicious(url_to_predict)print(f&#x27;该URL为：&#123;prediction_result&#125;&#x27;)\n\n请注意，上述代码仅提供了一个简单的示例，实际情况中可能需要更多的特征工程和模型调优。此外，训练数据和测试数据应该包含足够数量的恶意URL和正常URL样本以获得更准确的预测结果。\n如何用Python代码实现画出一个函数曲线的图像\n要画出一个函数曲线的图像，可以使用Python中的matplotlib库。下面是一个简单的示例代码：\n1234567891011121314151617181920import numpy as npimport matplotlib.pyplot as plt# 定义函数def func(x):    return np.sin(x)# 生成x轴数据x = np.linspace(-np.pi, np.pi, 100)# 生成y轴数据y = func(x)# 绘制图像plt.plot(x, y)plt.xlabel(&#x27;x&#x27;)plt.ylabel(&#x27;y&#x27;)plt.title(&#x27;Function Curve&#x27;)plt.grid(True)plt.show()\n\n这段代码会绘制出一个正弦函数的图像。首先定义了一个func函数，用于计算y值。然后通过np.linspace生成一组x轴数据，再调用func函数计算对应的y值。最后使用plt.plot将x和y传入，绘制出曲线图像。通过设置标签、标题和网格等属性，可以美化图像的展示效果。最后调用plt.show()显示图像。\n你也可以根据需要修改函数和参数来绘制其他函数曲线的图像。\nplt.show()可以在linux的命令行上显示吗？\n不可以。plt.show()是用于在Python脚本中显示绘图的函数，它会创建一个新的窗口来显示图形。在Linux的命令行上无法直接显示这个窗口。如果要在Linux的命令行上显示图形，可以使用其他工具如Xming或VcXsrv来实现远程图形显示。\n用Python实现一段，在函数曲线上画割线的代码\n下面是一个用Python实现的绘制函数曲线和割线的代码示例：\n1234567891011121314151617181920212223242526272829303132333435import numpy as npimport matplotlib.pyplot as pltdef plot_curve_derivative(func, x_range, num_points=100):    x = np.linspace(x_range[0], x_range[1], num_points)    y = func(x)    plt.figure(figsize=(8, 6))    plt.plot(x, y, label=&#x27;Function Curve&#x27;)        # 随机选择两个点    x1 = np.random.choice(x)    x2 = np.random.choice(x)    # 计算斜率（割线的斜率）    slope = (func(x2) - func(x1)) / (x2 - x1)    # 计算割线方程    line_func = lambda x: slope * (x - x1) + func(x1)    # 绘制割线    plt.plot(x, line_func(x), label=&#x27;Tangent Line&#x27;, linestyle=&#x27;--&#x27;)        plt.xlabel(&#x27;x&#x27;)    plt.ylabel(&#x27;y&#x27;)    plt.title(&#x27;Function Curve and Tangent Line&#x27;)        plt.legend()    plt.show()# 示例函数：f(x) = x^3 + 2x^2 - 3x + 4func = lambda x: x**3 + 2*x**2 - 3*x + 4# 绘制函数曲线和割线plot_curve_derivative(func, (-5, 5))\n\n这段代码使用了NumPy和Matplotlib库。首先定义了一个plot_curve_derivative函数，该函数接受三个参数：func表示要绘制的函数，x_range表示绘图的x轴范围，num_points表示绘制曲线的点数（默认为100）。\n在函数内部，首先使用np.linspace函数生成x轴上的等间距点，并根据给定的函数计算对应的y值。然后使用Matplotlib库绘制函数曲线。\n接下来，随机选择两个点（x1和x2），并根据这两个点计算割线的斜率。然后定义一个割线方程，并根据该方程绘制割线。\n最后，设置坐标轴标签、标题和图例，并使用plt.show()函数显示图形。\n","slug":"math/张量","date":"2024-03-14T06:15:59.727Z","categories_index":"深度学习","tags_index":"张量","author_index":"安全书"},{"id":"5c5de20a67a6d33c5fc513fbd8ccd4c3","title":"表达式与极限","content":"表达式与极限1.（x^2 - 1)/(x-1)的计算过程\n（x^2 - 1）/(x-1) \n= (x^2 - 1) / (x-1)\n= (x+1)(x-1) / (x-1)\n= x+1\n所以，（x^2 - 1）/(x-1) = x+1。\n2.(x+1)(x-1)的计算过程\n(x+1)(x-1)的计算过程如下：\n首先，使用分配律展开乘积：(x+1)(x-1) = x(x) + x(-1) + 1(x) + 1(-1)= x^2 - x + x - 1= x^2 - 1\n因此，(x+1)(x-1)的结果为x^2 - 1。\n\n x极限为1，表达式（x^2 - 1）/(x-1)的计算过程和计算结果\n\n当x趋向1时，表达式（x^2 - 1）/(x-1)可以化简为以下步骤：\n= lim (x^2 - 1)/(x-1)= lim ((x+1)(x-1))/(x-1)  // 分子因式分解= lim (x+1)  // 分母的(x-1)与分子的(x-1)相约\n因此，当x趋向1时，表达式（x^2 - 1）/(x-1)的极限为2。\n给出平方差公式\n(a + b)^2 = a^2 + 2ab + b^2\n(a - b)^2 = a^2 - 2ab + b^2\n","slug":"math/表达式与极限","date":"2024-03-14T06:15:59.727Z","categories_index":"数学","tags_index":"表达式与极限","author_index":"安全书"},{"id":"97cdf59faee5bb7d1615febce1441507","title":"平方差公式与完全平方差公式","content":"平方差公式与完全平方差公式给出平方和公式\n x^2 - 1表达式的用分配律解开乘积，分配律具体的内容\nx^2 - 1 = x^2 - 1^2          = (x + 1)(x - 1)\n分配律指的是将一个乘法运算分配到括号内的每个项上，即对于任意实数a、b、c有：a(b + c) = ab + ac(a + b)c = ac + bc\n (x + 1)(x - 1)这个公式是什么公式\n这是一个展开式，即两个括号中的内容进行乘法运算并合并同类项得到的结果。在这个例子中，展开式为 x^2 - 1。\n如何快速的知道x^2 - 1的展开式是 (x + 1)(x - 1)\n要快速知道x^2 - 1的展开式是 (x + 1)(x - 1)，可以使用差平方公式进行计算。\n首先，我们知道差平方公式为：a^2 - b^2 = (a + b)(a - b)。将x^2表示为x的平方，1表示为1的平方，即可得到：\nx^2 - 1 = x^2 - 1^2\n然后，根据差平方公式，将上式展开为：\n(x + 1)(x - 1)\n因此，x^2 - 1的展开式就是 (x + 1)(x - 1)。\n平方差公式：(a+b)(a-b)=a²-b²完全平方差公式：(a-b)²=a²-2ab+b²\n平方差公式， 完全平方差公式\n平方差公式是指两个数的平方之差等于它们的和乘以它们的差，即(a+b)(a-b) = a^2 - b^2。\n完全平方差公式是指一个二次多项式可以写成两个一次多项式的平方差形式，即a^2 + 2ab + b^2 = (a+b)^2。\n","slug":"math/平方差公式与完全平方差公式","date":"2024-03-14T06:15:59.727Z","categories_index":"数学","tags_index":"平方差公式","author_index":"安全书"},{"id":"cc60a0b020396d08e0b6b1865ad4e9c5","title":"ObsidianAddict插件教程网站","content":"ObsidianAddict插件教程网站https://obsidianaddict.com/\n","slug":"obsidian/ObsidianAddict插件教程网站","date":"2024-03-14T06:15:59.727Z","categories_index":"obsidian","tags_index":"ObsidianAddict","author_index":"安全书"},{"id":"2656993cf43ed1aa35c9954d6baa5550","title":"概述","content":"概述Lua 是用 C 语言开发的可扩展的轻量级编程语言。它起源于 1993 年由 Roberto lerusalimschy,Luiz Henrique de Figueiredo 与 Waddemar Celes 领导的一个内部项目。设计者的初衷是希望 Lua 可以成为一款整合 C 语言代码以及其它传统语言代码的软件。这种整合会带来很多好处，它让你不需要重复做 C 语言已经做的很好的工作，而专注于提供那些 C 语言不擅长的特性：提供更高的抽象（离硬件更远）、动态结构、无冗余、易于测试与调试。为了提供这些特性，Lua 提供了安全的环境、动态内存管理，以及擅长处理字符串和其它动态大小数据结构的工具。  \n特点Lua 有着许多自身的特点使得它与其它编程语言不同。主要包括：  \n\n可扩展性  \n简单  \n高效  \n跨平台  \n自由与开放  \n  \n\n示例代码print(&quot;Hello World!&quot;)\n\nLua 是如何实现的Lua 主要包括两个部分：Lua 解释器部分以及运行软件系统。  运行软件系统是真正解释执行由 Lua 语言编写的程序的应用程序（译注：此处 Lua 翻译器部分用于将 Lua　代码编译成中间字节码，运行软件系统指 Lua 虚拟机，而一般我们所说 Lua 解释器包括这两部分）。 Lua 解释器是由 ANSI C 编写的，因此它有很好的可移植性，可以运行各种各运的设备上，无论是大型网络服务器还是小型移动设备。  \n无论 Lua 语言还是 Lua 解释器都已经是非常成熟的、同时还兼备体积小，运行速度非常快的特点。小体积的特性也使得 Lua 可以运行在很多只有少量内存的小型设备中。\n学习 Lua学习 Lua 语言最重要的一点是把注意力放在它的概念上，千万不要迷失在语言的技术细节中。学习 Lua 的目的是成为一个更好的程序人员。也就是说，学习 Lua 可以帮助您在设计与实现新系统，或者维护旧系统的时候变得更加的高效。  \nLua 的应用场景\n游戏开发  \n开发单机应用  \n网站开发  \n扩展数据库或者为数据库开发插件，比如，MySQL 代理或 MySQL WorkBench  \n开发安全系统，如入侵检测系统（IDS）  \n  \n\n","slug":"lua/2016-06-01-overview","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"17f717e08ff041fef49c1fa8a71c5669","title":"repeat...until 循环","content":"#repeat…until 循环  \n与 for 和 while 循环中先检测条件再决定是否执行循环不同，repeat…until 先执行循环再检测条件判断是否再次执行。除了 repeat…until 循环一定会执行一次之外，repeat…until 与 while 循环很相似。  \n##语法  \nLua 语言中 repeat…until 循环的语法如下：  \n123456789101112repeat   statement(s)until( condition )```  请注意，条件表达式出现在循环的结束处，所以在检查条件之前，循环体中语句 statement(s) 已经执行了一次。  如果条件为假，则控制回到循环开始再次执行循环体。这个过程一直重复到条件为真时结束。##流程图  ![](images/repeat_until_loop.jpg)##示例  \n–[ 局部变量定义 –]local a = 10–[ 重复循环执行 –]repeat   print(“value of a:”, a)   a = a + 1until( a &gt; 15 )\n12执行上面的代码，将会得到如下的结果：  \nvalue of a:    10value of a:    11value of a:    12value of a:    13value of a:    14value of a:    15\n\n\n","slug":"lua/2016-06-01-repeat-until","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"cedbdf206a63ba0896535fb39f386996","title":"Lua字符串","content":"Lua 字符串字符串就是一个由字符或控制字符组成的序列。字符串可以用以下三种方式任意一种进行初始化。\n\n    单引号字符串\n    双引号字符串\n    [[和]]之间的字符串\n  \n\n上面三种初始化方式的示例如下：  \n1234567891011string1 = &quot;Lua&quot;print(&quot;\\&quot;String 1 is\\&quot;&quot;,string1)string2 = &#x27;Tutorial&#x27;print(&quot;String 2 is&quot;,string2)string3 = [[&quot;Lua Tutorial&quot;]]print(&quot;String 3 is&quot;,string3)```  运行上面的程序，我们可以得到如下的输出结果：  \n“String 1” is    LuaString 2 is    TutorialString 3 is    “Lua Tutorial”\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115字符串中转义字符用于改变字符的一般正常的解释。在上面的例子中，输出双引号（&quot;&quot;）的时候，我们使用的是 \\&quot;。下表列出了转义序列及相应的使用方法：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;转义序列&lt;/th&gt;\t\t&lt;th&gt;用法&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\a&lt;/td&gt;\t\t&lt;td&gt;响铃&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\b&lt;/td&gt;\t\t&lt;td&gt;退格&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\f&lt;/td&gt;\t\t&lt;td&gt;换页&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\n&lt;/td&gt;\t\t&lt;td&gt;换行&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\r&lt;/td&gt;\t\t&lt;td&gt;回车&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\t&lt;/td&gt;\t\t&lt;td&gt;制表符&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\v&lt;/td&gt;\t\t&lt;td&gt;垂直制表符&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\\\&lt;/td&gt;\t\t&lt;td&gt;反斜线&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\&quot;&lt;/td&gt;\t\t&lt;td&gt;双引号&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\&#x27;&lt;/td&gt;\t\t&lt;td&gt;单引号&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\[&lt;/td&gt;\t\t&lt;td&gt;左方括号&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;\\]&lt;/td&gt;\t\t&lt;td&gt;右方括号&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;## 字符串操作  Lua 支持如下的字符串操作方法：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;S.N.&lt;/th&gt;\t\t&lt;th&gt;函数及其功能&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;1&lt;/td&gt;\t\t&lt;td&gt;string.upper(argument):将输入参数全部字符转换为大写并返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;2&lt;/td&gt;\t\t&lt;td&gt;string.lower(argument):将输入参数全部字符转换为小写并返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;3&lt;/td&gt;\t\t&lt;td&gt;string.gsub(maingString,findString,replaceString):将 mainString 中的所有 findString 用 replaceString 替换并返回结果。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;4&lt;/td&gt;\t\t&lt;td&gt;string.strfind(mainString,findString,optionalStartIndex,optionalEndIndex):在主字符串中查找 findString 并返回 findString 在主字符串中的开始和结束位置，若查找失败则返回 nil。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;5&lt;/td&gt;\t\t&lt;td&gt;string.reverse(arg):将输入字符串颠倒并返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;6&lt;/td&gt;\t\t&lt;td&gt;string.format(...):返回格式化后的字符串。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;7&lt;/td&gt;\t\t&lt;td&gt;string.char(arg) 和 string.byte(arg):前者返回输出参数的所代表的字符，后者返回输入参数（字符）的数值。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;8&lt;/td&gt;\t\t&lt;td&gt;string.len(arg):返回输入字符串的长度。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;9&lt;/td&gt;\t\t&lt;td&gt;string.rep(string,n): 将输入字符串 string 重复 n　次后的新字符串返回。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;10&lt;/td&gt;\t\t&lt;td&gt;..:连接两个字符串。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;接下来我们用一些例子来讲解如何使用上面这些函数。  ## 大小写操作函数  下面的代码将字符串中字符全部转换成大写或小写：  \nstring1 = “Lua”;print(string.upper(string1))print(string.lower(string1))\n123执行上面的代码可以得到如下的输出结果：  \nLUAlua\n12345## 替换子串  用一个字符串替换字符串的某子串的示例代码如下：  \nstring = “Lua Tutorial”– 替换字符串newstring = string.gsub(string,”Tutorial”,”Language”)print(“The new string is”,newstring)\n123执行上面的代码可以得到如下的输出结果：  \nThe new string is    Lua Language\n12345## 查找与颠倒  查找一个子串的索引与颠倒一个字符串函数的示例代码如下所示：  \nstring = “Lua Tutorial”– 替换字符串print(string.find(string,”Tutorial”))reversedString = string.reverse(string)print(“The new string is”,reversedString)\n123执行上面的代码可以得到如下的输出结果：  \n5    12The new string is    lairotuT auL\n12345## 格式化字符串  在编程过程中，我们经常需要将字符串以某种格式输出。此时，你就可以使用 string.format 函数格式化你的输出内容。如下所示：  \nstring1 = “Lua”string2 = “Tutorial”number1 = 10number2 = 20– 基本字符串格式print(string.format(“Basic formatting %s %s”,string1,string2))– 日期格式化date = 2; month = 1; year = 2014print(string.format(“Date formatting %02d/%02d/%03d”, date, month, year))– 符点数格式化print(string.format(“%.4f”,1/3))\n123执行上面的代码可以得到如下的输出结果：  \nBasic formatting Lua TutorialDate formatting 02/01/20140.3333\n12345## 字符与字节表示  字节表示函数用于将字符的内部表示转换为字符表示，而字符表示函数正好相反。 示例代码如下：  \n– 字节转换– 第一个字符print(string.byte(“Lua”))– 第三个字符print(string.byte(“Lua”,3))– 倒数第一个字符print(string.byte(“Lua”,-1))– 第二个字符print(string.byte(“Lua”,2))– 倒数第二个字符print(string.byte(“Lua”,-2))\n– 内部 ASCII 字值转换为字符print(string.char(97))\n123执行上面的代码可以得到如下的输出结果：  \n769797117117a\n12345## 其它常用函数  其它常用的字符串处理函数包括字符串连接，字符串长度函数以及重复字符串多次的函数。它们的使用方法示例如下：  \nstring1 = “Lua”string2 = “Tutorial”– 用 .. 连接两个字符串print(“Concatenated string”,string1..string2)\n– 字符串的长度print(“Length of string1 is “,string.len(string1))\n– 重复字符串repeatedString = string.rep(string1,3)print(repeatedString)\n123执行上面的代码可以得到如下的输出结果：  \nConcatenated string    LuaTutorialLength of string1 is     3LuaLuaLua``` \n","slug":"lua/2016-06-01-strings","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"038bf88a1c7598385fc79ad2a48f60ba","title":"Lua表","content":"Lua 表在 Lua 语言中，表是唯一可以用来创建不同数据类型的数据结构，比如常见的数组和字典都是用表来创建的。 Lua 语言中经常到关联数组这种数据类型，它不仅可以用数值作为索引值，除了 nil 以外的字符串同样可以作为其索引。表没有固定的大小，当数据量增加时表会自动增大。  \nLua 语言中的各种结构表示都用到了表，包括包（package）的表示。当我们使用方法 string.format 时，我们用到的其实是包 string 中的方法 format。  \n使用表表被称之为对象，它既不是值也不是变量。Lua 用构造表达式 {} 创建一个空表。需要注意的是，在存储表的变量和表本身之间没有什么固定的对应关系（译注：一个表可以被不同的变量引用，一个变量也可以随时改变其所引用的表对象）。  \n123456789101112131415--简单的表初始化mytable = &#123;&#125;--简单的表赋值mytable[1]= &quot;Lua&quot;--移除引用mytable = nil-- lua 的垃圾回收机制负责回收内存空间```  当我们有一个拥有一系列元素的表时，如果我们将其赋值给 b。那么 a 和 b 都会引用同一个表对象(a 先引用该表)，指向相同的内存空间。而不会再单独为 b 分配内存空间。即使给变量 a 赋值 nil，我们仍然可以用变量 b 访问表本身。如果已经没有变量引用表时，Lua　语言垃圾回收机制负责回收不再使用的内存以被重复使用。  下面的示例代码使用到了上面提到的表的特性。　　\n– 声明空表mytable = {}print(“Type of mytable is “,type(mytable))\nmytable[1]= “Lua”mytable[“wow”] = “Tutorial”print(“mytable Element at index 1 is “, mytable[1])print(“mytable Element at index wow is “, mytable[“wow”])\n– alternatetable 与 mytable 引用相同的表alternatetable = mytable\nprint(“alternatetable Element at index 1 is “, alternatetable[1])print(“mytable Element at index wow is “, alternatetable[“wow”])\nalternatetable[“wow”] = “I changed it”\nprint(“mytable Element at index wow is “, mytable[“wow”])\n– 只是变量被释放，表本身没有被释放alternatetable = nilprint(“alternatetable is “, alternatetable)\n– mytable 仍然可以访问print(“mytable Element at index wow is “, mytable[“wow”])\nmytable = nilprint(“mytable is “, mytable)\n123执行上面的代码，我们可以得到如下的输出结果：  \nType of mytable is     tablemytable Element at index 1 is     Luamytable Element at index wow is     Tutorialalternatetable Element at index 1 is     Luamytable Element at index wow is     Tutorialmytable Element at index wow is     I changed italternatetable is     nilmytable Element at index wow is     I changed itmytable is     nil\n12345678910111213141516171819202122232425262728293031323334353637## 表的操作函数  下面的表中列出了 Lua 语言内置的表操作函数，具体内容如下所示：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;S.N.&lt;/th&gt;\t\t&lt;th&gt;方法与作用&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;1&lt;/td&gt;\t\t&lt;td&gt;table.concat(table[, sep [, i[,j]]]): 根据指定的参数合并表中的字符串。具体用法参考下面的示例。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;2&lt;/td&gt;\t\t&lt;td&gt;table.insert(table,[pos,]value):在表中指定位置插入一个值。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;3&lt;/td&gt;\t\t&lt;td&gt;table.maxn(table)：返回表中最大的数值索引。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;4&lt;/td&gt;\t\t&lt;td&gt;table.remove(table[,pos]):从表中移出指定的值。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;5&lt;/td&gt;\t\t&lt;td&gt;table.sort(table[,comp]):根据指定的（可选）比较方法对表进行排序操作。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;  让我们一起看一些上述函数使用的例子。  ### 表连接操作  我们可以使用表连接操作连接表中的元素，如下所示。  \nfruits = {“banana”,”orange”,”apple”}– 返回表中字符串连接后的结果print(“Concatenated string “,table.concat(fruits))\n–用字符串连接print(“Concatenated string “,table.concat(fruits,”, “))\n–基于索引连接 fruitsprint(“Concatenated string “,table.concat(fruits,”, “, 2,3))\n123执行上面的代码，我们可以得到如下的输出结果：  \nConcatenated string     bananaorangeappleConcatenated string     banana, orange, appleConcatenated string     orange, apple\n12345### 插入与移出操作  插入和移除表中元素是对表最常见的操作。使用方法如下所示：  \nfruits = {“banana”,”orange”,”apple”}\n– 在 fruits 的末尾插入一种水果table.insert(fruits,”mango”)print(“Fruit at index 4 is “,fruits[4])\n– 在索引 2 的位置插入一种水果table.insert(fruits,2,”grapes”)print(“Fruit at index 2 is “,fruits[2])\nprint(“The maximum elements in table is”,table.maxn(fruits))\nprint(“The last element is”,fruits[5])table.remove(fruits)print(“The previous last element is”,fruits[5])\n123执行上面的代码，我们可以得到如下的输出结果：  \nFruit at index 4 is     mangoFruit at index 2 is     grapesThe maximum elements in table is    5The last element is    mangoThe previous last element is    nil\n12345### 表排序操作  在程序开发过程中，常常有对表排序的需求。 sort 函数默认使用字母表对表中的元素进行排序（可以通过提供比较函数改变排序策略）。示例代码如下：  \nfruits = {“banana”,”orange”,”apple”,”grapes”}for k,v in ipairs(fruits) doprint(k,v)endtable.sort(fruits)print(“sorted table”)for k,v in ipairs(fruits) doprint(k,v)end\n123执行上面的代码，我们可以得到如下的输出结果：  \n1    banana2    orange3    apple4    grapessorted table1    apple2    banana3    grapes4    orange```  \n","slug":"lua/2016-06-01-tables","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"fa374b256846497ad36372533ba9888a","title":"Lua标准库","content":"Lua 标准库Lua 标准库利用 C 语言 API 实现并提供了丰富的函数，它们内置于 Lua 语言中。该标准库不仅可以提供 Lua 语言内服务，还能提供外部服务，比如文件或数据库的操作。  \n这些标准库使用标准的 C API 接口实现，它们作为独立的 C 语言模块提供给使用者。主要包括以下的内容：\n\n    基本库，包括协程子库\n    模块库\n    字符串操作\n    表操作\n    数学计算库\n    文件输入与输出\n    操作系统工具库\n    调试工具库\n\n\n基本库在本教程中，我们已经在很多地方都使用了基本库的内容。下面的表中列出了相关的函数与链接。  \n\n    \n        S.N.\n        库或者方法\n    \n    \n        1\n        错误处理库，包括错误处理函数，比如 assert，error等，详见错误处理。\n    \n    \n        2\n        内存管理，包括与垃圾回收相关的自动内存管理的内容，详见垃圾回收。\n    \n    \n        3\n        dofile([filename])，打开指定文件，并将文件内容作为代码执行。如果没有传入参数，则函数执行标准输入的内容。错误会传递至函数调用者。\n    \n    \n        4\n        _G，全局变量，它存储全局的环境。Lua 本身不使用此变量。\n    \n    \n        5\n        getfenv([f])，返回指定函数使用的当前环境（作用域），可以通过函数名或栈深度值指定函数。 1 表示调用 getfenv 的函数。如果传入的参数不是函数或者 f 为 0,则返回全局环境。f 的默认值为 1。\n    \n    \n        6\n        getmetatable(object)：如果对象没有元表，则返回 nil。如果对象的元表有 __metable 域，则返回该值；否则返回对象的元表。\n    \n    \n        7\n        ipairs(t)，用于遍历表，此函数返回三个值：next 函数，表 t, 以及 0。\n    \n    \n        8\n        load(func[,chunkname])，使用函数 func 加载一个块（代码块），每次调用func必须返回与先前的结果连接后的字符串\n    \n    \n        9\n        loadfile([filename]),与 load 函数相似，此函数从文件中或标准输入（没指定文件名时）读入代码块。\n    \n    \n        10\n        loadstring(string,[,chunkname])，与 load 类似，从指定字符串中获得代码块。\n    \n    \n        11\n        next(table[,index])，此函数用于遍历表结构。第一参数为表，第二个参数是一个索引值。返回值为指定索引的下一个索引与相关的值。\n    \n    \n        12\n        pairs(t),用于遍历表，此函数返回三个值：next 函数，表 t, 以及 nil。\n    \n    \n        13\n        print(...)，打印输出传入参数。\n    \n    \n        14\n        rawequal(v1,v2)，判断 v1 与 v2 是否相等，不会调用任何元方法。返回布尔值。\n    \n    \n        15\n        rawget(table,index)，返回 table[index]，不会调用元方法。table 必须是表，索引可以是任何值。\n    \n    \n        16\n        rawset(table,index,value)，等价于 table[index] = value，但是不会调用元方法。函数返回表。\n    \n    \n        17\n        select(index,...)，如果 index 为数字n,那么 select 返回它的第 n 个可变实参，否则只能为字符串 \"#\",这样select会返回变长参数的总数。\n    \n    \n        18\n        setfenv(f,table)，设置指定函数的作用域。可以通过函数名或栈深度值指定函数。 1 表示调用 setfenv 的函数。返回值为指定函数。特别地，如果 f 为 0，则改变当前线程的运行环境，这时候函数无返回值。\n    \n    \n        19\n        setmetatable(table,metatable)，设置指定表的元表（不能从 Lua 中改变其它类型的元表，其它类型的元表只能从 C 语言中修改）。如果 metatable 为 nil，则删除表的元表；如果原来的元表有 __metatable 域，则出错。函数返回 table。 \n    \n    \n        20\n        tonumber(e[,base])，将参数转换为数值。如果参数本身已经是数值或者是可以转换为数值的字符串，则 tonumber 返回数值，否则返回 nil。\n    \n    \n        21\n        tostring(e)，将传递的实参以合理的格式转换为字符串。精确控制字符串的转换可以使用 string.format 函数。\n    \n    \n        22\n        type(v)，以字符串的形式返回输入参数的类型。该函数的返回值可以取字符串：nil，number，string，boolean，table，function，thread，userdata。\n    \n    \n        23\n        unpack(list[,i[,j]])，从指定的表中返回元素。\n    \n    \n        24\n        _VERSION，存储当前解释器版本信息的全局变量。该变量当前存储的内容为：Lua 5.1。（译注：与解释器版本有关）\n    \n    \n        25\n        协程库，包括协程相关的函数，详见协程\n    \n\n\n模块库模块库提供了加载模块的基本函数。它在全局作用域内提供了 require 函数。其它的函数都是通过包管理的模块库提供的。详细内容请参见模块。\n字符串操作库详细内容请参见字符串。\n表操作库详细内容请参见表。\n数学函数库详细内容请参见数学函数库。 \n文件 IO 库详细内容请参见文件 IO。 \n操作系统工具库详细内容请参见操作系统工具库。 \n调试工具库详细内容请参见调试。 \n","slug":"lua/2016-06-01-standard-libraries","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"00031c756df5944ae03766354a37e479","title":"Lua的变量","content":"变量变量就是给一块内存区域赋予的一个名字。变量使得在程序中就可以修改或读取相应的内存区域中的内容。它可以代表各种不同类型的值，包括函数与表。 \n变量的名字由字母、数字与下划线组成。它必须是字母或下划线开头。由于 Lua 是字母大小写敏感的，所以大写字母与小写字母是不一样的。Lua 中有八种基本值类型： \n在 Lua 语言中，虽然我们没有变量数据类型，但是依据变量的作用域我们可以将变量分为三类： \n\n    全局变量：除非显示的声明一个局部变量，否则所有的变量都被默认当作全局变量。\n    局部变量：如果我们将一个变量定义为局部变量，那么这么变量的作用域就被限制在函数内。\n    表字段：这种特殊的变量可以是除了 nil 以外的所有类型，包括函数。\n\n\nLua 变量定义一个变量定义就意味着告诉解释器在什么地方创建多大的一块存储空间。一个变量定义包括一个可选的类型( type )以及该类型的一个或多个变量名的列表，如下所示：  \n12345type variable_list;```  其中，type 是可以选择指定为 local 或者不指定使用默认值 global，variable_list 是包含一个或多个由逗号分隔的标识符名字。下面是合法变量定义的示例：  \nlocal    i, jlocal    ilocal    a,c\n12345local i,j 声明定义了两个变量 i 与 j；它命令解释器创建两个名称分别为 i,j 的变量，并且将其作用域限制在局部。  在声明变量的时候可以同时初始化变量（为变量赋初值）。在变量名后跟上等号和一个常量表达式就可以初始化变量。如下所示：  \ntype variable_list = value_list;\n123一些例子如下：  \nlocal d , f = 5 ,10 –声明局部变量 d，f。d , f = 5, 10;      –声明全局变量 d，f。d, f = 10           –[[声明全局变量 d，f，其中 f 的值是 nil–]]\n12345678910111213如果只是定义没有初始化，则静态存储变量被隐式初始化为 nil。  ## Lua 变量声明  正如在上面例子看到的那样，为多个变量赋值就是在变量列表后跟上值列表。例子 local d，f = 5，10 中,变量列表是 d，f，值列表是 5，10。  Lua 赋值时会将第一个值赋给第一个变量，第二个值赋给第二个变量，依次类推。所以，d 的值是 5,f 的值是 10。  ## 示例  下面的示例中，变量被声明在顶部，但是它们在主函数中定义和初始化:  \n– 变量定义:local a, b– 初始化a = 10b = 30print(“value of a:”, a)print(“value of b:”, b)– 交换变量的值b, a = a, bprint(“value of a:”, a)print(“value of b:”, b)f = 70.0/3.0print(“value of f”, f)\n123上面的代码被编译生成和执行后，会产生如下的结果：  \nvalue of a:    10value of b:    30value of a:    30value of b:    10value of f    23.333333333333\n12345678910## Lua 中的左值与右值  Lua　中有两种表达式：  &lt;ul&gt;\t&lt;li&gt;左值：引用内存位置的表达式被称之为左值表达式。左值表达式既可以出现在赋值符号的左边也可以出现在赋值符号的右边。&lt;/li&gt;\t&lt;li&gt;右值：术语“右值”指存在内存某个位置的数据值。我们不能为右值表达式赋值，也就是说右值表达式只可能出现在赋值符号的右边，而不可能出现在赋值符号的左边。&lt;/li&gt;&lt;/ul&gt;变量属于左值表达式，所以它可以现在赋值符号的左边。数值常量属于右值表达式，它不能被赋值也不能出现在赋值符号的左边。下面是合法的语句：  \ng = 20\n123但是，下面的语句是非法的，它会产生生成时错误：  \n10 = 20 \n123在 Lua 语言中，除了上面讲的这种赋值，还允许在一个赋值语句中存在多个左值表达式与多个右值表达式。如下所示：  \ng,l = 20,30\n\n在这个语句中，g 被赋值为 20，l 被赋值为 30。\n\n","slug":"lua/2016-06-01-variables","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide,LUA教程","tags_index":"LUA教程","author_index":"安全书"},{"id":"7132dce4b61373adb37dd9650b6cc624","title":"Lua的while循环","content":"#Lua while 循环  \n在 Lua 语言中，只要 while 循环条件为真，while 语句就会一直执行，直到 while 循环条件为假为止。  \n#语法  \nLua 语言中 while 循环的语法如下所示：  \n1234567891011121314151617while(condition)do   statement(s)end```  其中，statement(s) 可能只是一条语句也可能是一个语句块。条件可以是任何表达式，若表达式结果为真，则循环继续。  循环为假时，程序结束 while 循环，执行 while 后面的代码。  ##流程图  ![](images/while_loop.jpg)  请注意，while 循环的关键点在于循环可能根本不会执行。当检测条件为假是，程序会跳过 while 循环体而直接执行 while 后的第一条语句。  ##示例  \na=10while( a &lt; 20 )do   print(“value of a:”, a)   a = a+1end\n123执行上面的代码，将会得到如下的结果：  \nvalue of a:    10value of a:    11value of a:    12value of a:    13value of a:    14value of a:    15value of a:    16value of a:    17value of a:    18value of a:    19\n\n\n\n\n","slug":"lua/2016-06-01-while","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide,LUA教程","tags_index":"LUA教程","author_index":"安全书"},{"id":"fdaf3a4aaab4da898c02189280754dc0","title":"mac say文字转语音","content":"mac say文字转语音在 macOS 系统下，你可以使用内置的 say 命令将文本转换为语音1。以下是具体的步骤：\n\n新建一个 TXT 文稿，我们取名为 my.txt，然后在 TXT 文件里写入你想要转换的内容，关闭保存1。\n打开终端，输入 cd Documents 然后回车，再输入 say -o my.aiff -f my.txt 然后回车1。这里的 my 是你的 TXT 文件名，如果你起的别的名字，请注意保持一致1。\n生成的 my.aiff 文件就是转换后的语音文件1。你可以直接播放这个文件，或者将其转换为其他格式的音频文件1。\n\n","slug":"mac/mac say文字转语音","date":"2024-03-14T06:15:59.726Z","categories_index":"Mac","tags_index":"Mac","author_index":"安全书"},{"id":"26bfa2ece82537ab5f6962e2d31968f1","title":"Lua中的for循环","content":"#Lua 中的 for 循环  \nfor 循环控制结构可以让你高效地写出需要执行特定次数的循环代码。  \n##语法  \nLua 语言中 for 循环的语法如下：  \n1234for init,max/min value, incrementdo   statement(s)end\n\n下面是 for 循环执行的流程：  \n\n    init 首先执行并且只执行一次。在这一步骤中，你需要声明并初始化循环控制变量。\n    \n    接下来，max/min 是循环结束的条件。程序中将 init 与 最大值或最小值进行比较，条件为真则继续执行循环，否则结束循环。\n    \n    循环体执行后，程序跳转至递增或递减语句( increment/descrement )。此语句中，我们可以更新我们的控制变量。\n    \n    再次检查条件。如果条件为真，则执行循环并重复过程（执行循环体，递增运算，再检查条件）。当条件为假时，结束循环。\n    \n\n\n##流程图  \n##示例  \n1234for i=10,1,-1 do    print(i) end\n\n执行上面的代码后，将得到如下的输出结果：  \n1234567891010987654321\n","slug":"lua/2016-06-11-for","date":"2024-03-14T06:15:59.726Z","categories_index":"lua_guide,lua教程","tags_index":"LUA,abc,basic","author_index":"安全书"},{"id":"f35637f6fb4f2abf97cdd32ce0593fe7","title":"Table复制","content":"Table复制构造一个lua table变量，然后对这个变量在调用函数进行制和专递。\n可以使用以下代码构造一个Lua table变量，并调用函数进行传递：\n12345678910111213141516-- 构造一个Lua table变量local myTable = &#123;    name = &quot;John&quot;,    age = 25,    occupation = &quot;Engineer&quot;&#125;-- 定义一个函数，接受一个table参数并打印其内容function printTable(table)    print(&quot;Name:&quot;, table.name)    print(&quot;Age:&quot;, table.age)    print(&quot;Occupation:&quot;, table.occupation)end-- 调用函数并传递myTable作为参数printTable(myTable)\n\n运行以上代码，输出结果如下：\n123Name: JohnAge: 25Occupation: Engineer\n\n创建声明一个大的Lua的table型变量的数组\n可以使用以下方法创建一个大的Lua table型变量的数组：\n12345678910111213-- 创建一个空的tablelocal myTable = &#123;&#125;-- 设置数组大小local arraySize = 1000000-- 填充数组for i = 1, arraySize do    myTable[i] = iend-- 输出数组大小print(&quot;Array size:&quot;, #myTable)\n\n上述代码创建了一个名为myTable的空table，并使用循环将数字1到1000000填充到数组中。最后，通过#myTable获取数组大小并输出。\n请注意，由于Lua的table是动态类型的，因此无需事先声明数组大小即可添加元素。该示例中声明数组大小仅是为了提前分配内存空间以优化性能。\n下面问题为什么发生，如何解决(error) LOADING Redis is loading the dataset in memory问题：Redis是一个内存中的数据库，当我们将大量的数据加载到Redis中时，会导致内存泄漏和性能下降。\n解决方法：\n\n使用分布式Redis或其他内存不足的数据库来处理大量数据。\n将数据分散在多个机器上，以减轻每个机器的加载压力。\n使用缓存技术来缓解Redis的加载压力。\n将数据分成多个部分，并在不同的Redis实例中处理每一部分。\n使用Redis的分布式功能来处理大量数据。\n使用其他内存不足的数据库来处理大量数据。\n将数据分散在多个机器上，以减轻每个机器的加载压力。\n使用缓存技术来缓解Redis的加载压力。️\n\n如何在redis的lua代码中用，redis.call执行，设置一个Key和Value值。\n在Redis的Lua脚本中，可以使用redis.call()函数执行Redis命令。要设置一个Key和Value值，可以使用以下Lua代码示例：\n1redis.call(&#x27;SET&#x27;, &#x27;mykey&#x27;, &#x27;myvalue&#x27;)\n\n上述代码将在Redis中设置一个名为mykey的键，并将其值设置为myvalue。\n在实际使用时，可以将上述代码与其他Lua脚本逻辑结合起来，例如：\n123-- 在Redis中设置一个键值对，并返回设置结果local result = redis.call(&#x27;SET&#x27;, &#x27;mykey&#x27;, &#x27;myvalue&#x27;)return result\n\n上述代码将执行SET命令，并将结果返回给调用者。\n请注意，在Redis的Lua脚本中，可以使用多个redis.call()函数来执行多个Redis命令。\n如何清空Reids中持久化的Key和value值，把用户设置的Key都清空。\n要清空Redis中的所有Key和value值，可以使用FLUSHALL命令。这个命令会删除所有数据库中的Key和value，包括持久化的数据。\n在Redis客户端中执行以下命令即可清空所有Key和value：\n1FLUSHALL\n\n请注意，这个操作是不可逆的，一旦执行将无法恢复被删除的数据。因此，在执行此操作之前，请确保您真的想要清空所有Key和value。\n","slug":"lua/luatest/Table复制","date":"2024-03-14T06:15:59.726Z","categories_index":"Lua","tags_index":"lua","author_index":"安全书"},{"id":"90762206aba1aa8a729d07e471d48c2c","title":"Lua中的 if...else 语句","content":"#Lua 中的 if…else 语句  \n如果 if 语句后面跟上 else 语句，那么条件为假时就执行 else 语句的代码。  \n##语法  \nLua 语言中 if…else 语句的语法如下所示：  \n1234567891011121314151617if(boolean_expression)then   --[ 如何条件为真，则执行此处代码。 --]else   --[ 如何条件为假，则执行此处代码。 --]end```  当布尔表达式为真时，执行 if 语句的代码块；如果条件为假时，则执行 else 语句的代码块。  Lua 语言中所有布尔真与非 nil 的组合的结果被当作真，而布尔假与 nil 组合被当作假。值得注意的是，Lua 中零被当作真，这一点与其它大部分语言不一样。##流程图  ![](http://www.tutorialspoint.com/lua/images/if_else_statement.jpg)  ##示例  \n–[ 定义局部变量 –]a = 100;–[ 检查条件 –]if( a &lt; 20 )then   –[ 如果条件为真，则输出如下内容 –]   print(“a is less than 20” )else   –[ 如果条件为假，则输出如下内容 –]   print(“a is not less than 20” )endprint(“value of a is :”, a)\n123执行上面的代码则可以得到如下的输出结果：  \na is not less than 20value of a is :    100\n123456789101112131415##if...else if...else 语句  if 语句后可以选择跟上 else if...else 语句。该语句对于检测多个条件时非常有用。  使用 if，else if 以及 else 时，请注意以下三点：  &lt;ul&gt;\t&lt;li&gt;if 语句后面至多可以有一个 else 语句。如果有　else if,则此 else 语句必须在 else if 语句之后。&lt;/li&gt;\t&lt;li&gt;if 语句之后可以有多零个或多个 else if，但是这些 else if 必须在　else 语句之前。&lt;/li&gt;\t&lt;li&gt;如果一个 if 语句的条件为真时，其后的所有剩余的 else 和 else if 的都不会再执行，也不会测试它们的条件真假。&lt;/li&gt;&lt;/ul&gt;  ##语法  Lua 中 if...else if...else 语句的语法规则如下：  \nif(boolean_expression 1)then   –[ 如果布尔表达式 1 为真时，则执行此处代码。–]\nelse if( boolean_expression 2)   –[ 如果布尔表达式 2 为真时，则执行此处代码。 –]\nelse if( boolean_expression 3)   –[ 如果布尔表达式 3为真时，则执行此处代码。 –]else   –[ 当上面所有布尔表达式条件都为假时执行此处代码。–]end\n123##示例  \n–[ 定义局部变量 –]a = 100–[ 检查布尔条件 –]if( a == 10 )then   –[ 条件为真时输出如下内容 –]   print(“Value of a is 10” )elseif( a == 20 )then   –[ if else if 条件为真时 –]   print(“Value of a is 20” )elseif( a == 30 )then   –[ if else if 条件为真时 –]   print(“Value of a is 30” )else   –[ 如果上述条件全部为假时 –]   print(“None of the values is matching” )endprint(“Exact value of a is: “, a )\n123  执行上面的代码将得到如下的输出结果：  \nNone of the values is matchingExact value of a is:    100\n\n\n","slug":"lua/2016-06-01-if-else-if-statement","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"15a63bcbcc45ec73313b8b26fa940570","title":"Lua中的if语句","content":"#Lua 中的 if 语句  \nif　语句包括一个布尔表达式和一个或多个语句。　　\n##语法  \nLua 语言 if 语句的语法如下：  \n123456789101112131415if(boolean_expression)then   --[如果布尔表达式为真，statement(s) 执行。--]end```  如果布尔表达式计算结果为真，则 if 语句内的代码块执行；如果布尔表达式计算结果为假，跳过 if 语句中的代码直接执行 if 语句后面的代码。  Lua 语言中所有布尔真与非 nil 的组合的结果被当作真，而布尔假与 nil 组合被当作假。值得注意的是，Lua 中零被当作真，这一点与其它大部分语言不一样：  ##流程图  ![](http://www.tutorialspoint.com/lua/images/if_statement.jpg)##示例  \n–[ 局部变量定义 –]a = 10;–[ 检查 if　语句使用的布尔条件 –]if( a &lt; 20 )then   –[ 如果条件为真则输出如下内容　–]   print(“a is less than 20” );endprint(“value of a is :”, a);\n123执行上面的代码可以得到如下的结果：　　\na is less than 20value of a is : 10\n\n\n","slug":"lua/2016-06-01-if-statement","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"50b76913de0a7e15924d6b0f0dac6bf2","title":"LUA的Loop循环","content":"循环　虽然一般情况下，语句都是顺序执行的：函数内的第一条语句先执行，然后是第二条，依次类推。  但是还是可能存在需要执行一段代码多次的情况。\n为此编程语言提供各式各样的控制结构实现复杂的程序执行路径。\n其中，循环语句可以让我们可以执行一条或一组语句多次。下图中所描述的是大多数语言中循环语句的形式：  \n  \nLua 语言提供了如下几种循环结构语句。点击链接可查看详细说明。  \n\n    \n        循环类型\n        描述\n    \n    \n        while 循环\n        先检测条件，条件为真时再执行循环体，直到条件为假时结束。\n    \n    \n        for 循环\n        执行一个语句序列多次，可以简化管理循环变量的代码。\n    \n        \n        repeat...until 循环\n        重复执行一组代码语句，直到 until 条件为真为止。\n    \n    \n        嵌套循环\n        可以在一个循环语句中再使用一个循环语句。\n        \n  \n\n循环控制语句循环控制语句改变循环正常的执行顺序。当离开一个作用域时，在该作用域内自动创建的对象都会被自动销毁。\nLua 支持如下所示的循环控制语句。点击下面的链接查看详细内容：  \n\n    \n        循环控制语句\n        描述\n    \n        \n        break\n        break 语句结束循环，并立即跳转至循环或 switch 语句后的第一条语句处开始执行。\n        \n\n\n无限循环如果循环条件永远不可能为假，则此循环为无限循环。while 语句经常被当作无限循环语句使用。因为我们可以直接将其条件设置为真，这样 while 就会一直循环下去。在无限循环中，可以使用 break 跳出循环。  \n1234while( true )do   print(&quot;This loop will run forever.&quot;)end\n\n","slug":"lua/2016-06-01-loop","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"LUA教程","author_index":"安全书"},{"id":"3f4bda6307129cf6a3004f8fe27cd085","title":"Lua数学函数库","content":"Lua 数学函数库在科学计算与工程计算领域，我们都需要用到大量的数学函数。在 Lua 的数学库提供了大量的数学函数，如下表所示：  \n\n    \n        S.N.\n        函数与功能\n    \n    \n        1\n        math.abs(x)：返回 x 的绝对值。\n    \n    \n        2\n        math.acos(x)：返回 x 的反余弦值（弧度）。\n    \n    \n        3\n        math.asin(x)：返回 x 的反正弦值（弧度）。\n    \n    \n        4\n        math.atan(x)：返回 x 的反正切值（弧度）。\n    \n    \n        5\n        math.atan2(y,x)，返回 y/x 的反正切值，使用两个参数的符号查找象限（ x 为 0 时也能正确的处理）。\n    \n    \n        6\n        math.ceil（x）:返回大于或等于 x 的最小整数。\n    \n    \n        7\n        math.cos(x)：返回 x 的余弦值（x 以弧度为单位）。\n    \n    \n        8\n        math.cosh(x)：返回 x 的双曲余弦值。\n    \n    \n        9\n        math.deg(x)：返回 x　的角度值（ｘ为弧度）。\n    \n    \n        10\n        math.exp(x)：返回 e 的 x 次幂。\n    \n    \n        11\n        math.floor(x)：返回小于或等于 x 的最大整数。\n    \n    \n        12\n        math.fmod(x,y): 返回 x%y。\n    \n    \n        13\n        math.frexp(x)：返回两个值 m，e，满足 x = m*2^e。其中，e 是整数，m 的绝对值属于区间 [0.5,1)。\n    \n    \n        14\n        math.huge：最大值，不小于任何其它数值。\n    \n    \n        15\n        math.ldexp(m,e)：返回 m*2^e(e 为整数)。\n    \n    \n        16\n        math.log(x)：计算自然对数。\n    \n    \n        17\n        math.log10(x)：计数以 10 为底的对数。\n    \n    \n        18\n        math.max(x,...)：返回输入参数的最大值。\n    \n    \n        19\n        math.min(x,...)：返回输入参数的最小值。\n    \n    \n        20\n        math.modf(x)：返回 x 的整数部分与小数部分。\n    \n    \n        21\n        math.pi：数值 PI。\n    \n    \n        22\n        math.pow(x,y)：等价于 x^y。\n    \n    \n        23\n        math.rad(x)：返回角度 x 的弧度值。\n    \n    \n        24\n        math.random([m,[n]])：该函数直接调用 ANSI C 的伪随机生成函数。无参数时，生成 [0,1) 区间的均匀分布的随机值；只传入参数 m 时，函数生成一个位于区间 [1,m] 的均匀分布伪随机值；同时传入参数 m,n 时，生成位于区间 [m,n] 的均匀分布伪随机值。\n    \n    \n        25\n        math.randomseed(x)：初始化伪随机数生成器种子值。\n    \n    \n        26\n        math.sin(x)：返回 x 的正弦值。\n    \n    \n        27\n        math.sinh(x)：返回 x 的双曲正弦值。\n    \n    \n        28\n        math.sqrt(x)：返回 x 的平方根。\n    \n    \n        29\n        math.tan(x)：返回 x 的正切值。\n    \n    \n        30\n        math.tanh(x)：返回 x 的双曲正切值。\n    \n\n\n三角函数三角函数的使用方法示例如下：  \n123456789101112131415161718radianVal = math.rad(math.pi / 2)io.write(radianVal,&quot;\\n&quot;)-- Sin value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.sin(radianVal)),&quot;\\n&quot;)-- Cos value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.cos(radianVal)),&quot;\\n&quot;)-- Tan value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.tan(radianVal)),&quot;\\n&quot;)-- Cosh value of 90(math.pi / 2) degreesio.write(string.format(&quot;%.1f &quot;, math.cosh(radianVal)),&quot;\\n&quot;)-- Pi Value in degreesio.write(math.deg(math.pi),&quot;\\n&quot;)```  运行上面的程序，我们可以得到如下的输出结果：  \n0.0274155677808040.01.00.01.0180\n123## 另外一些常用的数学函数  \n– Floorio.write(“Floor of 10.5055 is “, math.floor(10.5055),”\\n”)– Ceilio.write(“Ceil of 10.5055 is “, math.ceil(10.5055),”\\n”)– Square rootio.write(“Square root of 16 is “,math.sqrt(16),”\\n”)– Powerio.write(“10 power 2 is “,math.pow(10,2),”\\n”)io.write(“100 power 0.5 is “,math.pow(100,0.5),”\\n”)– Absoluteio.write(“Absolute value of -10 is “,math.abs(-10),”\\n”)–Randommath.randomseed(os.time())io.write(“Random number between 1 and 100 is “,math.random(),”\\n”)–Random between 1 to 100io.write(“Random number between 1 and 100 is “,math.random(1,100),”\\n”)–Maxio.write(“Maximum in the input array is “,math.max(1,100,101,99,999),”\\n”)–Minio.write(“Minimum in the input array is “,math.min(1,100,101,99,999),”\\n”)\n123运行上面的程序，我们可以得到如下的输出结果：  \nFloor of 10.5055 is 10Ceil of 10.5055 is 11Square root of 16 is 410 power 2 is 100100 power 0.5 is 10Absolute value of -10 is 10Random number between 1 and 100 is 0.22876674703207Random number between 1 and 100 is 7Maximum in the input array is 999Minimum in the input array is 1\n\n上面的例子只是给出了数学函数一些简单的使用方法，在实际中我们可以根据自己的需要进行选择和使用。通过更多的练习可以对这些函数更加的熟悉。\n\n","slug":"lua/2016-06-01-math-library","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Lua 元表正如其名，元表也是表。不过，将元表与表相关联后，我们就可以通过设置元表的键和相关方法来改变表的行为。元方法的功能十分强大，使用元方法可以实现很多的功能，比如：  \n\n    修改表的操作符功能或为操作符添加新功能（译注：如果您学过 C++ 之类的面向对象的语言，应该比较好理解，其实它实现的是操作的重载）。\n    使用元表中的 __index 方法，我们可以实现在表中查找键不存在时转而在元表中查找键值的功能。\n  \n\nLua 提供了两个十分重要的用来处理元表的方法，如下：  \n\n    setmetatable(table,metatable):此方法用于为一个表设置元表。\n    getmetatable(table)：此方法用于获取表的元表对象。\n  \n\n首先，让我们看一下如何将一个表设置为另一个表的元表。示例如下：  \n1234567mytable = &#123;&#125;mymetatable = &#123;&#125;setmetatable(mytable,mymetatable)```  上面的代码可以简写成如下的一行代码：  \nmytable = setmetatable({},{})\n12345## __index  下面的例子中，我们实现了在表中查找键不存在时转而在元表中查找该键的功能：  \nmytable = setmetatable({key1 = “value1”}, {  __index = function(mytable, key)    if key == “key2” then      return “metatablevalue”    else      return mytable[key]    end  end})\nprint(mytable.key1,mytable.key2)\n123运行上面的程序，我们可以得到如下的输出结果：  \nvalue1    metatablevalue\n1234567891011接下来逐步解释上面例子运行的过程：  &lt;ul&gt;\t&lt;li&gt;表 mytable 为 &#123;key = &quot;values1&quot;&#125;&lt;/li&gt;\t&lt;li&gt;为 mytable 设置了一个元表，该元表的键 __index 存储了一个函数，我们称这个函数为元方法。&lt;/li&gt;\t&lt;li&gt;这个元方法的工作也十分简单。它仅查找索引 “key2”,如果找到该索引值，则返回 &quot;metatablevalue&quot;,否则返回 mytable 中索引对应的值。&lt;/li&gt;&lt;/ul&gt;上面的程序同样可以简化成如下的形式：  \nmytable = setmetatable({key1 = “value1”}, { __index = { key2 = “metatablevalue” } })print(mytable.key1,mytable.key2)\n12345## __newindex  为元表添加 __newindex 后，当访问的键在表中不存在时，此时添加新键值对的行为将由此元方法（__newindex）定义。下面的例子中，如果访问的索引在表中不存在则在元表中新加该索引值（注意，是添加在另外一个表 mymetatable 中而非在原表 mytable 中。），具体代码如下(译注：请注意此处 __newindex 的值并非一个方法而是一个表。)：  \nmymetatable = {}mytable = setmetatable({key1 = “value1”}, { __newindex = mymetatable })\nprint(mytable.key1)\nmytable.newkey = “new value 2”print(mytable.newkey,mymetatable.newkey)\nmytable.key1 = “new  value 1”print(mytable.key1,mymetatable.newkey1)\n123执行上面的程序，我们可以得到如下的输出结果：  \nvalue1nil    new value 2new  value 1    nil\n1234可以看出，在上面的程序中，如果键存在于主表中，只会简单更新相应的键值。而如果键不在表中时，会在另外的表 mymetatable 中添加该键值对。  在接下来这个例子中，我们用 rawset 函数在相同的表（主表）中更新键值，而不再是将新的键添加到另外的表中。代码如下所示：  \nmytable = setmetatable({key1 = “value1”}, {  __newindex = function(mytable, key, value)        rawset(mytable, key, “&quot;“..value..”&quot;“)\n  end})\nmytable.key1 = “new value”mytable.key2 = 4\nprint(mytable.key1,mytable.key2)\n123执行上面的程序，我们可以得到如下的输出结果：  \nnew value    “4”\n1234567rawset 函数设置值时不会使用元表中的 __newindex 元方法。同样的，Lua 中也存的一个 rawget 方法，该方法访问表中键值时也不会调用 __index 的元方法。  ## 为表添加操作符行为  使用 + 操作符完成两个表组合的方法如下所示（译注：可以看出重载的意思了）：  \nmytable = setmetatable({ 1, 2, 3 }, {  __add = function(mytable, newtable)    for i = 1, table.maxn(newtable) do      table.insert(mytable, table.maxn(mytable)+1,newtable[i])    end    return mytable  end})\nsecondtable = {4,5,6}\nmytable = mytable + secondtablefor k,v in ipairs(mytable) doprint(k,v)end\n123执行上面的的程序，我们可以得到如下的输出结果：  \n1    12    23    34    45    56    6\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354元表中 __add 键用于修改加法操作符的行为。其它操作对应的元表中的键值如下表所示。  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;键&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__add&lt;/td&gt;\t\t&lt;td&gt;改变加法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__sub&lt;/td&gt;\t\t&lt;td&gt;改变减法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__mul&lt;/td&gt;\t\t&lt;td&gt;改变乘法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__div&lt;/td&gt;\t\t&lt;td&gt;改变除法操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__mod&lt;/td&gt;\t\t&lt;td&gt;改变模除操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__unm&lt;/td&gt;\t\t&lt;td&gt;改变一元减操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__concat&lt;/td&gt;\t\t&lt;td&gt;改变连接操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__eq&lt;/td&gt;\t\t&lt;td&gt;改变等于操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__lt&lt;/td&gt;\t\t&lt;td&gt;改变小于操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;__le&lt;/td&gt;\t\t&lt;td&gt;改变小于等于操作符的行为。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;  ## __call  使用 __call 可以使表具有像函数一样可调用的特性。下面的例子中涉及两个表，主表 mytable 和 传入的实参表结构 newtable，程序完成两个表中值的求和。\nmytable = setmetatable({10}, {  __call = function(mytable, newtable)    sum = 0    for i = 1, table.maxn(mytable) do        sum = sum + mytable[i]    end    for i = 1, table.maxn(newtable) do        sum = sum + newtable[i]    end    return sum  end})newtable = {10,20,30}print(mytable(newtable))\n123运行上面的代码，我们可以得到如下的输出结果：  \n70\n12345## __tostring  要改变 print 语句的行为，我们需要用到 __tostring 元方法。下面是一个简单的例子：  \nmytable = setmetatable({ 10, 20, 30 }, {  __tostring = function(mytable)    sum = 0    for k, v in pairs(mytable) do        sum = sum + v    end    return “The sum of values in the table is “ .. sum  end})print(mytable)\n123运行上面的代码，我们可以得到如下的输出结果：  \nThe sum of values in the table is 60\n```  \n如果你完全掌握了元表的用法，你就可以实现很多看上面很复杂的操作。如果不使用元表，就不仅仅是看上去很复杂了，而是真的非常复杂。所以，多做一些使用元表的练习，并熟练掌握所有元表的可选项，这会让你受益匪浅。\n","slug":"lua/2016-06-01-metatables","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"LUA教程","author_index":"安全书"},{"id":"eacf32e453764fca08d4d96ce1e78183","title":"Lua迭代器","content":"Lua 迭代器迭代器是用于遍历集合或容器中元素的一种结构。在 Lua 语言中，集合往往指的是可以用来创建各种数据结构的表。比如，数组就是用表来创建的。  \n通用迭代器通用迭代器可以访问集合中的键值对。下面是通用迭代器的一个简单例子：  \n12345678910array = &#123;&quot;Lua&quot;, &quot;Tutorial&quot;&#125;for key,value in ipairs(array) do   print(key, value)end```  执行的上面的代码，我们可以得到如下的输出结果：  \n1  Lua2  Tutorial\n12345678910111213141516上面的例子中使用了 Lua 提供的默认迭代器函数 ipairs。  在 Lua 语言中，我们使用函数表示迭代器。根据是否在迭代器函数中是否维护状态信息，我们将迭代器分为以下两类：  &lt;ul&gt;\t&lt;li&gt;无状态迭代器&lt;/li&gt;  \t&lt;li&gt;有状态迭代器&lt;/li&gt;&lt;/ul&gt;  ## 无状态迭代器  由此迭代器的名称就可以看出来，这一类的迭代器函数中不会保存任何中间状态。  让我们一起来看一下下面这个例子。在这个例子中，我们用一个简单的函数创建了一个自己的迭代器。这个迭代器用以输出 n 个数的平方值。  \nfunction square(iteratorMaxCount,currentNumber)   if currentNumber&lt;iteratorMaxCount   then      currentNumber = currentNumber+1   return currentNumber, currentNumber*currentNumber   endend\nfor i,n in square,3,0do   print(i,n)end\n123执行上面的代码，我们可以得到如下的输出结果：  \n1    12    43    9\n123我们可以稍微的修改一下上面的代码，使得此迭代器可以像 ipairs 那样工作。如下所示：  \nfunction square(iteratorMaxCount,currentNumber)   if currentNumber&lt;iteratorMaxCount   then      currentNumber = currentNumber+1   return currentNumber, currentNumber*currentNumber   endend\nfunction squares(iteratorMaxCount)   return square,iteratorMaxCount,0end  \nfor i,n in squares(3)do    print(i,n)end\n12执行上面的代码，我们可以得到如下的输出结果：  \n1    12    43    9\n1234567## 有状态迭代器  前面的例子使用的迭代器函数是不保存状态的。每次调用迭代器函数时，函数基于传入函数的第二个变量访问集合的下一个元素。在 Lua 中可以使用闭包来存储当前元素的状态。闭包通过函数调用得到变量的值。为了创建一个新的闭包，我们需创建两个函数，包括闭包函数本身和一个工厂函数，其中工厂函数用于创建闭包。  下面的示例中，我们将使用闭包来创建我们的迭代器。  \narray = {“Lua”, “Tutorial”}\nfunction elementIterator (collection)   local index = 0   local count = #collection   – 返回闭包函数   return function ()      index = index + 1      if index &lt;= count      then         – 返回迭代器的当前元素         return collection[index]      end   endend\nfor element in elementIterator(array)do   print(element)end\n123执行上面的代码，我们可以得到如下的输出结果：  \nLuaTutorial\n```  \n上面的例子中我们可以看到，在　elementIterator 函数内定义了另外一个匿名函数。此匿名函数中使用了一个外部变量 index (译注：此变量在匿名函数之外，elementIterator 函数内)。每次内部的匿名函数被调用时，都会将 index 的值增加 1，并统计数返回的每个元素。 \n我们可以参照上面的方法使用闭包创建一个迭代器函数。每次我们使用迭代器遍历集合时，它都可以返回多个元素。\n","slug":"lua/2016-06-01-iterators","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"795dd91f8815508a13e65b7151fdf68c","title":"Lua模块","content":"Lua 模块什么是模块？Lua 中的模块与库的概念相似，每个模块都有一个全局唯一名字，并且每个模块都包含一个表。使用一个模块时，可以使用 require 加载模块。模块中可以包括函数和变量，所有这些函数和变量被表存储于模块的表中。模块中的表的功能类似于命名空间，用于隔离不同模块中的相同的变量名。在使用模块的时候，我们应该遵守模块定义的规范，在 require 加载模块时返回模块中的包含函数和变量的表对象。  \nLua 模块的特别之处模块中表的使用使得我们可在绝大多数情况下可以像操作其它表一样操作模块。由于 Lua 语言允许对模块本身进行操作，所以 Lua 也就具备了许多其它语言需要特殊机制才能实现的特殊性质。例如，这种自由的表操作机制使得编程人员可以用多种方法调用模块中的函数。下面的例子演示了其中的一些方法：  \n1234567891011121314151617181920212223242526-- 假设我们有一个板块 printFormatter-- 该模块有一个函数 simpleFormat(arg)-- 方法 1require &quot;printFormatter&quot;printFormatter.simpleFormat(&quot;test&quot;)-- 方法 2local formatter = require &quot;printFormatter&quot;formatter.simpleFormat(&quot;test&quot;)-- 方法 3require &quot;printFormatter&quot;local formatterFunction = printFormatter.simpleFormatformatterFunction(&quot;test&quot;)```  从上面的例子中可以看出，Lua 不需要任何额外的代码就可以实现非常灵活的编程技巧。  ## require 函数  Lua 提供了一个高层次抽象的函数 require，使用这个函数可以加载所有需要的模块。在设计之初，这个函数就被设计的尽可能的简单，以避免加载模块时需要太多的模块信息。require 函数加载模块时把所有模块都只当作一段定义了变量的代码（事实上是一些函数或者包含函数的表）而已，完全不需要更多的模块信息。  ## 示例  让我们看一下面这个例子。在这个例子中，我们定义了模块 mymath,在这个模块中定义一些数学函数，并将该模块存储于 mymath.lua 文件中。具体内容如下：  \nlocal mymath =  {}function mymath.add(a,b)   print(a+b)end\nfunction mymath.sub(a,b)   print(a-b)end\nfunction mymath.mul(a,b)   print(a*b)end\nfunction mymath.div(a,b)   print(a/b)end\nreturn mymath\n123接下来，我们在另一个文件　moduletutorial.lua 文件中访问这个模块。具体代码如下所示：  \nmymathmodule = require(“mymath”)mymathmodule.add(10,20)mymathmodule.sub(30,20)mymathmodule.mul(10,20)mymathmodule.div(30,20)\n123运行这段代码这前，我们需要将两个 lua 源代码文件放在同一目录下，或者把模块代码文件放在包路径下（这种情况需要额外的配置）。运行上面的代码，可以得到如下的输出结果：  \n30102001.5\n12345678910111213## 注意事项  &lt;ul&gt;\t&lt;li&gt;把模块和待运行的文件放在相同的目录下。&lt;/li&gt;\t&lt;li&gt;模块的名称与文件名称相同。&lt;/li&gt;\t&lt;li&gt;为 require 函数返回模块（在模块中使用 return 命令返回存储了函数和变量的表）。尽管有其它的模块实现的方式，但是建议您使用上面的实现方法。&lt;/li&gt;&lt;/ul&gt;  ## 更老的实现模块的方法 下面，我们将用 package.seall 这种比较老的方法重新实现上面的例子。这种实现方法主要用于 Lua 5.1 或 5.2 版本。使用这种方式实现模块的代码如下所示：  \nmodule(“mymath”, package.seeall)\nfunction mymath.add(a,b)   print(a+b)end\nfunction mymath.sub(a,b)   print(a-b)end\nfunction mymath.mul(a,b)   print(a*b)end\nfunction mymath.div(a,b)   print(a/b)end\n123使用此模块的代码如下所示：  \nrequire(“mymath”)mymath.add(10,20)mymath.sub(30,20)mymath.mul(10,20)mymath.div(30,20)\n```  \n当我们运行这段代码，我们会得到与前面相同的输出结果。但是建议你不要使用这种方式，因为普遍认为这种方式不及新的方法安全。许多用到 Lua 语言的 SDK 都已经不再使用这种方式定义模块，例如, Corna SDK。\n","slug":"lua/2016-06-01-modules","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"5244c371e170ba321efd30c500d79562","title":"Lua中的嵌套 if 语句","content":"#Lua 中的嵌套 if 语句  \n在 Lua 语言中，你可以合法的嵌套使用 if-else 语句。这也就是说，你可以在一个 if 或 if-else 语句内再使用一个　if 或 if-else 语句。  \n##语法  \n嵌套 if 语句的语法规则如下：  \n1234567891011121314if( boolean_expression 1)then   --[ 如果布尔表达式 1 为真，则执行此处代码。 --]   if(boolean_expression 2)   then      --[ 如果布尔表达式 2 为真（注：布尔表达式 1 为真），则执行此处代码）。 --]   endend```  你也可以像嵌套使用 if 语句那样使用嵌套使用 else if...else 语句。  ##示例  \n–[ 定义局部变量 –]a = 100;b = 200;–[ 检查条件真假 –]if( a == 100 )then   –[ 如果前面的条件为真，再检查下面的条件。 –]   if( b == 200 )   then      –[ 如果条件为真，则输出如下内容 –]      print(“Value of a is 100 and b is 200” );   endendprint(“Exact value of a is :”, a );print(“Exact value of b is :”, b );\n123执行上面的代码，可以得到如下的输出结果：  \nValue of a is 100 and b is 200Exact value of a is :    100Exact value of b is :    200```\n","slug":"lua/2016-06-01-nested-if-statement","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"cce4b5e763b43300a4fad206fcb6b9e4","title":"Lua循环嵌套","content":"#Lua 循环嵌套  \nLua 编程语言允许使用循环嵌套。接下来这一节中将用例子来说嵌套循环的使用方法：  \n##语法  \nfor 循环嵌套的语法如下：  \n1234567891011for init,max/min value, incrementdo   for init,max/min value, increment   do      statement(s)   end   statement(s)end```  while 循环嵌套的语法如下：  \nwhile(condition)do   while(condition)   do      statement(s)   end   statement(s)end\n123repeat...until  循环嵌套的语法如下：  \nrepeat   statement(s)   repeat      statement(s)   until( condition )until( condition )\n1234567需要注意的是，在任何外层循环类型内可以使用任何内层循环类型。  ##示例  下面的例子中使用了嵌套循环：  \nj =2for i=2,10 do   for j=2,(i/j) , 2 do      if(not(i%j))      then         break      end      if(j &gt; (i/j))then         print(“Value of i is”,i)      end   endend\n123运行上面的代码，可以得到如下的输出结果：　　\nValue of i is    8Value of i is    9Value of i is    10\n\n\n","slug":"lua/2016-06-01-nested-loop","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"67d9d5e60b37525bc4954f8a5bb0acb9","title":"操作符","content":"操作符操作符是用于告诉解释器执行特定的数学或逻辑运算的符号。Lua 语言有丰富的内置操作符，主要包括以下几类：  \n\n    算术运算操作符\n    关系运算操作符\n    逻辑运算操作符\n    其它操作符\n\n这篇教程将会依次介绍以上四类操作符。  \n\n算术去处操作符下面的表中列出了所有 Lua 语言支持的算术运算操作符。假设 A 变量的值为 10，B 变量的值为 20，则：  \n\n    \n        操作符\n        描述\n        示例\n    \n    \n        +\n        两个操作数据相加\n        A + B = 30\n    \n    \n        -\n        第一个操作数减去第二个操作数据\n        A - B = 10\n    \n    \n        *\n        两个操作数相乘\n        A * B = 200\n    \n    \n        %\n        模除操作符\n        A % B = 0\n    \n    \n        ^\n        幂运算符\n        A ^ 2 = 100\n    \n    \n        -\n        一元减操作符用于取反\n        -A = -10\n    \n\n\n关系运算符下面的表列出了 Lua 支持的所有关系运算符。假设 A 的值为 10，B 的值为 20，则：  \n\n    \n        操作符\n        描述\n        示例\n    \n    \n        ==\n        判断两个操作数是否相等，若相等则条件为真，否则为假。\n        (A == B) 为假。\n    \n    \n        ~=\n        判断两个操作数是否相等，若不相等则条件为真，否则为假。\n        (A ~= B) 为真。\n    \n    \n        >\n        如果左操作数大于右操作数则条件为真，否则条件为假。\n        (A > B) 为假。\n    \n    \n        \n        如果左操作数小于右操作数则条件为真，否则条件为假。\n        (A \n    \n    \n        >=\n        如果左操作数大于或等于右操作数则条件为真，否则条件为假。\n        (A >= B) 为假。\n    \n    \n        \n        如果左操作数小于或等于右操作数则条件为真，否则条件为假。\n        (A \n    \n    \n\n\n逻辑运算符下面的表列出了 Lua 支持的所有逻辑运算符。假设 A 的值为 真（非零），B 的值为 假（零），则： \n\n    \n        操作符\n        描述\n        示例\n    \n    \n        and\n        逻辑与运算符。如果两个操作数都非零，则条件为真。\n        (A and B) 为假。\n    \n    \n        or\n        逻辑或运算符。如果两个操作数中其中有一个非零，则条件为真。\n        (A or B) 为真。\n    \n    \n        not\n        逻辑非运算符。翻转操作数的逻辑状态。如果条件是真，则逻辑非运算符会将其变成假。\n        !(A and B) 为真。\n    \n\n\n其它操作符Lua 语言还支持另外两个操作符：\n\n    \n        操作符\n        描述\n        示例\n    \n    \n        ..\n        连接两个字符串。\n        若 a 为 \"Hello\"，b 为 \"World\",则 a..b 返回 \"Hello World\"。\n    \n    \n        #\n        一元运算符，返回字符串或者表的长度。\n        #\"Hello\" 返回 5。\n    \n\n\n\n操作符优先级操作符的优先级将决定表达式中的项如何组合。这会影响到表达式的求值。一些操作符比另外一些操作符有更高的优先级。例如，乘法操作符优先级比加法操作符更高。 \n例如 x = 7 +3*2，这里 x 的值为 13，而不是 20。这是因为操作符 * 优级级比操作符 + 优先级更高，所以先得到 3*2 的乘积，然后再加上 7。  \n下面的表中，从上到下优先级递减。在每个表达式中，高优先级操作数先运算。  \n\n    \n        分类\n        操作数\n        结合性\n    \n    \n        一元运算符类\n        not # -\n        从右至左\n    \n    \n        连接运算符\n        ..\n        从右至左\n    \n    \n        乘除运算符类\n        * / %\n        从左至右\n    \n    \n        加减运算符类\n        + - \n        从左至右\n    \n    \n        关系运算符类\n         = == ~=\n        从左至右\n    \n    \n        等于运算符类\n        == ~=\n        从左至右\n    \n    \n        逻辑与运算符\n        and\n        从左至右\n    \n    \n        逻辑或运算符\n        or\n        从左至右\n    \n\n","slug":"lua/2016-06-01-operators","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"a1b21463fc87d45dd3b0b4f9d1ff1b21","title":"Lua面向对象","content":"Lua 面向对象面向对象概述面向对象编程技术是目前最常用的编程技术之一。目前大量的编程语言都支持面向对象的特性： \n\n    C++\n    Java\n    Objective-C\n    Smalltalk\n    C#\n    Ruby\n\n\n面向对象的特征\n    类（class）：类是可以创建对象，并为状态（成员变量）提供初值及行为实现的可扩展模板。\n    对象（objects）：对象是类的实例，每个对象都有独立的内存区域。\n    继承（inheritance）：继承用于描述一个类的变量和函数被另一个类继承的行为。\n    封装（encapsulation）：封装是指将数据和函数组织在一个类中。外部可以通过类的方法访问内中的数据。封装也被称之为数据抽象。\n\n## Lua 中的面向对象  \n\n在 Lua 中，我们可以使用表和函数实现面向对象。将函数和相关的数据放置于同一个表中就形成了一个对象。继承可以用元表实现，它提供了在父类中查找存在的方法和变量的机制。Lua 中的表拥有对象的特征，比如状态和独立于其值的标识。两个有相同值的对象（表）是两个不同的对象，但是一个对象在不同的时间可以拥有不同的值。与对象一样，表拥有独立于其创建者和创建位置的生命周期。  \n一个真实世界的例子面向对象已经是一个广泛使用的概念，但是你需要正确清楚地理解它。让我们看一个数学方面的例子。我们经常需要处理各种形状，比如圆、矩形、正方形。这些形状有一个共同的特征——面积。所以，所有其它的形状都可以从有一个公共特征——面积的基类扩展而来。每个对象都可以有它自己的特征和函数，比如矩阵有属性长、宽和面积，printArea 和 calculateArea 方法。  \n创建一个简单的类下面例子实现了矩阵类的三个属性：面积、长和宽。它还同时实现了输出面积的函数 printArea。  \n123456789101112131415161718192021222324-- 元类Rectangle = &#123;area = 0, length = 0, breadth = 0&#125;-- 继承类的方法 newfunction Rectangle:new (o,length,breadth)  o = o or &#123;&#125;  setmetatable(o, self)  self.__index = self  self.length = length or 0  self.breadth = breadth or 0  self.area = length*breadth;  return oend-- 继承类的方法 printAreafunction Rectangle:printArea ()  print(&quot;The area of Rectangle is &quot;,self.area)end```  ### 创建对象  创建对象即是为类的实例分配内存空间的过程。每个对象都有自己独立的内存区域，同时还会共享类的数据。  \nr = Rectangle:new(nil,10,20)\n12345### 访问属性我们可以使用点操作符访问类中属性。  \nprint(r.length)\n12345### 访问成员方法  使用冒号操作符可以访问对象的成员方法，如下所示：  \nr:printArea()\n1234567初始化阶段，调用函数为对象分配内存同时设置初值。这与其它与面向对象的语言中的构造器很相似。其实，构造器本身也就和上面的初始化代码一样，并没有什么特别之处。  ## 完整的例子  让我们一起看一个 Lua 实现面向对象的完整例子。  \n– 元类Shape = {area = 0}\n– 基类方法 newfunction Shape:new (o,side)  o = o or {}  setmetatable(o, self)  self.__index = self  side = side or 0  self.area = side*side;  return oend\n– 基类方法 printAreafunction Shape:printArea ()  print(“The area is “,self.area)end\n– 创建对象myshape = Shape:new(nil,10)\nmyshape:printArea()\n123运行上面的程序，我们可以得到如下的输出结果：  \nThe area is     100\n123456### Lua 中的继承  继承就是从基对象扩展的过程，正如从图形扩展至矩形、正方形等等。在现实世界中，常用来共享或扩展某些共同的属性和方法。  让我们看一个简单的类扩展的例子。我们有如下的类：  \n – 元类Shape = {area = 0}– 基类方法 newfunction Shape:new (o,side)  o = o or {}  setmetatable(o, self)  self.__index = self  side = side or 0  self.area = side*side;  return oend– 基类方法 printAreafunction Shape:printArea ()  print(“The area is “,self.area)end\n123我们从上面的类中扩展出正方形类，如下所示：  \nSquare = Shape:new()– 继承类方法 newfunction Square:new (o,side)  o = o or Shape:new(o,side)  setmetatable(o, self)  self.__index = self  return oend\n12345### 重写基类的函数  继承类可以重写基类的方法，从而根据自己的实际情况实现功能。示例代码如下所示：  \n– 继承方法 printAreafunction Square:printArea ()  print(“The area of square is “,self.area)end\n12345## 继承的完整示例  在元表的帮助下，我们可以使用新的 new 方法实现类的扩展（继承）。子类中保存了所有基类的成员变量和方法。  \n – Meta classShape = {area = 0}– Base class method newfunction Shape:new (o,side)  o = o or {}  setmetatable(o, self)  self.__index = self  side = side or 0  self.area = side*side;  return oend– Base class method printAreafunction Shape:printArea ()  print(“The area is “,self.area)end\n– Creating an objectmyshape = Shape:new(nil,10)myshape:printArea()\nSquare = Shape:new()– Derived class method newfunction Square:new (o,side)  o = o or Shape:new(o,side)  setmetatable(o, self)  self.__index = self  return oend\n– Derived class method printAreafunction Square:printArea ()  print(“The area of square is “,self.area)end\n– Creating an objectmysquare = Square:new(nil,10)mysquare:printArea()\nRectangle = Shape:new()– Derived class method newfunction Rectangle:new (o,length,breadth)  o = o or Shape:new(o)  setmetatable(o, self)  self.__index = self  self.area = length * breadth  return oend\n– Derived class method printAreafunction Rectangle:printArea ()  print(“The area of Rectangle is “,self.area)end\n– Creating an objectmyrectangle = Rectangle:new(nil,10,20)myrectangle:printArea()\n123运行上面的程序，我们可以得到如下的输出结果：  \nThe area is     100The area of square is     100The area of Rectangle is     200\n```  \n上面的例子中，我们继承基类 Shape 创建了两个子类 Rectange 与 Square。在子类中可以重写基类提供的方法。在这个例子中，子类重写了 printArea 方法。\n","slug":"lua/2016-06-01-object-oriented","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"690a2272c904046df2d9d8b8e3328a46","title":"Lua操作系统工具库","content":"Lua 操作系统工具库在很多应用中，我们都需要访问到操作系统级别的函数，操作系统库就给我们提供了这样的工具。下面的列表给出操作系统工具包提供的方法：  \n\n    \n        S.N.\n        函数与功能\n    \n    \n        1\n        os.clock()：以秒为单位返回程序运行所用 CPU 时间的近似值。\n    \n    \n        2\n        os.date([format[,time]])：返回时间字符串或包含时间的表，时间按指定格式格式化。\n    \n    \n        3\n        os.difftime(t2,t1)：返回从 t1 时刻至 t2 时刻经历的时间。在 POSIX，windows，及其它某些系统中，该值就是 t2-t1。\n    \n    \n        4\n        os.execute([command])：该函数等价于 ANSI C 中的 system 函数。传递的参数 command 由操作系统的 shell 执行。如果命令成功结束，则返回的第一个值为 true，否则为 nil。\n    \n    \n        5\n        os.exit([code[,close]])：调用 ANSI C 的 exit 函数，结束程序。如果 code 为　true, 则返回状态为 EXIT_SUCESS；若 code 为 false,则返回状态为 EXIT_FAILURE。如果 code 为数值，则返回状态也就为该数值。\n    \n    \n        6\n        os.getenv(varname)：返回进程的环境变量 varname 的值，如果此环境变量没有定义则返回 nil。\n    \n    \n        7\n        os.remove(filename)：删除文件（或 POSIX 系统中的空目录）。如果函数失败，则返回 nil 以及描述错误的字符串与错误代码。\n    \n    \n        8\n        os.rename(oldname,newname)：重命名文件或目录。如果函数失败，则返回 nil 以及描述错误的字符串与错误代码。\n    \n    \n        9\n        os.setlocale(locale[,category])：设置程序当前的地区（locale），locale 是一个与操作系统相关的字符串。category 是一个可选的字符串，描述设置更改的范围，包括: all，collate，ctype，monetary，numeric，time。默认为 all。函数返回新地区的名称，如果函数调用失败则返回 nil。\n    \n    \n        10\n        os.time([table])：无参数时，返回当前时间；传入参数时，则返回指定参数表示的日期和时间。传入的参数必须包含以下的域:年、月、日。时（默认 12）、分（默认 0）、秒（默认 0）、isdst（默认 nil） 四个域是可选的。\n    \n    \n        11\n        os.tmpname()：返回一个可作为临时文件名的字符串。这个临时文件必须显式地打开，使用结束时也必须显式地删除。\n    \n\n\n常用的 OS 函数示例如下：  \n12345678910111213141516171819-- 格式化日期io.write(&quot;The date is &quot;, os.date(&quot;%m/%d/%Y&quot;),&quot;\\n&quot;)-- 日期与时间io.write(&quot;The date and time is &quot;, os.date(),&quot;\\n&quot;)-- 时间io.write(&quot;The OS time is &quot;, os.time(),&quot;\\n&quot;)-- 等待一段时间for i=1,1000000 doend-- Lua 启动的时长io.write(&quot;Lua started before &quot;, os.clock(),&quot;\\n&quot;)```  执行上面的程序，我们可以得到如下的输出结果： \nThe date is 01/25/2014The date and time is 01/25/14 07:38:40The OS time is 1390615720Lua started before 0.013\n\n上面的例子只是简单的说明了一下操作系统相关函数的使用，实际开发过程中，可以根据实际情况使用所有函数。可以多做一些练习熟悉上面所列出的函数。\n\n","slug":"lua/2016-06-01-operating-system-facilities","date":"2024-03-14T06:15:59.725Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"a760ef6d11a2d6078a812f5bc31cf898","title":"数据类型","content":"数据类型Lua 是动态类型编程语言，变量没有类型，只有值才有类型。值可以存储在变量中，作为参数传递或者作为返回值。尽管在 Lua 中没有变量数据类型，但是值是有类型的。下面的列表中列出了数据类型： \n\n    \n        值类型\n        描述\n    \n    \n        nil\n        用于区分值是否有数据，nil 表示没有数据。\n    \n    \n        boolean\n        布尔值，有真假两个值，一般用于条件检查。\n    \n    \n        number\n        数值，表示实数(双精度浮点数)。\n    \n    \n        string\n        字符串。\n    \n    \n        function\n        函数，表示由 C 或者 Lua 写的方法。\n    \n    \n        userdata\n        表示任意 C 数据。\n    \n    \n        thread\n        线程，表示独立执行的线程，它被用来实现协程。\n    \n    \n        table\n        表，表示一般的数组，符号表，集合，记录，图，树等等，它还可以实现关联数组。它可以存储除了 nil 外的任何值。\n    \n \n \ntype 函数Lua　中有一个 type　函数，它可以让我们知道变量的类型。下面的代码中给出了一些例子：　　\n123456789101112print(type(&quot;What is my type&quot;))   --&gt; stringt=10print(type(5.8*t))               --&gt; numberprint(type(true))                --&gt; booleanprint(type(print))               --&gt; functionprint(type(type))                --&gt; functionprint(type(nil))                 --&gt; nilprint(type(type(ABC)))           --&gt; string```  在 Linux 系统中运行上面的代码可以得到如下的结果：  \nstringnumberfunctionfunctionbooleannilstring\n\n默认情况下，在被初始化或赋值前，所有变量都指向 nil。 Lua 中空字符串和零在条件检查时，都被当作真。所以你在使用布尔运算的时候要特别注意。在下一章中，我们会了解到更多关于这些类型的知识。\n\n","slug":"lua/2016-06-01-data-types","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"5593d949c022c9556ceb62d288c587d5","title":"Lua数据库访问","content":"Lua 数据库访问简单的数据操作，我们用文件就可以处理。但是，某些时候文件操作存在性能、扩展性等问题。这时候，我们就需要使用数据库。LuaSQL 是一个提供数据库操作的库，它支持多种 SQL 数据库的操作。包括：  \n\n    SQLite\n    MySQL\n    ODBC\n  \n在本教程中，我们会讲解用 Lua 语言对 MySQL 数据库与 SQLite 数据库进行操作。这些操作具有一般性，它们也可以移植到其它类型 SQL 数据库中。首先让我们看一下如何操作 MySQL 数据库。  \n\nMySQL 数据库环境设置为了下面的例子可以正确演示，我们需要首先初始化数据库设置。我们假设你已经完成了如下的工作：  \n\n    安装 MySQL 数据库，使用默认用户名 root， 默认密码为： 123456。\n    已经创建数据库 test。\n    已经阅读过关于 MySQL 的基本教程，并掌握了 MySQL 的基本知识。\n  \n\n导入 MySQL假设你已经安装配置正确了，那么我们可以使用 require 语句导入 sqlite 库。安装过程中会产生一个存储数据相关文件的目录 libsql。  \n123456789mysql = require &quot;luasql.mysql&quot;```  我们可以通过 mysql 变量访问 luasql.mysql 中的 mysql 表，该表中存存储数据库操作相关的函数。### 建立连接 先初始化 MySQL 的环境，再建立一个连接。如下所示：  \nlocal env  = mysql.mysql()local conn = env:connect(‘test’,’root’,’123456’)\n1234567上面的程序会与已存在的 MySQL 数据库 test 建立连接。### 执行函数LuaSQL 库中有一个 execute 函数，此函数可以完成所有数据加操作，包括创建、插入、更新等操作。其语法如下所示：  \nconn:execute([[ ‘MySQLSTATEMENT’ ]])\n1234567执行上面的语句这前，我们需要保证与 MySQL 数据库的连接 conn 是打开的，同时将 MySQLSTATEMENT 更改为合法的 SQL 语句。  ### 创建表下面的示例演示如何创建一个数据库表。例子中为表创建了两个属性分别为 id 和 name，其类型分别为整数和 vchar。  \nmysql = require “luasql.mysql”\nlocal env  = mysql.mysql()local conn = env:connect(‘test’,’root’,’123456’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample2 (id INTEGER, name TEXT);]])print(status,errorString )\n123运行上面的程序后，数据库中创建了一个表 sample，该表有两列，属性名分别为 id 和 name。\nMySQL environment (004BB178)    MySQL connection (004BE3C8)0    nil\n123如果发生错误，则函数将返回一个错误消息，成功执行则返回 nil。下面是错误消息的一个例子：  \nLuaSQL: Error executing query. MySQL: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘“id INTEGER, name TEXT)’ at line 1\n12345### 插入语句  ＭySQL 插入语句的示例如下所示：  \n conn:execute([[INSERT INTO sample values(‘11’,’Raj’)]])\n12345### 更新语句  ＭySQL 更新语句的示例如下所示：  \nconn:execute([[UPDATE sample3 SET name=’John’ where id =’12’]])\n12345### 删除语句  ＭySQL 删除语句的示例如下所示：  \nconn:execute([[DELETE from sample3 where id =’12’]])\n12345### 查找语句   成功查找返回后，我们需要循环遍历返回的所有行以取得我们需要的数据。查找语句的示例如下：  \ncursor,errorString = conn:execute([[select * from sample]])row = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  – reusing the table of results  row = cursor:fetch (row, “a”)end\n1234567上面的代码中，我们先打开了一个 MySQL 连接。通过 execute 函数返回的游标(cursor)，我们可以使用游标遍历返回的表，取得我们查找的数据。### 完整示例  下面这个例子用到了所有上面提到的数据的操作函数，请看下面这个完整的例子：  \nmysql = require “luasql.mysql”\nlocal env  = mysql.mysql()local conn = env:connect(‘test’,’root’,’123456’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample3 (id INTEGER, name TEXT)]])print(status,errorString )\nstatus,errorString = conn:execute([[INSERT INTO sample3 values(‘12’,’Raj’)]])print(status,errorString )\ncursor,errorString = conn:execute([[select * from sample3]])print(cursor,errorString)\nrow = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  row = cursor:fetch (row, “a”)end– close everythingcursor:close()conn:close()\n123运行上面的程序，我们可以得到如下的输出结果：  \nMySQL environment (0037B178)    MySQL connection (0037EBA8)0    nil1    nilMySQL cursor (003778A8)    nilId: 12, Name: Raj\n12345678910111213141516## 执行事务  事务是数据库中保证数据一致性的一种机制。事务有以下四个性质：  &lt;ul&gt;\t&lt;li&gt;原子性：一个事务要么全部执行要么全部不执行。&lt;/li&gt;\t&lt;li&gt;一致性：事务开始前数据库是一致状态，事务结束后数据库状态也应该是一致的。&lt;/li&gt;\t&lt;li&gt;隔离性：多个事务并发访问时，事务之间是隔离的，一个事务的中间状态不能被其它事务可见。&lt;/li&gt;\t&lt;li&gt;持久性： 在事务完成以后，该事务所对数据库所做的更改便持久的保存在数据库之中，并不会被回滚。&lt;/li&gt;\t&lt;/ul&gt;事务以 START_TRANSACTION 开始，以 提交（commit）或 回滚（rollback）语句结束。  ### 事务开始  为了初始化一个事务，我们需要先打开一个 MySQL 连接，再执行如下的语句：  \nconn:execute([[START TRANSACTION;]])\n12345### 事务回滚  当需要取消事务执行时，我们需要执行如下的语句回滚至更改前的状态。\nconn:execute([[ROLLBACK;]])\n12345### 提交事务  开始执行事务后，我们需要使用 commit 语句提交完成的修改内容。\nconn:execute([[COMMIT;]])\n1234567前面我们已经了解了 MySQL 的基本知识。接下来，我们将解释一下基本的  SQL 操作。请记住事务的概念，虽然我们在 SQLite3 中我们不在解释它，但是它的概念在 SQLite3 中同样适用。  ## 导入 SQLite 假设你已经安装配置正确了，那么就可以使用 require 语句导入 sqlite 库。安装过程中会产生一个存储数据相关文件的目录 libsql。  \n sqlite3 = require “luasql.sqlite3”\n1234567通过 sqlite3 变量可以访问提供的所有数据库操作相关函数。  ### 建立连接  我们先初始化 sqlite 环境，然后为该环境创建一个连接。语法如下：  \nlocal env  = sqlite3.sqlite3()local conn = env:connect(‘mydb.sqlite’)\n1234567上面的代码会与一个 sqlite 文件建立连接，如果文件不存在则创建新的 sqlite 文件并与该新文件建立连接。  ### 执行函数  LuaSQL 库中有一个 execute 函数，此函数可以完成所有数据加操作，包括创建、插入、更新等操作。其语法如下所示：  \nconn:execute([[ ‘SQLite3STATEMENT’ ]])\n1234567执行上面的语句这前，我们需要保证与 MySQL 数据库的连接 conn 是打开的，同时将 SQLite3STATEMENT 更改为合法的 SQL 语句。  ### 创建表下面的示例演示如何创建一个数据库表。例子中为表创建了两个属性分别为 id 和 name，其类型分别为整数和 vchar。  \nsqlite3 = require “luasql.sqlite3”\nlocal env  = sqlite3.sqlite3()local conn = env:connect(‘mydb.sqlite’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample (‘id’ INTEGER, ‘name’ TEXT)]])print(status,errorString )\n123运行上面的程序后，数据库中创建了一个表 sample，该表有两列，属性名分别为 id 和 name。\nSQLite3 environment (003EC918)    SQLite3 connection (00421F08)0    nil\n123如果发生错误，则函数将而一个错误消息；若成功执行则返回 nil。下面是错误消息的一个例子：  \nLuaSQL: unrecognized token: “”‘id’ INTEGER, ‘name’ TEXT)”\n12345### 插入语句  插入语句的示例如下所示：  \n conn:execute([[INSERT INTO sample values(‘11’,’Raj’)]])\n12345### 查找语句   查找返回后，我们需要循环遍历每行以取得我们需要的数据。查找语句的示例如下：  \ncursor,errorString = conn:execute([[select * from sample]])row = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  – reusing the table of results  row = cursor:fetch (row, “a”)end\n12345678上面的代码中，我们先打开了一个 sqlite3 连接。通过 execute 函数返回的游标(cursor)，我们可以遍历返回的表，以取得我们查找的数据。### 完整示例  下面这个例子用到了所有上面提到的数据的操作函数，请看下面这个完整的例子： \nsqlite3 = require “luasql.sqlite3”\nlocal env  = sqlite3.sqlite3()local conn = env:connect(‘mydb.sqlite’)print(env,conn)\nstatus,errorString = conn:execute([[CREATE TABLE sample (‘id’ INTEGER, ‘name’ TEXT)]])print(status,errorString )\nstatus,errorString = conn:execute([[INSERT INTO sample values(‘1’,’Raj’)]])print(status,errorString )\ncursor,errorString = conn:execute([[select * from sample]])print(cursor,errorString)\nrow = cursor:fetch ({}, “a”)while row do  print(string.format(“Id: %s, Name: %s”, row.id, row.name))  row = cursor:fetch (row, “a”)end– close everythingcursor:close()conn:close()env:close()\n123运行上面的程序，我们可以得到如下的输出结果：  \nSQLite3 environment (005EC918)    SQLite3 connection (005E77B0)0    nil1    nilSQLite3 cursor (005E9200)    nilId: 1, Name: Raj\n\n使用 libsql 库我们可以执行所有的数据库操作。所以，看完这些例子后，请自己多做一些练习。\n\n","slug":"lua/2016-06-01-database-access","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"374513b04e64d95f7bc41ddb08581b8d","title":"Lua调试","content":"Lua 调试Lua 提供一个调试库，这个库中提供了创建自己的调试器所需的所有原语函数。虽然，Lua 没有内置调试器，但是开发者们为 Lua 开发了许多的开源调试器。 \nLua 调试库包括的函数如下表所示。\n\n    \n        S.N.\n        方法和描述\n    \n    \n    1\n        debug():进入交互式调试模式，在此模式下用户可以用其它函数查看变量的值。\n    \n    \n        2\n        getfenv(object):返回对象的环境。\n    \n    \n        3\n        gethook(optional thread)：返回线程当前的钩子设置，总共三个值：当前钩子函数、当前的钩子掩码与当前的钩子计数。\n    \n    \n        4\n        getinfo(optional thread,function or stack leve,optional flag)：返回保存函数信息的一个表。你可以直接指定函数，或者你也可以通过一个值指定函数，该值为函数在当前线程的函数调用栈的层次。其中，0 表示当前函数（getinfo 本身）；层次 1 表示调用 getinfo 的函数，依次类推。如果数值大于活跃函数的总量，getinfo 则返回 nil。\n    \n    \n        5\n        getlocal(optional thread,stack level,local index)：此函数返回在 level 层次的函数中指定索引位置处的局部变量和对应的值。如果指定的索引处不存在局部变量，则返回 nil。当 level 超出范围时，则抛出错误。\n    \n    \n        6\n        getmetatable(value)：返回指定对象的元表，如果不存在则返回 nil。\n    \n    \n        7\n        getregistry()：返回寄存器表。寄存器表是一个预定义的用于 C 代码存储 Lua 值的表。\n    \n    \n        8\n        getupvalue(func function,upvalue index)：根据指定索引返回函数 func 的 upvalue 值（译注：upvalue 值与函数局部变量的区别在于，即使函数并非活跃状态也可能有 upvalue 值，而非活跃函数则不存在局部变量，所以其第一个参数不是栈的层次而是函数）。如果不存在，则返回 nil。\n    \n    \n        9\n        setfenv(function or thread or userdata,environment table)：将指定的对象的环境设置为 table,即改变对象的作用域。\n    \n    \n        10\n        sethook(optional thread,hook function,hook mask string with \"c\" and/or \"r\" and/or \"l\",optional instruction count)：把指定函数设置为钩子。字符串掩码和计数值表示钩子被调用的时机。这里，c 表示每次调用函数时都会执行钩子；r 表示每次从函数中返回时都调用钩子；l 表示每进入新的一行调用钩子。\n    \n    \n        11\n        setlocal(optional thread,stack level,local index,value):在指定的栈深度的函数中，为 index 指定的局部变量赋予值。如果局部变量不存在，则返回 nil。若 level 超出范围则抛出错误；否则返回局部变量的名称。\n    \n    \n        12\n        setmetatable(value,metatable):为指定的对象设置元表，元表可以为 nil。\n    \n    \n        13\n        setupvalue(function,upvalue index,value):为指定函数中索引指定的 upvalue 变量赋值。如果 upvalue 不存在，则返回 nil。否则返回此 upvalue 的名称。\n    \n    \n        14\n        traceback(optional thread,optional meesage string,opitona level argument)：用 traceback 构建扩展错误消息。\n    \n\n\n上面的表中列出了 Lua 的全部调试函数，我们经常用到的调试库都会用到上面的函数，它让调试变得非常容易。虽然提供了便捷的接口，但是想要用上面的函数创建一个自己的调试器并不是件容易的事。无论怎样，我们可以看一下下面这个例子中怎么使用这些调试函数的。  \n12345678function myfunction ()print(debug.traceback(&quot;Stack trace&quot;))print(debug.getinfo(1))print(&quot;Stack trace end&quot;)\treturn 10endmyfunction ()print(debug.getinfo(1))\n\n执行上面的程序，我们可以得到如下的栈轨迹信息：  \n123456789101112131415Stack tracestack traceback:\ttest2.lua:2: in function &#x27;myfunction&#x27;\ttest2.lua:8: in main chunk\t[C]: ?table: 0054C6C8Stack trace end```  上面的例子中，我们使用 debug.trace 函数输出了栈轨迹。 debug.getinfo 函数获得函数的当前表。  ## 示例二  在调试过程中，我们常常需要查看或修改函数局部变量的值。因此，我们可以用 getupvalue 获得变量的值，用 setupvalue 修改变量的值。示例如下：  \nfunction newCounter ()  local n = 0  local k = 0  return function ()    k = n    n = n + 1    return n    endend\ncounter = newCounter ()print(counter())print(counter())\nlocal i = 1\nrepeat  name, val = debug.getupvalue(counter, i)  if name then    print (“index”, i, name, “=”, val)    if(name == “n”) then        debug.setupvalue (counter,2,10)    end    i = i + 1  end – ifuntil not name\nprint(counter())\n123运行上面的程序，我们可以得到如下面的输出结果：  \n12index    1    k    =    1index    2    n    =    211\n```  \n在这个例子中，每次调用 counter 都会更新该闭包函数。我们可以通过 getupvalue 查看其当前的局部变量值。随后，我们更新局部变量的值。在为 n 设置新值之前，其值为 2。调用 setupvalue 后，n 被设置为 10。再调用 counter 时，它就会返回值 11 而不再是 3。  \n调试类型\n    命令行调试\n    图形界面调试\n\n\n命令行调试工具命令行调试就是使用命令行命令和 print 语句来调试程序。已经有许多现成的 Lua 命令行调试工具，下面列出了其中的一部分：\n\nRemDebug：RemDebug 是一个远程的调试器，它支持 Lua 5.0 和 5.1 版本。允许远程调试 Lua 程序，设置断点以及查看程序的当前状态。同时，它还能调试 CGILua 脚本。\nclidebugger：此调试器是用纯 Lua 脚本开发的命令行调试工具，支持 Lua 5.1。除了 Lua 5.1 标准库以外，它不依赖于任何其它的 Lua 库。虽然它受到了 RemDebug 影响而产生的，但是它没有远程调试的功能。\nctrace：跟踪 Lua API 调用的小工具。\nxdbLua：windows 平台下的 Lua 命令行调试工具。\nLuaInterface - Debuger：这个项目是 LuaInterface 的扩展，它对 Lua 调试接口进行进一步的抽象，允许通过事件和方法调用的方式调试程序。\nRIdb：使用套接字的远程 Lua 调试器，支持 Linux 和 Windows 平台。它的特性比任何其它调试器都丰富。\nModDebug：允许远程控制另外一个 Lua　程序的执行、设置断点以及查看程序的当前状态。\n\n图形界面调试工具图形界面的调试工具往往和集成开发环境（IDE）打包在一起。它允许在可视环境下进行调试，比如查看变量值，栈跟踪等。通过 IDE 的图形界面，你可以设置断点单步执行程序。  \n下面列出了几种图形界面的调试工具。  \n\n    SciTE：Windows 系统上默认的 Lua 集成开发环境，它提供了丰富的调试功能，比如，断点、单步、跳过、查看变量等等。\n    Decoda：一个允许远程调试的图形界面调试工具。\n    ZeroBrane Studio：一个 Lua 的集成开发环境，它集成了远程调试器、栈视图、远程控制终端、静态分析等诸多功能。它兼容各类 Lua 引擎，例如 LuaJIT,Love2d,Moai等。支持 Windows, OSX, Linux；开源。\n    akdebugger：eclipse 的 Lua 调试器和编辑器插件。\n    luaedit：支持运程调试、本地调试、语法高亮、自动补完、高级断点管理（包括有条件地触发断和断点计数）、函数列表、全局和本地变量列表、面对方案的管理等。\n","slug":"lua/2016-06-01-debugging","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"d6286a3606fee451e0f5f2e41e7f6205","title":"Lua判断","content":"决策决策结构要求程序开发人员设置一个或多测试或计算条件。如果条件计算结果为真，则执行一个或多个语句；如果条件为假，则执行另外的语句。 \n下面是大多数程序语言中的决策结构的一般形式：  \n  \nLua 语言中所有布尔真和非 nil 值都当作真；把所有的布尔假和 nil 作为假。请注意，Lua 中的零会被当作真，而其它大部分语言会将零当作假。\nLua 语言提供了如下几类决策语句。点击下面的链接查看详细内容。\n\n    \n        语句\n        描述\n    \n    \n        if 语句\n        if 语句中包括一个布尔表达式和一个或多个语句。\n    \n    \n        if...else 语句\n        if 语句也可以选择和 esle 语句一起使用。当条件为假时，则执行 else 语句。\n    \n    \n        嵌套 if 语句\n        在 if 语句或者 else if 语句内使用　if 或者 else if。\n    \n","slug":"lua/2016-06-01-decision-making","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"8fa5391aad4ba0aa8b3b2333eb0ffb7d","title":"Lua错误处理","content":"Lua 错误处理为什么需要错误处理机制在真实的系统中程序往往非常复杂，它们经常涉及到文件操作、数据库事务操作或网络服务调用等，这个时候错误处理就显得非常重要。不关注错误处理可能在处理诸如涉密或金融交易这些业务时造成重大的损失。无论什么时候，程序开发都要求小心地做好错误处理工作。在 Lua 中错误可以被分为两类：  \n\n    语法错误\n    运行时错误\n\n\n语法错误语法错误是由于不正确的使用各种程序语法造成的，比如错误的使用操作符或表达式。下面即是一个语法错误的例子：  \n12345a == 2```  正如你知道的那样，单个等号与双等号是完全不一样的。二者之间随意的替换就导致语法错误。一个等号表示的是赋值，而双等号表示比较。类似地，下面这一小段代码中也存在语法错误：  \nfor a= 1,10   print(a)end\n123执行上面的这段程序，我们会得到如下的输出结果：  \nlua: test2.lua:2: ‘do’ expected near ‘print’\n1234567语法错误相比于运行时错误更容易处理，因为 Lua 解释器可以更精确的定位到语法错误的位置。由上面的错误，我们可以容易就知道，在 print 语句前添加 do 语句就可以了，这是 Lua 语法结构所要求的。  ## 运行时错误  对于运行时错误，虽然程序也能成功运行，但是程序运行过程中可能因为错误的输入或者错误的使用函数而导致运行过程中产生错误。下面的例子显示了运行时错误如何产生的：  \nfunction add(a,b)   return a+bend\nadd(10)\n123当我们尝试生成(build)上面的程序，程序可以正常的生成和运行。但是一旦运行后，立马出现下面的运行时错误。  \nlua: test2.lua:2: attempt to perform arithmetic on local ‘b’ (a nil value)stack traceback:    test2.lua:2: in function ‘add’    test2.lua:5: in main chunk    [C]: ?\n1234567这个运行时错误是由于没有正确的为 add 函数传入参数导致的，由于没有为 b 传入值，所有 b 的值为 nil 从而导致在进行加法运算时出错。  ## Assert and Error 函数  我们经常用到 assert 和 error 两个函数处理错误。下面是一个简单的例子。  \nlocal function add(a,b)   assert(type(a) == “number”, “a is not a number”)   assert(type(b) == “number”, “b is not a number”)   return a+bendadd(10)\n123执行上面的程序，我们会得到如下的输出结果：  \nlua: test2.lua:3: b is not a numberstack traceback:    [C]: in function ‘assert’    test2.lua:3: in function ‘add’    test2.lua:6: in main chunk    [C]: ?\n12345678error(message [,level]) 函数会结束调用自己的函数，并将 message 作为错误信息返回调用者(译注:保护模式下才会返回调用者，一般情况会结束程序运行并在控制终端输出错误信息)。error 函数本身从不返回。一般地，error 函数会在消息前附上错误位置信息。级别(level) 参数指定错误发生的位置。若其值为 1(默认值)，返回的错误的位置是 error 函数被调用的位置。若为 2, 返回的错误位置为调用 error 函数的函数被调用的位置，依次类推。将 level 参数的值设为 0 就不再需要在消息前增加额外的位置信息了。  ## pcall 与 xpcall　　在 Lua 中，为了避免使用抛出错误和处理错误，我们需要用到 pcall 和 xpcall 函数来处理异常。  使用 pcall(f,arg1,...) 函数可以使用保护模式调用一个函数。如果函数 f 中发生了错误， 它并不会抛出一个错误，而是返回错误的状态。使用的 pcall 函数的方法如下所示：  \nfunction myfunction ()   n = n/nilend\nif pcall(myfunction) then   print(“Success”)else    print(“Failure”)end\n123执行上面的程序，我们可以得到如下的输出结果：  \nFailure\n123xpcall(f,err) 函数调用函数 f 同时为其设置了错误处理方法 err，并返回调用函数的状态。任何发生在函数 f 中的错误都不会传播，而是由 xpcall 函数捕获错误并调用错误处理函数 err，传入的参数即是错误对象本身。xpcall 的使用示例如下：  \nfunction myfunction ()   n = n/nilend\nfunction myerrorhandler( err )   print( “ERROR:”, err )end\nstatus = xpcall( myfunction, myerrorhandler )print( status)\n123执行上面的程序，我们可以得到如下的输出结果：  \nERROR:    test2.lua:2: attempt to perform arithmetic on global ‘n’ (a nil value)false\n\n作为程序开发人员，在程序中正确合理地处理错误是非常重要的。正确地处理错误可以保证发生意外情况不会影响到程序用户的使用。\n\n","slug":"lua/2016-06-01-error-handling","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"1c92a7bccc4e1c860aee5220573c9c25","title":"Lua运行环境","content":"Lua 运行环境本地环境搭建在本地搭建 Lua 编程语言的开发运行环境，你需要在你的计算机上安装如下三个软件：(1) 文本编辑器。(2)  Lua 解释器。（3）Lua 编译器。  \n文本编辑器文本编辑器用来编辑你的程序代码。有如下几款常用的文本编辑器软件：Windows notepad、Brief、Epsilon、EMACS、vim/vi。\n在不同的操作系统中有各自不同的编辑器，而且编辑器的版本不一样。例如，Notepad 主要用在 Windows 系统中，vim/vi 不仅可以用于 Windows 系统也可以用于 Linux 和 UNIX 操作系统。 \n用文本编辑器编辑的文件被称为源文件。源文件中包含程序的源代码。Lua 程序的源文件经常以 .lua　作为其后缀名。\n开始编写程序之前，请确保您已经安装好一个文本编辑软件，并且曾经有过写代码，将其存入文件，生成并执行的经验。  \nLua 解释器Lua 解释器是一个能让您输入 Lua　命令并立即执行的小程序。它在执行一个　Lua 文件过程中，一旦遇到错误就立即停止执行，而不像编译器会执行完整个文件。  \nLua 编译器如果将 Lua 扩展到其它语言或者应用中时，我们需要一个软件开发工具箱以及 Lua 应用程序接口兼容的编译器。  \n在 Windows 系统安装 Lua在 Windows 系统环境可以安装一个叫 SciTE 的 Lua 开发 IDE (集成开发环境)。它可以在这儿下载：http://code.google.com/p/luaforwindows。\n运行下载的可执行程序就可安装 Lua 语言的 IDE 了。  \n在这个 IDE 上，你可以创建并生成 Lua 代码。\n如果你希望在命令行模式下安装 Lua，你则需要安装 MinGW 或者 Cygwin，然后在 Ｗindows 系统中编译安装 Lua。  \n在 Linux 系统安装 Lua使用下面的命令下载并生成 Lua 程序：\n12345678910$ wget http://www.lua.org/ftp/lua-5.2.3.tar.gz$ tar zxf lua-5.2.3.tar.gz$ cd lua-5.2.3$ make linux test```  在其它系统上安装 Lua 时，比如 aix，ansi，bsd，generic，linux，mingw，posix，solaris，你需要将 make linux test 命令中的 linux 替换为相应的系统平台名称。 假设我们已经有一个文件 helloWord.lua ，文件内容如下：   \nprint(“Hello World!”)\n123我们先使用 cd 命令切换至 helloWord.lua　文件所在的目录，然后生成并运行该文件：　　\n$ lua helloWorld\n123执行上面的命令，我们可以看到如下的输出：  \nhello world\n12345## 在 Mac OS X 系统安装 Lua  使用下面的命令可以在 Mac OS X 系统生成并测试 Lua：  \n$ curl -R -O http://www.lua.org/ftp/lua-5.2.3.tar.gz$ tar zxf lua-5.2.3.tar.gz$ cd lua-5.2.3$ make macosx test\n123456如果你没有安装 Xcode 和命令行工具，那么你就不能使用 make 命令。你先需要从 mac 应用商店安装 Xcode，然后在 Xcode 首选项的下载选项中安装命令行工具组件。完成上面的步骤后，你就可以使用 make 命令了。  make macosx test 命令并不是非执行不可的。即使你没有执行这个命令，你仍可以在你的 Mac OS X 系统中使用 Lua。  假设我们已经有一个文件 helloWord.lua ，文件内容如下：  \nprint(“Hello World!”)\n123我们先使用 cd 命令切换至 helloWord.lua　文件所在的目录，然后生成并运行该文件：　　\n$ lua helloWorld\n123执行上面的命令，我们可以看到如下的输出：  \nhello world\n```  \nLua IDE正如前面提到的那样，Windows 系统中 SciTE 是 Lua 创始团队提供的默认的 Lua 集成开发环境（IDE)。 此外，还有一款名叫 ZeroBrane 的 IDE。 它具有跨平台的特性，支持 Windows、Mac 与 Linux。同时，许多 eclipse 插件使得 eclipse 能成为 Lua 的 IDE。IDE 中像代码自动补全等诸多特性使得开发变得简单了很多，因此建议你使用 IDE 开发 Lua 程序。同样，IDE 也能像 Lua 命令行版本那样提供交互式编程功能。\n","slug":"lua/2016-06-01-environment","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"4b8da2e6835e8f700ba371a83ecbe6ab","title":"Lua函数","content":"Lua 函数函数用于将一组语句组合起来完成一个任务。你可以将你的代码分割到不同的函数中。如何将你的代码分到不同的函数中完全由你自己决定，不过一般会按照逻辑功能进行划分，每个函数都执行一个特定的任务。 \n在 Lua 中提供了大量的内置函数供我们使用。例如，print() 函数用于将输入的参数输出到终端。 \n函数往往也被称作方法，子例程或过程等等。  \n函数定义Lua 中函数定义的语法如下所示：　　\n1234567891011121314151617181920optional_function_scope function function_name( argument1, argument2, argument3..., argumentn)function_bodyreturn result_params_comma_separatedend```  Lua 中函数定义包括函数头和函数名两部分。如下列出函数的所有部分：  &lt;ul&gt;\t&lt;li&gt;可选的函数作用域：你可以使用关键字 local 限制函数的作用域，你也可以忽略此部分而使用默认值。函数作用域默认是全局。&lt;/li&gt;\t&lt;li&gt;函数名：函数的真正名称。函数名与函数的参数列表一起被称为函数签名。&lt;/li&gt;\t&lt;li&gt;参数：一个参数就一个占位符一样。函数调用时，把值传递给参数。这个值被称之为实际参数或直参数。参数列表指参数的类型，顺序与数量。参数是可选的，一个函数可以没有参数。&lt;/li&gt;\t&lt;li&gt;函数体：函数体是代码语句集合，定义了函数的功能。&lt;/li&gt;\t&lt;li&gt;返回：在 Lua 中，可以使用 return 关键字同时返回多返回值，每个返回值之间使用逗号分隔。&lt;/li&gt;&lt;/ul&gt;  ## 示例  下面是函数 max() 源代码。此函数接受两个参数 num1 与 num2，返回两个输入参数的最大值。  \n–[[ function returning the max between two numbers –]]function max(num1, num2)\n   if (num1 &gt; num2) then      result = num1;   else      result = num2;   end\n   return result;end\n123456789101112131415## 函数参数  如果函数需要用到参数，则它必须声明接受参数值的变量。这些被声明的变量被称为函数的形式参数或简称形参。  函数的形参与函数中其它局部变量一样，在函数的入口处被创建，函数结束时被销毁。  ## 调用函数  创建函数的时候，我们已经定义了函数做什么。接下来，我们就可以调用函数来完成已定义的任务或功能。  当程序中调用一个函数时，程序的控制转移到被调用的函数中。被调用的函数执行定义的任务；当 return 语句被执行或者到达函数末尾时，程序的控制回到主程序中。   调用函数的方法很简单，你只需要将函数要求的参数传递给函数就可以实现函数的调用。如果函数有返回值，你也可以将函数的返回值存储下来。如下如示：  \nfunction max(num1, num2)   if (num1 &gt; num2) then      result = num1;   else      result = num2;   end\n   return result;end\n– 调用函数print(“The maximum of the two numbers is “,max(10,4))print(“The maximum of the two numbers is “,max(5,6))\n123执行上面的代码，可以得到如下的输出结果：  \nThe maximum of the two numbers is     10The maximum of the two numbers is     6\n12345## 赋值与传递函数  在 Lua 语言中，我们可以将函数赋值给一个变量，也可以将函数作为参数传递给另外一个函数。下面是赋值传递函数的一个例子：  \nmyprint = function(param)   print(“This is my print function -   ##”,param,”##”)end\nfunction add(num1,num2,functionPrint)   result = num1 + num2   functionPrint(result)endmyprint(10)add(2,5,myprint)\n123执行上面的代码，可以得到如下的输出结果：  \nThis is my print function -   ##    10    ##This is my print function -   ##    7    ##\n12345## 变参函数  在 Lua 语言中，使用 ... 作为参数可以创建参数个数可变的函数，即变参函数。我们可以使用下面的这个例子来理解变参函数的概念。下面的这个例子中函数返回输入参数的平均值：  \nfunction average(…)   result = 0   local arg={…}   for i,v in ipairs(arg) do      result = result + v   end   return result/#argend\nprint(“The average is”,average(10,5,3,4,5,6))\n123执行上面的代码，可以得到如下的输出结果：  \nThe average is    5.5``` \n","slug":"lua/2016-06-01-functions","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"a34942b7e84e08a52441ea25cc5475d6","title":"Lua垃圾回收机制","content":"Lua 垃圾回收机制Lua 通过特定算法的垃圾回收机制实现自动内存管理。由于自动内存管理机制的存在，作为程序开发人员：  \n\n    不需要关心对象的内存分配问题。\n    不再使用对象时，除了将引用它的变量设为 nil，不需要主动释放对象。\n  \nLua 的垃圾回收器会不断运行去收集不再被 Lua 程序访问的对象。  \n所有的对象，包括表、userdata、函数、线程、字符串等都由自动内存管理机制管理它们空间的分配和释放。Lua 实现了一个增量式标记清除垃圾收集器。它用两个数值控制垃圾回收周期，垃圾收集器暂停时间（garbage-collector pause） 和垃圾收集器步长倍增器（garbage-collector step multiplier）。其数值是以百分制计数的，即数值 100 内部表示 1。  \n\n垃圾收集器暂停时间该数值被用于控制垃圾收集器被 Lua 自动内存管理再次运行之前需要的等待时长。当其小于 100 时意味着收集器在新周期开始前不再等待。其值越大垃圾回收器被运行的频率越低，越不主动。当其值 200 时，收集器在总使用内存数量达到上次垃圾收集时的两倍时再开启新的收集周期。因此，根据程序不同的特征，可以通过修改该值使得程序达到最佳的性能。  \n垃圾收集器步长倍增器步长倍增器用于控制了垃圾收集器相对内存分配的速度。数值越大收集器工作越主动，但同时也增加了垃圾收集每次迭代步长的大小。值小于 100 可能会导致垃圾器一个周期永远不能结束，建议不要这么设置。默认值为 200，表示垃圾收集器运行的速率是内存分配的两倍。\n垃圾回收器相关函数作为开发人员，我们可能需要控制 Lua 的自动内存管理机制，可以使用下面的这些方法：  \n\n    collectgarbage(\"collect\")：运行一个完整的垃圾回收周期。\n    collectgarbage(\"count\")：返回当前程序使用的内存总量，以 KB 为单位。\n    collectgarbage(\"restart\")：如果垃圾回收器停止，则重新运行它。\n    collectgarbage(\"setpause\")：设置垃圾收集暂停时间变量的值，值由第二个参数指出（第二参数的值除以 100 后赋予变量）。稍后，我们将详细讨论它的用法。\n    collectgarbage(\"setsetmul\")：设置垃圾收集器步长倍增器的值，第二个参数的含义与上同。\n    collectgarbage(\"step\")：进行一次垃圾回收迭代。第二个参数值越大，一次迭代的时间越长；如果本次迭代是垃圾回收的最后一次迭代则此函数返回 true。\n    collectgarbage(\"stop\")：停止垃圾收集器运行。\n\n\n下面的示例代码中使用了垃圾收集器相关函数，如下所示：  \n123456789101112131415mytable = &#123;&quot;apple&quot;, &quot;orange&quot;, &quot;banana&quot;&#125;print(collectgarbage(&quot;count&quot;))mytable = nilprint(collectgarbage(&quot;count&quot;))print(collectgarbage(&quot;collect&quot;))print(collectgarbage(&quot;count&quot;))```  运行上面的程序，我们可以得到如下的输出结果。请注意，输出结果与操作系统类型与 Lua 自动内存管理都有关，所以可能实际运行的结果与下面不相同。  \n20.956054687520.9853515625019.4111328125\n```  \n从上面的程序，我们可以看出，一旦垃圾回收运行后，使用的内存量立即就减少了。但是，我们并不需要主动去调用它。因为，即使我们不调用此函数，Lua 也会按配置的周期自动的调用垃圾回收器。显然，如果需要，我们可以用上面的这些函数调整垃圾回收器的行为。这些函数帮且程序开发人员处理更加复杂的场景。根据开发的不同程序的内存需求，我们可以使用到这些方法来提高程序的性能。虽然大部分情况下，我们都不会用到这些函数，但是了解这些方法可以帮助我们调试程序，以免应用上线后带来的损失。 \n译注：更多垃圾回收器的内容请参考官网或者此博客。\n","slug":"lua/2016-06-01-garbage-collection","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"0574a789cafc1558adcaaf40b641bfb0","title":"Lua游戏开发","content":"Lua 游戏开发Lua 语言因其结构和语法的简洁性而在各类游戏引擎中被广泛使用。游戏对图形画面要求非常苛刻，这无疑需消耗大量的内存空间，而这些内存空间的管理是非常棘手的问题。Lua 语言有自动的垃圾回收机制，这种自动化的内存管理机制也使得 Lua 受到游戏引擎开发者的青睐。著名的 Lua 游戏引擎主要包括：  \n\n    Cornoa SDK\n    Gideros Mobile\n    ShiVa3D\n    Moai SDK\n    LOVE\n    CryEngine\n\n\n上面每一个游戏引擎都是基于 Lua 的，并且每一个都提供了丰富的 API。我们下面看一下每一款游戏引擎的特点。  \nCorna SDK这是一款支持 iPhone，iPad，Android 平台的移动设备游戏引擎。它提供了一个免费版本的 SDK, 不过该免费版本的功能也受到限制。你可以在需要的时候升级到其它版本。\nGorona SDK 提供了如下的特征：  \n\n    物理与冲突处理接口\n    Web 和网络接口\n    游戏网络接口\n    广告接口\n    数据分析接口\n    数据库和文件处理接口\n    加密和数学计算接口\n    音频和多媒体接口\n\n\n相比于使用 iOS 或 Android 系统原生 API， 使用上面的接口可以让我们的开发效率更高。  \nGideros MobileGideros 提供 iOS 和 Android 跨平台的软件开发工具包（SDK）。它是一个免费的游戏引擎，其主要的优点包括：  \n\n    集成开发环境：它提供一套集成开发环境，使用应用开发变得容易许多。\n    即时测试：在游戏开发过程中，通过 wifi 在 1 秒之内就可以在真实设备上测试应用。为开发者省去了导出和部署应用的时间。\n    插件：支持使用插件的方式扩展。导入的代码（C, C++, Java，Obje-C），Lua　可以直接解释执行。目前网络上已有了大量的开源插件可供使用。\n    面向对象编程：Gideros 提供了自己的类系统，支持 OOP 标准，开发可以开发干净的 OOP 代码。\n    原生速度：基于 C/C++ 和 openGL,应用可以以原生的运行，完全利用 CPU 和 GPU 的处理能力。\n\n\nShiVa3D这一款 3D 的游戏引擎，它提供了图形化的编辑器，可以为 Web、终端、移动设备开发应用或游戏。它支持多个平台，包括：Windows，Mac，Linux，iOS，Android，BlackBerry，Palm OS，Wii，WebOS。\n它主要的特点包括：  \n\n    标准插件\n    网格修改接口\n    集成开发环境\n    内置 Terrain，Ocean 与 动画编辑器\n    支持 ODE 物理引擎\n    完全的光线映射控制\n    实时预览\n    Collada 交换格式的支持\n\n\nShiVa3D 的 Web 版本是免费的，但其它的版本是收费版本。  \nMoai SDKMoai SDK 是跨平台的移动游戏开发引擎，它支持 iPhone，iPad 以及 Android 系统。Moai　平台包括　Moai SDK，开源的引擎，以及 Moai 云。 Moai 云是一个 SaaS 平台，提供游戏部署的服务。不过，Moai 云平台已经关闭，现在只有游戏引擎是可用的。  \nLOVELOVE 是一个开源的 2D 游戏的开始框架，它支持 Windows，Mac OS X 以及 Linux 多个平台。\n它主要提供以下的开发接口：  \n\n    音频接口\n    文件系统接口\n    键盘和操纵杆接口\n    数据计算 API\n    窗口和鼠标接口\n    物理接口\n    系统和定时器接口\n\n\nCryEngineCryEngine 是由德国的游戏引擎开发商 Cryteck 开发的游戏引擎。到目前为止，它已由第一代引擎发展到了第四代，是一个高级的游戏开发解决方案。它目前支持 PC，Xbox 360，PlayStation3，以及 WiiU。\n它主有以下的优点：  \n\n    视觉效果就像自然光线，态柔和阴影，实时动态全局光照，光传输容量控制，颗粒底纹，镶嵌等。\n    角色动画系统与人物个性化系统。\n    参数骨骼动画和独特的专用人脸动画编辑器。\n    人工智能系统如多层导航网格战术角度系统。还提供了设计师友好的 AI 编辑系统。\n    游戏混合及分析，数据驱动的音响系统的动态声音和互动音乐等。\n  \n\n结束语每个款游戏引擎都有着自己的优势以及不足之处。正确的选择游戏引擎会让你的开发变得容易和有趣得多。所以，在选择之前，请先仔细斟酌你的需求，分析哪一款游戏引擎真正的适合你，然后再决定使用它。\n","slug":"lua/2016-06-01-game-programming","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"7cdf9755b9d268215aaceca81f7a3596","title":"Lua文件I/O","content":"Lua 文件 I/OLua 的 IO 库用于读取或操作文件。Lua IO 库提供两类文件操作，它们分别是隐式文件描述符(implict file descriptors)和显式文件描述符(explicit file descriptors)。\n在接下来的例子的，我们会用到一个示例文件 test.lua，文件内容如下：  \n123456-- sample test.lua-- sample2 test.lua```  简单的打开文件操作可以用如下的语句完成。  \nfile = io.open (filename [, mode])\n1234567891011121314151617181920212223242526272829303132333435363738可选的打开文件的模式如下表所示。  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;模式&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;r&quot;&lt;/td&gt;\t\t&lt;td&gt;只读模式，这也是对已存在的文件的默认打开模式。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;w&quot;&lt;/td&gt;\t\t&lt;td&gt;可写模式，允许修改已经存在的文件和创建新文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;a&quot;&lt;/td&gt;\t\t&lt;td&gt;追加模式，对于已存的文件允许追加新内容，但不允许修改原有内容，同时也可以创建新文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;r+&quot;&lt;/td&gt;\t\t&lt;td&gt;读写模式打开已存的在文件。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;w+&quot;&lt;/td&gt;\t\t&lt;td&gt;如果文件已存在则删除文件中数据；若文件不存在则新建文件。读写模式打开。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;a+&quot;&lt;/td&gt;\t\t&lt;td&gt;以可读的追加模式打开已存在文件，若文件不存在则新建文件。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;## 隐式文件描述符  隐式文件描述符使用标准输入输出模式或者使用单个输入文件和输出文件。使用隐匿文件描述符的示例代码如下：  \n– 只读模式打开文件file = io.open(“test.lua”, “r”)\n– 将 test.lua 设置为默认输入文件io.input(file)\n–打印输出文件的第一行print(io.read())\n– 关闭打开的文件io.close(file)\n– 以追加模式打开文件file = io.open(“test.lua”, “a”)\n– 将 test.lua 设置为默认的输出文件io.output(file)\n– 将内容追加到文件最后一行io.write(“– End of the test.lua file”)\n– 关闭打开的文件io.close(file)\n123执行上面的程序，我们可以看到输出了 test.lua 文件的第一行。在本例中，输出的结果为：  \n\nSample test.lua123456789101112131415161718192021222324252627282930313233343536373839404142输出的内容是 test.lua 文件中的第一行。“-- End of the test.lua file” 他会被追加到 test.lua 文件的最后一行。  从上面的例子中，你可以看到隐式的描述述如何使用 io.&quot;x&quot;  方法与文件系统交互。上面的例子使用 io.read() 函数时没有使用可选参数。此函数的可选参数包括：  &lt;table&gt;\t&lt;tr&gt;\t\t&lt;th&gt;模式&lt;/th&gt;\t\t&lt;th&gt;描述&lt;/th&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*n&quot;&lt;/td&gt;\t\t&lt;td&gt;从文件当前位置读入一个数字，如果该位置不为数字则返回 nil。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*a&quot;&lt;/td&gt;\t\t&lt;td&gt;读入从当前文件指针位置开始的整个文件内容。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;&quot;*i&quot;&lt;/td&gt;\t\t&lt;td&gt;读入当前行。&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t\t&lt;td&gt;number&lt;/td&gt;\t\t&lt;td&gt;读入指定字节数的内容。&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;另外一些常用的方法：&lt;ul&gt;\t&lt;li&gt;io.tmpfile():返回一个可读写的临时文件，程序结束时该文件被自动删除。&lt;/li&gt;\t&lt;li&gt;io.type(file):检测输入参数是否为可用的文件句柄。返回 &quot;file&quot; 表示一个打开的句柄；“closed file” 表示已关闭的句柄；nil 表示不是文件句柄。&lt;/li&gt;\t&lt;li&gt;io.flush():清空输出缓冲区。&lt;/li&gt;\t&lt;li&gt;io.lines(optional file name): 返回一个通用循环迭代器以遍历文件，每次调用将获得文件中的一行内容,当到文件尾时，将返回nil。若显示提供了文件句柄，则结束时自动关闭文件；使用默认文件时，结束时不会自动关闭文件。&lt;/li&gt;&lt;/ul&gt;  ## 显示文件描述符  我们也会经常用到显示文件描述符，因为它允许我们同时操作多个文件。这些函数与隐式文件描述符非常相似，只不过我们在这儿使用 file:function_name 而不是使用 io.function_name 而已。下面的例子使用显示文件描述符实现了与前面例子中完全相同的功能。  　\n\n只读模式打开文件file = io.open(“test.lua”, “r”)\n\n\n\n– 输出文件的第一行print(file:read())\n– 关闭打开的文件file:close()\n– 以追加模式打开文件file = io.open(“test.lua”, “a”)\n– 添加内容到文件的尾行file:write(“–test”)\n– 关闭打开的文件file:close()\n123执行上面的程序，我们可以得到与前面使用隐式文件描述符类似的输出结果：  \n– Sample test.lua\n12345678910在显式文件描述符中，打开文件的描述与读文件时的参数与隐式文件描述中的完全相同。另外的常用方法包括：&lt;ul&gt;\t&lt;li&gt;file:seek(option whence,option offset)：此函数用于移动文件指针至新的位置。参数 whence 可以设置为 “set”，&quot;cur&quot;,&quot;end&quot;，offset 为一个偏移量值，描述相对位置。如果第一个参数为 &quot;set&quot;，则相对位置从文件开始处开始计算；如果第一个参数为 &quot;cur&quot;，则相对位置从文件当前位置处开始计算； 如果第一个参数为 &quot;end&quot;，则相对位置从文件末尾处开始计算。函数的参数默认值分别为 &quot;cur&quot; 和 ０，因此不传递参数调用此函数可以获得文件的当前位置。&lt;/li&gt;\t&lt;li&gt;file:flush()：清空输出缓冲区。&lt;/li&gt;\t&lt;li&gt;io.lines(optional file name)：提供一个循环迭代器以遍历文件，如果指定了文件名则当遍历结束后将自动关闭该文件；若使用默认文件，则遍历结束后不会自动关闭文件。&lt;/li&gt;&lt;/ul&gt;下面的例子演示 seek 函数的使用方法。它将文件指针从文件末尾向前移动 25。并使用 read 函数从该位置出输出剩余的文件内容。  \n– Opens a file in readfile = io.open(“test.lua”, “r”)\nfile:seek(“end”,-25)print(file:read(“*a”))\n– closes the opened filefile:close()\n12执行上的面的程序，你可以得到类似下面的输出结果：  \n sample2 test.lua–test\n\n你还可以尝试不同的参数了解更多的 Lua 文件操作方法。\n\n","slug":"lua/2016-06-01-file-io","date":"2024-03-14T06:15:59.724Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"48abcf7000096b713f7adec4c94e4012","title":"如何查看Linux的RPM安装包安装文件的目录","content":"如何查看Linux的RPM安装包安装文件的目录如何查看Linux的RPM安装包安装文件的目录\n要查看Linux上RPM安装包的安装文件目录，可以使用以下命令：\n\n列出已安装的RPM包：\n1rpm -qa\n查找特定RPM包的安装目录：\n1rpm -ql &lt;package_name&gt;\n将 &lt;package_name&gt; 替换为要查询的RPM包的名称。\n\n\n这将显示该RPM包中所有文件的完整路径。\n","slug":"linux/如何查看Linux的RPM安装包安装文件的目录","date":"2024-03-14T06:15:59.723Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"e91abac01034f4c3267537e7e279ad34","title":"查看进程打文件大小","content":"查看进程打文件大小如何查看Linux那个进程的打开了大文件\n要查看Linux中哪个进程打开了大文件，可以使用lsof命令。lsof是一个用于显示已打开的文件的工具。\n以下是使用lsof命令来查看Linux中哪个进程打开了大文件的步骤：\n\n打开终端。\n输入以下命令并按下Enter键：1sudo lsof | awk &#x27;&#123; if($7 &gt; 1048576000) print $0 &#125;&#x27;\n这个命令会列出所有打开的文件，并筛选出文件大小超过1MB的文件。\n命令执行后，终端会显示所有满足条件的打开文件的相关信息，包括进程ID、进程名称、文件描述符、文件类型以及文件路径等。\n在结果中找到你想要的大文件所对应的进程ID和进程名称。\n\n请注意，上述命令使用sudo来获取更高权限以访问系统级别的信息。如果你没有sudo权限，请联系管理员或者使用其他适用于你的权限级别的命令。\n","slug":"linux/查看进程打文件大小","date":"2024-03-14T06:15:59.723Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"145d446aa776a5e466b322bb34339497","title":"如何看RPM文件安装的位置","content":"如何看RPM文件安装的位置如何能知道在Linux上安装的PRM具体安装到了什么位置在\nLinux中，可以使用lsmod命令来查看所有模块的列表，然后通过输入modprobe &lt;模块名&gt;来加载模块。如果您想知道安装到了什么位置，可以使用lsmod命令并输入-l选项来列出所有模块的缓存信息，然后通过查看缓存文件中的模块名来确定它们是否已经安装在了您想要的地方。️\n在Linux上，安装完RPM安装文件后，如何能找到RPM安装的具体目录在Linux上，安装完RPM安装文件后，可以通过以下方式找到RPM安装的具体目录：\n\n使用rpm -q命令来查看当前系统中所有已安装的RPM包。这将显示每个包的名称和版本号，以及其所在的目录。\n使用find命令来搜索所有RPM文件。例如，可以使用以下命令：1find / -name &quot;*.rpm&quot;\n这将显示所有RPM文件的路径和名称。\n使用locate命令来搜索所有RPM文件。例如，可以使用以下命令：1locate -rpm\n这将显示所有RPM文件的路径和名称。\n在终端中输入pwd命令，这将显示当前工作目录。然后可以使用以下命令来搜索RPM安装的具体目录：1find / -name &quot;*.rpm&quot; -type d\n这将显示所有RPM文件的路径和名称，并且只查找目录类型的文件。\n在终端中输入ls命令，这将显示当前工作目录下所有文件和目录。然后可以使用以下命令来搜索RPM安装的具体目录：1find / -name &quot;*.rpm&quot; -type d -exec ls &#123;&#125; \\;\n这将显示所有RPM文件的路径和名称，并且只查找目录类型的文件。\n\n以上是一些常见的方法来找到RPM安装的具体目录。需要注意的是，这些命令可能会在不同的Linux系统上有所不同。️\n","slug":"linux/如何看RPM文件安装的位置","date":"2024-03-14T06:15:59.723Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Lua 中文指南permalink: /lua_guide/README/Lua 语言是基于 C 语言之上的开源编程语言。它的价值在于其跨平台的特性，从大型服务器系统到小型移动应用都可以看到它的身影。\n这篇教程不仅包括 Lua 编程语言的基本知识，还包括 Lua 语言在各类应用场景中的应用。  \n适用人群这篇教程主要是为 Lua 语言的初学者准备的。不过，其中也包含了既适合初学者也适合高级用户的主题。  \n学习前途建议您在开始学习这篇教程之前先掌握一些计算机编程的基本概念。但是这篇教程本身是自包含的，即使您是完全的初始者，您也能够学习到大量的 Lua 语言的编程概念。您只需有一些基本的文本编辑与命令行的知识即可。  \n官方英文原版：http://www.tutorialspoint.com/lua/index.htm \n","slug":"lua/2016-06-01-README","date":"2024-03-14T06:15:59.723Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"d774f91f96abd1bb1c7fd97a15cf6621","title":"2016-06-01-TOC","content":"2016-06-01-TOC\nlua 基础 \n概述permalink: /lua_guide/TOC/\n运行环境\n基本语法\n变量\n日期类型\n操作符\n循环\n决策\n函数\n字符串\n数组\n迭代器\n表\n模块 \n元表  \n协程 \n文件 I/O\n错误处理\n\n\nlua 进阶\n调试\n垃圾回收机制\n面向对象\nWeb 编程\n数据库访问\n游戏开发\n标准库\n\n\n\n","slug":"lua/2016-06-01-TOC","date":"2024-03-14T06:15:59.723Z","categories_index":"教程","tags_index":"lua","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Lua基础教程permalink: /lua_guide/Home/\n","slug":"lua/2016-06-01-Home","date":"2024-03-14T06:15:59.723Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"84194321ed7a1438454fe622f34bf356","title":"汇编语言实现Basic","content":"汇编语言实现Basic用汇编语言，写一个Basic语言的编译器\n编写一个完整的Basic语言编译器需要大量的工作和代码，因此在这里只提供一个简单的示例，以展示如何将Basic语言转换为汇编语言。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657section .data    memory db 100 dup(0)   ; 内存空间用于存储变量和数据    pointer db 0           ; 指向下一个可用内存位置的指针section .text    global _start_start:    mov eax, offset program ; 将程序指针设置为程序开始位置    call parse_line         ; 解析第一行parse_line:    mov esi, eax            ; 保存当前行的指针    lodsb                   ; 加载当前字符到AL寄存器    cmp al, &#x27;\\n&#x27;            ; 判断是否到达行末尾    je next_line            ; 如果是，则跳转到下一行        cmp al, &#x27;A&#x27;             ; 判断是否是变量声明    je declare_variable     ; 如果是，则跳转到声明变量处理        cmp al, &#x27;P&#x27;             ; 判断是否是PRINT语句    je handle_print         ; 如果是，则跳转到处理PRINT语句        jmp parse_line          ; 继续解析当前行的下一个字符declare_variable:    lodsb                   ; 加载下一个字符到AL寄存器（获取变量名）        mov bl, pointer         ; 获取当前可用内存位置    mov byte [memory+ebx], al; 将变量名存储在内存中        inc pointer             ; 更新下一个可用内存位置    jmp parse_line          ; 继续解析当前行的下一个字符handle_print:    lodsb                   ; 加载下一个字符到AL寄存器（获取变量名）        mov bl, al              ; 获取变量名在内存中的位置    mov al, byte [memory+ebx]; 获取变量值        add al, &#x27;0&#x27;             ; 将数值转换为ASCII码    mov [output], al        ; 存储结果        mov eax, 4              ; 调用系统调用，输出结果    mov ebx, 1    mov ecx, output    mov edx, 1    int 0x80next_line:    ret                     ; 返回主程序section .bss    output resb 1           ; 存储输出结果的缓冲区section .dataprogram db &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &#x27;\\n&#x27;, &quot;P&quot;, &quot;A&quot;, &#x27;\\n&#x27;, 0   ; Basic语言程序示例\n\n请注意这只是一个简单的示例，可能无法处理复杂的Basic语言程序。编写一个完整的Basic编译器需要更多的代码和功能，如语法分析、语义分析、目标代码生成等。\n","slug":"linux/汇编语言实现Basic","date":"2024-03-14T06:15:59.723Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"e16187d7a3c490f96b788338bdd79d24","title":"数组","content":"Lua 数组数组是一组有序的对象排列，既可以是一维的也可以是多维的。  \n在 Lua 语言中，数组是用整数索引表实现的。数组的大小并不固定，随着数组元素的增加，它可以动态地增加内存空间大小。  \n一维数组一维数组可以使用一个简单的表结构表示。可以通过一个简单循环初始化数组或者读取数组中数据。示例代码如下所示：  \n123456789array = &#123;&quot;Lua&quot;, &quot;Tutorial&quot;&#125;for i= 0, 2 do   print(array[i])end```  执行上面的代码可以得到如下的输出结果：  \nnilLuaTutorial\n123从上面的例子中可以看出，当我们尝试着访问数组中一个不存在的索引时，会得到 nil 值。 Lua 语言与 C 语言不同，Lua 数组的索引是从 1 开始的，而 C 语言中索引是从 0 开始的。不过呢，你也可以在索引值为 0 或小于 0 的位置创建对象。下面的代码演示了如何使用负索引值创建并初始化数组：  \narray = {}\nfor i= -2, 2 do   array[i] = i *2end\nfor i = -2,2 do   print(array[i])end\n123执行上面的代码可以得到如下的输出结果：  \n-4-2024\n1234567891011## 多维数组  多维数组有以下两种实现方式：  &lt;ol&gt;\t&lt;li&gt;数组的数组（译注：数组的每一个元素是一个数组）。&lt;/li&gt;\t&lt;li&gt;修改一维数组的索引值（译注：将多维数组映射到一维数组中）。&lt;/li&gt;&lt;/ol&gt;  使用方法一创建 3x3 的二维数组：  \n– 初始化数组array = {}for i=1,3 do   array[i] = {}      for j=1,3 do         array[i][j] = i*j      endend\n– 访问数组元素for i=1,3 do   for j=1,3 do      print(array[i][j])   endend\n123执行上面的代码可以得到如下的输出结果：  \n123246369\n123通过修改数组的的索引值实现 3x3 的二维数组，示例代码如下:  \n– 初始化数组array = {}maxRows = 3maxColumns = 3for row=1,maxRows do   for col=1,maxColumns do      array[rowmaxColumns +col] = rowcol   endend\n– 访问数组元素for row=1,maxRows do   for col=1,maxColumns do      print(array[row*maxColumns +col])   endend\n123执行上面的代码可以得到如下的输出结果：  \n123246369\n```  \n正如从上面例子中所看到的那样，数组中数据是基于索引存储的。这使得数组可以以稀疏的方式存储，这也是 Lua 矩阵的存储方式。正是因为 Lua 中不会存储 nil 值，所以 Lua　不需要使用任何特殊的技术就可以节约大量的空间，这一点在其它语言中是做不到的。\n","slug":"lua/2016-06-01-arrays","date":"2024-03-14T06:15:59.723Z","categories_index":"lua_guide,lua教程","tags_index":"lua","author_index":"安全书"},{"id":"1e07952645adeb0063307933aff99e35","title":"Break语句","content":"#break 语句  \n程序在解释执行过程中，在循环内遇到 break 语句时，循环将立即结束。程序将循环语句的下一条语句开始执行。如果你是在嵌套循环（即，一个循环内还有一个循环语句）内使用 break 语句，break 只结束内层循环，并从该代码块后的第一条语句处开始执行。  \n语法break 语句的语法如下所示：  \n12345678910111213141516171819202122232425262728293031323334break;```  ## 流程图：  ![](images/break.jpg)  ## 示例  ```lua--[ 局部变量定义--]a = 10--[ 执行 while 循环--]while( a &lt; 20 )do   print(&quot;value of a:&quot;, a)   a=a+1   if( a &gt; 15)   then      --[ terminate the loop using break statement --]      break   endend```  执行上面的代码可以得到如下的结果：  ```luavalue of a:\t10value of a:\t11value of a:\t12value of a:\t13value of a:\t14value of a:\t15\n\n\n\n","slug":"lua/2016-06-01-break","date":"2024-03-14T06:15:59.723Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"9b97fd5c58ceb41de2e73474e4dfb1f8","title":"Lua基本语法","content":"基本语法Lua 学起来非常简单。现在，让我们开始创建我们的第一个 Lua 程序吧！  \n第一个 Lua 程序Lua 提供交互式编程模式。在这个模式下，你可以一条一条地输入命令，然后立即就可以得到结果。你可以在 shell 中使用 lua -i 或者 lua 命令启动。输入命令后，按下回车键，就启动了交互模式，显示如下：  \n1234567$ lua -i $ Lua 5.1.4  Copyright (C) 1994-2008 Lua.org, PUC-Rioquit to end; cd, dir and edit also available```  你可以使用如下命令打印输出：  \n$&gt; print(“test”)\n123按下回车键后，你会得到如下输出结果：  \n‘test’\n1234567## 默认模式编辑  使用 Lua 文件做为解释器的参数启动解释器,然后开始执行文件直到文件结束。当脚本执行结束后，解释器就不在活跃了。  让我们写一个简单的 Lua 程序。所有的 Lua　文件都扩展名都是`.lua`。因此，将下面的源代码放到 test.lua 文件中。  \nprint(“test”)\n123假如你已经设置好 Lua 程序的环境，用下面的命令运行程序：  \n$ lua test.lua\n123我们会得到如下的输出结果：  \ntest\n123让我们尝试使用另外的方式运行 Lua 程序。下面是修改后的 test.lua 文件：  \n#!/usr/local/bin/luaprint(“test”)\n123这里，我们假设你的 Lua 解释器程序在 /usr/local/bin/lua 目录下。test.lua 文件中第一行由于以 # 开始而被解释器忽略，运行这个程序可以得到如下的结果：  \n$ chmod a+rx test.lua$./test.lua\n123我们会得到如下的的输出结果：  \ntest\n1234567接下来让我们看一下 Lua 程序的基本结构。这样，你可以更容易理解 Lua 编程语言的基本结构单元。  ## Lua 中的符号  Lua 程序是由大量的符号组成的。这些符号可以分为关键字、标识符、常量、字符串常量几类。例如，下面的 Lua 语句中包含三个符号：  \nio.write(“Hello world, from “,_VERSION,”!\\n”)\n123这三个符号分别是:  \nio.write(“Hello world, from “,_VERSION,”!\\n”)\n12345### 注释  注释就是 Lua 程序中的帮助文档，Lua 解释器会自动忽略它们。所有注释都以 --[[ 开始，并以 --]]结束。如下所示：  \n–[[ my first program in Lua –]]\n123456### 标识符  Lua 中标识符是识别变量、函数或者其它用户自定义项的名字。标符识总是以字母或者下划线开始，其后可以是零个或多个字母、下划线或数字。  Lua 标识符中不允许出现任何标点符号，比如，@，$ 或者 %。Lua 是大小写敏感的语言，因此 Manpower 和 manpower 是 Lua 中两个不同的标识符。下面所列的是一些合法标识符的例子。  \nmohd         zara      abc     move_name    a_123myname50     _temp     j       a23b9        retVal\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849### 关键字  下面列表中所示的是 Lua 中一小部分保留字。这些保留字不能用作常量、变量以及任何标识符的名字。  &lt;table&gt;\t&lt;tr&gt;\t&lt;td&gt;and&lt;/td&gt;\t&lt;td&gt;break&lt;/td&gt;\t&lt;td&gt;do&lt;/td&gt;\t&lt;td&gt;else&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t&lt;td&gt;elseif&lt;/td&gt;\t&lt;td&gt;end&lt;/td&gt;\t&lt;td&gt;false&lt;/td&gt;\t&lt;td&gt;for&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t&lt;td&gt;function&lt;/td&gt;\t&lt;td&gt;if&lt;/td&gt;\t&lt;td&gt;in&lt;/td&gt;\t&lt;td&gt;local&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t&lt;td&gt;nil&lt;/td&gt;\t&lt;td&gt;not&lt;/td&gt;\t&lt;td&gt;or&lt;/td&gt;\t&lt;td&gt;repeat&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t&lt;td&gt;return&lt;/td&gt;\t&lt;td&gt;then&lt;/td&gt;\t&lt;td&gt;true&lt;/td&gt;\t&lt;td&gt;until&lt;/td&gt;\t&lt;/tr&gt;\t&lt;tr&gt;\t&lt;td&gt;while&lt;/td&gt;\t&lt;td&gt;&lt;/td&gt;\t&lt;td&gt;&lt;/td&gt;\t&lt;td&gt;&lt;/td&gt;\t&lt;/tr&gt;&lt;/table&gt;### Lua 中的空白符  如果 Lua 程序中某一行只包含空格或者注释，那么这样的一行被称之为空行。 Lua 解释器将完全忽略这一行。  在 Lua 中，空白是用来描述空格、制表符、换行符和注释的术语。空白符用于将语句中的一部分与其它部分区分开，使得解释器可以语句中的一个元素，比如 int，何处结束，以及另一个元素从何处开始。因此，在下面的语句中：  \nlocal age\n123在 local 与 age 之间至少有一个空白符（通常是空格）,这个空白符使得解释器可以将 local 与 age 区分开。另一方面，在下面的语句中：  \nfruit = apples + oranges   –get the total fruit\n```  \nfruit 与 = 之间以及 = 与 apples 之间的空白符都是可以没有的。但是为了程序的可读性目的，建议你在它们之间使用空白符。\n","slug":"lua/2016-06-01-basic-syntax","date":"2024-03-14T06:15:59.723Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"bce3027296f15638c976f1ebef15c96b","title":"Lua协程","content":"Lua 协程概述协程具有协同的性质，它允许两个或多个方法以某种可控的方式协同工作。在任何一个时刻，都只有一个协程在运行，只有当正在运行的协程主动挂起时它的执行才会被挂起（暂停）。 \n上面的定义可能看上去比较模糊。接下来让我讲得很清楚一点，假设我们有两个方法，一个是主程序方法，另一个是一个协程。当我们使用 resume 函数调用一个协程时，协程才开始执行。当在协程调用 yield 函数时，协程挂起执行。再次调用 resume 函数时，协程再从上次挂起的地方继续执行。这个过程一直持续到协程执行结束为止。  \n协程中可用的函数下面的表中列出 Lua 语言为支持协程而提供的所有函数以及它们的用法。  \n\n    \n        S.N.\n        方法和功能\n    \n    \n        1\n        coroutine.create(f):用函数 f 创建一个协程，返回 thread 类型对象。\n    \n    \n        2\n        coroutine.resume(co[,val1,...]): 传入参数（可选），重新执行协程 co。此函数返回执行状态，也可以返回其它值。\n    \n    \n        3\n        coroutine.running():返回正在运行的协程，如果在主线程中调用此函数则返回 nil。\n    \n    \n        4\n        coroutine.status(co):返回指定协程的状态，状态值允许为：正在运行(running)，正常(normal)，挂起(suspended)，结束(dead)。\n    \n    \n        5\n        coroutine.wrap(f):与前面 coroutine.create 一样，coroutine.wrap 函数也创建一个协程，与前者返回协程本身不同，后者返回一个函数。当调用该函数时，重新执行协程。\n    \n    \n        6\n        coroutine.yield(...):挂起正在执行的协程。为此函数传入的参数值作为执行协程函数 resume 的额外返回值（默认会返回协程执行状态）。\n    \n\n\n示例让我们通过下面的例子来理解一下协程这个概念。  \n1234567891011121314151617181920co = coroutine.create(function (value1,value2)   local tempvar3 =10   print(&quot;coroutine section 1&quot;, value1, value2, tempvar3)   local tempvar1 = coroutine.yield(value1+1,value2+1)   tempvar3 = tempvar3 + value1   print(&quot;coroutine section 2&quot;,tempvar1 ,tempvar2, tempvar3)   local tempvar1, tempvar2= coroutine.yield(value1+value2, value1-value2)   tempvar3 = tempvar3 + value1   print(&quot;coroutine section 3&quot;,tempvar1,tempvar2, tempvar3)   return value2, &quot;end&quot;end)print(&quot;main&quot;, coroutine.resume(co, 3, 2))print(&quot;main&quot;, coroutine.resume(co, 12,14))print(&quot;main&quot;, coroutine.resume(co, 5, 6))print(&quot;main&quot;, coroutine.resume(co, 10, 20))```  执行上面的程序，我们可以得到如下的输出结果：  \ncoroutine section 1    3    2    10main    true    4    3coroutine section 2    12    nil    13main    true    5    1coroutine section 3    5    6    16main    true    2    endmain    false    cannot resume dead coroutine\n123456789101112131415161718## 上面的例子到底做了些什么呢？  和前面说到的一样，在例子中我们使用 resume 函数继续执行协程，用 yield 函数挂起协程。同样，从例子中也可以看出如何为执行协程的 resueme 函数返回多个值。下面我将逐步解释上面的代码。  &lt;ul&gt;\t&lt;li&gt;首先，我们创建了一个协程并将其赋给变量 co。此协程允许传入两个参数。&lt;/li&gt;\t&lt;li&gt;第一次调用函数 resume 时，协程内局部变量 value1 和 value2 的值分别为 3 和 2。&lt;/li&gt;\t&lt;li&gt;为了便于理解，我们使用了局部变量 tempvar3 该变量被初始化为 10。由于变量 value1 的值为3，所以 tempvar3 在随后的协程调用过程中被先后更新为 13 和 16。&lt;/li&gt;\t&lt;li&gt;第一次调用 coroutine.yield 时，为 resume 函数返回了值 4 和 3，这两个值是由传入的参数 3，2 分别加 1 后的结果，这一点可以从 yield 语句中得到证实。除了显示指定的返回值外，resume 还收到隐式的返回值 true，该值表示协程执行的状态，有 true 和 false 两个可能取值。&lt;/li&gt;\t&lt;li&gt;上面的例子中，我们还应该关注在下一次调用 resume 时如何为协程传入参数。从例子中可以看到，coroutine.yield 函数返回后为两个变量赋值，该值即是第二次调用 resume 时传入的参数。这种参数传递的机制让可以结合前面传入的参数完成很多新的操作。&lt;/li&gt;\t&lt;li&gt;最后，协程中所有语句执行完后，后面的调用就会返回 false 状态，同时返回 &quot;cannot resume dead coroutine&quot;消息。&lt;/li&gt;&lt;/ul&gt;## 另一个协程的示例  下面这例子中的协程使用 yield 函数和 resume 函数依次返回数字 1 到 5。示例中，如果没有协程对象或对象已结束（dead），则重新创建一个新的协程对象；若协程已经存在，则执行已经存在的协程。  \nfunction getNumber()   local function getNumberHelper()      co = coroutine.create(function ()      coroutine.yield(1)      coroutine.yield(2)      coroutine.yield(3)      coroutine.yield(4)      coroutine.yield(5)      end)      return co   end   if(numberHelper) then      status, number = coroutine.resume(numberHelper);      if coroutine.status(numberHelper) == “dead” then         numberHelper = getNumberHelper()         status, number = coroutine.resume(numberHelper);      end      return number   else      numberHelper = getNumberHelper()      status, number = coroutine.resume(numberHelper);      return number   endendfor index = 1, 10 do   print(index, getNumber())end\n12执行上述的程序，我们可以得到如下的输出结果：  \n1    12    23    34    45    56    17    28    39    410    5\n```\n大家经常会把协程和多线程编程语言中的线程进行对比，但我们要明白，协程有着与线程类似的特性，但是协程与线程的区别在于协程不能并发，任意时刻只会有一个协程执行，而线程允许并发的存在。（译注：译者认为本质上协程其是就是线程，不过是用户态的线罢了，它将调度问题交由程序开发人员手动完成。）  \n我们通过控制程序执行顺序以满足获取某些临时信息的需求。配合全局变量的使用，协和会变得更加的灵活方便。\n","slug":"lua/2016-06-01-coroutines","date":"2024-03-14T06:15:59.723Z","categories_index":"lua_guide","tags_index":"lua","author_index":"安全书"},{"id":"381f6f7e3cde6d1b00fec638aae91387","title":"CentOS中Rsync加入自动启动服务","content":"CentOS中Rsync加入自动启动服务在CentOS下，如何将rsync服务，加入到systemctl自动启动项目中，如何进行配置\n要将rsync服务加入到systemctl自动启动项目中，在CentOS下，可以按照以下步骤进行配置：\n\n创建一个rsync的systemd服务配置文件。在终端中执行以下命令：\n1sudo nano /etc/systemd/system/rsync.service\n在打开的文件中，输入以下内容：\n12345678910[Unit]Description=rsync serviceAfter=network.target[Service]ExecStart=/usr/bin/rsync --daemon --config=/etc/rsyncd.confRestart=always[Install]WantedBy=default.target\n保存并关闭文件。\n\n创建一个rsync的配置文件。在终端中执行以下命令：\n1sudo nano /etc/rsyncd.conf\n在打开的文件中，输入你想要的rsync配置。例如，下面是一个简单的示例：\n1234567891011uid = nobodygid = nobodyuse chroot = yesmax connections = 4strict modes = yes[myshare]path = /path/to/your/foldercomment = My shared folderread only = nolist = yes \n保存并关闭文件。\n\n启动并激活rsync服务。在终端中执行以下命令：\n12sudo systemctl start rsync.servicesudo systemctl enable rsync.service\n\n现在，每次系统启动时，rsync服务都会自动启动。\n","slug":"linux/CentOS中Rsync加入自动启动服务","date":"2024-03-14T06:15:59.722Z","categories_index":"linux,rsync","tags_index":"rsync","author_index":"安全书"},{"id":"1d8bd87db6e909e4afecaef1ed59c41b","title":"Linux下命令工具箱","content":"Linux下命令工具箱z.lua + ripgrep + fzf + fish shell + starship +  exa + lazygit + byobu + spacevim + zed\nz.lua目录跳转zsh配置\n.zshrc\neval &quot;$(lua /path/to/z.lua --init zsh)&quot;\nfish配置\n`~/.config/fish/conf.d/z.fish`\nlua /path/to/z.lua --init fish | source\n\n跳转到有hexo的目录\nz -i hexo\nhttps://github.com/skywind3000/z.lua\n\nriggrep高级查找功能查到当前目录的所有文件，含有关键字&quot;rbenv&quot;\nrg -rn &quot;rbenv&quot;\n\nfzf 模糊查找工具跳转到检索目录\ncd $(find * -type d | fzf)\n跳转到检索文件\nvim $(fzf)\nzed $(fzf)\n完整安装有按键快捷键绑定\nsudo $(brew --prefix)/opt/fzf/install\nCtrl-t(bash)\nCtrl-r(zsh)\nAtl-c(fish)\n\nfish shell和好用的shell工具https://fishshell.com/\nconda init zsh\n\nstarship提示符配置工具在Fish shell中启动starship\n ~/.config/fish/config.fish\nstarship init fish | source\n\nhttps://starship.rs/\n\nexa增加版本的lslazygit命令窗口的git工具byobu高级化的tmuxspacevim配置完各种常用插件neovimohmyz.sh官网\nhttps://ohmyz.sh/#install\n主题（prompt提示符的风格不一样，路径和提示符分两行显示）\nhttps://git.sjtu.edu.cn/sjtug/ohmyzsh/-/blob/master/themes/bira.zsh-theme\n\nthefuck 自动纠正命令行错误brew install thefuck\n\nZsh主题插件管理工具antigencd ~/.\ncurl -L git.io/antigen &gt; .antigen.zsh\n\n相关依赖1pip3 install pygments\n\n\nautojump是Python写的， z.lua是用lua写的，直观速度上z.lua速度可以。\n","slug":"linux/Linux下命令工具箱","date":"2024-03-14T06:15:59.722Z","categories_index":"linux","tags_index":"zsh,fishell,fzf,riggrep,starship","author_index":"安全书"},{"id":"99c222df6265914694fe0a0c6fdad83f","title":"C语言实现Basic语言","content":"C语言实现Basic语言C语言实现Basic语言，给出C语言实现代码\n以下是一个简单的C语言实现Basic语言的示例代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#define MAX_LINE_LENGTH 1000#define MAX_VARIABLES 100typedef struct &#123;    char name[20];    int value;&#125; Variable;Variable variables[MAX_VARIABLES];int variableCount = 0;void executeCommand(char* line);void parseAssignment(char* line);void parsePrint(char* line);int main() &#123;    char line[MAX_LINE_LENGTH];    while (1) &#123;        printf(&quot;&gt;&gt; &quot;);        fgets(line, MAX_LINE_LENGTH, stdin);        if (strcmp(line, &quot;QUIT\\n&quot;) == 0) &#123;            break;        &#125;        executeCommand(line);    &#125;    return 0;&#125;void executeCommand(char* line) &#123;    if (strncmp(line, &quot;PRINT&quot;, 5) == 0) &#123;        parsePrint(line);    &#125; else &#123;        parseAssignment(line);    &#125;&#125;void parseAssignment(char* line) &#123;    char varName[20];    int varValue;    sscanf(line, &quot;%s = %d&quot;, varName, &amp;varValue);    for (int i = 0; i &lt; variableCount; i++) &#123;        if (strcmp(variables[i].name, varName) == 0) &#123;            variables[i].value = varValue;            return;        &#125;    &#125;    Variable variable;    strcpy(variable.name, varName);    variable.value = varValue;    variables[variableCount++] = variable;&#125;void parsePrint(char* line) &#123;    char varName[20];    sscanf(line, &quot;PRINT %s&quot;, varName);    for (int i = 0; i &lt; variableCount; i++) &#123;        if (strcmp(variables[i].name, varName) == 0) &#123;            printf(&quot;%s = %d\\n&quot;, variables[i].name, variables[i].value);            return;        &#125;    &#125;    printf(&quot;Variable %s not found\\n&quot;, varName);&#125;\n\n这个实现简单地解析用户输入的命令，并根据命令类型执行不同的操作。目前支持两个命令：赋值命令和打印命令。赋值命令形如变量名 = 值，将值赋给对应的变量。打印命令形如PRINT 变量名，输出对应变量的值。用户可以通过输入”QUIT”来退出程序。\n","slug":"linux/C语言实现Basic语言","date":"2024-03-14T06:15:59.722Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"0a67ef7b868dad2d1302f7dda41cf2d2","title":"Linux查看CPU内存硬盘大小的命令","content":"Linux查看CPU内存硬盘大小的命令如何用命令查Linux系统CPU核数、内存大小、磁盘的总容量\n要查看Linux系统的CPU核数，可以使用以下命令：\n1cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l\n\n要查看Linux系统的内存大小，可以使用以下命令：\n1free -h\n\n要查看Linux系统磁盘的总容量，可以使用以下命令：\n1df -h\n\n这些命令会分别显示CPU核数、内存大小和磁盘总容量。\n内存大小cat /proc/meminfo | head -n 1 | awk ‘{print $2/(1024 * 1024),”G”}’\nCPU核数cat /proc/cpuinfo | grep “cpu cores” | uniq\nLinux命令如何查看CPU的个数\n要查看CPU的个数，可以使用以下命令之一：\n\n使用lscpu命令：\n\n1lscpu\n\n在输出中，可以查看”CPU(s)”一行，显示了系统中的CPU核心数。\n\n使用nproc命令：\n\n1nproc\n\n这个命令会直接输出系统中的CPU核心数。\nLinux下什么命令工具可以看到时程占用内存大小的分布，用什么命令\n在Linux系统下，可以使用命令pmap来查看进程占用内存大小的分布。具体命令如下：\n1pmap &lt;进程ID&gt;\n\n其中，&lt;进程ID&gt;是待查看进程的PID，通过该命令可以查看指定进程占用内存的详细信息。\ntop 命令显示的时候，如何显示单是G\n要在 top 命令中显示单位为 G（Gigabytes），可以按下 shift+e 键，这样会切换单位显示。或者在运行 top 命令时使用 -E 参数，如：top -E g。这样就可以以 G 为单位显示内存和 CPU 使用情况了。\n12ps -aux --sort -pcpu | less  # 根据CPU使用率升序排序ps -aux --sort -pmem | less  # 根据内存使用率升序排序\n\n\ncat /proc/16676/status\n查看进程16676的状态\n","slug":"linux/Linux查看CPU内存硬盘大小的命令","date":"2024-03-14T06:15:59.722Z","categories_index":"linux","tags_index":"cpu,内存,硬盘","author_index":"安全书"},{"id":"908bb14a39f34acac1b8c6da5e195381","title":"lsof命令","content":"lsof命令lsof 除了-i参数，还有那些参数可使用\n除了-i参数，lsof命令还有以下常用参数可使用：\n\n-p ：显示指定进程ID所打开的文件列表。\n-u ：显示指定用户名所打开的文件列表。\n-c ：显示指定命令名所打开的文件列表。\n-t：仅显示进程ID，不显示其他信息。\n-n：不解析主机名和端口号，直接显示IP地址和端口号。\n-i ip:port：仅显示与指定IP地址和端口号相关联的开放文件。\n-s ：根据连接状态过滤并显示相应的文件列表。可用状态包括ESTABLISHED、LISTEN、CLOSE_WAIT等。\n+d ：仅显示指定目录下被打开的文件列表。\n+D ：递归地显示指定目录及其子目录下被打开的文件列表。\n\n这些参数可以组合使用来实现更复杂的查询需求。\nlsof -i参数作用是什么\nlsof -i参数用于显示正在运行的进程和它们所打开的网络连接。它可以用来查看特定端口上的活动和与特定IP地址或域名相关联的进程。\n","slug":"linux/lsof命令","date":"2024-03-14T06:15:59.722Z","categories_index":"linux,lsof","tags_index":"lsof","author_index":"安全书"},{"id":"fdf5523b962ad37a37098f0c3f441f33","title":"rsync同步本地文件到远程服务器","content":"rsync同步本地文件到远程服务器如何将本地的一个目录，rsync同步到目的服务器/data0/sd目录下1. 首先，您需要在目标服务器上安装rsync。2. 然后，您可以使用以下命令将本地目录同步到目的服务器/data0/sd目录：\n1rsync -avz -e &quot;ssh&quot; /local_folder/ /dest_server/data0/sd/\n其中，-a表示忽略所有错误和歧义的选项。-v表示显示进度条。-z表示使用最优的传输方式。-e “ssh”表示使用SSH连接。3. 如果您想要将所有文件同步到目的服务器，可以使用以下命令：\n1rsync -avz -e &quot;ssh&quot; * /dest_server/data0/sd/\n其中，*表示所有文件。4. 如果您想要将特定目录同步到目的服务器，可以使用以下命令：\n1rsync -avz -e &quot;ssh&quot; /local_folder/ /dest_server/data0/sd/my_folder/\n其中，/local_folder/表示本地目录。/dest_server/data0/sd/my_folder/表示目的服务器上的目标目录。5. 如果您想要将文件夹内容同步到目的服务器，可以使用以下命令：\n1rsync -avz -e &quot;ssh&quot; /local_folder/my_sub_folder/ * /dest_server/data0/sd/my_folder/\n其中，/local_folder/表示本地目录。/dest_server/data0/sd/my_folder/表示目的服务器上的目标目录。*表示所有文件夹内容。️dockerfiles\nrsync -avz &#117;&#x73;&#x65;&#114;&#x31;&#x40;&#x31;&#x30;&#46;&#x32;&#x31;&#x30;&#x2e;&#x31;&#x2e;&#54;::aigc/  –password-file=/root/pwd.txt /data0  -v -h –progress\nrsync -avzP ./AutoMatic1111/stable-diffusion-webui/models/Stable-diffusion/blindbox_V1Mix.safetensors &#x75;&#x73;&#101;&#x72;&#49;&#64;&#49;&#48;&#x2e;&#50;&#49;&#x30;&#46;&#49;&#x2e;&#x36;::aigc/blindbox_V1Mix.safetensors –password-file=pwd.txt\n上传一个文件\nrsync -avz &#116;&#x65;&#115;&#x74;&#64;&#x31;&#x39;&#x32;&#x2e;&#49;&#x36;&#56;&#x2e;&#x31;&#x2e;&#x31;::aigc/ –password-file=/root/pwd.txt /data0 -v -h –progress\nsudo /usr/bin/rsync –daemon –config /etc/rsyncd.conf\n","slug":"linux/rsync同步本地文件到远程服务器","date":"2024-03-14T06:15:59.722Z","categories_index":"linux","tags_index":"rsync,linux","author_index":"安全书"},{"id":"f51f6a7100298360c1660abcde8f9070","title":"deb安装包如何在Linux上安装","content":"deb安装包如何在Linux上安装deb安装包如何在Linux上安装\ndeb包是Debian软件包管理系统中的一种二进制软件包格式。在Linux上安装deb包可以通过以下步骤实现：\n\n打开终端，使用以下命令切换到root用户：\n1sudo su\n使用以下命令安装dpkg软件包管理器（如果尚未安装）：\n1apt-get install dpkg\n使用以下命令安装deb包：\n1dpkg -i &lt;path_to_deb_package&gt;\n\n其中，&lt;path_to_deb_package&gt;是deb包的完整路径。\n\n如果出现依赖性错误，可以尝试使用以下命令修复依赖关系：\n1apt-get install -f\n安装成功后，可以使用以下命令验证软件包是否已正确安装：\n1dpkg -l | grep &lt;package_name&gt;\n\n其中，&lt;package_name&gt;是要验证的软件包名称。\n\n\n需要注意的是，使用dpkg直接安装deb包可能会导致依赖关系问题。建议优先考虑使用apt或apt-get等高级软件包管理器来安装和管理deb软件包。\n","slug":"linux/deb安装包如何在Linux上安装","date":"2024-03-14T06:15:59.722Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"43a47fb5980bfbe40ff0b0471b3c6171","title":"lazygit的常用操作命令","content":"lazygit的常用操作命令lazygit的只对当前选中文件进行add，用什么快捷键？\n在lazygit中，您可以使用快捷键”a”来仅将当前选中的文件添加到暂存区。\n列出lazygit的操作快捷键\n以下是lazygit的一些操作快捷键：\n\nCtrl + h：显示/隐藏帮助菜单\nCtrl + q：退出lazygit\nCtrl + c：复制选中的提交信息\nCtrl + v：粘贴提交信息\nTab：在不同的面板之间切换焦点\nShift + Tab：在不同的面板之间反向切换焦点\nEnter：打开或选中当前选项卡中的文件/文件夹\n/：搜索文件或提交信息\nn：下一个搜索结果\nN：上一个搜索结果\nu：更新仓库状态，获取最新的提交和分支信息\ns：切换到状态面板，查看和选择待提交的文件更改\nc：切换到提交面板，查看和编辑提交信息并进行提交操作\nb：切换到分支面板，查看当前分支和其他可用分支，并进行分支操作（如创建、切换、合并等）\nr：切换到远程面板，查看远程仓库和远程分支，并进行相关操作（如推送、拉取等）\ng + c：打开Git命令行界面，可以执行各种git命令\n\n这只是一部分常用的快捷键列表，还有其他更多操作可以通过在lazygit中按下h键来查看帮助菜单获取。\ngit add这个命令用lazygit如何实现在lazygit中，你可以通过以下步骤来实现git add命令：\n\n打开终端并进入项目的根目录。\n运行lazygit命令以打开lazygit界面。\n在lazygit界面中，你将看到文件列表。使用上下箭头键和Enter键选择要添加到暂存区的文件。\n选定文件后，可以按下空格键来选择或取消选择文件。\n选定所有要添加的文件后，按下a键来添加选择的文件到暂存区。\n最后，按下Ctrl + C键退出lazygit界面。\n\n这样就完成了使用lazygit进行git add操作的过程。\n用空格实现git add，而a是对应git add -A\n","slug":"linux/lazygit的常用操作命令","date":"2024-03-14T06:15:59.722Z","categories_index":"git","tags_index":"lazygit","author_index":"安全书"},{"id":"7093c58211fbd5549aefd074e9a48181","title":"直接税与间接税","content":"直接税与间接税直接税和间接税有什么区别？ 生产税和资产税的区别？\n直接税和间接税的区别在于征收对象和征收方式。\n直接税是指由个人或企业直接缴纳给政府的税费，征收对象是个人或企业的所得、财产等。常见的直接税包括个人所得税、企业所得税、房产税等。直接税的征收方式是根据纳税人的实际情况，按照一定比例对其应纳税额进行计算。\n间接税是指由企业或个人作为商品和服务提供者向消费者收取，并由其代表消费者缴纳给政府的税费，征收对象是商品和服务的销售额。常见的间接税包括增值税、消费税、关税等。间接税的征收方式是通过对商品和服务价格的调整，在销售环节进行征收。\n而生产税和资产税则是两种不同类型的直接税。\n生产税是针对特定产品或行业，在其生产过程中对生产者征收的一种特殊形式的直接税。它通常以固定金额或按比例计算，并与产品数量无关。生产过程中需要支付该项费用，最终会转嫁到产品价格上，由消费者承担。\n资产税是指对个人或企业拥有的财产（如房地产、土地、车辆等）进行征收的直接税。它通常以财产的价值为基础，按照一定比例计算并缴纳。资产税是对财富的一种征收方式，不同于其他形式的直接税，它主要关注个人或企业所拥有的财产规模和价值。\n","slug":"life/直接税与间接税","date":"2024-03-14T06:15:59.722Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"359bc28e92765470188f434797655186","title":"达克效应","content":"达克效应Obsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。\nObsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。\nObsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。\nObsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。\nObsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。\n达克效应具体提的是什么？\n达克效应是指在多任务处理中，当一个任务的执行与其他任务同时进行时，会出现注意力分配不均衡的现象。具体来说，达克效应指的是在进行多个任务时，如果一个任务需要较高的认知资源或注意力资源，而其他任务相对较低，则人们倾向于将更多的注意力和认知资源分配给那个需要更高资源的任务，导致其他任务的执行效率下降。\n","slug":"life/达克效应","date":"2024-03-14T06:15:59.722Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"7df51df4529217f4655b03a0bc83e0ff","title":"NMAP扫描主机开发的端口","content":"NMAP扫描主机开发的端口如何用NMap扫描主机的端口，那些是开放的。\n要使用NMap扫描主机的端口，并确定哪些是开放的，可以按照以下步骤进行：\n\n下载和安装NMap：从官方网站（https://nmap.org）下载适用于您的操作系统的NMap安装程序，并完成安装。\n\n打开终端或命令提示符：在Windows上，按下Win + R，键入”cmd”并按Enter打开命令提示符。在Mac和Linux上，打开终端应用程序。\n\n运行扫描命令：在终端或命令提示符中，输入以下命令：\n1nmap -p- &lt;目标IP地址&gt;\n\n其中”&lt;目标IP地址&gt;”是您要扫描的主机的IP地址。\n\n等待扫描完成：NMap将开始扫描指定主机上所有可能的端口。这可能需要一些时间，具体取决于您所选择扫描的范围和目标主机的网络状况。\n\n分析结果：一旦扫描完成，您将看到一个列出了每个端口状态（开放、关闭、过滤等）以及服务/应用程序名称（如果可识别）的结果列表。根据状态为”open”的端口即可确定其为开放状态。\n\n\n请注意，使用NMap进行未经授权的扫描可能违反法律规定，请确保在合法和道德的范围内使用该工具。\n如何用Nmap查看ip为192.168.1.1的6070端口是否开放\n要使用Nmap来查看IP为192.168.1.1的6070端口是否开放，可以按照以下步骤进行操作：\n\n打开终端或命令提示符，并确保已经安装了Nmap工具。\n\n在终端或命令提示符中输入以下命令：\n1nmap -p 6070 192.168.1.1\n等待Nmap扫描完成。它将会显示目标IP地址的开放端口列表。\n\n查找端口6070的扫描结果。如果该端口显示为”open”，则表示该端口开放；如果显示为”closed”，则表示该端口关闭；如果显示为”filtered”，则表示该端口被防火墙过滤。\n\n\n请注意，您需要具有适当的权限才能执行此操作，并且可能需要在网络中具有相应的访问权限才能成功扫描目标IP地址。\n如何用NC查看ip为192.168.1.1的端口9000的端口是否开放\n要使用nc命令来检查IP地址为192.168.1.1的主机上的9000端口是否开放，可以按照以下步骤进行操作：\n\n打开终端或命令提示符窗口。\n\n输入以下命令：\n1nc -zv 192.168.1.1 9000\n-z：表示不发送任何数据。-v：表示以详细模式运行，显示更多信息。192.168.1.1：目标IP地址。9000：目标端口号。\n\n按回车键执行命令。如果端口开放，则终端会显示以下信息：\n1Connection to 192.168.1.1 9000 port [tcp/*] succeeded!\n这表示端口是开放的。\n\n如果端口关闭或阻塞，则终端会显示以下信息：\n1nc: connect to 192.168.1.1 port 9000 (tcp) failed: Connection refused\n或者：\n1nc: connect to 192.168.1.1 port 9000 (tcp) timed out: Operation now in progress\n\n通过以上步骤，你可以使用nc命令来检查指定IP地址和端口号的主机是否开放了特定端口。\n","slug":"linux/kali/NMAP扫描主机开发的端口","date":"2024-03-14T06:15:59.722Z","categories_index":"kali,nmap","tags_index":"nmap","author_index":"安全书"},{"id":"385bcd3cd24544069f11e9b55c33d2c8","title":"好用不贵的机械键盘","content":"好用不贵的机械键盘Gasket结构的机械键盘\nGasket结构的机械键盘是一种通过垫圈来隔离键盘底板和键帽的设计。它的设计灵感来自于汽车发动机的垫圈，旨在提供更好的键盘手感和减少按键声音。\nGasket结构的机械键盘通常由四个垫圈环绕在每个按键周围，起到隔离振动和减震的作用。这些垫圈可以通过不同材质、硬度和形状来调整按键手感和声音。\n相比传统的机械键盘，Gasket结构的机械键盘在按下按键时能够提供更柔软、弹性的手感，使得打字更加舒适。同时，垫圈也能够减少按键底部碰撞时产生的噪音，使得整体键盘声音更加静音。\n此外，Gasket结构的机械键盘还具有可定制性高的特点。由于垫圈可以根据不同需求进行更换或调整，用户可以根据自己喜好选择不同硬度或材质的垫圈来改变手感和声音。这使得Gasket结构的机械键盘成为了许多打字爱好者和游戏玩家的首选。\n总的来说，Gasket结构的机械键盘通过使用垫圈来隔离振动和减震，提供柔软、弹性的手感和静音的按键声音。它是一种高度可定制的键盘设计，适合那些追求舒适打字体验和个性化定制的用户使用。\n原厂高度机械键盘键帽\n原厂高度机械键盘键帽是指由键盘制造商生产的与特定品牌和型号的机械键盘配套使用的键帽。高度指的是键帽的形状和尺寸，不同品牌和型号的机械键盘可能有不同的高度设计。原厂高度机械键盘键帽通常采用优质材料制作，如ABS或PBT塑料，具有耐用性和舒适手感。它们经过精密设计，与机械轴相匹配，确保按下时稳定性和响应性。\n使用原厂高度机械键盘键帽可以提供更好的按键体验，并确保与机械轴完全兼容。此外，一些原厂高度机械键盘键帽还具有特殊功能按键，如多媒体控制、宏定义等，可进一步提升使用体验。\n采用POM材的机械键盘轴体\nPOM材料是一种高分子材料，具有优异的物理和化学性质，因此被广泛应用于机械键盘轴体的制造中。\nPOM材料具有以下特点：\n\n耐磨性：POM材料具有出色的耐磨性能，可以保证键盘轴体在长时间使用后仍然保持良好的手感和稳定性。\n\n高强度：POM材料具有高强度和刚性，可以承受较大的力量和压力，不易变形或断裂。\n\n低摩擦系数：POM材料具有较低的摩擦系数，使得按键操作更加顺畅，并且减少了因摩擦而产生的噪音。\n\n耐化学腐蚀性：POM材料对常见的化学物质具有较好的耐腐蚀性，不易受到酸碱等物质的侵蚀。\n\n热稳定性：POM材料具有良好的热稳定性，能够在较高温度下保持其机械性能不变。\n\n\n综上所述，采用POM材料制造机械键盘轴体可以提供良好的手感、稳定性和耐用性，使得键盘使用更加舒适和持久。\n","slug":"keyboard/好用不贵的机械键盘","date":"2024-03-14T06:15:59.721Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"079e6baebd5d8e475a537e84c2a1db36","title":"萌新的第一把机械键盘，请问罗技g610和ikbcC210怎么选择呢？","content":"萌新的第一把机械键盘，请问罗技g610和ikbcC210怎么选择呢？\n\n\n\n\n\n\n\n\nExcerpt其实这两款都行，主要还是看你眼缘。逻技系列和cherry很像，就是键盘在模具方面都有自己的设计， 还多了…\n\n其实这两款都行，主要还是看你眼缘。\n逻技系列和cherry很像，就是键盘在模具方面都有自己的设计， 还多了键子，或是加了一些控制键。\n玩游戏罗技友好，但是我要说的是，其实这两个键盘没有那么大差异，但是有一个容易被忽视的问题。\n问题就是你：你换键盘帽吗？如果你键帽，你会发现罗技的键帽真的以后换键帽有点问题，罗技的键盘呢外型设计风格有自己的特点， 但是说换键帽真的是，不在好搭配，就像典型的历史上的Cherry g80-3800这种键盘， 最后感觉换配啥键帽都不好看，这个就比较麻烦， 买键盘某种程序上都想让键盘好看，但你看g610这个外型设计。\n\n之前前几年，PBT键帽没有现在这么花哨，就是从阿米洛、akko这波带起来的， IKBC也开始做各种键帽主题，这草其实不好拔，如果你铁了心，以后就不想换键帽，一起玩游戏， 罗技g610没没毛病， 至于那些什么音量控制的特殊键，其实别的键盘也可以通过组合键来完成。\n有人说Cherry轴现在版本的弹簧声点，是有这个想象，但同时也有一个问题，也不是其他的啥国产轴都行， TTC，BOX这种的是可以。\n而大厂产品线比较全的，其实能用手数过的，cherry、罗技、IKBC、雷蛇、包括灯厂的。\n500元的价位，每个品牌都有自己特色的型号,依次说一下：\nCherry樱桃机械键盘500元要是在以前，基本是g80-3850红轴，以前红轴的贵。g80-3000青茶黑轴， g80-3494不行，过了500元这个预算，因为产品升级，不推荐买上一代产品了， 除了g80-3494意外，如果好这个手感和 外观还可以继续买， 现在500元左右，还得是mx 2.0s和3.0s。\n3.0黑色背光版可以， 白了不行，过预算了。\n背光版要贵一些， 全键盘的cherry就推荐上面这两款，主要是工业设计可以，但是配键帽也和罗技一样， 因为他们都太有自己的特点了。\n罗技机械键盘现在特价479就可以入手，最开始都是原厂大家买买买，这些年逻技术的机械键盘整全的系列全了以后，大家对罗技的认可度也高了，但是罗技的轴也就那样。\nIKBC机械键盘IKBC的C系列太经典， 以至于我现在敲文字这段，用的就是C87键盘， IKBC经过市场和用户长时间的考研， 感觉活动价的时候，基本属于闭眼入系列。但游戏的不光是C系列，其实R系列也可以。\n以前的Cherry主题键帽没有现在这么多，基本就是黑白三元色，今年的高达和巧克力系列真的让原本低调朴素的IKBC也玩起了联名款了。\nIKBC基本属于各方面都中规中矩的产品，对得起这个价格，但是不能拿那和阿米洛和F和L比，游戏要用有线有，其实还有W系列的，就是把有线变成2.4G蓝牙的。\n雷蛇机械键盘雷蛇就是做游戏键盘的，特别是他们家自己的轴体，好坏先不说，主要就是他自己的独特生，要是有人就好这个手感，其实也没啥可聊的，就买就行了，今年最火的，感觉还是她的鼠标新出的，而不是键盘。\n经典的不能再经典系列，没啥可说的，就是活动价格100元以内买就行了，我桌子上放了两个。\n今年最猛的鼠标。\n主要还是说键盘，黑寡妇有点过预算，但看着顺眼，入也不是不行，毕竟多少也就100元的事， 以后玩个顺心，看着舒心，能用上几年。\n美商海盗船灯厂的这个红色的背光和雷蛇的绿色背光，简直就是对比色的干活，玩灯还得是灯厂，但是稳定型和质量，其实感觉不一定比以上面的强多少。\n以上凡是有自己膜具设计的厂商，其实配键帽都有点问题，就是IKBC这大众脸的设计，反倒是怎么配都行。从功能性上来说，以上这些品牌其实，也都是大差不差，如果主要使用场景是游戏，其实还是选罗技和雷蛇、海盗船，如果游戏办公兼顾，IKBC和Cherry，如果玩键帽，我建议还是IKBC。\n","slug":"keyboard/萌新的第一把机械键盘，请问罗技g610和ikbcC210怎么选择呢？","date":"2024-03-14T06:15:59.721Z","categories_index":"文章","tags_index":"键盘（计算机）,机械键盘,电脑外设,Cherry（键盘）,机械键盘选购","author_index":"安全书"},{"id":"09fdb404fe7dff8a7f6fd0c4f0fd9bc4","title":"值得背诵英文短文(英语美文)","content":"值得背诵英文短文(英语美文)1.Ernetst Hemingway\nTrue Nobility\n2.Bertrand Russel\nHow to Grow Old\n3.William Worldsworth\nI wandered lonely as a clould.\n4.Robert Frost\nThe Road Not Taken.\n1.”True Nobility”—Ernest Hemingway2.”How to Grow Old”—Bertrand Russell3.”I wanderedlonely as a cloud”—William Woedsworth4.”The Road Not Taken”—Robert Frost\n虽然我是个女生但完全看不出丸子化妆跟素颜的区别怎么破，不管怎样都很美(｡･ω･｡)ﾉ♡1.True Nobility——Ernest Hemingway 《真正的高贵》——海明威两两对立的效果：alliteration(押头韵)：pleasure vs pain bereavements(丧亲之痛) vs blessing(祝福)在讨论一些比较高深的问题的时候，可以引用文章中的金句来表达观点。2.How to Grow Old——Bertrand Russell 《怎样老去》——罗素文章讲述了如何有尊严的老去。最值得背诵的是最后一段，将人生比做一条河流。metaphor 比喻3.I wandered lonely as a cloud——William Wordsworth英国诗人作者讲述了看到一朵水仙花后愉悦的心情。适合陶冶性情，充满了美好的比喻。4.The Road Not Taken——Robert Frost美国诗人将人生比喻成交叉路口，在谈论人生谈论选择的时候，可以引用这首诗。\n","slug":"language/值得背诵英文短文(英语美文)","date":"2024-03-14T06:15:59.721Z","categories_index":"publish","tags_index":"english","author_index":"安全书"},{"id":"7220e1d3d9e7a433318ba2e74380f5e1","title":"NPD人格是什么","content":"NPD人格是什么NPD人格指提什么人格类型？\nNPD人格指的是“自恋性人格障碍”（Narcissistic Personality Disorder）的人格类型。这种人格障碍的特征包括过度自我中心、缺乏同理心、对自己的重视超过对他人的重视、对他人表现出轻视和傲慢态度等。这些特征会导致个体在社交关系中遇到困难，并可能导致与他人产生冲突。\n双相情感障碍指的是什么\n双相情感障碍，也称为躁郁症，是一种严重的心理疾病，常常表现为情绪波动剧烈和极端的情感变化。患者会经历两个极端的情绪状态：躁狂期和抑郁期。\n在躁狂期，患者会出现异常兴奋、多动、冲动、过度自信、注意力不集中、睡眠减少等症状。他们可能会表现出过度活跃、冲动行为（如挥霍金钱、过度参与风险活动），以及言语快速、思维跳跃等。\n而在抑郁期，则表现为丧失兴趣和快乐感、持续低落的情绪、精力不足、睡眠增加或减少以及自杀念头等。患者可能会感到无助、内心空虚，并经历自我怀疑和自责。\n双相情感障碍的发作时长和频率不一，每个人都可能有不同的表现形式。这种心理健康问题会对患者的日常生活和人际关系产生负面影响。治疗通常包括药物治疗和心理治疗，以帮助患者控制情绪波动并提高生活质量。\n人的情绪不稳定， 很容易就困的原因是什么？和神经系统发育有关系吗？\n人的情绪不稳定和容易感到困倦可能有以下原因：\n\n睡眠不足：缺乏充足的睡眠会导致人体疲劳，影响情绪稳定。长期睡眠不足还可能引发抑郁和焦虑等心理问题。\n\n压力过大：长期承受过大的精神压力会导致情绪波动，使人更容易感到疲惫。\n\n情绪调节困难：有些人天生就难以有效地调节自己的情绪，往往会表现出情绪波动较大的特点。\n\n神经系统异常：一些神经系统相关的疾病，如抑郁症、焦虑症、双相情感障碍等，可能导致人的情绪不稳定和容易困倦。这些疾病与神经系统发育及功能异常有关。\n\n\n尽管神经系统发育异常可能与情绪不稳定和容易困倦有关，但具体原因仍然需要进一步科学研究来明确。同时，个体差异也需要考虑，即使在正常的神经系统发育下，每个人对于情绪和疲劳的感受也会有所不同。因此，对于情绪不稳定和容易困倦的个体，建议咨询专业医生以获得更准确的诊断和治疗建议。\nNLD人格指的是什么\nNLD人格是指非语言性学习障碍（Nonverbal Learning Disability）人格。它是一种神经发育障碍，主要影响个体在非语言领域的学习和社交技能。NLD人格的特征包括语言能力正常但非语言能力较差、社交困难、空间感知困难、学习困难等。这种人格在儿童和成年人中都存在，但通常在儿童时期开始显现。NLD人格的具体原因尚不清楚，但研究表明可能与大脑半球之间的通信问题有关。\n自恋型人格指的是什么人格\n自恋型人格是指一种对自我高度自负、过分关注自己的态度和行为。这种类型的人格特征包括对自己的能力、外貌和成就过分夸大，常常表现出自大、傲慢、独断和不关心他人感受的行为。他们常常渴望被别人赞美和钦佩，并且对批评或否定极度敏感。此外，他们也缺乏对他人的关心和同理心，往往以自己为中心，只关注满足自己的需求和欲望。\n","slug":"life/NPD人格是什么","date":"2024-03-14T06:15:59.721Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"efa5c6ba65f1069db1e0e2fbed2f610c","title":"人的右脑负责审美","content":"人的右脑负责审美人的右脑负责审美吗\n右脑被认为与创造力、想象力和艺术感知相关，因此有人认为右脑负责审美。然而，大脑的功能是复杂的，并不是简单地由左右两半球分工负责。审美体验可能涉及多个区域和网络的合作，包括右脑和左脑之间的相互作用。因此，认为右脑独立负责审美可能过于简化了大脑的功能分工。\n","slug":"life/人的右脑负责审美","date":"2024-03-14T06:15:59.721Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"269812094a9dc7c1362a98413c7fc64c","title":"多巴胺","content":"多巴胺Obsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。\n多巴胺和内啡肽的分泌水平受到遗传、神经调节、环境刺激、药物作用和心理因素等多个因素的综合影响。具体来说，个体的基因组成可以影响多巴胺和内啡肽的合成、释放和降解过程，进而影响其分泌水平。神经系统中的不同神经递质和神经调节物质也可以调节多巴胺和内啡肽的合成、释放和再摄取过程，从而影响其分泌水平。此外，外界环境刺激（如噪音、光线等）以及社交互动等都可以对多巴胺和内啡肽的分泌产生影响。一些药物（如兴奋剂、镇静剂等）可以直接或间接地影响多巴胺和内啡肽的合成、释放和再摄取过程，从而改变其分泌水平。此外，情绪状态、压力水平、心理健康状况等也可以对多巴胺和内啡肽的分泌产生影响。综上所述，多巴胺和内啡肽的分泌水平受到遗传、神经调节、环境刺激、药物作用和心理因素等多个因素的综合影响。\n多巴胺的分泌、血清对抑郁症的影响是什么\n多巴胺是一种神经递质，参与调节情绪、动机和奖赏等方面的功能。抑郁症是一种常见的精神疾病，患者往往表现出情绪低落、兴趣减退、自我价值感降低等症状。以下是多巴胺的分泌和血清对抑郁症的影响：\n\n多巴胺分泌：抑郁症患者在大脑中多巴胺的分泌可能减少。这可能导致情绪低落、乏力和动力不足等抑郁症状。\n\n血清中的多巴胺水平：一些研究表明，抑郁症患者血清中多巴胺水平相对较低，与正常人群相比有所下降。这可能与抑郁症患者常见的缺乏兴趣和乐趣有关。\n\n\n然而，多巴胺在抑郁症发生机制中的作用仍然不完全清楚。尽管有些证据表明多巴胺水平降低与抑郁症存在关联，但也有其他因素如衰竭的神经回路、其他神经递质的异常等可能对抑郁症的发生和发展起着重要作用。因此，抑郁症的发病机制是非常复杂的，需要进一步研究来更好地理解多巴胺在其中的具体作用。\n是什么因素影响，多巴胺和内啡肽的分泌水平？\n多巴胺和内啡肽的分泌水平受多种因素影响，包括以下几个方面：\n\n遗传因素：个体的基因组成可以影响多巴胺和内啡肽的合成、释放和降解过程，进而影响其分泌水平。\n\n神经调节：神经系统中的不同神经递质和神经调节物质可以调节多巴胺和内啡肽的合成、释放和再摄取，从而影响其分泌水平。\n\n环境刺激：外界环境刺激（如噪音、光线等）以及社交互动等都可以对多巴胺和内啡肽的分泌产生影响。\n\n药物作用：一些药物（如兴奋剂、镇静剂等）可以直接或间接地影响多巴胺和内啡肽的合成、释放和再摄取过程，从而改变其分泌水平。\n\n心理因素：情绪状态、压力水平、心理健康状况等都可以对多巴胺和内啡肽的分泌产生影响。\n\n\n总之，多巴胺和内啡肽的分泌水平受到遗传、神经调节、环境刺激、药物作用和心理因素等多个因素的综合影响。\n","slug":"life/多巴胺","date":"2024-03-14T06:15:59.721Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"bb21997cc473c6905646b5f8e580527a","title":"大脑额叶","content":"大脑额叶Obsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。额叶发达对人心里健康有那些影响？\n额叶是大脑的一部分，位于前脑的顶部，对人的心理健康有着重要影响。额叶发达可以带来以下影响：\n\n情绪调节：额叶参与了情绪的产生和调节过程。额叶发达的人更容易控制自己的情绪，更具有情绪稳定性，能够更好地应对压力和挫折。\n\n决策能力：额叶与决策制定密切相关。额叶发达的人更加理性和清晰地思考问题，能够做出更明智、合理的决策。\n\n社交技能：额叶参与了社交行为和人际交往过程。额叶发达的人更具有社交技巧，能够更好地理解他人的情感和需求，并且擅长表达自己。\n\n记忆力：额叶与记忆形成和存储密切相关。额叶发达的人通常具有较好的工作记忆和长期记忆能力。\n\n创造力：一些研究表明，额叶发达与创造力之间存在一定关系。额叶发达的人通常具有较强的想象力、创新能力和艺术表达能力。\n\n\n需要注意的是，额叶发达并不意味着心理健康一定良好，同时额叶功能异常也可能导致心理问题。因此，维护好整体大脑的健康和平衡是关键。\n额叶不发达都的人的心里和精神上有那些影响。 \n额叶是大脑的一个重要区域，主要负责认知、决策、情绪调节和社交行为等功能。如果额叶发育不良或者损伤，可能会对个体的心理和精神产生一系列影响。\n\n认知功能受损：额叶是大脑的执行机构，负责高级认知功能，如学习记忆、语言理解和推理等。额叶发育不良或者损伤可能导致注意力不集中、学习困难、记忆力下降等问题。\n\n情绪调节困难：额叶与情绪调节密切相关。发育不良或者损伤可能导致情绪波动较大，容易出现焦虑、抑郁等情绪问题。此外，还可能影响个体对他人情感的感知和理解能力。\n\n社交行为异常：额叶在社交行为中起到重要作用。如果额叶发育不良或者损伤，可能导致社交技能及行为的异常。个体可能表现出社交困难、缺乏同理心和适应性行为等问题。\n\n决策困难：额叶参与决策过程中的评估、权衡和判断。额叶发育不良或者损伤可能导致决策困难，个体可能在做出选择时缺乏逻辑性和理智性。\n\n\n总的来说，额叶发育不良或者损伤会对个体的认知、情绪调节、社交行为和决策能力产生负面影响。然而，具体影响可能因个体差异而有所不同，还需要考虑其他因素的综合作用。\n人的额叶发达与否是天生的吗\n人的额叶的发达与否主要是由遗传因素和环境因素共同决定的。有研究表明，人的脑结构在一定程度上受基因影响，而额叶是大脑中负责高级认知功能的区域之一。因此，个体在天生时就可能存在额叶发达与否的差异。\n然而，环境因素也对额叶的发育起到重要作用。早期经验、教育程度、学习以及其他认知刺激对额叶的功能和结构有显著影响。例如，接受音乐培训或学习外语等活动被认为可以促进额叶功能的发展。\n综上所述，人的额叶发达与否是天生和环境因素相互作用的结果。遗传基因决定了个体在出生时存在的潜力和限制，而环境刺激则能够对额叶功能进行塑造和提升。\n","slug":"life/大脑额叶","date":"2024-03-14T06:15:59.721Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"3f117b2631c0b4791156c24ac7f20fb2","title":"大脑颞叶","content":"大脑颞叶Obsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。大脑颞叶负责人的什么工作\n大脑颞叶是大脑的一个重要结构，位于颞骨内，负责多种重要的功能。\n\n处理听觉信息：颞叶中的听觉皮层负责接收和处理听觉信息。\n\n记忆：海马体是颞叶中的一个重要结构，与记忆形成和存储密切相关。海马体参与了将短期记忆转化为长期记忆的过程。\n\n语言理解：颞叶中的左半球区域与语言理解密切相关。如果左侧颞叶损伤，可能导致失语症或语言障碍。\n\n视觉识别：颞叶中的部分区域参与了视觉对象识别和面孔识别等视觉认知功能。\n\n情感处理：颞叶与情绪和情感处理有关。一些研究表明，右侧颞叶在情绪识别和自主神经系统调节方面起着重要作用。\n\n空间导航：海马体还参与了空间导航和方向感知的调节。\n\n\n总之，大脑颞叶在听觉、记忆、语言理解、视觉识别、情感处理和空间导航等方面起着重要作用。\n大脑颞叶发达与不发达人之间的差异\n大脑颞叶是大脑的一个区域，位于额叶和顶叶之间。它在人类的认知、记忆、情绪和语言等方面起着重要作用。大脑颞叶发达与不发达人之间存在一些差异。\n\n认知能力：大脑颞叶发达的人可能具有更强的认知能力，包括注意力、学习能力和思维灵活性等方面。他们可能更容易理解复杂的概念和解决问题。\n\n记忆能力：大脑颞叶与记忆密切相关，尤其是对于长期记忆的存储和检索。发达的大脑颞叶可以提高个体的记忆能力，使其更容易回忆和使用已有的信息。\n\n情绪调控：大脑颞叶还参与情绪调控过程。发达的大脑颞叶可能使个体更具有情绪稳定性和情商，并且更容易理解和处理他人的情感。\n\n语言能力：大脑颞叶与语言相关联，特别是左侧颞叶与语言产生有关。因此，发达的大脑颞叶可能意味着更好的语言能力，包括词汇量丰富、语法正确性和流利度。\n\n\n需要注意的是，大脑颞叶的发育与个体的遗传基因、环境刺激和个人经验等多种因素有关。因此，不同人之间的大脑颞叶差异并不绝对，也不能仅根据大脑颞叶大小来评判一个人的智力或能力水平。\n","slug":"life/大脑颞叶","date":"2024-03-14T06:15:59.721Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"52dc08e318eeea411ae9c76ce6c182e3","title":"小农意识具体指的是什么","content":"小农意识具体指的是什么小农意识具体指的是什么？\n小农意识是指农村居民在思想观念和价值观念上所具有的一种特殊心态。它源自于中国传统的农耕文化和乡村社会结构，表现为对土地和农业的情感依恋、对传统生活方式的认同、对城市化和现代化进程的不满和抵制等。小农意识反映了农村居民对自身地位、生活方式以及社会变迁的一种认知和感受，具有保守、稳定、封闭等特点。\n小农意识的具体表现是什么？\n小农意识是指一种传统的农村生活观念和价值观，通常表现为以下几个方面：\n\n依赖于土地和自然资源：小农意识的人们通常依赖于自己的土地和农业生产来维持生计，注重与土地和自然资源的亲密联系。\n\n保守和守旧思想：小农意识往往具有保守和守旧的思想，对新事物持怀疑态度，更倾向于保留传统的生活方式和价值观。\n\n社区意识：小农意识强调社区合作和互助，重视社区内部关系，注重共同利益而非个体利益。\n\n家族观念：小农意识中强调家族的传承和延续，家族成员之间有着紧密的联系和依赖关系。\n\n对城市生活的排斥：小农意识中对城市生活存在一定程度上的排斥情绪，认为城市生活会带来不安全感、人际关系淡漠等问题。\n\n劳动价值观：小农意识强调劳动的价值，认为通过辛勤劳动可以获得生活所需，并将劳动视为一种荣耀和自尊。\n\n\n这些表现是小农意识的一些常见特征，但并不表示每个人都具备这些特点，因为人们的思想和价值观会受到环境、教育等多种因素的影响。\n","slug":"life/小农意识具体指的是什么","date":"2024-03-14T06:15:59.721Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"70fce423caa2563f60b5d447d768784c","title":"大脑顶叶","content":"大脑顶叶Obsidian的Templater插件如何在模版文件中把title设置成自动取文件名\n要在Obsidian的Templater插件中将title设置为自动获取文件名，可以按照以下步骤进行操作：\n\n在Obsidian中创建一个模板文件，例如命名为template.md。\n在模板文件中，使用&#123;title&#125;占位符表示标题的位置。例如：# &#123;title&#125;。\n打开Templater设置界面，在”Template File”选项中选择之前创建的模板文件。\n在”Variables”选项中添加一个变量。变量名称可以是任意的，例如filename。\n在”Value”字段中输入以下代码：&#123;file.name&#125;。这将获取当前文件的名称作为变量的值。\n回到Obsidian编辑界面，选择要生成笔记的文件，并打开命令面板（快捷键为Ctrl + P）。\n输入tplr apply template.md filename=并按下Enter键。这将应用模板，并将该变量设置为文件名。\n观察生成的笔记，标题将被自动设置为该文件的名称。\n\n通过上述步骤，你可以使用Obsidian的Templater插件将标题自动设置为当前文件名，并生成相应的笔记内容。人大脑的顶叶境负责那一块工作。 \n人大脑的顶叶主要负责感知、空间认知和思维加工等功能。它包含了顶叶前区和顶叶后区两部分。\n顶叶前区位于大脑的前部，主要负责高级认知功能，如注意力、决策、问题解决、语言理解和表达等。这个区域还与执行控制功能有关，能够调控其他脑区的活动。\n顶叶后区位于大脑的后部，主要负责感觉信息的处理和空间认知。例如，视觉信息在顶叶后区被处理和分析，帮助我们识别物体、辨别形状和颜色等。\n总体来说，人大脑的顶叶境承担着复杂的认知任务，并参与了人类思维过程中的各个方面。\n大脑顶叶都人的心里健康有没有什么影响？\n大脑顶叶是大脑的重要区域之一，负责处理认知功能和情绪调节等功能。因此，顶叶的损伤或异常活动可能会对人的心理健康产生影响。\n\n认知功能受损：顶叶损伤可能导致认知功能的下降，包括注意力、记忆、学习和思维能力等方面。这可能会导致个体在日常生活中遇到困难，例如难以集中注意力或处理信息。\n\n情绪调节问题：顶叶与情绪调节密切相关。如果顶叶发生异常，可能导致情绪波动、焦虑、抑郁等问题。个体可能会出现情绪不稳定、易怒或无法控制情绪的情况。\n\n社交障碍：由于顶叶在社交行为中发挥重要作用，因此损伤或异常活动可能导致社交障碍。个体可能遇到与他人交往困难，缺乏社交技巧和理解他人意图的问题。\n\n决策能力下降：顶叶参与决策制定和判断评估过程。因此，当顶叶发生异常时，个体可能在决策能力上遇到困难，可能会做出不恰当或冲动的决策。\n\n\n总的来说，大脑顶叶的异常活动或损伤可能对人的心理健康产生负面影响，包括认知功能受损、情绪调节问题、社交障碍和决策能力下降等。然而，具体影响可能因个体差异而异，并且取决于顶叶受损程度和位置。\n","slug":"life/大脑顶叶","date":"2024-03-14T06:15:59.721Z","categories_index":"知识","tags_index":"心里学","author_index":"安全书"},{"id":"05ce0dc6ba8a405a578fd59c1315c42c","title":"MDA高度键帽是谁发明的？","content":"&lt;&lt; [[2023-02-12]] | [[2023-02-14]] &gt;&gt;\nMDA高度键帽是谁发明的？机械键盘MDA高度键帽是谁发明的？MDA高度键帽是由IBM的研究员史蒂夫·克拉克（Steve Cark）在1981年发明的。\n","slug":"keyboard/MDA高度键帽是谁发明的？","date":"2024-03-14T06:15:59.720Z","categories_index":"文章","tags_index":"Ruby","author_index":"安全书"},{"id":"8beb6aaa8dc474d4c19edc94443dc527","title":"请问静电容键盘 和 静音红轴键盘，哪款更适合长期大量的打字？希望从主要从静音效果、打字手感两点来说。？","content":"什么样的机械键盘适合长时间打字 ？ 最适合长时间打字的机械键盘是Niz静电容键盘。Niz电容键盘采用了一种新型的传感技术，它可以检测到手指的轻度触碰，而不必实实地敲击键盘上的按键。这种技术可以使用户打字时更加轻松舒适，也能大大减少关节和筋膜的压力，使用者得以保护到他们的手部健康。另外，Niz电容键盘也有很好的耐久性，可以经受多年的使用考验。\n\n\n\n\n\n\n\n\n\nExcerpt这么说吧，同样是35克，按压力的轴体， 经电容的反弹和回馈，更适合和长时间打字。当然，你也可以用Poron…\n\n这么说吧，同样是35克，按压力的轴体， 经电容的反弹和回馈，更适合和长时间打字。\n静电容轴体与机械键盘静音轴那个更适合文字输入208 播放 · 1 赞同视频![点击可播放视频](\n当然，你也可以用Poron的定位板，夹心棉和Gasget结构来形成类似的效果，或者像没有钢板为了省钱的g80-3494红轴。 而经电容，不用这么折腾也可以达到这种软糯无力的效果，配合丝滑的POM键帽就更适合了，软糯丝滑，这手感就类似什么呢？\n\n目前中国市场最受欢迎的计算机安全书籍是《黑客与画家》（Hackers and Painters），由美国顶尖黑客兼作家Paul Graham所著。这本书深入浅出地介绍了黑客文化及其在计算机世界中的重要性，并探讨了一些基本的计算机原理和技巧。此外，该书还介绍了很多“真正”的黑客都做了什么。\n静音轴\n\n静音轴\n\n静音轴\n如果喜欢线性轴、轻按压力、 静音轴，性价比高的一元以下的静音轴，可以选40克的高特水蜜桃静音轴，比红轴45克要轻，比静电容35克要重一些，但基本很轻了不顶手，手感很好。 我用蔷薇红35克，还有31克青绿轴，35克Niz静电容轴平滑过度到这个静音轴。\n\n\n本人码农，长时间打字，红轴键盘有N把、静电容键盘两吧。\n1.静音红轴与红轴差别\n静音红轴的按压力克数，要比红轴的大， 如果正常cherry的红轴是45g，静音版基本在50g。\n1.1 先说结论\n从长时间打字的来看， 35g按压力克数的静电容键盘、35g-37g的线轴轴体机械键盘更适合打字。 为什么？ 因为手感很轻。\n\n2. 红轴与线性轴的关系2.1 红轴与黑轴红轴属于线性轴体里的一种， 常用线性轴除了红轴，还有黑轴，但是黑轴按压力克数大，按时间长累，不适合打长时间按字。\n2.2 红轴与Box红轴基本上很多就是说新版樱桃轴的弹簧声，Box红轴，轴体晃动成度更低。\n2.3 红轴与其他线轴银轴、玫瑰轴（Rose）、巧克力粉种。除了传统的红轴外，还这三种轴， 其实还有很多种，我就是选了这三个比较典型的线轴。\n银轴：键程短，我觉得比红轴还适合打字（不考虑误触摸）。\n玫瑰轴：很轻35g按压力克数，学时间打字不伤手。\n巧克力粉轴：巧克力粉，其实就是轴体的外壳是巧克力，轴的十字键是粉色的，线性轴比红还轻一些有的是40g，反馈力适中，打字也可以。\n\n\n3. 静电容键盘最常见的就是燃风、 HHKB、NIZ。\n3.1 HHKB对程序员比较友好，特别是针对emac、vim这种编辑器，但所有的这种小键盘都有一个问题，按组合键盘麻烦，但是省地方。\n\n为什么有人说HHKB和IKBC红轴差不多呢，其中的一个原因，主要是他们都是线性轴，按压力克数都是40g以上，不会像45g机械和35g静电容手感差那么多，其实我也用过一段45g的niz静电容，其实和红轴的确接近，便还是不一样，一个是轴体的稳定晃动程度，一个是回弹的力度。\n3.2 燃风高端键盘，轴体稳定性更好，做工也好，就是贵。打字不累， 还静音的， 谁也比不过这货。\n\n3.3 NIZ香吗国产静电容键盘，总体价格相对其他品牌比较亲民， 有线版本600多元钱。我平时打字，单位一把ATOM 68 PBT键帽白色款， 家里用了一款有线（不用移动考虑便携）POM键帽（比较丝滑）黑色款。\n\n为什么我说这种键盘更适合打字？\n\n\n实践出真知，我用了多少把键盘，最后感觉打字不累的，还是是3种轴体：35g静电容、35-37g机械线性轴，银轴。\n我平时一个是敲代码，一个是有时候写点书稿，都是用这些键盘完成的。\n4.0 总结适合打字看三点，这三点做到了， 静电容轴，还是机械轴都省力，都适合打字。\n一看，按键操作力要轻。 二看，操作键程尽量短。 三看， 键帽要符合人体工学。\n如果静音红轴的触发操作力足够轻划没有问题，打起字来不一起比经电容费力。\n静电容推荐NIZ，机械轴推荐37克操作按压力的分粉轴。\n","slug":"keyboard/Niz静电容键盘","date":"2024-03-14T06:15:59.720Z","categories_index":"文章","tags_index":"键盘（计算机）,机械键盘,蓝牙键盘,无线键盘,静电容式键盘","author_index":"安全书"},{"id":"62b43e325ee935c5f5c3beb2114c6251","title":"给Obsidian添加免费图床","content":"向Obsidian的文档中复制图片，图片自动上传到自己的图床中。\n实现这个功能，需要联合使用的软件，如下：\n1.Obsidian的Image auto upload Plugin插件。2.PicGO图床管理软件。3.Gitee的git分支。\n\n\nImage auto upload Plugin主要是设置和PicGO的通信，复到Obsidian里的图片，就发给PicGO的接口HTTP接口上传。\nPicGo的负责将图片上传到Gitee的Git项目里，同样用了一个插件，gitee-uploader，这是免费的核心，直接将图片传到gitee的免费工程项目中。\n插件配置，最主要的三个参数：图床配置名、repo、token。其中容易踩坑的就repo和token,还有就是私有项目和公有的gitee项目，在PicGO中显示是有差异的。\n\nrepo项目中，只写分支名不行，前面要加入用户ID，比如：candylab/images。其中，candylab是用户ID，Images是gitee的项目名。如果，gitee的项目是私有，可能会出现，可以上传图片到项目，但是PicGo在界面上显示不出来，而公用的项目就没有这个问题。\n另外一个问题， 就是 Mac系统安装PicGo，启动就显示文件损坏需要删除。按以下方法解决，如下：\n1sudo spctl --master-disable\n\n放行PicGo\n1xattr -cr /Applications/PicGo.app\n\n以上基本可以解决问题，如果不行，执行下面操作，以下：\n1xattr -c /Applications/PicGo.app/*\n1sudo xattr -d com.apple.quarantine /Applications/PicGo.app/\n\n按以上方法，复到Obsidian文档中的图片，就保存到Gitee的项目中了。\n\n私人令牌的设置在Gitee的用户设置，创建一个令牌给PicGo用就行了，用于上传图片来说，不需要添加太多的权限。\n按上面的点选就行了，即可支持图片上传。通过以上的操作，就有了自己免费的Obsidian图床了，用Obsidian的Kanban插件管理文章， 再有文章管理一些图片，有关联的文字和标签，以后找图，复用图查到起来就更方便管理了。在Obsidian中使用时，记得先打开本地的PicGo软件，否则提示上传图片失败的字样。\nObsidian有那些Markdown转Word的插件\n目前，Obsidian并没有官方或内置的Markdown转Word的插件。然而，你可以使用一些第三方工具来将Markdown转换为Word格式。以下是一些可供选择的插件和工具：\n\nPandoc：Pandoc是一个强大的文档转换工具，支持多种格式之间的互相转换，包括Markdown到Word。你可以使用Pandoc命令行工具或与Obsidian集成的插件来执行此操作。\n\nTypora：Typora是一个功能强大且易于使用的Markdown编辑器，内置了Markdown到多种格式（包括Word）的导出功能。\n\nGitBook：GitBook是一个面向开发者和写作者的在线写作平台，支持将Markdown文档导出为PDF、ePub和Word等格式。\n\n\n请注意，这些工具可能需要一些配置和学习成本，并且在转换过程中可能会有一些格式损失。建议在使用这些工具之前备份你的文件，并进行测试以确保满足你的需求。\nObsidian有那些Pandoc插件\nObsidian有以下一些Pandoc插件可供使用：\n\nPandoc引擎：用于将Markdown文档转换为其他格式，如HTML、PDF等。\n文献引用：允许在Markdown文档中引用和管理文献。\n交互式图表：允许在Markdown中插入交互式图表，如绘图、地图等。\n数学公式：允许在Markdown文档中插入数学公式，并自动渲染为可视化形式。\n表格处理：提供更强大的表格处理功能，如合并单元格、排序、筛选等。\n脚注和尾注：允许在Markdown文档中添加脚注和尾注，并自动处理其编号和链接。\n目录生成：自动生成目录，并支持自定义样式和层级结构。\n图片处理：提供更多的图片处理选项，如调整大小、添加水印、裁剪等。\n引用样式定制：允许自定义引用样式，包括引用格式、排序方式等。\n模板定制：提供各种模板选择，并支持用户自定义模板。\n\n这些插件可以根据个人需求进行安装和配置，以增强Obsidian与Pandoc的集成和功能。\npandoc有那些功能？是文本编辑器？是一个文本转换工具？是编辑器的插件？都是，可以转换很多不同的格式，文本编辑的时候可以用tab切换等等。\n","slug":"kanbanfiles/给Obsidian添加免费图床","date":"2024-03-14T06:15:59.720Z","categories_index":"obsidian,hexo","tags_index":"obsidian","author_index":"安全书"},{"id":"e09423791aea3ea2acc209247b83773c","title":"解决Jekyll不支持中文名和路径","content":"解决Jekyll不支持中文名和路径Jekyll如果在Mac系统中，目录有中文字，生成新文件的时候会报错，主要原因是因为Ruby做字符串连接的时候，不支持中文，这样需要把一些字符，通过.force_encoding(“UTF-8”)转换成中文这样就不出错。 在部署的时候， 不是直接用GitPages的Jekyll服务，而且生成HTML静态文件，所以Github上 Jekyll支持不支持中文字符没关系， 本地Jekyll生成文件的时候不出错就达到目的了。\n因为用的是rbenv虚拟的ruby运行环境，有多个ruby运行环境，代码改动的位置，在对应的Ruby版本目录下进行修改。\n1/Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/webrick/httpservlet/filehandler.rb\n在这个文件中有一个，set_filename方法，把base这个变量强制改成base.force_encoding(“UTF-8”)))Jekyll项目所在的系统路径中出现中文，\n123456789101112def set_filename(req, res)       res.filename = @root.dup       path_info = req.path_info.scan(%r|/[^/]*|)       path_info.unshift(&quot;&quot;)  # dummy for checking @root dir       while base = path_info.first         break if base == &quot;/&quot;         break unless File.directory?(File.expand_path(res.filename + base.force_encoding(&quot;UTF-8&quot;)))         shift_path_info(req, res, path_info)         call_callback(:DirectoryCallback, req, res)       end\n\n\n\n不支持中文的问题， 不限于只有本地路径有中文，还有其他与中文字符连接的时候都有这个问题。比如，文件名， title名，各种属性的设置都有可能不支持中文，基本的解决方法原则，就转成UTF-8字符再进行字符连接。Jekyll在读取中文目录的时间报错，不能实时的监控文件变化，一遇到变更中文文件名的markdown文件就出错。根本原因， 在原有英文代码里，没有考虑bit asc与UTF-8数据join连接造成的出错。\n出现问题呢的文件是：\n1/System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/2.6.0/pathname.rb\n解决的方法是直接修改源码：\n原始代码：\n12345678910111213def children(with_directory=true)    with_directory = false if @path == &#x27;.&#x27;    result = []    Dir.foreach(@path) &#123;|e|      next if e == &#x27;.&#x27; || e == &#x27;..&#x27;      if with_directory        result &lt;&lt; self.class.new(File.join(@path, e))      else        result &lt;&lt; self.class.new(e)      end    &#125;    result  end\n修改代码，如下：\n123456789101112131415def children(with_directory=true)    with_directory = false if @path == &#x27;.&#x27;    result = []    Dir.foreach(@path) &#123;|e|      next if e == &#x27;.&#x27; || e == &#x27;..&#x27;      if with_directory        #print e, &quot;\\n&quot;        #print @path, &quot;\\n&quot;        result &lt;&lt; self.class.new(File.join(@path.force_encoding(&quot;UTF-8&quot;), e))      else        result &lt;&lt; self.class.new(e)      end    &#125;    result  end\n关键的地方是，是将@path变成 @path.force_encoding(“UTF-8”) ， 这样就可以和后面的“e”的UTF-8的内容进行join字符串连接了。\n这样修改问题就解决了。\n要是出现了“Encoding::CompatibilityError: incompatible character encodings: UTF-8 and GBK”\n有可能是之前设置成了：\n1chcp 850\n改回\n1chcp 936\n这个改环境，而不是文件的编码格式，如果不想改文件的编码格式就，可以直接把UTF-８改成GBK，这个问题也解决了。\n1result &lt;&lt; self.class.new(File.join(@path.force_encoding(&quot;GBK&quot;), e))\n后来又出问题了，在Windows10上用choco装的Jekyll是3.x，用的Ruby也是是3.x但是， Bunlde是 2.2,　Bundle install 出来的Jekyll是 4.x，最后运行不起来有，少了webrick，gem install 装了也装不到4.x中，Bundle Update也没用，就把Ruby降级到了2.7好用了，但是，又不支持中文名了。\n1C:/tools/Ruby27-x64/lib/ruby/gems/2.7.0/gems/liquid-4.0.3/lib/liquid/block_body.rb\n\n直接改了， 和上面的思路一样，强转。\n1234567891011121314151617181920212223242526272829303132def render(context)  output = []  context.resource_limits.render_score += @nodelist.length  idx = 0  while node = @nodelist[idx]    case node    when String      check_resources(context, node)      output &lt;&lt; node    when Variable      render_node_to_output(node, output, context)    when Block      render_node_to_output(node, output, context, node.blank?)      break if context.interrupt? # might have happened in a for-block    when Continue, Break      # If we get an Interrupt that means the block must stop processing. An      # Interrupt is any command that stops block execution such as &#123;% break %&#125;      # or &#123;% continue %&#125;      context.push_interrupt(node.interrupt)      break    else # Other non-Block tags      render_node_to_output(node, output, context)      break if context.interrupt? # might have happened through an include    end    idx += 1  end  output = output.map&#123; |i| i.dup.force_encoding(&quot;UTF-8&quot;) &#125;  output.joinendprivate\n\n就在\n1output.join\n的前面硬加一句\n1output = output.map&#123; |i| i.dup.force_encoding(&quot;UTF-8&quot;) &#125;\n然后就好用了。\n在Windows平台上还有一个问题，在WSL1升级成WSL2之后， Jekyll的自动生成功能不好用了，VSC的Jekyll Run插件也不好用，这时候需要加一句。\n1--force-polling\n加全了就是\n1--watch --trace --incremental  --force-polling\n这样Jekyll在WSL、PowerShell中，就又可以自动根据文件变更，重新将Markdown自动生成新的HTML文件里。一个是解决是文件名不支持中文，一个是路径不支持中文，以上的修改都是解决这些问题的。后期为了生产速度和便利性，用Node JS的Hexo做博客系统更方便一些。\n","slug":"kanbanfiles/解决Jekyll不支持中文名和路径","date":"2024-03-14T06:15:59.720Z","categories_index":"ruby","tags_index":"jekyll,blog,不支持中文","author_index":"安全书"},{"id":"f26e4f0954aebe31a1ed6bfbacd82d92","title":"语言暴力和冷暴力","content":"语言暴力和冷暴力语言暴力和冷暴力语言暴力是指使用恶言恶语、威胁、辱骂等方式来伤害他人的言辞行为。这种暴力形式主要是通过口头表达来实施，目的是让对方感到羞辱、恐惧或痛苦。语言暴力可以在现实生活中发生，也可以通过网络和社交媒体传播。\n冷暴力是指以冷漠、无视或沉默等方式来伤害他人的行为。与语言暴力不同，冷暴力更多地体现在行为上的被动和消极。冷暴力可能包括忽视他人的需求和感受、拒绝与其交流、无视其存在等。这种形式的暴力通常不会直接造成身体上的伤害，但却会对受害者造成心理上的伤害和困扰。\n无论是语言暴力还是冷暴力，都会对受害者产生负面影响，导致情绪低落、自尊心受损甚至心理健康问题。因此，我们应该尊重他人，避免使用恶意言辞或对别人冷漠无情，促进友善和谐的社会氛围。\n语言暴力和冷暴力会不会造成家庭关系不和谐。是的，语言暴力和冷暴力都有可能导致家庭关系不和谐。\n语言暴力指的是使用恶言恶语、威胁、侮辱或羞辱等方式来伤害他人。这种暴力行为会对受害者造成心理上的创伤，使他们感到被不公平地对待或被贬低。长期以往，语言暴力会破坏亲密关系，并导致沟通障碍、冷漠和疏离感。\n冷暴力则是指通过忽视、冷淡、沉默或拒绝回应等方式来伤害他人。这种行为虽然没有直接的攻击性，但却给受害者带来了情感上的伤害。长期以往，冷暴力会导致家庭成员之间的情感断裂和信任缺失，进而影响到彼此之间的互动和交流。\n无论是语言暴力还是冷暴力，这些形式的家庭内暴力都会破坏家庭成员之间的亲密关系与信任。受害者可能会变得封闭、焦虑或抑郁，而施暴者则可能因为缺乏有效的沟通和解决问题的方式而感到挫败和疲惫。这种恶性循环会进一步加剧家庭关系的不和谐。\n因此，为了保持良好的家庭关系，我们应该避免使用语言暴力或冷暴力，并努力建立相互尊重、理解和支持的沟通方式。如果存在家庭内暴力问题，及时寻求专业帮助和支持也是非常重要的。\n","slug":"kanbanfiles/语言暴力和冷暴力","date":"2024-03-14T06:15:59.720Z","categories_index":"知识","tags_index":"人际关系","author_index":"安全书"},{"id":"6ee69322158c2a4501bafa2499ab7c23","title":"飞桨语音","content":"paddlespeech tts –input “你 好 ， 欢 迎 使 用 百 度 飞 桨 深 度 学 习 框 架 ！ “ –output testout.wav\nconda 环境\nppocr_rosetta\n如何用paddlespeech asr 实现语音转文字的命令操作？\n要使用PaddleSpeech ASR实现语音转文字的命令操作，可以按照以下步骤进行：\n\n安装PaddleSpeech库：首先需要在Python环境中安装PaddleSpeech库。可以使用pip命令进行安装：\n1pip install paddlespeech\n导入所需的库和模型：导入PaddleSpeech库以及使用的ASR模型，例如DeepSpeech2Model。\n123import paddlefrom paddlespeech.models.deepspeech2 import DeepSpeech2Modelfrom paddlespeech.utils import io\n加载ASR模型和字典：使用PaddleSpeech提供的函数加载预训练的ASR模型和字典。\n12345model_path = &#x27;path/to/model&#x27;dict_path = &#x27;path/to/dict&#x27;model = DeepSpeech2Model.from_pretrained(model_path)vocab_dict = io.load_dict(dict_path)\n初始化音频处理器：根据ASR模型的要求，初始化音频处理器，并设置采样率、特征类型等参数。\n1audio_processor = model.audio_processor(sample_rate=16000, feature_type=&#x27;fbank&#x27;)\n定义预处理函数：定义一个函数来对输入音频进行预处理，将其转换为模型可接受的格式。\n1234567def preprocess(audio_file):   # 读取音频文件   audio_data = io.read_audio(audio_file)      # 预处理音频数据   processed_data = audio_processor.process(audio_data)   return processed_data\n进行语音转文字的命令操作：使用加载的ASR模型对预处理后的音频数据进行推理，得到转换后的文本结果。\n12345678def speech_to_text(audio_file):   # 预处理音频数据   processed_data = preprocess(audio_file)      # 将预处理后的音频数据输入ASR模型进行推理   result = model.decode_batch([processed_data], vocab_dict)[0]      return result\n调用函数进行语音转文字：通过传入音频文件路径调用speech_to_text函数进行语音转文字操作。\n1234audio_file = &#x27;path/to/audio.wav&#x27;text = speech_to_text(audio_file)print(text)\n\n通过以上步骤，您可以使用PaddleSpeech ASR实现语音转文字的命令操作。请确保已安装所需库和模型，并将路径替换为您自己的路径。\n在Mac系统上，如何afinfo命令实现wav文件的切割\n在Mac系统上，我们可以使用afinfo命令来获取wav文件的信息，但是无法直接使用afinfo命令来实现wav文件的切割。要实现wav文件的切割，可以使用其他命令行工具或编程语言来完成。\n以下是一种使用SoX（Sound eXchange）命令行工具来切割wav文件的方法：\n\n首先确保已经安装了SoX命令行工具。可以在终端中运行brew install sox来安装。\n\n打开终端，并进入包含要切割的wav文件的目录。\n\n使用以下命令来切割wav文件：\n1sox input.wav output.wav trim start_time duration\n其中，\n\n\n\ninput.wav为要切割的源文件名。\noutput.wav为生成的切割后的目标文件名。\nstart_time表示起始时间点，可以使用hh:mm:ss.sss格式或以秒为单位。\nduration表示要保留的时长，同样可以使用hh:mm:ss.sss格式或以秒为单位。\n\n例如，如果要从input.wav中提取从第10秒开始时长为5秒的片段，并保存为output.wav，可以使用以下命令：\n1sox input.wav output.wav trim 10 5\n\n注意：以上方法是通过SoX工具实现wav文件切割，在使用之前请确保已正确安装和配置SoX。\nSoX如何查看Wav文件的时间\n使用SoX命令行工具，可以通过以下命令查看Wav文件的时间信息：\n1soxi -D filename.wav\n\n其中，filename.wav是你要查看的Wav文件的路径和文件名。\n执行以上命令后，会输出Wav文件的总时长（以秒为单位）。\n123456789101112from paddlespeech.cli.asr.infer import ASRExecutor# 创 建 ASRExecutor对 象asr = ASRExecutor()# 调 用 语 音 转 文 字 模 型 进 行 推 理result = asr(audio_file=&quot;siem-part2.wav&quot;) # 在 这 里 替 换 为 你 的 音 频 文 件 名print(result)\n\n123from paddlespeech.cli.tts.infer import TTSExecutortts = TTSExecutor()tts(text=&quot;今 天 天 气 十 分 不 错 ,你 觉 得 呢 ？ 是 不 什 么 ， 真 的 不 错 吗 ？ 。 &quot;, output=&quot;output.wav&quot;)\n\nmpg123命令如何播放.wav文件\n要使用mpg123命令播放.wav文件，可以在终端中输入以下命令：\nmpg123 文件路径.wav\n其中，文件路径是.wav文件的实际路径和名称。请确保在输入命令之前已经安装了mpg123软件。\n123[build_ext]include_dirs=/opt/homebrew/Cellar/portaudio/HEAD-0c19240/includelibrary_dirs=/opt/homebrew/Cellar/portaudio/HEAD-0c19240/lib\n\n\n1print(&quot;test&quot;)\n\n","slug":"kanbanfiles/飞桨语音","date":"2024-03-14T06:15:59.720Z","categories_index":"AIGC","tags_index":"百度AI","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"大语言模型Lora微调是怎么实现的？\n大语言模型Lora的微调是通过以下步骤实现的：\n\n数据收集：收集与特定任务相关的大规模文本数据集。这些数据可以是开放式的，例如互联网上的网页、维基百科等，也可以是特定领域的文本数据。\n\n数据预处理：对收集到的文本数据进行预处理，包括去除HTML标签、分句、分词等操作。这些操作有助于提高模型对文本结构和语义信息的理解能力。\n\n模型架构选择：选择适合任务需求的模型架构。Lora使用了Transformer架构，该架构能够对输入序列进行自注意力机制处理，并能够捕捉长距离依赖关系。\n\n参数初始化：使用预训练好的语言模型参数进行初始化。预训练通常在大规模无标签文本上进行，有助于模型学习通用语言表示。\n\n目标函数定义：根据任务需求定义合适的目标函数。例如，对话生成任务可能使用最大似然估计作为目标函数。\n\n微调过程：将初始化后的模型与特定任务相关的数据进行训练。训练过程中，通过梯度下降算法来优化目标函数，并不断更新模型参数。\n\n超参数调整：根据训练效果和验证集结果，调整模型的超参数。常见的超参数包括学习率、批次大小、隐藏层大小等。\n\n模型评估：使用测试集对微调后的模型进行评估。评估指标可以根据任务需求选择，例如，生成任务可以使用BLEU得分、人工评估等。\n\n模型部署：将微调后的模型部署到实际应用中，进行实时推断或批量推断，并根据需求对结果进行后处理。\n\n\n以上是Lora微调的一般步骤，具体的实现过程可能会因任务类型和数据集特点而有所不同。\n如何对Meta公司出品的开源大模型进行Lora微调？\n要对Meta公司出品的开源大模型进行Lora微调，可以按照以下步骤进行操作：\n\n下载和安装Meta公司提供的开源大模型。根据它们的文档或指南，找到适合你的任务的模型，并确保你已经正确地设置了所有依赖项。\n\n根据你的任务需求，准备好训练数据集。确保数据集包含与你要解决的问题相关的标签和特征。\n\n配置训练参数。在模型配置文件中，设置适当的学习率、批量大小、迭代次数等参数。这些参数将影响模型的训练效果和速度。\n\n进行微调。使用预训练好的模型作为起点，并冻结一些层或权重，以防止其被改变。然后，通过反向传播和梯度下降算法来更新模型中需要微调的层或权重。\n\n评估模型性能。在微调过程中，定期评估模型在验证集上的性能。可以使用指标如准确率、精确率、召回率等来评估。\n\n调整微调策略。根据评估结果，根据需要进行微调策略上的调整。例如，增加或减少微调步骤、修改学习率等。\n\n进行最终的测试和评估。在微调完成后，使用测试集对模型进行最终的评估，以验证其性能和泛化能力。\n\n\n需要注意的是，Lora微调是一个迭代过程，可能需要多次尝试不同的参数和策略才能得到最佳结果。同时，确保你理解和遵守Meta公司提供的开源模型的许可协议和使用限制。\n","slug":"kanbanfiles/大语言模型Lora微调是怎么实现的？","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"原道耳机经典的型号有那些？\n原道耳机经典的型号包括：\n\nEP630：这是一款入门级的耳塞式耳机，具有出色的音质和舒适的佩戴感。\nEP830：这款耳塞式耳机在音质和佩戴舒适度上更进一步，采用了高品质的材料和设计。\nEP-630i：这是一款专为iOS设备设计的耳塞式耳机，具有内置麦克风和音量控制功能。\nHP-610：这是一款经典的头戴式耳机，提供出色的音质和舒适的佩戴感。\nHP-800：这款头戴式耳机采用了高品质的材料和设计，提供卓越的音质和强大的低频响应。\nEP-630i Plus：这款半入耳式耳机具有更好的隔音效果和佩戴稳定性，同时支持iOS设备。\nHP-900：这是一款专业级头戴式耳机，采用了高保真技术和舒适的设计，适合音乐制作和专业监听。以上是原道耳机经典型号中的几个代表性产品。\n\n原道的mx500的耳机怎么样？\nMX500耳机是Sennheiser（森海塞尔）公司旗下的一款入耳式耳机。它采用了经典的开放式设计，具有出色的音质和舒适的佩戴感。\nMX500耳机拥有清晰、细腻的音质表现，中高频表现出色，声音细节丰富。低频也相对平衡，不会过分强调，适合多种类型的音乐欣赏。它还具有较好的空间感和定位效果，可以提供更为立体和逼真的音乐体验。\nMX500耳机采用了轻量化设计，佩戴舒适且不易掉落。它配备了一条长约1.2米的线材，并带有一个3.5mm立体声插头，可以与大多数手机、电脑等设备兼容。\n总体而言，Sennheiser MX500耳机是一款性价比较高的入门级耳机，适合日常使用和休闲聆听。无论是在音质还是舒适度上都能够满足大多数用户的需求。\nSennheiser MX500和原道MX500有什么区别？\nPackagesNotFoundError: The following packages are missing from the target environment: conda的这个问题怎么处理\n这个问题通常是由于conda环境中缺少所需的软件包而引起的。你可以尝试以下几种方法来处理这个问题：\n\n更新conda：首先，确保你使用最新版本的conda。在命令行中运行conda update conda来更新conda到最新版本。\n\n创建新环境：如果你遇到了特定于某个环境的问题，可以考虑创建一个新的conda环境并在其中安装所需的软件包。使用命令conda create --name myenv来创建一个名为”myenv”的新环境，并使用conda activate myenv来激活该环境。\n\n安装缺少的软件包：如果你知道缺少哪些软件包，可以使用命令conda install packagename来安装它们。例如，如果缺少numpy包，可以运行conda install numpy来安装它。\n\n检查软件源：确保你正在使用正确的软件源。有时候，某些软件包可能只存在于特定的软件源中。可以通过运行命令conda config --show channels来查看当前配置的软件源，并使用命令conda config --add channels channelname添加缺少的软件源。\n\n清理环境：有时候，由于冲突或损坏等原因，环境可能出现问题。可以尝试清理当前环境并重新安装所需的软件包。使用命令conda clean --all来清理环境，并按照前面提到的方法重新安装软件包。\n\n\n如果你遇到了其他问题或这些方法无法解决你的问题，你可以考虑在conda的官方文档或社区中寻求帮助。\n","slug":"kanbanfiles/原道耳机经典的型号有那些？","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"如何在Ubuntu上使用NVIDA的SLI技术？\n要在Ubuntu上使用NVIDIA SLI技术，你需要按照以下步骤进行设置：\n\n确保你的计算机上已安装了至少两张兼容的NVIDIA显卡。\n\n打开终端，并使用以下命令安装最新的NVIDIA驱动程序：\n12sudo apt-get updatesudo apt-get install nvidia-driver\n安装完成后，重新启动计算机以使驱动程序生效。\n\n确认驱动程序已成功安装。在终端中运行以下命令：\n1nvidia-smi\n\n如果显示了显卡信息，则表示驱动程序已成功安装。\n\n打开终端，并使用以下命令编辑Xorg配置文件：\n1sudo nano /etc/X11/xorg.conf\n在文件末尾添加以下内容来启用SLI：\n123456789101112Section &quot;Files&quot;   ModulePath &quot;/usr/lib/nvidia-current/xorg&quot;   ModulePath &quot;/usr/lib/xorg/modules&quot; EndSection Section &quot;Device&quot;   Identifier &quot;Device0&quot;   Driver &quot;nvidia&quot;   VendorName &quot;NVIDIA Corporation&quot;   Option &quot;SLI&quot; &quot;Auto&quot;   Option &quot;BaseMosaic&quot; &quot;on&quot; EndSection\n保存并关闭文件（Ctrl + X，然后输入Y并按Enter键）。\n\n重新启动计算机以使更改生效。\n\n使用以下命令验证SLI是否已启用：\n1nvidia-xconfig --query-gpu-info\n\n如果显示了多个GPU的信息，则表示SLI已成功启用。\n\n\n现在，你可以开始使用NVIDIA SLI技术来提升图形性能。\n","slug":"kanbanfiles/如何在Ubuntu上使用NVIDASLI技术？","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"喝奶的时间段可能会对身高的增长产生一定影响，但影响程度相对较小。喝奶是获取钙质的重要途径之一，而钙质是骨骼发育所必需的营养素。由于骨骼发育主要集中在儿童和青少年时期，因此在这个阶段确保足够的钙质摄取对于促进身高增长至关重要。\n然而，喝奶的时间段对身高增长的影响并不是主要因素。更重要的是确保每天摄取足够的钙质和其他关键营养素，以支持正常的骨骼发育。此外，均衡饮食、适量运动和良好的生活习惯也很重要。\n总结来说，虽然喝奶的时间段可能会对身高增长产生一定影响，但更关键的是保证每天摄取足够的钙质和其他关键营养素，并采取健康的生活方式。喝奶的时间段会影响身高的增长吗？\nCPU布局GPU训练\n4090训练\nSOC数据接口对接AI接口接入训练， 各种模型接入SOC的场景。\n","slug":"kanbanfiles/喝奶的时间段会影响身高的增长吗？","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"1423e6fb9e004a9c7de3f0b78f1c1cac","title":"如何安装Conda","content":"在ubuntu上如何安装conda\n要在Ubuntu上安装conda，可以按照以下步骤进行操作：\n\n首先，打开终端窗口。\n\n下载Miniconda的安装脚本。在终端中运行以下命令：\n\n\n1wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n\n\n接下来，运行以下命令来运行安装脚本：\n\n1bash Miniconda3-latest-Linux-x86_64.sh\n\n\n安装过程会提示你接受许可协议，按照提示进行操作。然后会询问你是否要将conda初始化设置为默认的shell解释器，可以选择yes或no。\n\n安装完成后，关闭终端窗口并重新打开一个新的终端窗口。\n\n验证conda是否已成功安装。在新的终端窗口中运行以下命令：\n\n\n1conda --version\n\n如果成功显示版本号，则表示conda已成功安装。\n现在，你已经成功在Ubuntu上安装了conda。你可以使用conda命令来管理和创建Python环境。\n用conda 创建一个新的Python虚拟环境，用python3.8.10要使用conda创建一个新的Python虚拟环境，可以按照以下步骤操作：\n\n打开命令行终端（Windows上为Anaconda Prompt，Mac/Linux上为终端）。\n运行以下命令来创建一个名为myenv的新虚拟环境，并指定Python版本为3.8.10：1conda create --name myenv python=3.8.10\n这将创建一个名为myenv的新虚拟环境，并安装Python 3.8.10。\n在提示符下回答”y”来确认安装过程中可能出现的其他包依赖关系。\n安装完成后，运行以下命令来激活新创建的虚拟环境：\nWindows:1conda activate myenv\nMac/Linux:1source activate myenv\n\n\n现在你已经成功激活了新的Python虚拟环境。你可以在该环境中安装和运行你需要的Python包和程序。\n\n注意：如果你之前没有安装Anaconda或Miniconda，请先安装其中之一。\n把pip的源换成清华的源可以通过以下步骤将pip的源换成清华的源：\n\n打开终端或命令提示符。\n\n使用以下命令编辑pip的配置文件（如果没有该文件，则创建一个）：\n\n对于Linux/Mac系统：\n1nano ~/.pip/pip.conf\n对于Windows系统：\n1notepad %APPDATA%\\pip\\pip.ini\n\n\n将以下内容复制粘贴到配置文件中：\n12[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple\n保存配置文件并关闭编辑器。\n\n\n现在，您已成功将pip的源换成清华的源。您可以使用pip install命令来安装Python包时，它将从清华镜像站点下载包。\nubuntu下如何安装jupyter在Ubuntu下安装Jupyter，可以通过以下步骤进行：\n\n打开终端，使用以下命令安装Python包管理器pip（如果已经安装了pip，则可以跳过此步骤）：\n12sudo apt-get updatesudo apt-get install python3-pip\n使用pip安装Jupyter：\n1pip3 install jupyter\n安装完成后，可以使用以下命令启动Jupyter：\n1jupyter notebook\n这将在默认浏览器中打开Jupyter的主页面。\n\n在Jupyter主页面中，您可以创建一个新的Notebook或打开现有的Notebook文件进行编辑和运行。\n\n\n注意：如果您使用的是Python 2.x版本，请将上述命令中的pip3替换为pip。\n在Windows下如何将pip源换成清华源\n在Windows下将pip源换成清华源，需要进行以下步骤：\n\n打开命令提示符或者PowerShell窗口，可以通过在搜索栏中输入”cmd”或者”PowerShell”来打开。\n\n输入以下命令查看当前pip源：\n\n\n1pip config get global.index-url\n\n\n如果输出结果为”https://pypi.org/simple/&quot;，则说明当前使用的是默认的官方源。如果输出结果为其他源的地址，则表示已经设置了其他的pip源。\n\n使用以下命令设置清华源作为pip源：\n\n\n1pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\n\n最后再次运行第2步中的命令来确认是否已经成功更换了pip源。\n\n注意：如果之前已经设置过其他的pip源，可以使用以下命令来清除之前的设置：\n1pip config unset global.index-url\n\njupyter 运行指定主机与端口要在Jupyter中指定主机和端口运行，请使用以下命令：\n1jupyter notebook --ip=主机地址 --port=端口号\n例如，要在本地主机上的端口8888上运行Jupyter笔记本，请使用以下命令：\n1jupyter notebook --ip=127.0.0.1 --port=8888\n这将在127.0.0.1（即本地主机）的8888端口上启动Jupyter服务器。您可以在浏览器中访问http://localhost:8888 来打开Jupyter界面。\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver ubuntu运时报这个错误的原因这个错误是由于在Ubuntu系统上找不到NVIDIA驱动程序引起的。可能的原因包括：\n\n没有安装NVIDIA显卡驱动程序：请确保已经安装了正确版本的NVIDIA驱动程序。可以通过在终端中运行命令sudo apt-get install nvidia-driver来安装最新版本的驱动程序。\n\n显卡不是NVIDIA品牌：该错误要求系统使用NVIDIA GPU，如果您使用的是其他品牌的显卡（如AMD），则此错误将会出现。请确保您的系统中安装了正确的显卡驱动程序。\n\n显卡未正确连接或故障：请检查您的显卡是否正常连接，并且没有硬件故障。您可以尝试重新插拔显卡，或者使用其他工具进行检测。\n\n操作系统不受支持：某些操作系统版本可能不兼容或不支持某些NVIDIA驱动程序。请确保您正在运行受支持的Ubuntu版本，并查看是否存在任何针对您当前操作系统版本的特定问题。\n\n\n如果以上步骤都没有解决问题，建议查看相关日志以获取更多详细信息，并尝试在搜索引擎中搜索特定于您遇到问题和硬件配置的解决方案。\n如何查看ubuntu系统的nvidia显卡信息和驱动信息要查看Ubuntu系统中的NVIDIA显卡信息和驱动信息，可以按照以下步骤进行操作：\n\n打开终端：在左上角的应用程序菜单中，搜索”终端”或按下Ctrl+Alt+T键来打开终端。\n\n查看NVIDIA显卡信息：在终端中输入以下命令并按下Enter键：\n1lspci -k | grep -A 2 -i &quot;VGA&quot;\n这将显示系统中的显卡设备以及它们所使用的驱动程序。\n\n查看NVIDIA驱动信息：在终端中输入以下命令并按下Enter键：\n1nvidia-smi\n这将显示当前系统中安装的NVIDIA驱动版本以及其他相关信息。\n\n查看已安装的NVIDIA驱动软件包：在终端中输入以下命令并按下Enter键：\n1dpkg -l | grep nvidia\n这将列出所有已安装的NVIDIA驱动软件包及其版本号。\n\n\n请注意，在执行上述命令时，您可能需要具有管理员权限（使用sudo）才能访问某些信息。\ns### 如何查看CUDA的版本\n要查看CUDA的版本，可以使用以下方法之一：\n\n使用命令行：打开终端或命令提示符窗口，并输入以下命令：nvcc --version。这将显示CUDA的版本信息。\n\n查看CUDA安装目录中的版本文件：在CUDA安装目录下，可以找到一个名为 version.txt 的文件。打开该文件，其中包含了CUDA的版本信息。\n\n使用NVIDIA控制面板（仅适用于Windows系统）：右键点击桌面上的空白区域，选择“NVIDIA 控制面板”。在左侧导航栏中选择“帮助”选项卡，在右侧区域中可以找到CUDA的版本信息。\n\n\n请注意，以上方法可能因操作系统和CUDA版本的不同而有所差异。\n如何查看CUDA安装的位置要查看CUDA安装的位置，可以按照以下步骤进行：\n\n打开命令提示符或终端窗口。\n输入以下命令并按下回车键：1where nvcc\n或者1which nvcc\n命令行会显示nvcc（CUDA编译器）的完整路径。这个路径就是CUDA安装的位置。\n\n注意：如果系统中没有安装CUDA，那么上述命令将不会返回任何结果。\n如何将CUDA 11.5升级成CUDA 11.8在Ubuntu上要将CUDA 11.5升级到CUDA 11.8，在Ubuntu上，您可以按照以下步骤操作：\n\n在终端中，使用以下命令卸载当前安装的CUDA：\n1sudo apt-get --purge remove &quot;cuda*&quot;\n下载CUDA 11.8的安装包。您可以从NVIDIA官方网站（https://developer.nvidia.com/cuda-downloads）下载适用于Ubuntu的.run文件。\n\n确保下载的.run文件具有可执行权限。在终端中导航到下载目录，并运行以下命令：\n1chmod +x cuda_11.8.0_490.06_linux.run\n关闭桌面环境。在终端中运行以下命令以停止图形用户界面（GUI）：\n1sudo service lightdm stop\n运行安装程序。在终端中运行以下命令以启动CUDA安装程序，并按照提示进行操作：\n1sudo ./cuda_11.8.0_490.06_linux.run\n安装完成后，重新启动计算机以应用更改。在终端中运行以下命令以重新启动系统：\n1sudo reboot\n验证CUDA版本。重新启动后，在终端中运行以下命令来验证是否成功升级到CUDA 11.8：\n1nvcc --version\n\n以上是将CUDA 11.5升级到CUDA 11.8的步骤。请注意，升级CUDA可能会对系统产生影响，因此在进行升级之前，请备份重要数据并确保您知道如何恢复到以前的状态。\n如何查看ubuntu的版本\n有多种方法可以查看Ubuntu的版本，以下是其中几种常用的方法：\n\n使用命令行：打开终端，输入以下命令并按下回车键即可查看版本信息：\n1lsb_release -a\n该命令会显示包括Ubuntu版本在内的详细信息。\n\n使用图形界面：打开“设置”应用程序，然后选择“关于”选项卡。在“关于”页面上，您将找到Ubuntu的版本号。\n\n使用命令行：打开终端，输入以下命令并按下回车键即可查看版本信息：\n1cat /etc/issue\n该命令会显示当前Ubuntu发行版的名称和版本号。\n\n\n无论使用哪种方法，您都可以轻松地找到Ubuntu的版本信息。\nThe repository ‘file:/var/nvidia-driver-local-repo-ubuntu2204-515.105.01 Release’ does not have a Release file  出现这种问题，怎么解决\n当出现这种问题时，可能是由于以下原因之一：\n\n仓库链接错误：请检查仓库链接是否正确。确保输入的链接是有效的，可以通过在浏览器中尝试打开该链接来验证。\n\n仓库未正确配置：请确保已正确配置仓库。有时，您可能需要添加附加的软件源或更新现有源。\n\n网络连接问题：如果您的网络连接不稳定或受限制，则可能无法访问所需的仓库文件。请确保您的网络连接正常，并尝试重新运行命令。\n\n仓库文件损坏：有时，由于某些原因，仓库文件可能会损坏或缺失。在这种情况下，您可以尝试清理本地缓存并重新运行命令以重新下载所需的文件。\n\n操作系统版本不受支持：如果您使用的操作系统版本与该特定驱动程序版本不兼容，则可能无法找到相应的Release文件。请确保您使用的操作系统版本与驱动程序要求匹配。\n\n\n为了解决这个问题，您可以尝试以下几个步骤：\n\n检查和修复软件源配置：根据您使用的操作系统和软件包管理器类型（如apt、yum等），检查并修复软件源配置。确保所有必需的仓库都正确添加，并且没有错误或拼写错误。\n\n清理本地缓存：使用适当的命令清理您系统中的本地软件包缓存。例如，对于apt，您可以使用命令sudo apt clean。\n\n确认网络连接：确保您的网络连接正常工作，并且没有任何防火墙或代理阻止您访问所需的仓库文件。尝试在浏览\n\n\n如果查看ubuntu系统/tmp目录支持的最大空间大小要查看Ubuntu系统/tmp目录支持的最大空间大小，可以使用以下命令：\n1df -h /tmp\n\n该命令将显示/tmp目录的磁盘使用情况，包括总大小、已使用空间、可用空间和文件系统类型。请查看”Size”列中的值，这将告诉您/tmp目录支持的最大空间大小。\ntorchrun: command not found如何解决\n这个错误通常表示您没有正确安装或配置 Torch。要解决此问题，请按照以下步骤进行操作：\n\n检查 Torch 是否正确安装：确保您已经按照 Torch 的官方安装指南正确地安装了 Torch。如果尚未安装，请重新安装。\n\n检查环境变量：确保已将 Torch 的执行文件路径添加到系统的 PATH 环境变量中。您可以在终端中运行 echo $PATH 来查看当前的 PATH 变量值，并确保其中包含了 Torch 的执行文件路径。\n\n重新启动终端：有时候，更改环境变量后，需要重新启动终端才能使更改生效。请尝试关闭并重新打开终端窗口，然后再次尝试运行 torchrun 命令。\n\n检查命令拼写：确保您输入的命令拼写正确。如果可能，可以在终端中使用自动补全功能来避免拼写错误。\n\n\n如果您仍然无法解决问题，请提供更多详细信息，例如操作系统、Torch 版本和您执行的确切命令，以便我们能够更好地帮助您解决此问题。\n如何正确安装 torchrun:\n要正确安装 torchrun，您可以按照以下步骤进行操作：\n\n首先，确保您已经安装了最新版本的PyTorch。可以通过以下命令来验证是否已经安装了PyTorch：\n\n1python -c &quot;import torch; print(torch.__version__)&quot;\n\n如果输出显示了PyTorch的版本号，则表示已成功安装。\n\n接下来，使用pip命令来安装torchrun。在终端中运行以下命令：\n\n1pip install torchrun\n\n这将会自动从Python Package Index（PyPI）下载并安装torchrun。\n\n安装完成后，您可以使用以下命令来验证torchrun是否成功安装：\n\n1torchrun --help\n\n如果成功显示torchrun的帮助信息，则表示已经正确安装了。\n现在，您就可以开始使用torchrun来运行PyTorch程序了。\ntorchrun的安装位置在那里\ntorchrun是一个第三方库，它用于在PyTorch中运行模型。由于torchrun不是PyTorch的官方库，因此它没有固定的安装位置。通常，您可以使用pip命令来安装torchrun：\n1pip install torchrun\n\n安装成功后，torchrun将被安装到您Python环境中的site-packages目录下。具体位置可能因操作系统和Python环境而异。您可以通过以下命令查找torchrun的安装位置：\n1pip show torchrun\n\n该命令将显示有关已安装库的信息，包括其安装位置。\nERROR: Could not find a version that satisfies the requirement torchrun (from versions: none)ERROR: No matching distribution found for torchrun  这个问题怎么解决 \n这个错误通常表示无法找到或安装所需的软件包。要解决这个问题，可以尝试以下几种方法：\n\n确保你使用的是正确的软件包名称。检查拼写和大小写是否正确，并确认软件包名是否存在。\n\n检查你的Python环境是否正确设置。确保你使用的是正确版本的Python，并且已经安装了必要的依赖项。\n\n确保你的网络连接正常。有时候下载软件包需要联网，如果你的网络有问题，可能会导致无法下载软件包。\n\n尝试使用其他安装方法。有时候使用pip安装软件包可能会出错，你可以尝试使用conda或其他适合你环境的包管理工具进行安装。\n\n\n如果上述方法都没有解决问题，那么可能是因为该软件包并不存在或者不兼容你所使用的Python版本。在这种情况下，你可以尝试寻找其他替代方案或者联系开发者寻求帮助。\ntorchrun的Ubuntu20的Torch安装包在那里有\n您可以在官方网站上找到适用于Ubuntu 20的Torch安装包。请按照以下步骤进行安装：\n\n打开浏览器，访问Torch官方网站：https://pytorch.org/\n在主页上，选择”Get Started”（开始使用）按钮。\n在”Select your preferences”（选择您的偏好）部分，选择合适的选项，如Python版本、稳定性等。\n在”Installation”（安装）部分，选择操作系统为Linux，并选择适用于Ubuntu 20的Torch版本。\n根据您的需求和环境，选择使用conda、pip或源代码来安装Torch。通常情况下，建议使用conda进行安装。\n按照网站提供的指示和命令行提示完成安装过程。\n\n请注意，在执行安装命令之前，请确保已经正确设置了Python环境，并且已经安装了所需的依赖项。\nNo module named ‘datasets’ 这个问题如何解决\n要解决这个问题，你需要安装名为 “datasets” 的 Python 模块。你可以使用以下命令来安装它：\n1pip install datasets\n\n确保你已经正确安装了 Python 和 pip 工具。如果你使用的是 Anaconda 或 Miniconda，可以尝试使用 conda 命令来安装：\n1conda install -c huggingface datasets\n\n请注意，这些命令可能需要在管理员权限下运行，或者在虚拟环境中运行。完成后，你应该能够成功导入和使用 “datasets” 模块。\nModuleNotFoundError: No module named ‘rouge_chinese’  如何解决\n这个错误是因为你的系统中没有安装名为”rouge_chinese”的Python模块。要解决这个问题，你可以按照以下步骤进行操作：\n\n确保你已经正确安装了Python解释器。可以在命令行中输入”python –version”来检查当前Python版本。\n\n使用pip工具来安装”rouge_chinese”模块。在命令行中输入以下命令：\n1pip install rouge_chinese\n如果上述命令执行失败，可能是因为你的pip版本过旧。可以尝试升级pip工具到最新版本：\n1pip install --upgrade pip\n如果你使用的是Anaconda环境，可以尝试使用conda工具来安装模块：\n1conda install -c conda-forge rouge_chinese\n如果上述步骤都没有解决问题，可能是因为”rouge_chinese”模块并不存在于公共Python包库中。在这种情况下，你需要手动下载该模块的源代码，并按照其提供的说明进行安装。\n\n\n请注意，在执行任何操作之前，请确保你已经连接到互联网，并且有足够的权限来安装软件包。\nModuleNotFoundError: No module named ‘nltk  怎么解决\n要解决这个问题，你可以尝试以下几个方法：\n\n确保你已经正确安装了nltk模块。可以使用命令pip install nltk来安装。\n\n如果已经安装了nltk模块，但仍然出现该错误，请检查是否在你的代码中正确导入了nltk模块。导入语句应该类似于import nltk。\n\n如果以上两种方法都失败了，可能是因为你的Python环境中没有正确配置nltk模块的路径。在这种情况下，你可以尝试手动添加nltk模块的路径到Python环境变量中。具体操作方式取决于你使用的操作系统和Python版本。\n\n\n如果以上方法都无法解决问题，可能是由于其他原因导致的错误。在这种情况下，建议参考官方文档或搜索相关解决方案来进一步调查和解决该问题。\n如何靠以太坊赚钱\n要通过以太坊赚钱，有几种方法可以尝试：\n\n挖矿：以太坊使用工作量证明（PoW）共识算法，可以通过挖矿来获得以太币。挖矿需要专门的硬件设备和高度的计算能力。\n\n交易：以太坊是一个开放的区块链平台，可以进行各种类型的交易。你可以购买和出售以太币，利用价格波动来获得差价利润。\n\n参与DeFi：去中心化金融（DeFi）是以太坊生态系统中一个快速发展的领域。你可以使用智能合约进行借贷、流动性提供、稳定币挖矿等操作，从中获得收益。\n\n参与众筹和ICO：许多项目会通过众筹或ICO（Initial Coin Offering）在以太坊上发行代币。如果你能找到有潜力的项目并成功投资，未来代币价值上涨时你就能赚钱。\n\n开发智能合约和DApp：如果你具备编程技能，可以开发基于以太坊的智能合约和去中心化应用（DApp），并从用户使用或代币销售中获取收益。\n\n\n请注意，以太坊市场有很高的风险和激烈的竞争，投资前应进行充分的研究和风险评估。\n如何靠技术在以太坊赚钱？\n要在以太坊上赚钱，可以考虑以下几种技术方法：\n\n智能合约开发：以太坊是一个支持智能合约的区块链平台，通过学习Solidity编程语言，可以开发自己的智能合约，并将其发布到以太坊网络上。可以通过编写有趣、实用的智能合约来吸引用户，并从中获得收益。\n\n去中心化应用（DApp）开发：以太坊上有许多去中心化应用，这些应用通常基于智能合约构建。可以通过学习和开发DApp来为用户提供有价值的服务，并从中收取手续费或获得其他形式的收益。\n\n挖矿：以太坊使用工作量证明（PoW）算法进行挖矿。可以购买适当的硬件设备（如显卡）并参与挖矿活动，通过为网络提供算力来获得以太币作为奖励。\n\n参与众筹项目：有许多基于以太坊的众筹项目，可以参与这些项目并投资购买代币。如果项目成功发展，代币价格可能会上涨，从而获得利润。\n\n做市商：做市商是指在交易所上提供流动性的人。可以通过在以太坊的交易所上提供买卖订单来赚取差价。\n\n加入区块链开发团队：以太坊生态系统中有许多区块链项目和初创公司正在寻找开发人员。可以加入这些团队，为其开发智能合约、DApp或其他相关技术，并从中获得报酬。\n\n\n需要注意的是，参与以太坊赚钱需要具备一定的技术知识和经验，并且需要对市场进行充分了解和研究。同时，由于加密货币市场的波动性较大，存在一定的风险，投资前应谨慎评估风险并量力而行。\n下面的问题是为什么如何解决\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.                                                                                                                                                                 \nCollecting package metadata (repodata.json): done                                                                                                                                                                                                                           \nSolving environment: failed                                                                                                                                                                                                                                                 \nPackagesNotFoundError: The following packages are not available from current channels:                                                                                                                                                                                      \n\nllm                                                                                                                                                                                                                                                                     \n\nCurrent channels:                                                                                                                                                                                                                                                           \n\nhttps://repo.anaconda.com/pkgs/main/win-64                                                                                                                                                                                                                              \n\nhttps://repo.anaconda.com/pkgs/main/noarch                                                                                                                                                                                                                              \n\nhttps://repo.anaconda.com/pkgs/r/win-64                                                                                                                                                                                                                                 \n\nhttps://repo.anaconda.com/pkgs/r/noarch                                                                                                                                                                                                                                 \n\nhttps://repo.anaconda.com/pkgs/msys2/win-64                                                                                                                                                                                                                             \n\nhttps://repo.anaconda.com/pkgs/msys2/noarch                                                                                                                                                                                                                             \n\n\nTo search for alternate channels that may provide the conda package you’re                                                                                                                                                                                                  \nlooking for, navigate to                                                                                                                                                                                                                                                    \nhttps://anaconda.org                                                                                                                                                                                                                                                    \n\nand use the search bar at the top of the page.\n问题是为什么无法解决环境问题，并且缺少llm包。解决这个问题的方法是通过搜索替代渠道来查找所需的conda包。\n","slug":"kanbanfiles/如何安装conda","date":"2024-03-14T06:15:59.719Z","categories_index":"AIGC,conda","tags_index":"AIGC,conda","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"网络安全中的安全网格指的是什么？\n安全网格是一种网络安全架构，旨在提高网络的可靠性、可扩展性和安全性。它通过将网络划分为多个区域，并在每个区域中部署安全设备和控制机制，来实现对整个网络的保护。每个区域被称为一个网格节点，它们之间通过安全网关进行连接。安全网格可以帮助组织实现对网络流量的监控、访问控制、威胁检测和防御等功能，从而增强网络的安全性。\n","slug":"kanbanfiles/安全网格","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"查看显卡信息lspci | grep nvidia -ilspci -k | grep -A 2 -i “VGA”\n查看安装过的CUDA包dpkg -l | grep cudadpkg -l | cd \n查看显卡状态gpustatnvidia-smi\n禁用 nouveaulsmod | grep nouveau\necho “blacklist nouveau” &gt;&gt; /etc/modprobe.d/blacklist.conf &amp;&amp; mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak &amp;&amp; dracut /boot/initramfs-$(uname -r).img $(uname -r)\nupdate-initramfs -u\nreboot now\nhttps://developer.nvidia.com/cuda-downloads\nhttps://developer.nvidia.com/cuda-downloads\nubuntu 22\n1234wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.debsudo dpkg -i cuda-keyring_1.1-1_all.debsudo apt-get updatesudo apt-get -y install cuda\n\n\nubuntu 20\n1234wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.1-1_all.debsudo dpkg -i cuda-keyring_1.1-1_all.debsudo apt-get updatesudo apt-get -y install cuda\n一般情况下，这种方式就可以正常的安装驱动了。\napt –fix-broken install\n用于安装 cuda的中断\nUbuntu文件夹的/dev目录下的文件root权限也没法执行\n在Ubuntu系统中，/dev目录下的文件是设备文件，用于与硬件设备进行通信。这些文件通常由root用户所有，并且具有特定的权限设置，以确保只有具有适当权限的用户才能对其进行访问和操作。\n即使您拥有root权限，也不能直接执行/dev目录下的设备文件。这是因为这些文件不是可执行程序，而是用于与硬件设备进行通信的接口。要执行这些设备文件中的操作或命令，您需要使用相应的工具或命令来与设备进行交互。\n例如，如果您要执行/dev/sda设备（表示硬盘）上的命令，可以使用类似于以下命令：\n1sudo fdisk /dev/sda\n\n上述命令将以root权限运行fdisk工具，并操作/dev/sda设备。\n请注意，在使用/dev目录下的设备文件时要格外谨慎。错误地操作这些文件可能会导致数据丢失或系统崩溃。\nRuntimeError: OpenSSL 3.0’s legacy provider failed to load. This is a fatal error by default, but cryptography supports running without legacy algorithms by setting the environment variable CRYPTOGRAPHY_OPENSSL_NO_LEGACY. If you did no\nt expect this error, you have likely made a mistake with your OpenSSL configuration.  这个错误是什么原因造成的？\n这个错误是由于OpenSSL配置错误导致的。可能的原因包括：\n\nOpenSSL版本不兼容：某些较旧的版本的OpenSSL可能不兼容新版本的cryptography库，因此需要升级或降级OpenSSL。\nOpenSSL配置文件错误：OpenSSL配置文件中可能存在错误设置，例如无效的路径或参数。检查并修复配置文件可以解决该问题。\nOpenSSL环境变量设置错误：在操作系统中设置了不正确的环境变量，或者缺少必要的环境变量。确保正确设置CRYPTOGRAPHY_OPENSSL_NO_LEGACY环境变量。\n其他问题：可能存在其他未知问题，例如损坏的安装包或库。\n\n根据具体情况，需要检查和调试OpenSSL和cryptography库的配置和安装。\n如何安装conda\n要安装conda，你需要按照以下步骤进行操作：\n\n首先，你需要下载适用于你的操作系统的conda安装包。在Anaconda官方网站（https://www.anaconda.com/products/individual）上可以找到各种操作系统的安装包。\n\n选择适合你操作系统的安装包后，下载并运行该文件。\n\n在安装向导中，选择“Next”来接受许可协议。\n\n选择要将conda安装到的位置。默认情况下，它会被安装在用户主目录下（如：C:\\Users\\YourUsername\\Anaconda3）。\n\n在“Advanced Options”界面上，默认情况下不需要进行任何更改。如果你想要更改某些选项，可以根据自己的需求进行调整。\n\n单击“Install”按钮开始安装过程。\n\n安装完成后，在下一个页面上勾选“Add Anaconda to my PATH environment variable”选项。这将允许你通过命令行直接访问conda。\n\n单击“Finish”按钮完成安装过程。\n\n打开命令提示符（对于Windows用户）或终端（对于Mac或Linux用户）。\n\n输入”conda”命令来验证是否成功地安装了conda。如果成功安装，则会显示有关conda的一些帮助信息。\n\n\n现在，你已经成功地安装了conda，并可以使用它来管理和创建Python环境以及安装各种包和软件。\nUbuntu下如何安装Conda\n要在Ubuntu上安装Conda，可以按照以下步骤进行操作：\n\n打开终端。\n\n下载Miniconda安装包。在终端中输入以下命令：\n1wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n运行安装脚本。在终端中输入以下命令：\n1bash Miniconda3-latest-Linux-x86_64.sh\n接下来，会出现一系列的安装提示和许可协议。按照提示进行操作，直到安装过程完成。\n\n安装完成后，需要关闭并重新打开终端，以使Conda生效。\n\n验证是否成功安装了Conda。在终端中输入以下命令：\n1conda --version\n\n如果成功显示Conda的版本号，则说明已经正确地在Ubuntu上安装了Conda。\n注意：以上步骤是针对最新版的Miniconda进行的，如果你想要使用Anaconda而不是Miniconda，则需要下载相应的Anaconda安装包，并将命令中的”Miniconda”替换为”Anaconda”。\nAttributeError: module ‘cryptography.hazmat.backends’ has no attribute ‘openssl’ 这个问题是什么原因造成的？\n这个问题可能是因为您使用的cryptography库版本过低或安装不完整所导致的。在较早的版本中，cryptography.hazmat.backends模块确实没有名为openssl的属性。\n要解决这个问题，您可以尝试升级cryptography库到最新版本，并确保正确安装了所有依赖项。您可以使用以下命令升级cryptography库：\n1pip install --upgrade cryptography\n\n如果问题仍然存在，请检查您的环境是否正确配置了OpenSSL。您可以参考cryptography文档中关于安装和配置OpenSSL的部分来确保正确设置了OpenSSL。\nnvidia显卡用什么命令可以查看显卡的使用率，特别是一机多显卡的情况\n在Windows系统中，可以使用以下命令来查看nvidia显卡的使用率：\n\n打开命令提示符或PowerShell。\n输入以下命令：1nvidia-smi\n这将显示当前系统中所有nvidia显卡的详细信息，包括使用率、温度等。\n\n如果你的系统中存在多个nvidia显卡，可以使用以下命令来查看每个显卡的使用率：\n1nvidia-smi -i &lt;index&gt;\n\n其中 &lt;index&gt; 是显卡的索引号，从0开始。例如，要查看第二个显卡的使用率，可以输入 nvidia-smi -i 1。\n在Linux系统中，可以通过以下命令来查看nvidia显卡的使用率：\n1nvidia-smi\n\n该命令将显示所有nvidia显卡的详细信息，类似于Windows系统中的输出。\n如果你有多个nvidia显卡，并且想要查看每个显卡的使用率，可以使用以下命令：\n1nvidia-smi -i &lt;index&gt;\n\n其中 &lt;index&gt; 是显卡的索引号。同样地，在Linux系统中也是从0开始索引。例如，要查看第二个显卡的使用率，可以输入 nvidia-smi -i 1。\nollama运行的时候如何指定运行具体那块显卡\nkali上如何安装conda\n要在Kali上安装Conda，您可以按照以下步骤进行操作：\n\n打开终端窗口。\n\n下载Miniconda安装脚本。在终端中输入以下命令：\n1wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh\n运行安装脚本。输入以下命令：\n1bash Miniconda3-latest-Linux-aarch64.sh\n按照提示进行安装。您可以使用默认设置，或根据需要进行自定义设置。\n\n在安装过程中，会要求您接受许可协议和选择安装位置。请按照提示操作。\n\n安装完成后，关闭终端窗口并重新打开一个新的终端窗口。\n\n检查Conda是否成功安装。在终端中输入以下命令：\n1conda --version\n\n如果成功安装，将显示Conda的版本号。\n\n\n现在您已成功在Kali上安装了Conda。\n","slug":"kanbanfiles/常用的显卡操作命令","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"梅子青哥窑与弟窑有什么区别？\n梅子青哥窑与弟窑是中国古代青瓷窑口的两个代表。它们的区别主要体现在以下几个方面：\n\n地理位置：梅子青哥窑位于河南省开封市尉氏县梅子山区，而弟窑位于河南省郑州市新郑市。\n\n历史时期：梅子青哥窑是北宋时期的一个重要制瓷窑口，而弟窑则出现在明朝万历年间。\n\n窑瓷特点：梅子青哥窑以其独特的“梅子青”釉色而闻名，釉色深浅不一，呈现出深蓝、浅蓝、碧绿等多种色调。而弟窑则以其“弟红”为特色，红色鲜艳而温润。\n\n窑器形制：梅子青哥窑主要生产器型为盘、碗、盏等小型器皿，以及壶、罐等大型器皿；而弟窑则主要生产各类盘碗、盏、壶罐等。\n\n釉面装饰：两者的装饰风格也有所不同。梅子青哥窑的釉面装饰以刻花、划花、浮雕等技法为主，图案多为植物纹样和人物故事；弟窑则采用了红彩绘画技法，以花鸟、山水等题材作为装饰。\n\n\n总体来说，梅子青哥窑和弟窑在地理位置、历史时期、窑瓷特点、器型和装饰风格等方面有所差异。但它们都是中国古代制瓷的重要代表，对后世的陶瓷制作有着深远影响。\n梅子青瓷器是一种什么样的瓷器？\n梅子青瓷器是一种传统的中国瓷器，以其特殊的青色釉料而闻名。它通常具有细腻的质地和光滑的表面，釉色呈现出深沉的青色，有时还带有微妙的纹理和斑点。梅子青瓷器制作精细，工艺复杂，需要经过多道繁琐的工序才能完成。它在中国传统文化中被视为高雅和珍贵的艺术品，常用于茶具、花瓶、碗盘等器物制作。\n","slug":"kanbanfiles/梅子青哥窑","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"梅子青哥窑与弟窑有什么区别？\n梅子青哥窑与弟窑是中国古代青瓷窑口的两个代表。它们的区别主要体现在以下几个方面：\n\n地理位置：梅子青哥窑位于河南省开封市尉氏县梅子山区，而弟窑位于河南省郑州市新郑市。\n\n历史时期：梅子青哥窑是北宋时期的一个重要制瓷窑口，而弟窑则出现在明朝万历年间。\n\n窑瓷特点：梅子青哥窑以其独特的“梅子青”釉色而闻名，釉色深浅不一，呈现出深蓝、浅蓝、碧绿等多种色调。而弟窑则以其“弟红”为特色，红色鲜艳而温润。\n\n窑器形制：梅子青哥窑主要生产器型为盘、碗、盏等小型器皿，以及壶、罐等大型器皿；而弟窑则主要生产各类盘碗、盏、壶罐等。\n\n釉面装饰：两者的装饰风格也有所不同。梅子青哥窑的釉面装饰以刻花、划花、浮雕等技法为主，图案多为植物纹样和人物故事；弟窑则采用了红彩绘画技法，以花鸟、山水等题材作为装饰。\n\n\n总体来说，梅子青哥窑和弟窑在地理位置、历史时期、窑瓷特点、器型和装饰风格等方面有所差异。但它们都是中国古代制瓷的重要代表，对后世的陶瓷制作有着深远影响。\n梅子青瓷器是一种什么样的瓷器？\n梅子青瓷器是一种传统的中国瓷器，以其特殊的青色釉料而闻名。它通常具有细腻的质地和光滑的表面，釉色呈现出深沉的青色，有时还带有微妙的纹理和斑点。梅子青瓷器制作精细，工艺复杂，需要经过多道繁琐的工序才能完成。它在中国传统文化中被视为高雅和珍贵的艺术品，常用于茶具、花瓶、碗盘等器物制作。\n","slug":"kanbanfiles/梅子青哥窑_冲突文件_root_20231115114817","date":"2024-03-14T06:15:59.719Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"Kali上的弱口令扫描工具有那些可以使用？\n在Kali上有很多弱口令扫描工具可以使用，以下是一些常见的工具：\n\nHydra：Hydra是一个强大的登录破解工具，支持多种协议和服务，可以用于进行弱口令扫描。\nMedusa：Medusa也是一个密码破解工具，类似于Hydra，支持多种协议和服务。\nNcrack：Ncrack是一个网络认证破解工具，可以用于扫描和破解弱口令。\nPatator：Patator是一个多功能暴力攻击工具，可以用于进行弱口令扫描和其他类型的攻击。\nCrowbar：Crowbar是一个针对多个协议的快速强制攻击工具，包括SSH、RDP、VNC等。\nBrutus：Brutus是一个Windows平台上的远程身份验证爆破工具，可以用于扫描弱口令。\nTHC-Hydra：THC-Hydra也是一个非常流行的登录爆破工具，在Kali中已经预装了该工具。\n\n这只是一些可用的选项，并不代表所有可用的弱口令扫描工具。在选择使用任何安全测试工具之前，请确保您对法律和道德规范有所了解，并获得相关系统所有者的授权。\n Hydra如何对一个FTP服务进行弱口令扫描\nHydra是一个强大的密码破解工具，可以用于对各种不同的服务进行弱口令扫描。下面是使用Hydra对FTP服务进行弱口令扫描的步骤：\n\n确保已经安装了Hydra工具。可以通过在终端中运行”hydra”命令来检查是否已经安装。\n\n打开终端，并输入以下命令来使用Hydra进行FTP弱口令扫描：\n1hydra -l &lt;用户名字典文件&gt; -P &lt;密码字典文件&gt; ftp://&lt;目标IP地址&gt;\n其中，&lt;用户名字典文件&gt;是包含可能的用户名列表的文件路径，&lt;密码字典文件&gt;是包含可能的密码列表的文件路径，&lt;目标IP地址&gt;是目标FTP服务器的IP地址。\n\n运行上述命令后，Hydra将开始尝试使用给定的用户名和密码组合进行登录。如果找到了正确的登录凭据，则会显示成功登录的消息，并输出成功登录时使用的用户名和密码。\n\n\n注意事项：\n\n在选择用户名和密码字典时，建议使用常见且广泛使用的字典以提高成功率。\n弱口令扫描可能涉及到未经授权访问他人设备或系统，请确保遵守法律和道德规范，并获得相关授权。\n弱口令扫描是一种被动的攻击方式，可能引起目标系统的日志记录和报警，请谨慎使用。\n\n 一个机器有内网IP和外网IP，为什么监听内网SSH，外网IP还能访问这个SSH服务？\n这种情况可能是因为机器的网络环境中存在端口转发或者NAT(Network Address Translation)配置。\n当机器有内网IP和外网IP时，内网IP是在局域网中使用的，而外网IP是在公共网络中使用的。通常情况下，外部网络无法直接访问内网IP上的服务。\n然而，如果在路由器或防火墙上进行了端口转发配置，将外部网络对某个特定端口的请求转发到机器的内网IP上相应的端口，那么即使监听在内网IP上，外部网络也能够通过访问外网IP和相应端口来访问该SSH服务。\n另一种情况是使用了NAT(Network Address Translation)技术。NAT会将内部网络中的私有IP地址映射为公共网络中的唯一IP地址。在这种情况下，当机器监听在内网IP上时，由于NAT的映射关系，在公共网络中仍然可以通过访问对应的外网IP来访问该SSH服务。\n总结起来，监听在内网IP上的SSH服务可以通过端口转发或者NAT技术使得外部网络可以访问到。\n","slug":"kanbanfiles/Kali上的弱口令扫描工具","date":"2024-03-14T06:15:59.718Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"有那些优秀的Hexo主题可以选择使用\n以下是一些优秀的Hexo主题供选择使用：\n\nNext：Next是一款功能强大且高度可定制的Hexo主题，具有响应式布局和多种颜色方案。它支持多种插件和功能，如代码高亮、搜索、多语言支持等。\n\nLandscape：Landscape是Hexo自带的默认主题，具有简洁而漂亮的设计风格。它适用于个人博客和摄影作品展示等。\n\nCactus：Cactus是一款以极简主义为特点的Hexo主题，具有简洁而美观的设计。它支持多种布局和自定义选项，并且易于配置和使用。\n\nHueman：Hueman是一款响应式设计的Hexo主题，具有清晰明亮的界面和丰富的自定义选项。它支持多种布局和插件，并且适合各类博客类型。\n\nApollo：Apollo是一款专注于阅读体验的Hexo主题，具有简洁而舒适的界面。它提供了多个可定制选项，如字体样式、背景图像等。\n\nIcarus：Icarus是一款现代化设计风格的Hexo主题，具有干净、简洁和注重内容呈现。它支持多种布局、标签云、评论系统等功能。\n\n\n这些主题都具有不同的特点和优势，可以根据个人需求和喜好选择适合自己的主题。\n","slug":"kanbanfiles/Hexo的优秀主题","date":"2024-03-14T06:15:59.718Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"","slug":"kanbanfiles/LSTM神经网络","date":"2024-03-14T06:15:59.718Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"846015a39439fe7ecae742a0ab7587b9","title":"Linux加载磁盘","content":"0x01  概述在Linux下如何加载一个分区，需要几个过程。\n0x02 操作过程查看分区|[&#x72;&#111;&#111;&#x74;&#64;&#108;&#117;&#97;&#x2e;&#114;&#101;&#x6e;~]# df -h  Filesystem      Size  Used Avail Use% Mounted on  /dev/vda1        40G  2.2G   36G   6% /  devtmpfs         63G     0   63G   0% /dev  tmpfs            63G     0   63G   0% /dev/shm  tmpfs            63G   17M   63G   1% /run  tmpfs            63G     0   63G   0% /sys/fs/cgroup  tmpfs            13G     0   13G   0% /run/user/60422|\n查看所有磁盘|[&#x72;&#x6f;&#x6f;&#116;&#64;&#x6c;&#x75;&#97;&#x2e;&#114;&#101;&#110; ~]# fdisk -l    Disk /dev/vda: 42.9 GB, 42949672960 bytes, 83886080 sectors  Units = sectors of 1 * 512 = 512 bytes  Sector size (logical/physical): 512 bytes / 512 bytes  I/O size (minimum/optimal): 512 bytes / 512 bytes  Disk label type: dos  Disk identifier: 0x000a2636       Device Boot      Start         End      Blocks   Id  System  /dev/vda1   *        2048    83886046    41941999+  83  Linux    Disk /dev/vdb: 536.9 GB, 536870912000 bytes, 1048576000 sectors  Units = sectors of 1 * 512 = 512 bytes  Sector size (logical/physical): 512 bytes / 512 bytes  I/O size (minimum/optimal): 512 bytes / 512 bytes|\n格式化|[&#114;&#111;&#x6f;&#x74;&#x40;&#x6c;&#117;&#x61;&#x2e;&#x72;&#x65;&#110; ~]# mkfs.ext4 /dev/vdb  mke2fs 1.42.9 (28-Dec-2013)  Filesystem label=  OS type: Linux  Block size=4096 (log=2)  Fragment size=4096 (log=2)  Stride=0 blocks, Stripe width=0 blocks  32768000 inodes, 131071744 blocks  6553587 blocks (5.00%) reserved for the super user  First data block=0  Maximum filesystem blocks=2279604224  4000 block groups  32768 blocks per group, 32768 fragments per group  8192 inodes per group  Superblock backups stored on blocks:      32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,      4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,      102400000    Allocating group tables: done  Writing inode tables: done  Creating journal (32768 blocks): done|\n写/etc/fstab, 服务器重启可以自动挂载\n创建挂载目录\n\n|[&#x72;&#111;&#x6f;&#x74;&#64;&#108;&#x75;&#x61;&#x2e;&#x72;&#101;&#110; ~]# mkdir /data\n\n查询分区UUID\n\n|[&#114;&#x6f;&#x6f;&#x74;&#x40;&#108;&#117;&#97;&#46;&#114;&#x65;&#x6e; ~]# blkid  /dev/sr0: UUID=”2020-06-23-11-46-23-00” LABEL=”cidata” TYPE=”iso9660”  /dev/vda1: UUID=”a5ed5a70-ec40-4fcf-b436-9dab87463f08” TYPE=”ext4”  /dev/vdb: UUID=”e3cce3c2-3d28-4397-b94e-b744e5ce6b93” TYPE=”ext4”|\n\n分区UUID（数据以实际的查询结果为准）  UUID=”e3cce3c2-3d28-4397-b94e-b744e5ce6b93”\n写fstab\n\n[&#x72;&#x6f;&#x6f;&#x74;&#x40;&#108;&#117;&#97;&#x2e;&#x72;&#x65;&#x6e; ~]# vim /etc/fstab  \nUUID=a5ed5a70-ec40-4fcf-b436-9dab87463f08 / ext4 defaults 1 1UUID=e3cce3c2-3d28-4397-b94e-b744e5ce6b93 /data ext4 defaults 1 1\n\n挂载目录\n\n[&#114;&#x6f;&#111;&#116;&#x40;&#x6c;&#x75;&#97;&#x2e;&#114;&#x65;&#110; ~]# mount -a[&#x72;&#x6f;&#111;&#116;&#64;&#x6c;&#x75;&#97;&#46;&#114;&#x65;&#110; ~]# df -hFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 2.2G 36G 6% /devtmpfs 63G 0 63G 0% /devtmpfs 63G 0 63G 0% /dev/shmtmpfs 63G 17M 63G 1% /runtmpfs 63G 0 63G 0% /sys/fs/cgrouptmpfs 13G 0 13G 0% /run/user/60422/dev/vdb 493G 73M 467G 1% /data\n0x03 总结/etc/fstab的配置CenOS与Ubuntu的配置有一些差异，需要特别注意。\n\nUbuntu的//etc/fstab文件\n\n/dev/disk/by-uuid/fa3d8567-f154-4802-baae-af75e1d85c18 / ext4 defaults 0 0/swap.img none swap sw 0 0/dev/disk/by-uuid/dde4e123-7c68-42eb-9dab-0c9e94c352bb /data0 ext4 defaults 0 0\n","slug":"kanbanfiles/Linux加载磁盘","date":"2024-03-14T06:15:59.718Z","categories_index":"linux","tags_index":"linux,mount,磁盘","author_index":"安全书"},{"id":"ac33f15bf65cd9ebaf4db663ac638a56","title":"Obsidian有那些语音插件？","content":"Obsidian有那些语音插件？\nObsidian目前有以下几个语音插件：\n\n音频录制插件：这个插件允许你在Obsidian中录制音频笔记。你可以随时随地录制你的想法、会议记录、讲座等。\n\n语音转文字插件：这个插件可以将你的语音笔记自动转换为文字。它使用语音识别技术，将录制的语音转化为可编辑的文本。\n\n语音指令插件：这个插件允许你使用语音指令来操作Obsidian。例如，你可以通过说“打开文件”、“创建链接”等指令来快速执行相应的操作。\n\n语音阅读器插件：这个插件可以将文本内容以语音形式朗读出来。它支持多种语言和声音选择，可以帮助你更好地理解和回顾笔记内容。\n\n\n请注意，以上列举的只是一些常见的语音插件，实际上Obsidian还有很多其他相关的扩展和定制选项，可以根据个人需求选择合适的插件。\n\n\n\n\n\n\n\n\n\n如何只对网页中的img标签进行no-referrer限制。\n要对网页中的img标签进行no-referrer限制，您可以使用以下方法：\n\n使用JavaScript：在网页中插入以下JavaScript代码，它将遍历所有的img标签，并为每个img标签设置rel属性为”noreferrer”。\n\n123456window.addEventListener(&#x27;DOMContentLoaded&#x27;, function() &#123;  var imgTags = document.getElementsByTagName(&#x27;img&#x27;);  for (var i = 0; i &lt; imgTags.length; i++) &#123;    imgTags[i].setAttribute(&#x27;referrerpolicy&#x27;, &#x27;no-referrer&#x27;);  &#125;&#125;);\n\n\n使用CSS：在网页的样式表（CSS）中添加以下代码，它将为所有的img标签设置rel属性为”noreferrer”。\n\n123img &#123;  referrerpolicy: no-referrer;&#125;\n\n请注意，这些方法都是在客户端（浏览器）执行的，并且只会影响到加载了该代码或样式表的网页。如果您想全局应用no-referrer限制，您可能需要在服务器端配置相关设置。\n直接在头文件中禁用，是可以跃过图片防盗链，但同时百度统计也屏蔽了， 图是可以显示了， 但是百度统计不过了。\n\n\n\n\n用JS动态进行no-referrer设置。\n\n\n\n\n\n(function () {\n  // 添加 no-referrer\n  // \n  var meta = document.createElement('meta')\n  meta.content = 'no-referrer'\n  meta.name = 'referrer'\n  document.getElementsByTagName('head')[0].appendChild(meta)\n})()\n\n\n\n要在百度的统计JS加载之后，加载上面的代码，这样百度就可以正常统计了， 这段代码要放到Hexo的主题文件里， 标签不能用普通的JS标签，要用Hexo主题用的标签。\n12345678if theme.baidu_analytics  script.    (function () &#123;    var meta = document.createElement(&#x27;meta&#x27;)    meta.content = &#x27;no-referrer&#x27;    meta.name = &#x27;referrer&#x27;    document.getElementsByTagName(&#x27;head&#x27;)[0].appendChild(meta)    &#125;)()\n\n这段代码放在主题的百度代码统计之后， 图墙的图片就可以显示了， 并且百度的统计也是正常。 \n","slug":"kanbanfiles/Obsidian有那些语音插件？","date":"2024-03-14T06:15:59.718Z","categories_index":"obsidian,hexo","tags_index":"obsidian","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"https://dashboard.cohere.com/api-keys\n Obsidian中使用Cohere AI的API对应使用那个插件。\n在Obsidian中使用Cohere AI的API可以使用Obsidian插件“Cohere”来实现。该插件允许用户直接在Obsidian中访问Cohere AI的API，并将其集成到笔记和文档中。用户可以使用该插件来生成文本、回答问题、翻译文本等。\n那些Obsidian的GPT插件，支持使用Cohere AI的API？\n目前为止，Obsidian的GPT插件还不支持直接使用Cohere AI的API。然而，你可以使用Cohere AI的API来自己开发插件或者集成到Obsidian中。通过Cohere AI的API，你可以访问其强大的语言模型，实现各种自然语言处理任务，如生成文本、回答问题等。你可以参考Cohere AI提供的API文档和示例代码来开始开发。\nObsidian社区插件中，那些插件，支持使用cohere的API\n在Obsidian社区插件中，目前有以下插件支持使用cohere的API：\n\nhttps://dashboard.cohere.com/api-keys - 这个插件是专门为Obsidian开发的，它提供了与Cohere API的集成，可以使用Cohere API来生成文本摘要、自动补全、语义搜索等功能。\nDataview - 这个插件允许用户通过查询和过滤Markdown笔记中的数据，创建动态的表格和视图。虽然它本身不直接支持Cohere API，但可以结合Coherence插件一起使用，从而在Dataview视图中实现自然语言处理功能。\nTemplater - 这个插件可以根据模板和变量生成自定义文本。虽然它也没有直接集成Cohere API，但你可以使用Coherence插件来获取通过Cohere API生成的文本，并将其作为变量传递给Templater进行后续处理。\n\n这些插件都是由Obsidian社区开发者开发和维护的，可以在Obsidian的插件商店中找到并安装。请注意，这些插件可能需要你具备有效的Cohere API凭证才能正常工作。\n如何从本地安装一个Obisidian插件\n要从本地安装一个Obisidian插件，你需要按照以下步骤进行操作：\n\n下载插件文件：首先，你需要从Obisidian插件的官方仓库或其他可靠来源下载插件的压缩文件。通常，这个文件是以.zip或.tar.gz的格式提供的。\n\n解压插件文件：将下载的插件压缩文件解压到一个你可以轻松访问到的位置。你可以选择将其解压到任意一个文件夹中。\n\n打开Obsidian：打开你的Obsidian应用程序。\n\n进入插件设置页面：在Obsidian界面上，点击左侧导航栏中的设置图标（齿轮图标），然后选择“Community plugins”选项卡。\n\n打开本地插件目录：在“Community plugins”选项卡下，找到页面底部的“Installed plugins”部分。点击右下角的“Open folder”按钮。\n\n将插件复制到本地插件目录：在打开的本地插件目录中，将之前解压得到的插件文件夹复制到这个目录中。\n\n刷新Obsidian：回到Obsidian应用程序，点击左侧导航栏中的设置图标（齿轮图标），然后选择“Community plugins”选项卡。Obsidian会自动检测并加载新添加的插件。\n\n启用插件：在“Community plugins”选项卡下，找到你刚刚安装的插件，并将其启用。有些插件可能需要一些配置步骤，你可以按照插件的文档或说明进行设置。\n\n\n完成以上步骤后，你就成功从本地安装了一个Obisidian插件。你可以在Obsidian中使用这个插件\n","slug":"kanbanfiles/Obsidian的CohereAI插件","date":"2024-03-14T06:15:59.718Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"6f69935454a41ee16cb899c98008b9e3","title":"X79和X99主板之间差多少？","content":"X79和X99主板之间差多少？\nX79和X99主板之间的差异主要体现在以下几个方面：\n\n芯片组：X79主板采用的是Intel X79芯片组，而X99主板采用的是Intel X99芯片组。X99芯片组相对于X79芯片组有更高级别的功能和性能。\n\n处理器支持：X79主板支持LGA 2011接口的Intel Sandy Bridge-E和Ivy Bridge-E系列处理器，而X99主板支持LGA 2011-3接口的Intel Haswell-E和Broadwell-E系列处理器。因此，X99主板具有更好的处理器兼容性。\n\n内存支持：X79主板最多支持4个内存插槽，最高支持64GB DDR3内存；而X99主板最多支持8个内存插槽，最高支持128GB DDR4内存。因此，X99主板具有更高的内存扩展性。\n\nPCIe通道数量：X79主板通常具有较少的PCIe插槽，并且不支持PCIe 3.0标准；而X99主板通常具有更多的PCIe插槽，并且支持PCIe 3.0标准。因此，X99主板具有更好的扩展性能。\n\n\n总体来说，相对于X79主板，X99主板在处理器兼容性、内存扩展性和扩展性能方面更加先进和强大。\nX79和X99可以支持的最高级别的显卡是什么型号 ？\nX79和X99主板都支持最高级别的显卡型号，例如NVIDIA GeForce RTX 3090或AMD Radeon RX 6900 XT等。\nX99主板是否支持4090显卡？\n很抱歉，目前没有关于X99主板是否支持4090显卡的明确信息。X99主板的PCIe插槽一般支持最新的PCIe 3.0标准，而4090显卡尚未发布，因此无法确定其兼容性。建议在购买前查阅相关产品文档或联系厂商以获取准确信息。\nZen3的R5主板比X99怎么样？\nZen3的R5主板相比X99主板有以下几个优点：\n\n性能更强：Zen3架构采用了全新的7nm制程工艺，拥有更高的单核和多核性能，相比之下，X99主板上的处理器性能相对较低。\n\n功耗更低：Zen3架构采用了全新的7nm制程工艺，电压调节更为高效，功耗更低，相比之下，X99主板上的处理器功耗较高。\n\n支持PCIe 4.0：Zen3主板支持最新的PCIe 4.0技术，可以提供更高的带宽和速度，支持更快速度的固态硬盘、显卡等设备。而X99主板只支持PCIe 3.0。\n\n更多USB端口：Zen3主板通常配备了更多USB 3.2 Gen 2接口，可提供更快速度和更好的兼容性。而X99主板上常见的是USB 3.0接口。\n\n\n综上所述，Zen3的R5主板在性能、功耗、技术支持等方面都优于X99主板。但需要注意的是，在选择使用哪种主板时还需考虑自己的需求和预算等因素。\nESXI运行多虚拟机，用Zen3的R5主板好， 还是用X99的主板好？\n在选择主板时，需要考虑以下几个因素：\n\nCPU支持：根据您提到的情况，Zen3的R5主板和X99主板都支持多虚拟机运行。但是，Zen3的R5主板使用AMD Ryzen处理器，而X99主板使用Intel LGA 2011-3处理器。所以您需要根据您计划使用的CPU来选择相应的主板。\n\n性能：Zen3的R5主板通常具有较高的性能和更好的功耗管理。AMD Ryzen处理器在多任务处理和多核性能方面表现出色，这对于同时运行多个虚拟机非常有利。\n\n扩展性：X99主板通常具有更多扩展插槽和更高的内存容量支持。如果您计划在未来增加更多硬件设备或者需要大容量内存支持，那么X99可能是一个更好的选择。\n\n成本：Zen3的R5主板通常比X99主板便宜。这可能是因为AMD Ryzen处理器价格相对较低，并且AMD平台上其他硬件组件也可能比Intel平台上便宜。\n\n\n综上所述，如果您计划在ESXI上运行多个虚拟机，并且希望获得较好的性能和有效管理功耗，那么选择一块支持AMD Ryzen处理器的Zen3的R5主板可能是一个不错的选择。如果您需要更高的扩展性和内存容量支持，那么X99主板可能更适合您的需求。最终选择取决于您的具体需求和预算。\n","slug":"kanbanfiles/X79和X99主板之间差多少？","date":"2024-03-14T06:15:59.718Z","categories_index":"主机硬件","tags_index":"主板,x79,x99","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"gitee与pico做成的图床图片文件网站引入图片时无法显示怎么解决？\n如果在gitee或pico搭建的图床图片文件网站中，引入的图片无法显示，可能有以下几种解决方法：\n\n检查图片链接是否正确：确保引入图片时使用的是正确的链接地址。可以尝试在浏览器中直接打开该链接来确认图片是否能够正常显示。\n\n检查图片权限设置：如果你使用的是私有仓库，需要确保你有足够的权限来访问该图片。可以检查一下仓库或文件夹的权限设置，并确保你具有访问权限。\n\n检查网络连接和防火墙设置：由于网络问题或防火墙配置，可能导致无法加载外部资源。建议检查网络连接是否正常，并且确保没有任何防火墙或安全软件阻止了该网站加载图片。\n\n检查图床服务商是否可用：如果你使用第三方图床服务商（如sm.ms、imgur等），可以尝试打开该服务商的官方网站来确认是否能够正常访问和上传图片。\n\n尝试替换其他图床服务商：如果上述方法都没有解决问题，可以考虑更换其他图床服务商。目前有很多免费的图床服务可供选择，例如GitHub、ImgBB等。\n\n\n综上所述，通过检查链接、权限设置、网络连接和更换图床服务商等方法，应该能够解决无法显示图片的问题。\nHexo使用gitee的图床图片文件，图片路径正常，但是图片无法正常显示，如何解决？\n如果在Hexo中使用gitee的图床图片文件，但是图片无法正常显示，可能是以下几个原因导致的：\n\n图片链接错误：首先请确保图片链接是正确的，可以尝试在浏览器中直接访问该链接，看是否能够正常显示图片。\n\n图片权限问题：如果图片是私有的或者没有公开访问权限，那么在Hexo中也无法正常显示。请确保图片设置为公开访问或者具有足够的权限。\n\n图片路径问题：在Hexo的配置文件(_config.yml)中，需要正确配置图像路径。请检查配置文件中的url和root参数是否正确设置。\n\nCDN缓存问题：如果使用了CDN加速服务，在更新图片后可能需要等待一段时间才能看到最新的图片。可以尝试清除CDN缓存或者等待一段时间再刷新页面。\n\n服务器访问限制：有些图床服务可能会对访问频率进行限制，如果超过了限制次数，则无法正常显示图片。可以尝试减少访问频率或者更换其他图床服务。\n\n\n以上是一些常见的解决方法，根据具体情况排查可能存在的问题，并进行相应调整。\nHexo使用gitee的图床图片文件，图片链接正常，图片路径正常，但是图片无法正常显示，如何解决？\n如果Hexo使用gitee的图床图片文件，但是图片路径正常，但是图片无法正常显示，可能有以下几种解决办法：\n\n确认图片路径是否正确：检查Hexo配置文件中的图床地址、图片文件名等是否正确，确保路径没有错误。\n\n检查网络连接：确保你的网络连接正常，可以访问gitee图床地址和图片链接。\n\n检查图床设置：确认你在gitee的图床设置中是否允许外链。有些图床服务可能默认禁止外链，需要手动设置允许外链才能正常显示图片。\n\n清除缓存：尝试清除浏览器缓存和Hexo生成的静态页面缓存，然后重新加载页面看是否能够正常显示图片。\n\n使用其他图床服务：如果以上方法都无法解决问题，可以考虑使用其他的图床服务，例如GitHub、Imgur等，并更新Hexo配置文件中的图床地址。\n\n检查权限设置：确保你在gitee上上传的图片文件具有公开访问权限，否则可能无法通过链接访问。\n\n\n以上是一些常见的解决方法，根据具体情况选择适合自己的方法进行尝试。\nHexo使用gitee的图床图片文件，图片链接正常，图片路径正常，但是图片无法正常显示，如何解决？\n有以下几种可能的解决方案：\n\n检查图片链接是否正确：确认图片链接是否与实际存储位置一致，确保没有任何错误。\n\n检查图片路径是否正确：确认图片路径是否正确配置，特别是在使用相对路径时需要注意路径的正确性。\n\n检查图片文件格式是否支持：确保使用的图片文件格式是Hexo所支持的，如JPEG、PNG等。\n\n检查图床服务是否正常：如果使用的图床服务有问题，可能会导致图片无法正常显示。可以尝试切换到其他图床服务或者检查当前图床服务的状态。\n\n清除浏览器缓存：有时候浏览器缓存会导致图片无法显示，可以尝试清除浏览器缓存后重新加载页面。\n\n检查网络连接：如果网络连接不稳定或者速度较慢，可能会导致图片加载失败。可以尝试在其他网络环境下打开页面或者使用代理来测试。\n\n检查Hexo配置文件：有时候Hexo配置文件中的某些设置可能会导致图片无法正常显示。可以检查相关配置项是否正确设置。\n\n\n如果以上方法都无法解决问题，建议详细检查Hexo和图床服务的相关文档或寻求相应技术支持进行进一步排查和解决。\n如何设置Gitee的项目图片充许外链？\n要设置Gitee项目图片允许外链，可以按照以下步骤进行操作：\n\n登录Gitee账号并进入要设置的项目页面。\n在项目页面上方的导航栏中，点击“仓库”选项卡。\n在左侧菜单中，找到并点击“设置”选项。\n在设置页面的左侧菜单中，选择“外链加速”选项。\n在外链加速页面中，将“图片外链加速”选项开启。\n点击页面底部的“保存修改”按钮以保存设置。\n\n完成以上步骤后，你的Gitee项目中的图片就可以通过外链进行访问了。你可以复制图片的链接地址并在其他网页或应用中使用。请注意，开启外链加速可能会导致图片被更多人访问，可能会增加流量消耗和带宽使用。\n","slug":"kanbanfiles/gitee与pico做成的图床图片文件网站引入图片时无法显示怎么解决","date":"2024-03-14T06:15:59.718Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"7951604bcce5cb8d2f8131e9a9d0848a","title":"hexo显示gitee图床图片","content":"\\themes\\butterfly\\layout\\includes目录下有一个head.pug文件，修改该文件的meta信息，会使生成的所有页面都带有该head。\n1meta(name=&quot;referrer&quot; content=&quot;no-referrer&quot;)\n\n新测，这种方式是好用的， 直接修改要主体的文件加入这个设定后，图片就可以正常的显示了。\n","slug":"kanbanfiles/hexo显示gitee图床图片不显示图","date":"2024-03-14T06:15:59.718Z","categories_index":"Sec,Graylog","tags_index":"Graylog","author_index":"安全书"},{"id":"9418719c0649bc35464381494a75a244","title":"iMaotai预约","content":"iMaotai预约在 GitHub 上发现个宝藏项目，可帮你在 i茅台 App 上每日自动预约。  \nGitHub：github.com/oddfar/campus-imaotai  \n具有如下功能：  \n\n平台注册账号  \n添加多个用户  \n自动预约  \n门店选择（出货量最大，或附近位置）  \n自动旅行  \n首次旅行分享  \n获取申购耐力值  \n自定义时间/随机事件预约或旅行  \n申购结果消息推送  \n支持 Docker 一键部署\n\n","slug":"kanbanfiles/iMaotai预约","date":"2024-03-14T06:15:59.718Z","categories_index":"开源项目","tags_index":"github","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"用C语言描述一个人工神经网络。\n人工神经网络是一种基于生物神经网络的计算模型，用来模拟人脑的学习和决策过程。在C语言中，可以使用结构体和数组来实现一个简单的人工神经网络。\n首先，我们需要定义神经元的结构体：\n1234typedef struct Neuron &#123;    double input;  // 输入值    double output; // 输出值&#125; Neuron;\n每个神经元都有一个输入值和一个输出值。\n接下来，我们定义神经网络的结构体：\n123456789typedef struct NeuralNetwork &#123;    int num_inputs;        // 输入层神经元数量    int num_hidden_layers; // 隐藏层数量    int num_outputs;       // 输出层神经元数量        Neuron **input_layer;        // 输入层    Neuron ***hidden_layers;     // 隐藏层    Neuron **output_layer;       // 输出层&#125; NeuralNetwork;\n其中，num_inputs表示输入层的神经元数量，num_hidden_layers表示隐藏层数量，num_outputs表示输出层的神经元数量。input_layer是一个指向输入层神经元数组的指针，hidden_layers是一个指向隐藏层二维数组（每个隐藏层包含多个神经元）的指针，output_layer是一个指向输出层神经元数组的指针。\n接着，我们需要实现一些函数来创建和训练神经网络，比如初始化函数、前向传播函数和反向传播函数等。以下是一个简单的例子：\n```c// 初始化神经网络void init_neural_network(NeuralNetwork *network) {    // 初始化输入层    network-&gt;input_layer = malloc(network-&gt;num_inputs * sizeof(Neuron *));    for (int i = 0; i &lt; network-&gt;num_inputs; i++) {        network-&gt;input_layer[i] = malloc(sizeof(Neuron));\n       \n","slug":"kanbanfiles/人工神经网络","date":"2024-03-14T06:15:59.718Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"9d54c438e5c0987af1b3cb3ae965517a","title":"人工神经网络的激活算法","content":"人工神经网络的激活算法人工神经网络激活算法的作用是什么？\n人工神经网络激活算法的作用是将输入信号转换为输出信号，从而模拟生物神经元的激活过程，使神经网络能够学习和处理复杂的非线性关系。激活算法通常在每个神经元中应用，通过对输入信号进行加权求和，并通过激活函数对结果进行非线性映射，生成输出信号。这样可以引入非线性特性，增强网络的表达能力，使其能够适应更复杂的数据模式和任务。常见的激活函数包括sigmoid函数、ReLU函数、tanh函数等。不同的激活函数具有不同的特性和适用范围，选择合适的激活函数可以提高神经网络的性能和效果。\n如何将一些URL集合数据，转换成LSTM神经网络可以用于训练的数据，用Pythoi语言实现。\n要将URL集合数据转换成LSTM神经网络可以用于训练的数据，可以按照以下步骤进行：\n\n导入必要的库和模块：\n1234import numpy as npfrom keras.preprocessing.sequence import pad_sequencesfrom keras.preprocessing.text import Tokenizerfrom keras.utils import to_categorical\n准备URL数据集合：\n1urls = [&#x27;http://example.com&#x27;, &#x27;http://example2.com&#x27;, &#x27;http://example3.com&#x27;]\n使用Tokenizer将URL转换成整数序列：\n123tokenizer = Tokenizer()tokenizer.fit_on_texts(urls)sequences = tokenizer.texts_to_sequences(urls)\n获取词汇表大小和最大序列长度：\n12vocab_size = len(tokenizer.word_index) + 1max_length = max(len(seq) for seq in sequences)\n对序列进行填充，使其具有相同的长度：\n1padded_sequences = pad_sequences(sequences, maxlen=max_length, padding=&#x27;post&#x27;)\n创建输入和输出数据集：\n123X = padded_sequences[:, :-1]y = padded_sequences[:, -1]y = to_categorical(y, num_classes=vocab_size)\n打印输入和输出数据集的形状：\n12print(X.shape)  # (3, 4)print(y.shape)  # (3, 4)\n这里假设每个URL被转换为一个四个词的整数序列。\n\n\n现在，你可以使用X和y作为LSTM神经网络的训练数据。\nLSTM神经网络训练用的数据， 数据结构是什么样的， 用C语言描述。\n在LSTM神经网络的训练中，输入数据通常是一个序列，比如一段文字、音频或视频等。每个序列都由若干个时间步组成，每个时间步包含一个或多个特征。为了描述这样的数据结构，可以使用C语言中的数组和结构体。\n首先，我们可以定义一个结构体来表示一个时间步的特征向量：\n123456typedef struct &#123;    float feature1;    float feature2;    // 其他特征...&#125; TimeStep;\n\n然后，我们可以使用动态数组来表示整个序列：\n12int sequence_length = 10;  // 序列长度TimeStep* sequence = (TimeStep*)malloc(sequence_length * sizeof(TimeStep));\n\n上述代码定义了一个长度为10的序列，并使用malloc函数分配了相应大小的内存空间。\n接下来，我们可以为每个时间步赋值特征向量：\n12345for (int i = 0; i &lt; sequence_length; ++i) &#123;    sequence[i].feature1 = ...;  // 设置feature1的值    sequence[i].feature2 = ...;  // 设置feature2的值    // 设置其他特征...&#125;\n\n在训练过程中，通常还需要为每个时间步提供目标值（即期望输出）来计算损失函数。我们可以类似地定义另一个动态数组来表示目标序列：\n1float* targets = (float*)malloc(sequence_length * sizeof(float));\n\n然后，为每个时间步赋值目标值：\n123for (int i = 0; i &lt; sequence_length; ++i) &#123;    targets[i] = ...;  // 设置目标值&#125;\n\n这样，我们就可以使用C语言中的数组和结构体来描述LSTM神经网络训练用的数据结构了。当然，实际情况可能更加复杂，需要根据具体问题进行适当\nLSTM神经网络算法， 训练的处理过程是什么？\nLSTM（长短期记忆）神经网络算法的训练过程如下：\n\n初始化权重和偏差：随机初始化LSTM网络的权重和偏差参数。\n\n前向传播计算：将输入数据通过LSTM网络进行前向传播计算，得到预测结果。\n\n计算损失函数：根据预测结果和真实标签之间的差异，计算损失函数。常用的损失函数包括平均平方误差（MSE）或交叉熵损失等。\n\n反向传播更新梯度：使用反向传播算法计算损失函数对于网络参数的梯度，并根据学习率和优化算法（如随机梯度下降）更新网络参数。\n\n重复步骤2-4：重复执行步骤2-4，直到达到预设的迭代次数或达到收敛条件。\n\n模型评估和调优：使用验证集或测试集对训练得到的模型进行评估，根据评估结果进行模型调优，如调整超参数、增加正则化项等。\n\n模型应用：使用经过训练得到的模型对新数据进行预测或分类。\n\n\n需要注意的是，LSTM网络中存在很多可调节的超参数，如隐藏层大小、学习率、迭代次数等，这些超参数的选择会对模型的性能产生影响，因此在训练过程中需要进行适当的调参工作。\nLSTM神经网络算法， 预测正常数据和异常数据的原理是什么？\nLSTM（Long Short-Term Memory）神经网络算法是一种循环神经网络（RNN）的变体，具有记忆单元，可以处理和预测时间序列数据。\n在预测正常数据和异常数据方面，LSTM算法的原理如下：\n\n训练阶段：首先，LSTM模型通过输入一系列已知的正常数据样本来进行训练。训练过程中，LSTM模型会学习到正常数据的模式和规律，并根据这些规律调整内部参数。\n\n测试阶段：在测试阶段，LSTM模型将被用于预测未知数据的标签。对于每一个输入样本，LSTM模型会计算出一个输出值，并与预先定义的阈值进行比较。\n\n预测正常数据：如果输出值低于或等于阈值，则被认为是正常数据。这是因为在训练阶段，LSTM模型已经学习到了大部分正常数据的模式和规律，在测试阶段能够较好地拟合这些正常样本。\n\n预测异常数据：如果输出值高于阈值，则被认为是异常数据。这是因为异常数据可能与训练集中的正常样本有所不同，导致无法完全符合已学习到的模式和规律。\n\n\n总体来说，LSTM神经网络算法通过在训练阶段学习正常数据的模式和规律，然后在测试阶段根据输出值与阈值的比较来预测正常数据和异常数据。这种方法可以用于异常检测、故障诊断等领域。\nLSTM神经网络的时间序列数据，样例数据长成什么样子，用Python语言描述。\n样例数据通常是一个二维数组，其中每一行代表一个时间步，每一列代表一个特征。假设我们有一个包含3个时间步和2个特征的样例数据，可以用Python语言描述如下：\n123456789import numpy as np# 定义样例数据X = np.array([[0.1, 0.2],              [0.3, 0.4],              [0.5, 0.6]])# 输出样例数据形状print(X.shape)\n\n输出结果：\n1(3, 2)\n\n这里的样例数据X是一个形状为(3, 2)的二维数组，表示有3个时间步和2个特征。每一行代表一个时间步的输入特征。在LSTM神经网络中，这个样例数据通常作为输入序列传递给模型进行训练或预测。\nURL怎么转换成LSTM神经网络算法训练需要的时间序列数据？\n要将URL转换为LSTM神经网络算法训练所需的时间序列数据，可以按照以下步骤进行：\n\n数据收集：使用网络爬虫或API等方式获取URL的内容。这可以包括网页文本、HTML标签、图片等。\n\n数据预处理：对获取的原始数据进行预处理。这可能涉及到以下步骤：\n\n文本清洗：去除HTML标签、特殊字符、停用词等。\n分词：将文本拆分为单个单词或词汇。\n标准化：将文本转换为小写字母形式。\n数值化：将文本转换为数值表示形式，例如使用单词嵌入（word embeddings）或独热编码（one-hot encoding）。\n\n\n构建时间序列数据：根据问题的特定要求和LSTM模型的输入格式，构建时间序列数据。这可能包括以下步骤：\n\n窗口划分：将数据划分为连续的时间窗口，每个窗口包含一定数量的连续数据点。\n序列化：将每个时间窗口中的数据点组合成一个序列，并考虑适当的顺序和时间间隔。\n\n\n数据归一化：对构建的时间序列数据进行归一化处理，以确保不同特征之间具有相似的尺度。\n\n数据划分：将时间序列数据划分为训练集、验证集和测试集。通常，可以使用时间的顺序将数据进行划分，确保模型在未来的预测中不会使用到过去的信息。\n\nLSTM模型训练：使用处理好的时间序列数据，构建和训练LSTM神经网络模型。可以使用深度学\n\n\nURL转换成的LSTM神经网络训练用的序列数据，只是转成了数组数据，如何与时间发生联系的？\n在将URL转换为LSTM神经网络训练用的序列数据时，可以使用时间窗口的概念来与时间发生联系。时间窗口是指以固定长度划分连续的时间序列数据，每个时间窗口包含一段连续的URL数据。可以通过滑动窗口的方式，将URL数据逐步移动一个固定步长，从而构建出多个重叠的时间窗口。\n具体步骤如下：\n\n将URL数据转换为数组形式，例如将每个字符转换为对应的整数。\n定义时间窗口的长度和步长。长度表示每个时间窗口包含的URL数量，步长表示相邻两个时间窗口之间URL数据的重叠程度。\n从第一个URL开始，依次取出指定数量（长度）的URL作为输入序列，并将其对应的下一个URL作为输出标签。\n按照指定步长移动滑动窗口，并重复步骤3直到遍历完所有URL数据。\n\n通过以上步骤，可以得到与时间相关联的训练样本序列。在训练过程中，LSTM神经网络会根据输入序列之间的时序关系学习到不同URL之间可能存在的模式和依赖关系。\nLSTM神经网络算法，对URL数据进行训练，如何将URL中字符转换成整数的，转换成整数的意义是什么？\n在LSTM神经网络算法中，将URL中的字符转换为整数是为了能够将URL数据表示为数字序列进行处理和训练。这是因为神经网络只能处理数值型数据。\n将URL中字符转换成整数的方法可以有多种，其中一种常见的方法是使用字符编码表或者字符映射表来对每个字符进行编码。例如，可以使用ASCII编码或者Unicode编码来将每个字符映射到一个唯一的整数值。\n转换成整数的意义在于，通过将URL中的字符转换成整数，可以实现对URL数据的离散化处理。这样做有以下几个好处：\n\n可以减少输入特征空间的维度：当URL包含大量不同字符时，直接使用字符作为输入特征会导致特征空间非常庞大，增加了训练和计算的复杂性。而将字符转换成整数后，可以大幅减少特征空间的维度。\n\n可以提供给LSTM神经网络更多信息：通过将URL中的字符转换成整数后，可以保留一些语义上的信息。例如，在ASCII编码中，相邻整数之间可能具有某种相关性或顺序关系。\n\n方便进行One-Hot编码：在LSTM神经网络训练过程中，通常会将整数表示的URL再进行One-Hot编码，将其转换为二进制向量。这样做可以更好地表示不同字符之间的关系，并且方便神经网络进行计算和学习。\n\n\n总之，将URL中的字符转换成整数是为了实现对URL数据的离散化处理，减少特征空间的维度，并为LSTM神经网络提供更多信息和\nOne-Hot编码是什么样的？用Python表示数据是什么的？\nOne-Hot编码是一种常用的数据表示方法，用于将离散型特征转换为向量形式。它将每个可能的取值映射到一个唯一的整数索引，并创建一个全零向量，只有对应索引位置为1。\n在Python中，可以使用scikit-learn库的OneHotEncoder类来进行One-Hot编码。首先需要导入该类，然后创建一个OneHotEncoder对象，并将待编码的特征数据作为输入。调用对象的fit_transform方法即可得到特征数据的One-Hot编码表示。\n下面是使用Python进行One-Hot编码的示例代码：\n12345678910111213from sklearn.preprocessing import OneHotEncoder# 创建OneHotEncoder对象encoder = OneHotEncoder()# 定义待编码的特征数据data = [[&#x27;Male&#x27;, 1], [&#x27;Female&#x27;, 3], [&#x27;Female&#x27;, 2]]# 将特征数据进行编码encoded_data = encoder.fit_transform(data).toarray()# 打印编码后的结果print(encoded_data)\n\n运行以上代码，输出结果如下：\n123[[0. 1. 1. 0.] [1. 0. 0. 1.] [1. 0. 1. 0.]]\n\n其中每行代表一个样本，每列代表一个可能取值。例如，在第一行中，第一个和第二个列对应于’Male’这个取值，分别为0和1；第三个和第四个列对应于1这个取值，分别为1和0。\n如何将字符串的比较变成向量数据量特征，通过两个字符串的向量特征，比较两个字符串是否相似。\n将字符串的比较变成向量数据特征可以使用文本向量化的方法，最常见的方法是使用词袋模型和TF-IDF。\n\n词袋模型（Bag of Words）：将每个字符串看作是一个由单词组成的集合，将每个单词视为一个特征。首先，建立一个包含所有可能单词的字典。然后，对于每个字符串，统计每个单词在该字符串中出现的次数，并将其转换为向量表示。这样每个字符串都可以表示为一个固定长度的向量。\n\nTF-IDF：Term Frequency-Inverse Document Frequency是一种用于评估在文档集中某个单词对于其中某篇文档的重要程度的方法。TF指标衡量了某个单词在当前文档中出现的频率，而IDF指标衡量了该单词在整个文档集中出现的频率。通过计算TF-IDF值，可以得到一个向量表示。\n\n\n使用以上两种方法之一将两个字符串转换为向量特征后，可以通过计算它们之间的相似度来判断它们是否相似。常用的相似度度量方法包括余弦相似度和欧氏距离等。\n例如，对于两个字符串A和B：\n\n将A和B分别转换为基于词袋模型的向量表示，得到向量A和向量B。\n计算向量A和向量B之间的余弦相似度。如果余弦相似度接近1，则说明两个字符串相似；如果余弦相似度接近0，则说明两个字符串不相似。\n\n需要注意的是，选择合适的文本向量化方法和相似度度量方法取决于具体问题和数据集的特\nLSTM神经网络算法，对时间序列的数组做了什么操作\nLSTM（Long Short-Term Memory）神经网络算法是一种特殊的循环神经网络（RNN），用于处理时间序列数据。它通过使用记忆单元和门控机制，能够有效地捕捉和存储长期依赖关系。\n对于时间序列的数组，LSTM算法主要做了以下操作：\n\n输入门（input gate）：根据当前输入和前一个时刻的隐藏状态，决定需要更新记忆单元的程度。输入门可以控制哪些信息需要被记忆。\n\n遗忘门（forget gate）：根据当前输入和前一个时刻的隐藏状态，决定需要从记忆单元中遗忘的信息。遗忘门可以控制哪些信息不再需要被记忆。\n\n记忆单元（memory cell）：存储时间序列中的信息，并根据输入和遗忘门进行更新。记忆单元是LSTM算法中的核心组件，通过累积不同时刻的输入和遗忘得到一个长期记忆。\n\n输出门（output gate）：根据当前输入、前一个时刻的隐藏状态和当前记忆单元，决定输出的程度。输出门可以控制哪些信息需要被输出。\n\n隐藏状态（hidden state）：LSTM算法通过隐藏状态来传递信息，并作为下一个时间步的输入。隐藏状态能够将过去的信息传递到未来。\n\n\n通过以上操作，LSTM算法能够在时间序列数据中捕捉到长期依赖关系，并保留重要的历史信息。这使得LSTM在处理语音识别、自然语言处理、股票预测等时间序列任务中具有很好的效果。\nLSTM算法在时间序列数据中捕捉的长期依赖关系指是什么？\nLSTM算法在时间序列数据中捕捉的长期依赖关系指的是，在一个时间序列中，当前时刻的输出与之前多个时刻的输入之间存在较长时间跨度的依赖关系。传统的循环神经网络 (RNN) 在处理长期依赖问题时容易出现梯度消失或梯度爆炸的情况，而LSTM通过引入门控机制，能够有效地捕捉到时间序列数据中较长时间跨度的依赖关系。具体来说，LSTM通过遗忘门、输入门和输出门来控制信息的流动，从而在模型中保留重要信息并抑制不重要信息，使得模型能够更好地处理长期依赖关系。\nLSTM算法为什么要做向前和向后的这种对时序的操作，意义在那里？\nLSTM算法中的向前和向后操作是为了捕捉时序信息的双向依赖关系。在许多自然语言处理任务中，例如语言建模、机器翻译和语音识别，上下文信息对于正确理解和生成连续序列非常重要。\n通过向前操作，LSTM可以从过去的输入中学习到当前时刻的隐藏状态。这样做可以帮助模型捕捉到过去时刻的信息，并将其传递给当前时刻进行决策。例如，在语言建模任务中，前文的单词对于预测当前单词的概率分布非常有用。\n通过向后操作，LSTM可以从未来的输入中学习到当前时刻的隐藏状态。这样做可以帮助模型捕捉到未来时刻可能出现的信息，并将其传递给当前时刻进行决策。例如，在机器翻译任务中，后文的单词对于生成当前单词的翻译具有指导意义。\n综合考虑过去和未来的信息可以提供更全面、更准确地理解和生成连续序列。因此，LSTM算法采用了向前和向后操作来充分利用时序信息，提高模型性能。\nRNN神经网络，为什么需要在输入层与输出层之间，创建一个隐藏层，和激活函数又有什么关系？\nRNN（Recurrent Neural Network）神经网络中的隐藏层是为了解决序列数据的建模问题而引入的。隐藏层中的神经元可以存储和传递之前输入的信息，从而能够处理任意长度的序列数据。在每个时间步，隐藏层接收当前输入和前一时刻隐藏状态作为输入，并输出当前时刻的隐藏状态和输出。\n激活函数在神经网络中起到非线性映射的作用，可以给网络引入非线性特性。在RNN中，激活函数通常被应用于隐藏层和输出层。它们对输入进行非线性变换，使得网络能够更好地学习复杂关系和模式。\n具体来说，激活函数在隐藏层中的作用是对当前时刻输入和前一时刻隐藏状态进行非线性变换，以便捕捉到序列数据中存在的非线性关系。这样可以提高网络对序列数据的建模能力，使其能够更好地理解并记忆过去的信息。\n在输出层中，激活函数将最终计算得到的输出转化为一个合适的形式。根据不同任务需求，可以选择不同类型的激活函数来实现不同的功能，在分类问题中常用sigmoid或softmax函数，在回归问题中常用线性激活函数等。\n总之，隐藏层和激活函数在RNN中起到了增强网络的非线性拟合能力、提高建模能力以及实现不同任务需求的作用。\n神经网络在训练的时候，样本集，为什么要有正常数据集和异常数据集之分？\n正常数据集和异常数据集的分别是为了训练神经网络能够正确地识别正常样本和异常样本。\n正常数据集包含了一系列正常的、符合预期的样本，用于训练神经网络以学习正常模式。这些样本反映了系统在正常操作下的行为，包括各种特征和属性。通过对正常数据集进行训练，神经网络能够学习到这些特征和属性，并在之后对新的未知样本进行判断时，能够辨别出是否属于正常范畴。\n异常数据集则包含了一些不符合预期、异常或罕见的样本。这些样本可能是由于系统故障、人为错误或未知原因而产生的。通过将异常数据集与正常数据集一起使用来训练神经网络，可以帮助网络识别并区分出不符合正常模式的样本。这使得神经网络能够更好地应对未知情况，并具有鲁棒性。\n分别使用正常数据集和异常数据集进行训练可以提高神经网络的准确性和可靠性。它可以增强网络对于各种情况下的判断能力，并提高对异常情况的检测率和识别率。\n基于Python代码对一些URL字符集做LSTM算法训练。\n要基于Python代码对URL字符集进行LSTM算法训练，首先需要准备数据和构建模型。\n\n准备数据\n\n收集用于训练的URL数据集，包含正常的URL和恶意的URL。\n将URL转换为字符序列，可以使用Python的字符串操作来实现。\n对字符序列进行编码，将每个字符转换为一个整数表示。可以使用Python的内置函数ord()来获取字符的ASCII码，并构建一个字符到整数的映射表。\n将编码后的字符序列转换为等长序列，可以使用填充或截断操作来保持序列长度一致。\n\n\n构建模型\n\n导入所需的库，如TensorFlow、Keras等。\n定义LSTM模型结构。可以使用Keras中的Sequential模型，并添加LSTM层、全连接层等。\n编译模型，并设置损失函数和优化器。\n\n\n训练模型\n\n将数据集划分为训练集和测试集。\n使用Keras中的fit()函数进行模型训练。设置训练轮数、批量大小等参数。\n监控训练过程中的损失值和准确率。\n\n\n\n下面是一个简单示例代码：\n1234567891011121314151617import numpy as npfrom keras.models import Sequentialfrom keras.layers import LSTM, Dense# 准备数据urls = [&#x27;www.example.com&#x27;, &#x27;www.malicious.com&#x27;]char_map = &#123;chr(i): i for i in range(256)&#125;max_length = max(map(len, urls))X = np.zeros((len(urls), max_length))for i, url in enumerate(urls):    for j, char in enumerate(url):        X[i, j] = char_map[char]# 构建模型model = Sequential()model.add(LSTM(128, input_shape=(max_length, 1)))model.add(Dense(1, activation=&#x27;\n\n\n\n用C语言实现一段RNN神经网络算法\n以下是一个简单的用C语言实现的RNN神经网络算法示例：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#define INPUT_SIZE 2#define HIDDEN_SIZE 4#define OUTPUT_SIZE 1typedef struct &#123;    double input[INPUT_SIZE];    double hidden[HIDDEN_SIZE];    double output[OUTPUT_SIZE];&#125; RNN;typedef struct &#123;    double weight_ih[INPUT_SIZE][HIDDEN_SIZE];    double weight_hh[HIDDEN_SIZE][HIDDEN_SIZE];    double weight_ho[HIDDEN_SIZE][OUTPUT_SIZE];&#125; RNNWeights;void sigmoid(double *x) &#123;    *x = 1 / (1 + exp(-(*x)));&#125;void forward(RNN *rnn, RNNWeights *weights) &#123;    // 计算隐藏层状态    for (int i = 0; i &lt; HIDDEN_SIZE; i++) &#123;        rnn-&gt;hidden[i] = 0;        for (int j = 0; j &lt; INPUT_SIZE; j++) &#123;            rnn-&gt;hidden[i] += rnn-&gt;input[j] * weights-&gt;weight_ih[j][i];        &#125;        for (int j = 0; j &lt; HIDDEN_SIZE; j++) &#123;            rnn-&gt;hidden[i] += rnn-&gt;hidden[j] * weights-&gt;weight_hh[j][i];        &#125;        sigmoid(&amp;rnn-&gt;hidden[i]);    &#125;        // 计算输出层状态    for (int i = 0; i &lt; OUTPUT_SIZE; i++) &#123;        rnn-&gt;output[i] = 0;        for (int j = 0; j &lt; HIDDEN_SIZE; j++) &#123;            rnn-&gt;output[i] += rnn-&gt;hidden[j] * weights-&gt;weight_ho[j][i];        &#125;        sigmoid(&amp;rnn-&gt;output[i]);    &#125;&#125;int main() &#123;    RNN rnn;    RNNWeights weights;        // 初始化输入    rnn.input[0] = 0.5;    rnn.input[1] = 0.3;        // 初始化权重    for (int i = 0; i &lt; INPUT_SIZE; i++) &#123;        for (int j = 0; j &lt; HIDDEN_SIZE; j++) &#123;            weights.weight_ih[i][j] = ((double) rand() /\n\n用Python语言实现一段RNN神经网络算法\nimport numpy as np\nclass RNN:    def init(self, input_size, hidden_size, output_size):        self.input_size = input_size        self.hidden_size = hidden_size        self.output_size = output_size\n    # 初始化权重矩阵\n    self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n    self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n    self.Why = np.random.randn(output_size, hidden_size) * 0.01\n    \n    # 初始化偏置项\n    self.bh = np.zeros((hidden_size, 1))\n    self.by = np.zeros((output_size, 1))\n    \ndef forward(self, inputs):\n    xs, hs, ys, ps = &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;\n    \n    hs[-1] = np.zeros((self.hidden_size, 1))\n    \n    for t in range(len(inputs)):\n        xs[t] = np.zeros((self.input_size, 1))\n        xs[t][inputs[t]] = 1\n        \n        hs[t] = np.tanh(np.dot(self.Wxh, xs[t]) + np.dot(self.Whh, hs[t-1]) + self.bh)\n        \n        ys[t] = np.dot(self.Why, hs[t]) + self.by\n        \n        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t]))\n        \n    return ps\n\ndef backward(self, inputs, targets):\n    dWxh, dWhh ,dWhy= np.zeros_like(self.Wxh),np.zeros_like(self.Whh),np.zeros_like(self.Why)\n    \n    dbh,dby=np.zeros_like(self.bh),np.zeros_like(self.by)\n    \n     p=self.forward(inputs)\n     dhnext=np.zeros_like(hs[0])\n    \n     for t in reversed(range(len(inputs))):\n         dy=np.copy(ps[t])\n         dy[targets[t]]-=1\n         \n         dWhy+=np.dot(dy,hs[t].T)\n         \n         dby+=dy\n         \n         dh=np.dot(self.Why.T,dy)+dhnext\n         \n         dhraw=(1-hs[t]*hs[t]) * dh  #反向传播到隐藏层的梯度\n         \n        dbh+=dhraw\n        \n        dWxh+=np.dot(dhraw,xs[t].T)\n        \n        dWhh+=np.dot(dhraw,hs[t-1].T)\n        \n        dhnext=np.dot(self.Whh.T,dhraw)\n        \n    return (dWxh,dWhh,dWhy,dbh,dby)\n\ndef update_parameters(self, dWxh, dWhh, dWhy, dbh, dby):\n    learning_rate = 0.01\n    \n    self.Wxh -= learning_rate * dWxh\n    self.Whh -= learning_rate * dWhh\n    self.Why -= learning_rate * dWhy\n    \n    self.bh -= learning_rate * dbh\n    self.by -= learning_rate * dby\n    \ndef train(self, inputs, targets):\n    ps=self.forward(inputs)\n    \n    loss=-np.sum(np.log(ps[np.arange(len(targets)),targets.flatten()]))\n    \n    gradients=self.backward(inputs,targets)\n    \n     self.update_parameters(*gradients)\n     \n     return loss\n\n神经网络中的时间窗口指是什么？\n在神经网络中，时间窗口是指在处理时间序列数据时，模型所考虑的过去时间步数。它可以看作是一个固定长度的历史信息窗口，在每个时间步上，模型只会考虑这个窗口内的数据。\n时间窗口的大小可以根据具体任务和数据特点进行选择。较小的时间窗口可以捕捉到更短期的关系和趋势，但可能会忽略较长期的依赖关系；较大的时间窗口则可以更好地捕捉到长期依赖关系，但可能会增加计算复杂度和内存消耗。\n在一些特定的神经网络模型中，如循环神经网络（RNN）和长短期记忆网络（LSTM），隐状态会通过时间步传递并存储过去一段时间窗口内的信息。这些模型能够利用时间窗口来建模序列中不同时间步之间的依赖关系，并进行预测或分类等任务。\n神经网络中序列数组，为什么叫做时间序列，和时间有什么关系\n在神经网络中，序列数组是指具有时间顺序的数据。它们被称为时间序列是因为它们的值按照时间的先后顺序排列。\n时间序列数据通常是在一段连续的时间内按照一定频率记录的观测值或测量数据。这些数据可以是以秒、分钟、小时、天、月或年为单位进行采集的。每个时间点上的观测值都与之前和之后的时间点相关联，因此在处理这类数据时，考虑了时间顺序可以提供更多有用的信息。\n神经网络中使用时间序列数据时，通常会利用前一个时间点（或一系列前面的时间点）上观测值对当前时间点上的观测值进行预测或分类。例如，在自然语言处理中，可以使用循环神经网络（RNN）来处理词语组成的句子，其中每个词语都被视为一个时间步骤。通过利用句子中前面出现过的单词来预测下一个单词，RNN可以生成连贯和上下文相关的文本。\n因此，将具有时间顺序排列的数组称为“时间序列”是因为这种排列方式与数据本身存在着紧密关联，并且使得我们能够更好地利用过去和未来观测值之间的关系来进行预测或分析。\n字符串转换的LSTM算法训练数据序列如何与时间产生联系\n在LSTM算法中，输入数据序列与时间的联系是通过将时间步骤信息作为输入特征之一来建立的。具体而言，训练数据序列中的每个样本都包含一个或多个时间步骤的输入和输出。\n对于字符串转换任务，可以将每个字符作为一个时间步骤，并将其编码为向量形式作为输入特征。例如，可以使用one-hot编码将每个字符表示为一个向量，其中向量的长度等于字母表的大小。\n对于训练数据序列中的每个样本，LSTM模型会按照时间顺序逐步处理输入特征，并生成相应的输出。在每个时间步骤上，LSTM单元会接收当前时间步骤的输入特征以及前一个时间步骤的隐藏状态和记忆状态，并产生当前时间步骤的输出和下一个时间步骤的隐藏状态和记忆状态。\n通过这种方式，LSTM模型能够学习到输入数据序列中不同时间步骤之间的关系，并在预测时利用这些关系来生成正确的输出。因此，在训练过程中，输入数据序列与时间产生了联系，并且模型能够捕捉到这种联系以提高预测准确性。\nLSTM的样本数据中， 数据结构中那些变量与时间相关， 用Python描述\n在LSTM的样本数据中，与时间相关的变量有输入序列、输出序列和隐藏状态。\n\n输入序列：它是一个由多个时间步组成的序列，每个时间步都有一个输入向量。在Python中，可以使用列表或NumPy数组来表示输入序列。例如，如果有10个时间步，每个时间步的输入向量维度为3，则可以使用以下代码表示一个输入序列：\n1input_sequence = [[1, 2, 3], [4, 5, 6], ..., [28, 29, 30]]\n输出序列：它也是一个由多个时间步组成的序列，每个时间步都有一个输出向量。与输入序列类似，在Python中可以使用列表或NumPy数组来表示输出序列。例如，如果有10个时间步，每个时间步的输出向量维度为2，则可以使用以下代码表示一个输出序列：\n1output_sequence = [[0.1, 0.2], [0.3, 0.4], ..., [0.9, 1.0]]\n隐藏状态：它是LSTM模型中用于存储过去信息和传递给未来的信息的变量。隐藏状态通常在每个时间步更新，并且会影响下一个时间步的输出和隐藏状态。在Python中，可以使用列表或NumPy数组表示隐藏状态。例如，如果有10个时间步，并且隐藏状态维度为5，则可以使用以下代码表示隐藏状态：\n1hidden_state = [[0.1, 0.2, 0.3, 0.4, 0.5], [0.2, 0.3, 0.4, 0.5, 0.6], ..., [1.0, 1.1, 1.2, 1.3, 1.4]]\n注意，以上只是示例代码，具体的实现方式可能因具体的LSTM库而异。\n\n\nLSTM的神经单元，用C语言描述怎么描述。\n在C语言中，可以使用结构体来描述LSTM（长短期记忆）的神经单元。以下是一个示例的C语言代码：\n123456789101112131415161718192021222324252627282930313233343536373839typedef struct &#123;    float *weights_input;    float *weights_hidden;    float *bias;    float *input_gate;    float *forget_gate;    float *output_gate;    float *cell_state;    int input_size;    int hidden_size;&#125; LSTMCell;void lstm_cell_forward(LSTMCell* cell, const float* input) &#123;    // 计算输入门    for (int i = 0; i &lt; cell-&gt;hidden_size; i++) &#123;        cell-&gt;input_gate[i] = 0.0f;        for (int j = 0; j &lt; cell-&gt;input_size; j++) &#123;            cell-&gt;input_gate[i] += input[j] * cell-&gt;weights_input[i*cell-&gt;input_size + j];        &#125;        cell-&gt;input_gate[i] += cell-&gt;bias[i];        cell-&gt;input_gate[i] = sigmoid(cell-&gt;input_gate[i]);    &#125;    // 计算遗忘门    // ...    // 计算细胞状态    // ...    // 计算输出门   // ...&#125;float sigmoid(float x) &#123;   return 1.0 / (1.0 + exp(-x));&#125;\n\n在这个示例中，LSTMCell结构体包含了LSTM单元的权重、偏置和各个门的输出。lstm_cell_forward函数用于计算LSTM单元的前向传播。在这个函数中，我们首先计算输入门，然后计算遗忘门、细胞状态和输出门。sigmoid函数用于进行激活函数的计算，这里简单地使用了Sigmoid函数。\nLSTM神经网络算法，用使用GPU吗？ 还是只使用CPU训练就行了？\nLSTM神经网络算法可以使用GPU进行训练，而不仅限于CPU。使用GPU进行训练可以显著加快训练速度，因为GPU具有并行计算能力，能够同时处理多个计算任务。在深度学习中，LSTM模型通常包含大量的参数和复杂的计算步骤，使用GPU可以加速这些计算过程。因此，如果有可用的GPU资源，建议使用GPU进行LSTM神经网络的训练。\n如何基于Python语言，利用GPU做正常URL和异常URL样本的LSTM训练？\n使用Python语言和GPU做LSTM训练\n要使用Python语言和GPU进行LSTM训练，你需要确保在你的机器上安装了以下库：\n\nTensorFlow：一个流行的深度学习库，可以在GPU上运行。\nKeras：一个高级神经网络API，可以在TensorFlow上运行。\nCUDA：NVIDIA提供的并行计算平台，用于在GPU上加速计算。\n\n一旦你安装了这些库，你可以按照以下步骤进行LSTM训练：\n\n导入所需的库：\n123import tensorflow as tffrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import LSTM, Dense\n配置GPU：\n12physical_devices = tf.config.list_physical_devices(&#x27;GPU&#x27;)tf.config.experimental.set_memory_growth(physical_devices[0], True)\n这将配置你的GPU以进行内存增长。\n\n构建LSTM模型：\n123model = Sequential()model.add(LSTM(128, input_shape=(timesteps, data_dim)))model.add(Dense(num_classes, activation=&#x27;softmax&#x27;))\n这是一个简单的LSTM模型，其中包含一个LSTM层和一个全连接层。你可以根据你的需求更改层数和参数。\n\n编译模型：\n1model.compile(loss=&#x27;categorical_crossentropy&#x27;, optimizer=&#x27;adam&#x27;, metrics=[&#x27;accuracy&#x27;])\n在编译模型时，你可以选择适当的损失函数、优化器和评估指标。\n\n加载数据并进行训练：\n1model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs)\n在这里，你需要提供训练数据x_train和对应的标签y_train。你还可以设置批大小和训练的轮数。\n\n\n这是一个简单的使用Python语言和GPU进行LSTM训练的示例。你可以根据你的具体需求进行调整和扩展。\n用Python语言，将正常的URL数据集和异常URL的数据集，转换成LSTM模型可以用于训练的时序数据。\n要将URL数据集转换为LSTM模型可以用于训练的时序数据，可以按照以下步骤进行操作：\n\n导入所需的库：\n123import numpy as npfrom keras.preprocessing.sequence import pad_sequencesfrom keras.utils import to_categorical\n定义函数将URL转换为时序数据：\n12345def url_to_sequence(url):    sequence = []    for char in url:        sequence.append(ord(char))    return sequence\n加载正常URL数据集和异常URL数据集：\n12normal_urls = [&#x27;http://www.example.com&#x27;, &#x27;https://www.google.com&#x27;, ...]abnormal_urls = [&#x27;http://www.example.com/attack&#x27;, &#x27;https://malicious-site.com&#x27;, ...]\n将正常URL和异常URL转换为时序数据：\n12normal_sequences = [url_to_sequence(url) for url in normal_urls]abnormal_sequences = [url_to_sequence(url) for url in abnormal_urls]\n对时序数据进行填充，使其长度一致：\n123max_length = max(max(len(sequence) for sequence in normal_sequences), max(len(sequence) for sequence in abnormal_sequences))normal_sequences = pad_sequences(normal_sequences, maxlen=max_length)abnormal_sequences = pad_sequences(abnormal_sequences, maxlen=max_length)\n创建标签并合并正常URL和异常URL的时序数据：\n1234normal_labels = np.zeros(len(normal_sequences))abnormal_labels = np.ones(len(abnormal_sequences))sequences = np.concatenate((normal_sequences, abnormal_sequences), axis=0)labels = np.concatenate((normal_labels, abnormal_labels), axis=0)\n对标签进行独热编码：\n1labels = to_categorical(labels)\n\n现在，你可以使用sequences作为输入数据，labels作为目标数据来训练LSTM模型了。\n写一段Python代码使用GPU计算1+1\nimport torch\n检查GPU是否可用device = torch.device(“cuda” if torch.cuda.is_available() else “cpu”)\n创建输入张量x = torch.tensor([1.0], device=device)\n在GPU上进行计算y = x + x\n将结果移到CPU上result = y.cpu().item()\nprint(result)\n用python torch 对异常和正常的URL进行训练，使用GPU\n要使用Python的torch库对异常和正常的URL进行训练并使用GPU，首先需要安装torch和torchvision库。可以使用以下命令进行安装：\n1pip install torch torchvision\n\n接下来，需要准备数据集。假设你有一个包含异常和正常URL的CSV文件，其中一列包含URL，另一列包含标签（1表示异常，0表示正常）。你可以使用pandas库加载CSV文件并将其转换为PyTorch张量。\n1234567891011121314151617181920import pandas as pdimport torch# 加载CSV文件data = pd.read_csv(&#x27;your_dataset.csv&#x27;)# 提取URL列和标签列urls = data[&#x27;url&#x27;].valueslabels = data[&#x27;label&#x27;].values# 将URL转换为PyTorch张量url_tensors = []for url in urls:    url_tensor = torch.tensor([ord(c) for c in url], dtype=torch.float)    url_tensors.append(url_tensor)url_tensors = torch.stack(url_tensors)# 将标签转换为PyTorch张量label_tensors = torch.tensor(labels, dtype=torch.long)\n\n接下来，需要创建一个自定义的数据集类来加载数据。\n123456789101112from torch.utils.data import Datasetclass URLDataset(Dataset):    def __init__(self, urls, labels):        self.urls = urls        self.labels = labels            def __len__(self):        return len(self.urls)        def __getitem__(self, index):        return self.urls[index], self.labels[index]\n\n然后，将数据集分割为训练集和验证集。\n1234567891011from sklearn.model_selection import train_test_split# 定义训练集和验证集的比例train_ratio = 0.8# 将数据集分割为训练集和验证集train_urls, val_urls, train_labels, val_labels = train_test_split(urls, labels, train_size=train_ratio)# 创建训练集和验证集的数据集实例train_dataset = URLDataset(train_urls, train_labels)val_dataset = URLDataset(val_urls, val_labels)\n\n接下来，创建一个数据加载器来加载数据。\n12345678from torch.utils.data import DataLoader# 定义批量大小batch_size = 32# 创建训练集和验证集的数据加载器train_loader = DataLoader(train_dataset, batch_size=batch_size)val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n然后，定义一个模型。这里使用一个简单的多层感知机模型。\n12345678910111213141516import torch.nn as nnclass URLClassifier(nn.Module):    def __init__(self):        super(URLClassifier, self).__init__()        self.fc1 = nn.Linear(1000, 256)        self.fc2 = nn.Linear(256, 64)        self.fc3 = nn.Linear(64, 2)            def forward(self, x):        x = nn.functional.relu(self.fc1(x))        x = nn.functional.relu(self.fc2(x))        x = self.fc3(x)        return xmodel = URLClassifier()\n\n接下来，定义损失函数和优化器。\n1234import torch.optim as optimcriterion = nn.CrossEntropyLoss()optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n然后，定义训练循环。\n1234567891011121314151617181920212223242526device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)model.to(device)criterion.to(device)# 定义训练循环的迭代次数num_epochs = 10for epoch in range(num_epochs):    running_loss = 0.0        for urls, labels in train_loader:        urls = urls.to(device)        labels = labels.to(device)                optimizer.zero_grad()                outputs = model(urls)        loss = criterion(outputs, labels)        loss.backward()        optimizer.step()                running_loss += loss.item()        # 在每个epoch结束时打印损失    print(f&#x27;Epoch &#123;epoch + 1&#125;/&#123;num_epochs&#125;, Loss: &#123;running_loss / len(train_loader)&#125;&#x27;)\n\n最后，可以使用验证集评估模型的性能。\n12345678correct = 0total = 0with torch.no_grad():    for urls, labels in val_loader:        urls = urls.to(device)        labels = labels.to(device)\n\n\n用tensorflow的LSTM模型，训练，正常的URL和异常的URL，然后，用一个正常的URL进行验证。\n要使用TensorFlow的LSTM模型进行训练和验证正常的URL和异常的URL，您可以按照以下步骤进行操作：\n\n数据准备：\n\n收集正常的URL和异常的URL数据集。\n将每个URL转换为一个向量表示，可以使用词袋模型或者其他文本表示方法。\n根据需要将数据集分为训练集和验证集。\n\n\n模型构建：\n\n使用TensorFlow构建LSTM模型。\n定义输入层、LSTM层和输出层。\n选择合适的损失函数和优化器。\n\n\n模型训练：\n\n使用训练数据集训练LSTM模型。\n通过反向传播算法更新模型参数，以减小损失函数值。\n迭代多次，直到模型收敛或达到预设迭代次数。\n\n\n模型评估：\n\n使用验证数据集对已训练好的模型进行评估，计算准确率、精确率、召回率等指标。\n\n\n验证正常URL：\n\n将要验证的正常URL转换为向量表示。\n使用已经训练好的LSTM模型对该向量进行预测，并输出预测结果。\n\n\n\n注意：以上是一个基本框架，具体实现过程中可能需要根据具体情况进行调整和优化。\n","slug":"kanbanfiles/人工神经网络的激活算法","date":"2024-03-14T06:15:59.718Z","categories_index":"AIGC","tags_index":"激活函数","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"如何通过开源的以太坊项目，通过提供编码或者技术赚钱？\n通过开源的以太坊项目，可以通过以下几种方式提供编码或技术来赚钱：\n\n提供定制化的智能合约开发：以太坊是一个智能合约平台，可以创建各种类型的智能合约来满足不同业务需求。你可以提供定制化的智能合约开发服务，为企业或个人创建他们需要的智能合约，并收取相应的费用。\n\n参与去中心化应用（DApp）开发：以太坊上有许多去中心化应用（DApp），你可以选择参与这些项目的开发。作为开发者，你可以通过贡献代码、解决bug、添加新功能等方式来为这些项目提供技术支持，并获得相应的奖励或报酬。\n\n提供安全审计服务：在以太坊上部署的智能合约存在一定的风险，可能会被黑客攻击或存在漏洞。作为安全审计专家，你可以对智能合约进行审计，识别潜在的安全风险并提供解决方案。这样做不仅可以帮助保护用户资产安全，也可以为你带来收入。\n\n创建和销售自己的以太坊相关产品：除了参与项目开发，你还可以开发自己的以太坊相关产品并销售。例如，你可以创建一个以太坊钱包应用或交易所应用，并通过应用内购买、广告等方式来获得收益。\n\n提供培训和咨询服务：由于以太坊技术相对复杂，许多人可能需要学习和咨询相关知识。作为专家，你可以提供培训和咨询服务，帮助他人了解以太坊的工作原理、开发技术等，并据此收取费用。\n\n\n需要注意的是，赚钱并不仅限于提供编码或技术服务，还可以通过参与以太坊社区、开展研究、撰写技术文章等方式来建立个人品牌和影响力，并从中获得其他机会和收益。\n如何实现对智能合约进行安全审计？\n要实现对智能合约进行安全审计，可以遵循以下步骤：\n\n静态分析：通过使用工具和技术，对智能合约源代码进行静态分析。这可以帮助发现潜在的漏洞和安全风险，例如重入攻击、整数溢出等。\n\n动态测试：通过模拟不同的交易场景和输入数据，对智能合约进行动态测试。这可以帮助检测合约在不同情况下的行为，并发现可能存在的漏洞。\n\n安全审计工具：使用专门的安全审计工具来检查智能合约代码中的弱点和漏洞。这些工具可以自动化一些安全审计任务，并提供有关潜在问题的详细报告。\n\n智能合约最佳实践：了解并遵循智能合约开发的最佳实践，以减少潜在的安全风险。这包括使用已经验证过的库、避免使用不安全的编码模式等。\n\n安全审计公司或专家：寻求专业的安全审计公司或专家来审核您的智能合约代码。他们具有丰富的经验和知识，可以帮助您发现并解决潜在的安全问题。\n\n社区审查：将您的智能合约代码分享给社区进行审查和反馈。开源社区可以提供有价值的意见和建议，帮助您改进代码质量和增加安全性。\n\n\n值得注意的是，智能合约的安全审计是一个持续的过程，应该在开发、部署和更新合约时进行。同时，及时跟踪并关注智能合约领域的最新安全漏洞和攻击技术也是非常重要的。\n智能合约代码是开源的吗？\n智能合约代码可以是开源的，也可以是闭源的。开源意味着合约的代码可以公开查看和使用，任何人都可以审查和修改代码。闭源则意味着合约的代码不公开，只有合约创建者才能访问和修改代码。在区块链领域，许多智能合约平台提供了开源的智能合约模板和库，以便开发者可以自由使用和共享。但是某些特定的商业项目可能会选择闭源智能合约来保护其商业机密或技术优势。\n以太坊是什么\n以太坊是一种基于区块链技术的开源平台，旨在构建分布式应用程序。它是一个去中心化的计算平台，可以执行智能合约，并通过以太币（Ether）进行交易。\n以太坊与比特币类似，都是使用区块链技术来实现去中心化和安全性。然而，以太坊不仅仅是一种数字货币，还提供了一个完整的编程环境，允许开发者构建和部署智能合约。\n智能合约是一种自动执行的合约，其中包含了预先定义好的规则和条件。它们可以用于创建各种应用程序，如去中心化金融（DeFi）、数字身份验证、供应链管理等。\n以太坊平台上的智能合约是由Solidity编程语言编写的，并且部署在区块链上。这些合约可以被所有参与者验证和执行，并且无法被篡改或删除。\n除了智能合约外，以太坊还支持去中心化应用程序（DApps）。DApps是基于区块链技术构建的应用程序，具有高度透明性、安全性和可靠性。\n总之，以太坊是一个为开发者提供了构建和部署分布式应用程序的平台，通过智能合约和以太币实现了去中心化和安全性。它在加密货币领域以及其他许多行业都具有广泛的应用潜力。\n以太坊开发的那些应用可以赚钱？\n以太坊开发的应用有很多种，其中一些可以赚钱的应用包括：\n\n去中心化金融（DeFi）应用：以太坊上的DeFi应用提供了各种金融服务，如借贷、存款、交易等。通过参与这些应用，用户可以获得利息、奖励或者通过投资加密资产赚取收益。\n\n加密货币交易所：以太坊上有许多加密货币交易所，用户可以在这些平台上进行交易，并通过手续费或者市场波动赚取利润。\n\n去中心化应用（DApp）开发：作为以太坊的智能合约平台，开发DApp可以为用户提供各种服务，并通过用户使用、广告或者收费模式获得收入。\n\n游戏和虚拟世界：以太坊上有一些基于区块链技术的游戏和虚拟世界。玩家可以通过游戏内物品的买卖、租借等方式赚取代币或者实际货币。\n\n代币发行和众筹：以太坊是一个支持代币发行和众筹的平台，通过自己发行代币并进行销售，可以获得募资。\n\n\n需要注意的是，以上提到的应用都存在风险，并且赚钱的结果取决于市场条件和用户参与情况。在选择参与这些应用时，务必谨慎评估风险和了解相关法规。\n以太坊DAO分享文章如何赚钱有收益？\n以太坊DAO是一个去中心化自治组织，它允许用户共同管理和运营一个项目或平台。在以太坊DAO中分享文章可以通过以下方式赚钱和获得收益：\n\n发布付费文章：以太坊DAO可以设定订阅费用或附加费用来访问特定的付费文章。这样一来，用户需要支付一定数量的以太币（ETH）才能阅读这些文章。作者可以从这些付费中获得收益。\n\n接受捐赠：以太坊DAO支持智能合约，可以设置捐赠功能。读者可以对喜欢的文章作者进行捐赠，而这些捐赠将直接发送到作者的钱包地址。\n\n广告和推广：以太坊DAO可以通过展示广告或推广特定产品来获得收益。作为文章的创作者，你可以与相关企业或品牌合作，在你的文章中展示他们的广告或进行推广，并从中获得佣金。\n\n代币奖励：有些以太坊DAO项目会发行自己的代币，并通过奖励内容创作者来鼓励他们为该项目作出贡献。你可以根据每个项目的规则和要求，参与并贡献你的文章，以获得相应的代币奖励。\n\n购买和出售文章：以太坊DAO可以提供一个市场，允许用户购买和出售文章。如果你是一位经验丰富的作者，你可以将自己的文章放在市场上，等待有人购买。这样一来，你可以通过销售文章获得收益。\n\n社区奖励：以太坊DAO通常有一个活跃的社区，他们会对为社区作出贡献的成员进行奖励。如果你在社区中分享了有价值的文章并受到认可，你可能会获得社区奖励。\n\n\n总之，在以太坊DAO中分享文章可以通过多种方式赚钱和获得收益。具体方法取决于每个DAO项目的规则和设定。\n以太坊的DAO是什么的缩写？\n以太坊的DAO是指去中心化自治组织（Decentralized Autonomous Organization）。\n以太坊最大社区的网站的网址是什么？\n以太坊最大社区的网站是ethereum.org。\n以太坊的英文是什么？\n以太坊的英文是Ethereum。\n以太坊是什么意思\n以太坊是一种开源的区块链平台，旨在支持智能合约的运行。它是由维塔利克·布特林（Vitalik Buterin）于2013年提出，并于2015年正式上线。以太坊使用了自己的加密货币以太币（Ether），作为其经济系统的燃料，用于支付交易费用和奖励矿工。\n以太坊不仅仅是一种数字货币，更重要的是它提供了一个开放平台，可以构建和部署去中心化应用程序（DApps）。通过智能合约，开发者可以在以太坊平台上创建和执行自动化的、不受干预的合约。这些合约可以用于实现各种功能，如数字资产交易、投票系统、去中心化金融服务等。\n以太坊的目标是建立一个去中心化的互联网应用平台，使得用户能够直接进行价值交换和信息传递，而无需依赖第三方机构。它具有可扩展性、安全性和灵活性等特点，并且得到了全球范围内开发者和社区的广泛支持。\nzk-rollup是什么意思\nzk-rollup是一种扩展以太坊区块链的解决方案，旨在提高可扩展性和性能。它通过将大量交易打包并在以太坊主链之外进行处理，从而减轻了主链的负担。zk-rollup使用零知识证明来确保交易的正确性和安全性，同时还可以实现隐私保护。这种技术可以大幅降低交易成本，并提高交易速度和吞吐量。\n零知识指的是什么？\n零知识是一种密码学概念，指的是在交互式证明协议中，证明者可以向验证者证明某个陈述的真实性，而不泄露任何关于这个陈述的额外信息。换句话说，验证者只能确认陈述的真实性，但无法获取除此之外的任何知识。这种技术可以用于保护隐私和确保安全的通信。\nzk-rollup技术的代码如何编写提交？\n要编写和提交zk-rollup技术的代码，您可以按照以下步骤进行操作：\n\n理解zk-rollup的工作原理和设计目标。zk-rollup是一种扩展以太坊网络容量的解决方案，它利用零知识证明（Zero-Knowledge Proofs）来将多个交易批量处理并压缩成一条交易。\n\n选择合适的编程语言和开发环境。根据您的喜好和经验，选择适合您的编程语言和开发环境。常见的选择包括Solidity、Rust、JavaScript等。\n\n设置开发环境。安装所选编程语言的开发工具链，并确保您正确设置了zk-rollup所需的依赖项和库。\n\n编写zk-rollup代码。根据zk-rollup设计规范，开始编写相关代码。这可能涉及到处理交易、验证零知识证明、构建Merklized Abstract Syntax Tree（MAST）等功能。\n\n进行单元测试。为您的代码编写单元测试，以确保其在各种情况下都能正常工作，并且能够正确处理各种边界条件。\n\n完成整体集成测试。将您的代码与其他相关组件集成，并进行整体集成测试。确保您的代码与其他系统正常协同工作，并且能够满足整体系统的性能和可靠性要求。\n\n进行代码审查和优化。邀请其他开发人员对您的代码进行审查，并根据他们的反馈进行必要的修改和优化。\n\n提交代码。将您的代码提交到版本控制系统（如Git），并确保您的代码符合项目所使用的代码风格和规范。\n\n进行持续集成和部署。配置持续集成工具，并将您的代码自动构建、测试和部署到目标环境中。\n\n参与社区讨论和反馈。积极参与zk-rollup社区讨论，与其他开发者分享您的经验和问题，并从他们那里获取反馈和建议。\n\n\n请注意，这只是一个基本的指南，具体编写和提交zk-rollup技术代码可能会因项目需求而有所不同。在实际操作中，请参考相关文档、教程或向社区寻求帮助以获取更详细和准确的指导。\n有没有zk-rollup相关的网站和技术？\n是的，以下是一些与zk-rollup相关的网站和技术：\n\nzkSync：zkSync是一种基于zk-rollup的Layer 2扩容解决方案，它提供了高性能和低费用的以太坊交易处理。您可以在他们的官方网站上了解更多信息：https://zksync.io/\n\nLoopring：Loopring是一个基于以太坊的去中心化交易协议，它使用了zk-rollup技术来实现高吞吐量和低费用的交易。您可以访问他们的官方网站以获取更多详细信息：https://loopring.org/\n\nHermez Network：Hermez Network也是一个使用zk-rollup技术的Layer 2扩容协议，旨在提供高性能和低成本的加密货币支付解决方案。您可以在他们的官方网站上了解更多信息：https://hermez.io/\n\nMatter Labs：Matter Labs是一个专注于zk-rollup技术研究和开发的公司，他们开发了zkSync协议。您可以访问他们的网站以获取更多关于他们的工作和技术细节：https://matter-labs.io/\n\n\n这些都是与zk-rollup相关的一些主要网站和技术，您可以通过访问它们来深入了解有关zk-rollup及其应用领域的更多信息。\n如何通过向以太坊社区提交代码赚钱，操作步骤是什么？\n要通过向以太坊社区提交代码赚钱，您可以按照以下步骤操作：\n\n学习以太坊开发：了解以太坊的基本原理、智能合约的编写和部署、DApp开发等相关知识。可以通过在线教程、编程课程或参与开发者社区来学习。\n\n寻找问题或项目：浏览以太坊开发者社区，寻找有待解决的问题或正在进行的项目。这些问题可能包括bug修复、功能增强或新项目的开发。\n\n贡献代码：在确定了感兴趣的问题或项目后，开始贡献自己的代码。可以在GitHub等版本控制平台上创建自己的分支，并提交解决方案。确保遵循项目规范和最佳实践，并写好文档说明。\n\n寻求反馈：提交代码后，请求社区成员对您的工作进行审查和反馈。他们可能会提出改进意见或建议，帮助您改善代码质量。\n\n提交合并请求：在经过反复修改和改进之后，向项目负责人提交合并请求。他们会仔细审查您的代码，并决定是否将其合并到主分支中。\n\n获得奖励：如果您的代码被接受并合并到主分支中，您可能会获得奖励。这些奖励可能以以太币或其他形式的代币支付，具体取决于项目的奖励机制。\n\n\n请注意，赚取报酬需要具备一定的技术能力和专业知识。此外，参与开源项目是一个长期的过程，需要耐心和持续的努力。\n要学习以太坊开发，以下是一些建议：\n\n了解区块链基础知识：首先需要了解区块链的基本概念、工作原理和技术特点。可以通过阅读相关书籍、在线教程或参加培训课程来学习。\n\n学习智能合约：以太坊的核心功能是智能合约，这是在以太坊上运行的自动执行的程序。学习智能合约编写语言Solidity，并掌握如何编写、部署和测试智能合约。\n\n掌握开发工具：学习使用以太坊开发工具，如Remix（在线IDE）、Truffle（开发框架）和Ganache（本地区块链）等。这些工具可以帮助你更方便地进行合约开发和调试。\n\n学习Web3.js：Web3.js是以太坊官方提供的JavaScript库，它提供了与以太坊网络交互的API。学习如何使用Web3.js与以太坊节点进行通信，发送交易和读取区块链数据。\n\n参与实践项目：找到一些实际的以太坊开发项目，并积极参与其中。通过实践项目可以加深对以太坊开发的理解，并提升自己的实际操作能力。\n\n加入社区：加入以太坊开发者社区，与其他开发者交流经验和学习资源。参加以太坊相关的活动、讲座或会议，与业内专业人士进行交流和学习。\n\n持续学习和实践：区块链技术发展迅速，以太坊也在不断更新和演进。要保持学习的状态，关注最新的开发技术和行业动态，并不断进行实践和项目探索。\n\n\n总之，学习以太坊开发需要一定的基础知识和技能，同时也需要不断地实践和积累经验。通过深入学习和实践，你可以成为一名合格的以太坊开发者。以太坊开发如何学习？\n如何运行以太坊？\n要运行以太坊，您需要遵循以下步骤：\n\n安装以太坊客户端：以太坊有几个不同的客户端可供选择，包括Geth、Parity和Besu等。根据您的需求选择一个适合您的客户端，并按照它们的安装指南进行安装。\n\n同步区块链数据：一旦安装了以太坊客户端，您需要通过同步区块链数据来获取最新的区块链状态。这个过程可能需要一些时间，因为它涉及下载和验证大量的数据。\n\n创建钱包地址：在以太坊上运行时，您需要一个钱包地址来接收和发送以太币或其他代币。您可以使用以太坊客户端来创建一个新的钱包地址。\n\n运行节点：使用命令行或图形界面界面启动以太坊客户端，并连接到主网络或测试网络。在启动节点后，它将开始同步区块链数据并接收交易。\n\n开发智能合约（可选）：如果您计划开发自己的智能合约，则可以使用Solidity等编程语言编写智能合约，并使用相应的工具进行部署和测试。\n\n\n请注意，运行以太坊节点可能需要较高的计算资源和带宽。此外，了解以太坊的基本概念和原理也是有益的，以便更好地理解和管理您的节点。\n以太坊Defi套利\n以太坊DeFi套利是指通过利用以太坊上的不同DeFi平台之间的差价或机会，从中获得利润的交易策略。这种套利策略可以通过快速买卖资产、借贷和交易费用优化等方式来实现。\n以下是一些常见的以太坊DeFi套利策略：\n\n闪电贷款套利：通过使用闪电贷款协议，借入资金并在其他平台上获得更高的收益。这种套利策略依赖于快速执行，并且需要确保在还款前能够获得足够的利润。\n\n跨平台套利：通过在不同DeFi平台之间进行资产转移，以获取不同平台上的价格差异。例如，在一个平台上购买低价资产，然后在另一个平台上高价出售。\n\n流动性挖矿套利：通过参与多个流动性挖矿项目，同时获得不同代币的奖励。这种策略可以通过优化投入资本和选择高回报项目来实现。\n\n借贷费用优化：通过分析不同DeFi平台上的借贷费用，并选择最低费用的平台来借入资金。这可以最大程度地减少成本，并提高套利的利润。\n\n\n需要注意的是，DeFi市场非常动态和复杂，套利策略可能存在风险和不确定性。在进行任何套利交易之前，应该进行充分的研究和风险评估，并确保合规操作。同时，由于以太坊网络的拥堵和交易费用的高昂，执行速度和成本也是成功套利的关键因素。\n","slug":"kanbanfiles/以太坊","date":"2024-03-14T06:15:59.718Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"ATT&amp;CK技术指是什么？\nATT&amp;CK技术指的是一种用于描述和分类威胁行为的系统。ATT&amp;CK代表Adversarial Tactics, Techniques, and Common Knowledge（对抗性战术、技术和共享知识），是由MITRE公司开发并维护的一套框架。\nATT&amp;CK技术指描述了攻击者在网络攻击中使用的各种战术和技术，例如利用漏洞进行入侵、执行恶意代码、横向移动等。该框架将这些战术和技术按照不同的阶段和目标进行分类，以帮助安全团队了解攻击者的行为模式，并提供一种标准化的方式来描述和分析威胁。\nATT&amp;CK技术指可以被安全团队用于评估组织的安全防御能力，帮助发现潜在的漏洞并制定相应的对策。此外，它还可以用于共享关于威胁行为的信息，促进安全社区之间的合作与交流。\n","slug":"kanbanfiles/ATT&CK技术","date":"2024-03-14T06:15:59.717Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"如何用apt-get 安装CUDA 11.8\n很抱歉，但是 CUDA 11.8 并不是一个存在的版本。CUDA 最新的稳定版本是 CUDA 11.5。以下是安装 CUDA 11.5 的步骤：\n\n首先，确保你的系统满足 CUDA 11.5 的要求。CUDA 11.5 支持 Linux、Windows 和 macOS 系统。你需要一块支持 NVIDIA GPU 的显卡，并且需要安装相应的驱动程序。\n\n访问 NVIDIA 开发者网站（https://developer.nvidia.com/cuda-downloads）并下载适用于你操作系统的 CUDA Toolkit 安装包。\n\n在终端中运行以下命令以添加 CUDA 的软件源：\n123$ sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub$ sudo sh -c &#x27;echo &quot;deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64 /&quot; &gt; /etc/apt/sources.list.d/cuda.list&#x27;$ sudo apt update\n\n这些命令将添加 NVIDIA CUDA 软件源到你的系统。\n\n接下来，运行以下命令安装 CUDA Toolkit：\n1$ sudo apt install cuda\n\n这将自动下载和安装 CUDA Toolkit 及其依赖项。\n\n安装完成后，重启系统以使更改生效。\n\n验证安装是否成功，可以运行以下命令查看 CUDA 版本：\n1$ nvcc --version\n\n如果显示了 CUDA 版本信息，则表示安装成功。\n\n\n请注意，以上步骤适用于 Ubuntu 20.04 系统。如果你使用的是其他操作系统或版本，请参考 NVIDIA 官方文档以获取相应的安装指南。\n希望能对你有所帮助！\napt-get 安装软件，如何指定安装目录\n在apt-get命令中，无法直接指定软件的安装目录。apt-get是一个高级包管理工具，它会自动将软件安装到预定义的目录结构中。\n默认情况下，apt-get会将软件安装到以下目录：\n\n可执行文件：/usr/bin/\n库文件：/usr/lib/\n配置文件：/etc/\n文档文件：/usr/share/doc/\n\n如果你需要指定软件的安装目录，可以考虑使用源代码编译的方式进行安装。这样可以手动指定软件的安装路径。\n以下是使用源代码编译方式进行软件安装以及指定安装目录的步骤：\n\n下载并解压源代码包。\n进入解压后的源代码目录。\n执行配置命令 ./configure --prefix=/desired/installation/path 来指定安装路径。\n执行 make 命令进行编译。\n执行 sudo make install 命令进行安装。\n\n在上述步骤中，通过 --prefix=/desired/installation/path 参数来指定你希望软件被安装到哪个路径下。\n如何用CUDA安显卡的占用率要使用CUDA来监测显卡的占用率，可以按照以下步骤进行操作：\n\n安装CUDA Toolkit：首先，您需要下载并安装适用于您的显卡型号和操作系统的CUDA Toolkit。在NVIDIA官方网站上可以找到相关的下载链接。\n\n编写CUDA程序：使用支持CUDA的编程语言（如C++、Python等），编写一个简单的CUDA程序。在该程序中，您可以创建一个或多个CUDA核函数，并通过调用这些函数来执行并行计算任务。\n\n获取显卡占用率信息：在主机端的代码中，您可以使用NVIDIA提供的运行时API函数来获取有关显卡占用率的信息。具体而言，您可以使用cudaGetDeviceProperties函数获得有关当前设备（即显卡）的属性信息，包括设备名称、总共可用内存、最大线程数等等。此外，还可以使用cudaEventRecord和cudaEventElapsedTime等函数来计算GPU执行任务所需时间。\n\n输出占用率信息：将获取到的显卡属性信息和执行时间等结果输出到终端或日志文件中，以便后续分析和监测。\n\n\n需要注意的是，在进行显卡监测时，请确保您已正确地安装了适当版本的CUDA Toolkit，并且已正确配置了环境变量等相关设置。此外，还应遵循CUDA编程指南中的最佳实践，以确保您的CUDA程序能够正确地与显卡进行通信并利用其计算资源。\n希望以上内容对您有所帮助！\n 如何安Ubuntu上GPU的使用情况\n您可以使用以下命令来查看Ubuntu上GPU的使用情况：\n\n使用nvidia-smi命令来查看当前GPU的使用情况和相关信息。这个命令会显示当前系统中所有可用GPU的实时状态，包括GPU的使用率、显存使用情况、温度等。输入以下命令来运行nvidia-smi：\n\n1nvidia-smi\n\n\n使用nvidia-settings命令来查看和修改NVIDIA显卡的设置。该命令提供了一个图形界面，可以用于查看显卡信息、调整显示设置、监控温度和风扇速度等。输入以下命令来运行nvidia-settings：\n\n1nvidia-settings\n\n\n使用gpustat命令来查看当前系统中所有GPU的使用情况和相关信息。该命令会显示每个GPU的利用率、显存使用情况、温度等详细信息，并以表格形式展示。输入以下命令来安装并运行gpustat：\n\n12sudo apt-get install gpustatgpustat\n\n\n使用其他第三方工具如NVIDIA System Management Interface（NVSMI）或NVIDIA CUDA Toolkit提供的相关工具来获取更详细的GPU使用情况。\n\n请注意，要正确显示和获取GPU信息，您需要安装相应的驱动程序和工具包，并且您必须有适当的权限才能访问GPU信息。\nChatglm在做微调训练时，train.sh如何设置，CUDA同时使用两个显卡GPU要在Chatglm中进行微调训练并同时使用两个显卡GPU，可以按照以下步骤设置train.sh文件：\n\n打开train.sh文件并找到CUDA_VISIBLE_DEVICES这一行。该行用于设置可见的GPU设备。\n更改CUDA_VISIBLE_DEVICES的值为你想要使用的GPU设备的索引。例如，如果你有两个GPU设备，索引分别为0和1，则可以将其设置为”0,1”。\n确保你已经按照Chatglm的要求安装了正确版本的CUDA和cuDNN，并且在运行训练脚本之前已经正确配置了环境变量。\n运行train.sh脚本来启动微调训练。Chatglm将会自动检测并使用设置好的GPU设备。\n\n请注意，同时使用多个GPU设备进行训练可能需要更长的训练时间和更高的系统资源要求。确保你的系统满足这些要求，并根据需要进行相应配置。\nChatglm在做微调训练时，train.sh如何设置，CUDA同时使用两台主机上的两个显卡GPU， 多机多卡部署。在进行多机多卡部署时，可以使用分布式训练的方式来同时使用两台主机上的两个显卡GPU。具体来说，在train.sh文件中，可以按照以下步骤进行设置：\n\n安装和配置分布式训练所需的依赖项。确保在每台主机上都安装了CUDA和相应的驱动程序，并且所有主机都能够互相通信。\n\n修改train.sh文件，添加分布式训练相关的参数。下面是一个示例：\n\n\n1234567891011export CUDA_VISIBLE_DEVICES=0,1  # 设置使用的GPU索引python -m torch.distributed.launch --nproc_per_node=2 --use_env main.py \\--data_dir /path/to/data \\--model_name bert-base-uncased \\--output_dir /path/to/output \\--max_seq_length 128 \\--per_device_train_batch_size 8 \\--gradient_accumulation_steps 4 \\--learning_rate 2e-5 \\--num_train_epochs 3\n\n其中，CUDA_VISIBLE_DEVICES参数用于指定要使用的GPU索引。在这个例子中，我们设置为0和1表示使用第一台主机上的两个显卡。\ntorch.distributed.launch模块是PyTorch提供的用于启动分布式训练的工具。--nproc_per_node参数指定每个节点（即每台主机）上使用的GPU数量，在这里设置为2表示每台主机上同时使用两个显卡。\n其余参数根据具体情况进行设置，如输入数据路径（--data_dir）、模型名称（--model_name）、输出路径（--output_dir）、每个设备上的训练批次大小（--per_device_train_batch_size）等。\n\n在每台主机上运行train.sh脚本。确保在每台主机上都运行相同的脚本，并且指定了正确的参数。\n\n这样，两台主\nChatglm在做微调训练时，train.sh如何设置，CUDA，分布式指定，如何配置远程服务器的IP\n在进行ChatGPT微调训练时，可以使用train.sh文件来设置训练的各种参数。以下是一些常用的设置：\n\nCUDA设置：如果你的机器上有多个GPU，你可以使用CUDA_VISIBLE_DEVICES环境变量来指定要使用的GPU设备。例如，如果你要使用第一张和第三张GPU设备，则可以将该变量设置为”0,2”。\n\n分布式训练指定：如果你想进行分布式训练，需要指定分布式训练的相关参数，如–num_gpus和–num_nodes。–num_gpus用于指定每个节点上使用的GPU数量，而–num_nodes则用于指定参与训练的节点数量。\n\n配置远程服务器IP：如果你要将训练任务提交到远程服务器上执行，你需要在train.sh文件中配置远程服务器的IP地址。具体配置方法取决于你所使用的分布式训练框架。例如，在PyTorch中，你可以通过设置MASTER_ADDR和MASTER_PORT环境变量来指定主节点（即远程服务器）的IP地址和端口号。\n\n\n示例train.sh文件内容如下：\n123456789101112131415export CUDA_VISIBLE_DEVICES=&quot;0,2&quot;export MASTER_ADDR=192.168.1.100export MASTER_PORT=1234python train.py \\    --model_name_or_path gpt2 \\    --output_dir ./output \\    --do_train \\    --train_data_file ./data/train.txt \\    --per_device_train_batch_size 4 \\    --num_train_epochs 5 \\    --logging_steps 100 \\    --save_steps 1000 \\    --overwrite_output_dir \\    --fp16\n\n在上述示例中，我们指定了使用第一张和第三张GPU设备，将训练任务提交到IP地址为192.168.1.100的远程服务器上执行。其他训练参数根据实际需求进行设置。\n请注意，具体的设置可能因你所\n chatglm分布微调训练，如何配置MASTER_ADDR和MASTER_PORT变量\n在进行chatglm分布微调训练时，需要配置MASTER_ADDR和MASTER_PORT变量来指定主节点的地址和端口。\n\n首先，确定一个机器作为主节点。这个节点将负责协调整个训练过程。\n\n然后，在其他参与训练的机器上设置MASTER_ADDR和MASTER_PORT变量，将它们指向主节点的地址和端口。可以使用以下命令设置环境变量：\n12export MASTER_ADDR=&lt;主节点地址&gt;export MASTER_PORT=&lt;主节点端口号&gt;\n确保所有参与训练的机器都设置了相同的MASTER_ADDR和MASTER_PORT值。\n\n在启动每个参与训练的机器上运行相应的代码。代码将连接到指定的主节点，并与其他机器进行通信。\n\n\n请注意，这些步骤可能因具体使用的框架或工具而有所不同。确保查阅相关文档以了解正确的配置方法。\nChatGLM微调训练如何配置主结点的train.sh\nChatGLM微调训练的主结点的train.sh可以配置如下：\n\n首先，需要设置训练数据和验证数据的路径。可以使用--train_path参数指定训练数据的路径，--valid_path参数指定验证数据的路径。\n\n接下来，可以设置模型保存的路径。可以使用--save_dir参数指定模型保存的目录。\n\n然后，需要指定模型的超参数。例如，可以使用--learning_rate参数设置学习率，--batch_size参数设置批次大小。\n\n可以选择加载预训练模型进行微调。可以使用--pretrained_model_path参数指定预训练模型的路径。\n\n可以选择冻结部分层进行微调。可以使用--frozen_layers参数指定要冻结的层。\n\n可以设置训练轮数和打印信息频率。例如，可以使用--num_epochs参数设置训练轮数，--log_steps参数设置打印信息频率。\n\n可以选择是否启用混合精度训练。可以使用--fp16_opt_level O1/O2/O3/Off 参数启用混合精度训练，并通过调整优化级别来控制精度和性能之间的平衡。\n\n最后，可以运行主结点脚本开始微调训练。\n12345678910python -m paddle.distributed.launch --gpus &quot;0,1,2,3&quot; train.py \\--train_path /path/to/train_data \\--valid_path /path/to/valid_data \\--save_dir /path/to/save_model \\--learning_rate 0.001 \\--batch_size 32 \\--pretrained_model_path /path/to/pretrained_model \\--frozen_layers 6 \\--num_epochs 10 \\--log_steps 100\n\n以上是一个示例的配置，具体的参数\nchatglm的web_demo.sh如何配置指定IP和端口\n要配置chatglm的web_demo.sh指定IP和端口，可以按照以下步骤进行操作：\n\n打开web_demo.sh文件，可以使用文本编辑器（如vi、nano等）打开该文件。\n\n在文件中找到以下行：\n1python3 -m chatglm.web.serve\n在该行的末尾添加参数以指定IP和端口，例如：\n1python3 -m chatglm.web.serve --host 192.168.1.100 --port 8000\n\n这将使web_demo.sh在IP地址为192.168.1.100，端口为8000的主机上运行。\n\n保存并关闭文件。\n\n运行web_demo.sh脚本以启动chatglm的Web demo，并监听指定的IP和端口：\n1sh web_demo.sh\n\n现在，chatglm的Web demo将在指定的IP地址和端口上运行。\nchatGLM的web_demo.py运行时指定IP和端口\n要在chatGLM的web_demo.py运行时指定IP和端口，可以使用以下命令：\n1python web_demo.py --ip &lt;IP地址&gt; --port &lt;端口号&gt;\n\n其中，&lt;IP地址&gt;是你想要指定的IP地址，可以是本地主机的IP地址或者其他可用的IP地址。\n&lt;端口号&gt;是你想要指定的端口号，可以是任意未被占用的端口号。\n例如，如果你想将chatGLM的web_demo.py运行在本地主机的IP地址为127.0.0.1，端口号为5000上，可以使用以下命令：\n1python web_demo.py --ip 127.0.0.1 --port 5000\n\n这样，chatGLM将会在指定的IP地址和端口上运行。你可以通过访问http://&lt;IP地址&gt;:&lt;端口号&gt;来查看和使用chatGLM。\nchatglm的demo.queue().launch(share=False, inbrowser=True)指定IP\n在chatglm的demo中，queue().launch()函数的share和inbrowser参数不支持指定IP。\nqueue().launch(share=False)参数用于控制是否与其他用户共享会话。如果设置为True，则可以与其他用户共享同一个会话，而设置为False则会创建一个新的私有会话。\nqueue().launch(inbrowser=True)参数用于控制是否在浏览器中打开机器人对话界面。如果设置为True，则会在默认浏览器中打开对话界面，而设置为False则不会打开对话界面。\n但是，这些参数都没有提供指定IP的选项。\nchatglm运行web demo如何指定IP和端口号启动\n要指定IP和端口号启动chatglm的web demo，您可以按照以下步骤进行操作：\n\n打开app.py文件。\n在文件的顶部找到以下代码段：\n\n12if __name__ == &quot;__main__&quot;:    app.run(debug=True)\n\n\n在app.run()函数中添加参数来指定IP和端口号。例如，如果您想要将IP设置为127.0.0.1，端口号设置为5000，则将代码修改为如下：\n\n12if __name__ == &quot;__main__&quot;:    app.run(debug=True, host=&quot;127.0.0.1&quot;, port=5000)\n\n\n保存文件并关闭。\n\n现在，当您运行web demo时，它将在指定的IP和端口号上启动。\n如何用go启动的一个程序转127.0.0.1:7860给 0.0.0.0:7860\n你可以使用net包中的Listen函数来启动一个TCP服务器，然后将地址参数设置为”127.0.0.1:7860”。接下来，你可以使用Accept函数等待客户端连接，并将连接转发到”0.0.0.0:7860”上。\n下面是一个示例代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package mainimport (\t&quot;io&quot;\t&quot;log&quot;\t&quot;net&quot;)func main() &#123;\t// 启动TCP服务器\tlistener, err := net.Listen(&quot;tcp&quot;, &quot;127.0.0.1:7860&quot;)\tif err != nil &#123;\t\tlog.Fatal(err)\t&#125;\tdefer listener.Close()\tlog.Println(&quot;Server started on 127.0.0.1:7860&quot;)\tfor &#123;\t\t// 等待客户端连接\t\tconn, err := listener.Accept()\t\tif err != nil &#123;\t\t\tlog.Println(err)\t\t\tcontinue\t\t&#125;        // 将连接转发到新的地址        go forwardConnection(conn)    &#125;&#125;func forwardConnection(conn net.Conn) &#123;    // 连接到目标地址    targetConn, err := net.Dial(&quot;tcp&quot;, &quot;0.0.0.0:7860&quot;)    if err != nil &#123;        log.Println(err)        conn.Close()        return    &#125;        // 在两个连接之间复制数据    go func() &#123;        _, err := io.Copy(conn, targetConn)        if err != nil &amp;&amp; !isClosedError(err) &#123;            log.Println(err)        &#125;        conn.Close()        targetConn.Close()    &#125;()        _, err = io.Copy(targetConn, conn)    if err != nil &amp;&amp; !isClosedError(err) &#123;        log.Println(err)    &#125;        conn.Close()    targetConn.Close()&#125;func isClosedError(err error) bool &#123;    if opErr, ok := err.(*net.OpError); ok &#123;        return opErr.Err.Error() == &quot;use of closed network connection&quot;    &#125;    return false&#125;\n\n这样，你的程序就可以将来自”127.0.0.1:7860”的连接转发到”0.0.0.0:7860”上了。\n如何执行一段go代码\n要执行一段Go代码，您需要按照以下步骤进行操作：\n\n安装Go：首先，您需要安装Go编程语言。您可以从官方网站（https://golang.org/dl/）下载适用于您操作系统的安装包，并按照安装向导的指示进行安装。\n\n编写代码：使用任何文本编辑器编写您的Go代码，并将其保存为以.go为扩展名的文件。例如，您可以创建一个名为hello.go的文件，并在其中编写一个简单的“Hello, World!”程序。\n\n\n1234567package mainimport &quot;fmt&quot;func main() &#123;    fmt.Println(&quot;Hello, World!&quot;)&#125;\n\n\n打开终端或命令提示符：打开终端（Mac和Linux）或命令提示符（Windows），并导航到保存了您的代码文件的目录。\n\n构建程序：使用以下命令构建您的Go程序：\n\n\n1go build hello.go\n\n这将生成一个可执行文件（在Windows上是.exe文件，在其他操作系统上没有扩展名），其名称与源代码文件相同（在此示例中为hello）。\n\n运行程序：使用以下命令运行生成的可执行文件：\n\n1./hello\n\n如果一切顺利，您应该能够在终端或命令提示符中看到输出结果：“Hello, World!”\n请注意，如果您只想运行而不构建可执行文件，则可以使用以下命令直接运行Go代码：\n1go run hello.go\n\n这将编译并运行您的代码，而不会在硬盘上生成可执行文件。\nubuntu 22如何安装golang\n要在Ubuntu 22上安装Golang，请按照以下步骤进行操作：\n\n打开终端。\n\n使用以下命令下载Golang的二进制文件：\n1wget https://golang.org/dl/go1.17.linux-amd64.tar.gz\n\n这将下载Golang 1.17版本的二进制文件，你也可以根据需要选择其他版本。\n\n解压下载的文件：\n1sudo tar -C /usr/local -xzf go1.17.linux-amd64.tar.gz\n配置环境变量。编辑~/.profile文件：\n1nano ~/.profile\n在文件末尾添加以下内容：\n1export PATH=$PATH:/usr/local/go/bin\n按下Ctrl + X保存并退出编辑器。\n\n刷新配置：\n1source ~/.profile\n验证Golang是否成功安装。在终端中运行以下命令：\n1go version\n如果正确显示了Go的版本号，那么恭喜你，已成功安装Golang！\n\n\n现在你可以开始使用Golang开发应用程序了。祝你好运！\n","slug":"kanbanfiles/CUDA安装","date":"2024-03-14T06:15:59.717Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"如何用Go语言实现代理转发HTTP请求的流量，从80端口转发给实际服务上的8000端口。\n要使用Go语言实现代理转发HTTP请求的流量，可以使用net/http包和httputil包来处理。以下是一个简单的示例代码：\n12345678910111213141516171819202122232425262728293031package mainimport (\t&quot;log&quot;\t&quot;net/http&quot;\t&quot;net/http/httputil&quot;\t&quot;net/url&quot;)func main() &#123;\t// 创建反向代理的目标URL\ttargetURL, err := url.Parse(&quot;http://localhost:8000&quot;)\tif err != nil &#123;\t\tlog.Fatal(err)\t&#125;\t// 创建反向代理处理器\tproxy := httputil.NewSingleHostReverseProxy(targetURL)\t// 创建HTTP服务器\tserver := http.Server&#123;\t\tAddr:    &quot;:80&quot;,\t\tHandler: proxy,\t&#125;\tlog.Println(&quot;Starting server on :80...&quot;)\terr = server.ListenAndServe()\tif err != nil &#123;\t\tlog.Fatal(err)\t&#125;&#125;\n\n在上述代码中，我们首先创建了一个targetURL，它是实际服务所在的地址。然后，我们使用httputil.NewSingleHostReverseProxy()函数创建了一个反向代理处理器。最后，我们创建了一个HTTP服务器，并将反向代理处理器作为其处理程序。\n当有请求到达80端口时，HTTP服务器将会将请求转发给实际服务上的8000端口，并将响应返回给客户端。\n请注意，在运行此代码之前，请确保实际服务已经在8000端口上运行，并且您具有足够的权限来监听和使用80端口。\n用Go语言创建一个HTTP服务， 响应用户的请求， 并在服务后端打印出用户请求的URL和请求的IP。\n以下是使用Go语言创建一个HTTP服务的示例代码：\n1234567891011121314151617181920212223package mainimport (\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;net/http&quot;)func helloHandler(w http.ResponseWriter, r *http.Request) &#123;\t// 打印用户请求的URL和请求的IP\tfmt.Println(&quot;URL:&quot;, r.URL.Path)\tfmt.Println(&quot;IP:&quot;, r.RemoteAddr)\t// 响应用户请求\tfmt.Fprintf(w, &quot;Hello, World!&quot;)&#125;func main() &#123;\thttp.HandleFunc(&quot;/&quot;, helloHandler)\tlog.Println(&quot;Server started on localhost:8080&quot;)\tlog.Fatal(http.ListenAndServe(&quot;:8080&quot;, nil))&#125;\n\n在上面的示例代码中，我们定义了一个名为helloHandler的处理函数来处理用户的请求。在该函数中，我们打印了用户请求的URL和请求的IP，并通过fmt.Fprintf将”Hello, World!”作为响应返回给用户。\n在main函数中，我们使用http.HandleFunc将helloHandler函数与根路径”/“绑定。然后，我们调用http.ListenAndServe启动一个HTTP服务器，并指定监听地址为”:8080”。\n运行这个程序后，你可以在浏览器中访问”http://localhost:8080&quot;来发送一个GET请求。然后你将会在服务端看到类似以下输出：\n12URL: /IP: 127.0.0.1:57679\n\n其中URL是用户请求的路径，IP是用户请求的IP地址。\n用Go语言实现一个Web服务，处理用户的HTTP请求。\npackage main\nimport (    “fmt”    “log”    “net/http”)\nfunc main() {    http.HandleFunc(“/“, handler)    log.Fatal(http.ListenAndServe(“:8080”, nil))}\nfunc handler(w http.ResponseWriter, r *http.Request) {    fmt.Fprintf(w, “Hello, World!”)}\n要向Graylog4的GELF HTTP接口发送POST请求，可以使用任何HTTP客户端工具或编程语言来实现。下面是使用Python的示例代码：\n123456789101112131415161718import requestsurl = &#x27;http://graylog4-server:12201/gelf&#x27;  # 替换为你的Graylog4服务器地址和端口号data = &#123;    &quot;version&quot;: &quot;1.1&quot;,    &quot;host&quot;: &quot;example.com&quot;,    &quot;short_message&quot;: &quot;This is a test message&quot;,    &quot;timestamp&quot;: 1609459200,    &quot;level&quot;: 6&#125;response = requests.post(url, json=data)if response.status_code == 202:    print(&quot;Message sent successfully&quot;)else:    print(&quot;Failed to send message:&quot;, response.text)\n\n上述代码使用requests库发送一个包含GELF消息的POST请求到指定的URL。请确保将url变量替换为你自己的Graylog4服务器地址和端口号。在data字典中，你可以设置GELF消息的各个字段，如版本、主机、短消息、时间戳和日志级别等。\n如果成功发送了消息，服务器将返回状态码202；否则，将返回错误信息。在Graylog4里，如何向一个GLEF的HTTP接口发送POST请求\n","slug":"kanbanfiles/Go语言实现代理","date":"2024-03-14T06:15:59.717Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"17128178a8a90f40f15298b35f6dcb19","title":"Graylog3的Python调用库","content":"早期的Graylog2时期 ，Python Graylog的库也是Python版本的。到了Graylog3时期，使用了Python3版本，这时候Python的库就不能在Python中使用的， 需要将原有Pygralog2变成支持Python3的版本。\n\n\n","slug":"kanbanfiles/Graylog库引用","date":"2024-03-14T06:15:59.717Z","categories_index":"Sec,Graylog","tags_index":"Graylog","author_index":"安全书"},{"id":"db337d0c1275ad3ba82eaea7216e78e0","title":"ChatGLM2如何使用多显卡GPU","content":"ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？ChatGLM和ChatGLM2，对GPU配置的传参数样式不太一样，一代的时候，“0,1”这么用双显卡，二代的时候直接输入NUM_GPUS=2.\n要配置双显卡进行训练，可以将NUM_GPUS设置为2，以表示使用两个GPU。以下是一个示例的train.sh文件的内容：\n12345678export NUM_GPUS=2python train.py \\  --data_dir=data \\  --model_dir=model \\  --num_gpus=$NUM_GPUS \\  --batch_size=64 \\  --learning_rate=0.001\n\n在这个示例中，将NUM_GPUS设置为2，并传递给train.py脚本的–num_gpus参数。根据你的需求，你可以调整其他参数，例如数据目录、模型目录、批量大小和学习率等。\n请注意，具体的命令可能会根据ChatGLM2的实际代码库有所不同，请根据你使用的代码库和框架进行相应调整。\nChatGLM2如何使用多显卡GPU要在ChatGLM2中使用多个显卡GPU，你需要使用分布式训练的方法。以下是一个使用多个显卡GPU进行ChatGLM2训练的示例：\n\n确保你的计算机上有多个显卡GPU，并安装了相应的驱动程序。\n\n使用transformers库加载ChatGLM2模型和tokenizer：\n\n\n1234from transformers import ChatGPTmodel = ChatGPT.from_pretrained(&quot;microsoft/DialoGPT-medium&quot;)tokenizer = AutoTokenizer.from_pretrained(&quot;microsoft/DialoGPT-medium&quot;)\n\n\n使用torch.nn.DataParallel将模型包装在多个GPU上：\n\n123456import torchimport torch.nn as nndevice = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)model = nn.DataParallel(model)model.to(device)\n\n\n在训练循环中，确保将输入数据和目标标签移动到正确的设备上：\n\n12345input_ids = input_ids.to(device)attention_mask = attention_mask.to(device)labels = labels.to(device)outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n\n这样，模型就会自动在多个显卡GPU上并行计算，并共享梯度更新。\n请注意，使用多个显卡GPU进行训练可能需要更大的批次大小和更长的训练时间。此外，还可以通过设置CUDA_VISIBLE_DEVICES环境变量来选择要使用的特定GPU设备。\n","slug":"kanbanfiles/ChatGLM2如何使用多显卡GPU","date":"2024-03-14T06:15:59.717Z","categories_index":"ChatGLM","tags_index":"ChatGLM2","author_index":"安全书"},{"id":"70ccad85c177ffedfa95e18f77517e68","title":"Hexo使用Gitee+PicGO图墙图片不显示","content":"\n如何只对网页中的img标签进行no-referrer限制。\n要对网页中的img标签进行no-referrer限制，您可以使用以下方法：\n\n使用JavaScript：在网页中插入以下JavaScript代码，它将遍历所有的img标签，并为每个img标签设置rel属性为”noreferrer”。\n\n123456window.addEventListener(&#x27;DOMContentLoaded&#x27;, function() &#123;  var imgTags = document.getElementsByTagName(&#x27;img&#x27;);  for (var i = 0; i &lt; imgTags.length; i++) &#123;    imgTags[i].setAttribute(&#x27;referrerpolicy&#x27;, &#x27;no-referrer&#x27;);  &#125;&#125;);\n\n\n使用CSS：在网页的样式表（CSS）中添加以下代码，它将为所有的img标签设置rel属性为”noreferrer”。\n\n123img &#123;  referrerpolicy: no-referrer;&#125;\n\n请注意，这些方法都是在客户端（浏览器）执行的，并且只会影响到加载了该代码或样式表的网页。如果您想全局应用no-referrer限制，您可能需要在服务器端配置相关设置。\n直接在头文件中禁用，是可以跃过图片防盗链，但同时百度统计也屏蔽了， 图是可以显示了， 但是百度统计不过了。\n\n\n\n\n用JS动态进行no-referrer设置。\n\n\n\n\n\n(function () {\n  // 添加 no-referrer\n  // \n  var meta = document.createElement('meta')\n  meta.content = 'no-referrer'\n  meta.name = 'referrer'\n  document.getElementsByTagName('head')[0].appendChild(meta)\n})()\n\n\n\n要在百度的统计JS加载之后，加载上面的代码，这样百度就可以正常统计了， 这段代码要放到Hexo的主题文件里， 标签不能用普通的JS标签，要用Hexo主题用的标签。\n12345678if theme.baidu_analytics  script.    (function () &#123;    var meta = document.createElement(&#x27;meta&#x27;)    meta.content = &#x27;no-referrer&#x27;    meta.name = &#x27;referrer&#x27;    document.getElementsByTagName(&#x27;head&#x27;)[0].appendChild(meta)    &#125;)()\n\n这段代码放在主题的百度代码统计之后， 图墙的图片就可以显示了， 并且百度的统计也是正常。 \nhtml的img标签显示图片的例子\n\n\n\n\n","slug":"kanbanfiles/Hexo使用Gitee+PicGO图墙图片不显示","date":"2024-03-14T06:15:59.717Z","categories_index":"obsidian,hexo","tags_index":"obsidian,hexo,picgo","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"北京海淀区小学一年级50米，买多少秒成绩及格。\n成绩及格的时间是根据个人情况而定的，无法通过跑50米的时间来确定。一般来说，小学一年级的学生在50米跑方面，如果能够在10-15秒之间完成，可以算作是成绩及格。但是需要根据学校或教师对于成绩评判标准来确定是否及格。\n北京海淀区小学生一年级坐位体前屈什么标准算及格\n北京海淀区小学生一年级坐位体前屈的及格标准一般是指学生能够完成一定程度的身体前屈动作。具体标准可能根据学校或教育机构的要求而有所差异，但一般来说，以下是常见的及格标准：\n\n学生双脚并排、挺直坐在地上，双手自然垂放在身体两侧。\n学生慢慢向前弯腰，尽量用手指触碰或接近脚尖，保持动作稳定。\n身体前屈时，头部和脊柱应保持挺直，不扭曲或歪斜。\n不要出现明显的疼痛或不适感。\n\n需要注意的是，这只是一般的及格标准，并不代表每个学校或机构都会采用相同的标准。具体的及格标准应以相关教育规定为准。同时，在进行任何身体活动时，也应注意安全和合理性。\n北京海淀区小学生跳绳成绩， 跳多少个算及格。\n北京海淀区小学生跳绳成绩及格的标准可能因学校、年级和性别而有所不同。一般来说，以下是一些可能的及格标准供参考：\n\n一年级男生：跳绳100个以上\n一年级女生：跳绳80个以上\n二年级男生：跳绳150个以上\n二年级女生：跳绳120个以上\n三年级男生：跳绳200个以上\n三年级女生：跳绳160个以上\n四年级男生：跳绳250个以上\n四年级女生：跳绳200个以上\n五年级男生：跳绳300个以上\n五年级女生：跳绳240个以上\n六年级男生：跳绳350个以上\n六年级女生：跳绳280个以上\n\n请注意，这只是一个大致的参考值，具体的及格标准可能会根据学校和教育机构的要求而有所不同。\n如何回复下面的话，怼回去“跑调忘词真唱歌手身上都有，专业歌手假唱对口型无法接受”\n作为一个专业歌手，我可以告诉你，跑调忘词确实是在演唱过程中可能会发生的事情。但是，专业歌手在演唱之前会进行充分的练习和准备，以尽量避免出现这些问题。而对于假唱来说，有时候出于舞台效果或其他原因，专业歌手可能会选择辅助口型的方式来呈现完美的演出。这并不意味着他们缺乏才华或不值得被接受。艺术表演有多种形式和风格，并且每个人都有自己的表达方式。所以，我们应该尊重和欣赏每位歌手独特的风格和选择。\n回复一下，下面这条评论， 花花是一名歌手我就是通过花花又了解喜欢上了Muse，gotye .从而还发现花的音乐挺像皇后乐队，又疯狂爱上了皇后，家里9岁的孩子也一样。现在孩子天天看非洲慈善演唱会里面的每个乐队。最后说一句，大地那首歌不适合花唱，改编的也是一塌糊度。\n谢谢你的留言！花花确实是一位优秀的歌手，她的音乐风格确实有些像皇后乐队。很高兴听到你通过花花认识并喜欢上了Muse和Gotye，同时还让你和你家里的孩子都疯狂爱上了皇后。非洲慈善演唱会中的每个乐队也是非常值得关注的。至于《大地》这首歌，可能对于花花来说确实不太适合，改编也可能做得不够理想。感谢你的分享！\n正向的回复下面的评论是这样，过去我看纯文学杂志，什么收获啊，北京文学啊经常遇到好小说一看一夜，现在在让我看看不进去了。穷人嘛，这个世界好玩的东西挺多，可惜大多数我都玩不起，拼命刷手机找点乐子。互联网让世界变大，同时也变小了。人们已经不追求深刻了，因为深度同样意味着沉重。干一天活挺累的是吧，我不知道我的感觉对不对，我身边的哥们现在玩命的造，就好像没明天了一样。连未来都不愿意想，谁关心过去发生过的事?\n是的，互联网让我们能够接触到更多的信息和娱乐方式，但有时候也会让我们迷失在琐碎的事物中。人们追求轻松和快乐，也是因为生活本身已经足够沉重了。工作累确实是一种常态，很多人都在为了生活而努力。对于未来的担忧和对过去的遗憾，确实有时候会被我们忽略掉。但每个人都有自己的选择和生活方式，只要能够找到属于自己的平衡点就好。\n","slug":"jinxing/海淀区","date":"2024-03-14T06:15:59.716Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"什么是函数的导数？导数在数值坐标上的几何意义是什么？函数的导数是描述函数变化率的概念。对于函数f(x)，其导数表示了在x点处函数值的变化速率。\n导数在数值坐标上的几何意义是函数曲线在某一点处的切线斜率。具体地说，导数可以告诉我们函数曲线在该点的陡峭程度和方向。如果导数为正，表示曲线向上倾斜；如果导数为负，表示曲线向下倾斜；如果导数为零，表示曲线在该点处平坦。此外，导数的绝对值越大，表示曲线变化越快；导数接近于零，表示曲线变化缓慢。\n通过研究函数的导数，我们可以了解函数在不同点上的行为，并推断函数图像的形状和趋势。这对于解决实际问题、优化函数以及理解物理、经济等领域中的变化过程非常重要。\n如何求一个函数的导数要求一个函数的导数，可以按以下步骤进行：\n\n确定函数的形式。假设函数为f(x)，并确定其表达式。\n\n使用导数的定义来计算导数。导数的定义是lim(h→0) [f(x+h) - f(x)] / h，其中h代表变量的微小增量。\n\n将函数表达式带入导数定义中，并进行化简。\n\n取极限，即令h趋近于零。这样就可以得到函数在某个点x处的导数。\n\n如果需要求整个函数的导数，则需要对每个点都进行上述计算。\n\n如果函数具有复杂结构或包含多个变量，可以使用常见的求导法则来简化计算过程。常见的求导法则包括常数法则、幂法则、和差法则、乘积法则、商法则、链式法则等。\n\n在计算过程中，可能还需要使用一些基本的微积分技巧，如分部积分、换元积分等。\n\n最后得到的结果就是所求函数的导数。\n\n\n函数的导数公式是什么函数的导数公式是指通过求导运算得到函数的导数表达式。对于一元函数，导数可以通过极限定义或基本的求导法则来计算。其中最基本的导数公式包括：\n\n常数函数：如果f(x) = c，其中c是一个常数，则f’(x) = 0。\n\n幂函数：如果f(x) = x^n，其中n是任意实数，则f’(x) = nx^(n-1)。\n\n指数函数：如果f(x) = a^x，其中a是正实数且a ≠ 1，则f’(x) = ln(a) * a^x。\n\n对数函数：如果f(x) = log_a(x)，其中a是正实数且a ≠ 1，则f’(x) = 1 / (ln(a) * x)。\n\n三角函数：对于常见的三角函数sin(x)，cos(x)，tan(x)，其导数分别为cos(x)，-sin(x)，sec^2(x)，其中sec(x)表示secant函数。\n\n反三角函数：对于常见的反三角函数arcsin(x)，arccos(x)，arctan(x)，其导数分别为1 / √(1 - x^2)，-1 / √(1 - x^2)，1 / (1 + x^2)。\n\n\n除了以上这些基本的导数公式外，还有一些组合规则和链式法则等用于求解复杂函数的导数。\n函数的积分如何计算，函数的积分是几何意义是什么函数的积分可以通过积分算法或数值积分方法进行计算。常见的积分算法包括不定积分和定积分。\n不定积分是指对函数进行求导的逆过程，即找到一个原函数，使得其导数等于给定函数。这个原函数称为不定积分，通常用符号∫表示。计算不定积分时，需要考虑常数项，因为对于同一个导数来说，可能存在多个原函数。\n定积分是指在给定区间上计算函数曲线与x轴之间的有向面积。它可以看作是将曲线下方的面积减去曲线上方的面积，并考虑了曲线所在位置的正负情况。定积分通常用符号∫a^b f(x) dx表示，其中f(x)为被积函数，a和b为区间的起始点和终点。\n几何意义上，函数的不定积分表示了曲线下方与x轴之间的面积与位置关系。它可以用来求解曲线长度、质心、转动惯量等几何问题。而函数的定积分则表示了曲线所围成的有向面积，在物理学中可以用来求解质量、能量、功等概念。\n总之，函数的积分在数学和物理学中具有重要的应用，可以用来解决各种几何和物理问题。\n微积分中的积指是积是什么数在微积分中，积指是指对一个函数进行积分运算后得到的结果。积指可以是一个实数或复数，取决于被积函数和积分区间的性质。\n微积分中的积分是什么运算？积分是微积分中的一种运算，它可以用来计算曲线下面的面积、计算函数的定积分、求函数的原函数等。在数学上，积分是对函数进行求和的逆过程，通过将函数划分成无穷小的小矩形或小梯形，并将其面积相加来近似计算。当划分越来越细时，即无穷小时，这个近似变得越来越精确，从而得到准确的积分值。\n曲线的斜率公式是什么曲线的斜率公式是：dy/dx = lim(h-&gt;0) [f(x+h)-f(x)]/h，其中dy/dx表示曲线在某一点处的斜率，f(x)表示曲线上的函数\n不是曲线函数，有没有斜率不是曲线函数的函数，也可以有斜率。斜率是指函数图像上某一点处的切线的斜率，可以用导数来表示。对于非曲线函数，例如直线函数，其图像是一条直线，而且在每个点处都有相同的斜率。\n有没有不连续的函数是的，有不连续的函数。一个函数在某个点上不连续，当且仅当在该点处没有定义或者定义的值与左右极限不相等。例如，阶梯函数是一个经典的不连续函数，在每个跳变点都不连续。另外，绝对值函数在x = 0处也是不连续的。\n不连续的函数，能不能求导不连续的函数不能在不连续点处求导。求导是一个连续函数的操作，要求函数在所求导的点附近有定义且连续。而对于不连续的点，由于其定义域上没有足够接近该点的连续部分，无法进行求导操作。\n斜线斜率功式积分和导数关系是什么\n卷积神经网络里，用了那此线性代数，矩阵运算的知识卷积神经网络（Convolutional Neural Network, CNN）在处理图像和其他类型的数据时，使用了许多线性代数和矩阵运算的知识。以下是一些常见的应用：\n\n卷积操作：卷积层是CNN的核心组件之一。它通过将输入数据与卷积核进行卷积运算来提取特征。这个过程可以看作是一个二维矩阵的乘法运算。\n\n线性激活函数：在CNN中，经常使用ReLU（Rectified Linear Unit）作为激活函数。ReLU函数将输入的负值设为零，保留正值不变。这可以看作是对矩阵进行逐元素比较和替换的操作。\n\n全连接层：在CNN的最后几层，通常会包含全连接层。全连接层将前一层的输出展平成一个向量，并与权重矩阵进行乘法运算，得到最终的分类结果。\n\n池化操作：池化层用于减小特征图尺寸并保留重要信息。常见的池化操作有最大池化和平均池化，它们可以看作是对矩阵进行降采样的操作。\n\n批量归一化：批量归一化是对CNN中间层输出进行归一化的操作，旨在加速训练过程和提高模型的鲁棒性。它涉及到对矩阵进行均值和方差计算。\n\n损失函数：CNN的训练过程通常使用损失函数来度量模型输出与真实标签之间的差异。常见的损失函数有平方损失函数、交叉熵损失函数等，它们涉及到对矩阵进行逐元素计算和求和。\n\n\n总之，线性代数和矩阵运算是CNN中各个组件实现的基础，通过这些操作，CNN可以有效地从图像和其他类型数据中提取特征并进行分类、识别等任务。\n微积分中的求和符号，转换成Python3的循环求和代码怎么写在微积分中，求和符号$\\sum$用于表示一系列数值的累加。在Python中，可以使用循环结构来实现求和符号的功能。\n假设有一个求和式$\\sum_{i=1}^{n} a_i$，其中$a_i$是一个与$i$有关的数值表达式。将该求和式转换为Python3的循环求和代码可以按照以下步骤进行：\n\n首先，创建一个变量total并初始化为0，用于存储累加的结果。\n使用for循环结构遍历从1到$n$的整数。在每次迭代中，将当前的$a_i$值加到total中。\n循环结束后，变量total即为求和结果。\n\n下面是示例代码：\n12345678n = 10  # 假设n的值为10total = 0  # 初始化累加结果为0for i in range(1, n+1):    ai = i**2  # 假设a_i的表达式是i的平方    total += aiprint(total)  # 打印累加结果\n\n以上代码将计算并打印出$1^2 + 2^2 + \\ldots + 10^2$的结果。根据实际情况，你可以根据需要修改变量n、$a_i$表达式以及打印输出方式。\n微积分函数如何用Python代码实现，如何实现请举例要实现微积分函数，可以使用Python中的数学库，如numpy和sympy。以下是一些示例：\n\n导入数学库\n\n12import numpy as npimport sympy as sp\n\n\n定义函数\n\n12def f(x):    return x**2 + 3*x + 1\n\n\n求导数\n\n使用sympy库可以直接求导数：\n1234x = sp.symbols(&#x27;x&#x27;)f_expr = x**2 + 3*x + 1f_prime = sp.diff(f_expr, x)print(f_prime)\n\n输出结果为：2*x + 3\n\n求不定积分\n\n使用sympy库可以直接求不定积分：\n1234x = sp.symbols(&#x27;x&#x27;)f_expr = x**2 + 3*x + 1f_integral = sp.integrate(f_expr, x)print(f_integral)\n\n输出结果为：(1/3)*x**3 + (3/2)*x**2 + x\n\n数值积分\n\n使用numpy库可以进行数值积分：\n12345678910111213import numpy as npdef f(x):    return x**2 + 3*x + 1a = 0   # 积分下限b = 1   # 积分上限n = 100 # 分割数目x_values = np.linspace(a, b, n+1)y_values = f(x_values)integral_value = np.trapz(y_values, x_values)print(integral_value)\n\n输出结果为：2.333333333333334\n切线斜率和割线斜率的定义是什么切线斜率是指曲线上某一点的切线与x轴正方向的夹角的正切值。在数学中，它可以通过求曲线在该点的导数来求得。\n割线斜率是指曲线上两个不同点之间的割线与x轴正方向的夹角的正切值。它可以通过求两个不同点处切线斜率的差分（即导数）来求得。\n正切值是定义是什么正切值是一个三角函数，表示一个角的正弦值与余弦值的比值。在直角三角形中，正切值等于对边长度与邻边长度的比值。在单位圆上，一个角的正切值等于该角对应的点到原点的纵坐标与横坐标的比值。在数学中，正切函数被定义为tan(x) = sin(x) / cos(x)，其中x为任意实数。\n三解函数sin是那个边比那个边三角函数sin是指在一个直角三角形中，正弦值是对边与斜边的比值。具体来说，对于一个直角三角形，如果我们将其中一个锐角定义为θ，则sinθ等于对边长度除以斜边长度。\n三解函数cos是那个边比那个边三角函数cos是邻边除以斜边的比值。\n如何画曲线上某一点的切线要画曲线上某一点的切线，可以按照以下步骤进行：\n\n找到曲线上要画切线的点，并确定该点的坐标。\n\n在该点附近选择一个相对较小的区间，并取几个点作为近似于该点的邻近点。\n\n使用这些邻近点，计算出通过它们的拟合曲线。可以使用插值或拟合方法，如线性拟合、二次拟合等。\n\n在图纸上绘制原始曲线和通过邻近点拟合出来的曲线。\n\n在原始曲线上找到要画切线的点，并确定该点在拟合曲线上对应的位置。\n\n在该位置处绘制一条与拟合曲线相切的直线，作为切线。可以使用斜率来确定直线的方向和倾斜程度。\n\n确定切线在图纸上适当的长度，并绘制出来。\n\n\n请注意，这种方法是通过近似方法来绘制切线，在某些情况下可能存在误差。如果需要更精确地绘制切线，请考虑使用微积分中求导数的方法来计算切线斜率，并利用斜率和给定点确定切线方程。\n笛卡尔积笛卡尔积是集合论中的一个概念，表示两个集合中所有可能的有序对的集合。\n假设有两个集合A和B，其元素分别为{a1, a2, … , an}和{b1, b2, … , bm}，那么A和B的笛卡尔积记作A × B，表示包含所有可能的有序对{(a1, b1), (a1, b2), … , (an, bm)}的集合。\n例如，如果A={1, 2}，B={3, 4}，那么A × B = {(1, 3), (1, 4), (2, 3), (2, 4)}。\n笛卡尔积在数学、计算机科学等领域有广泛应用。在关系数据库中，笛卡尔积可以用来实现多表联接操作；在编程中，可以用来生成排列组合等。\n牛顿对微分的定义与莱布尼茨对微分的定义牛顿对微分的定义是基于物理上的运动观察和速度概念。他认为微分是一种极限过程，即当变量无限接近某一特定值时的变化率。他将微分符号表示为”d”，表示变量的无穷小增量。\n莱布尼茨对微分的定义则是基于数学上的代数和函数观点。他提出了微分的基本原理，即将函数表示为无穷小元素之和，并通过求导来确定这些元素之间的关系。他将微分符号表示为”dx”，其中”d”表示无穷小变化，”x”表示自变量。\n两种定义都构成了微积分领域中微分的重要概念，并在不同学科领域中得到广泛应用。\n求出了函数的导数，是不是就求出了函数积分？\n不一定。虽然导数和积分是互为逆运算的概念，但是求出了函数的导数并不代表就求出了函数的积分。要求出函数的积分，需要使用积分运算来进行计算。虽然在某些情况下，函数的导数和积分有一定的关系，比如如果一个函数在某个区间上连续，并且在该区间上的导数存在，则该函数在该区间上是可积的，但这并不意味着导数和积分是完全等价的运算。\n什么是点的切线点的切线是指在给定点上与曲线相切的直线。在数学中，对于一条光滑的曲线，可以通过求取曲线在该点的导数来确定该点的切线。切线与曲线在给定点处有相同的斜率，并且只接触曲线一次。切线可以用于研究曲线在某一点的斜率和变化率。\n如何画函数的切线要画函数的切线，可以按照以下步骤进行：\n\n确定函数的表达式。如果已经给出了函数的表达式，可以直接使用。如果没有给出，可以根据问题描述或者已知条件来确定函数。\n\n找到要画切线的点。选择一个特定的x值作为切线点。这个点应该在函数定义域内，并且是你感兴趣的位置。\n\n计算函数在该点的导数。使用求导法则计算函数在选定点处的导数值。\n\n根据导数值和选定点，确定切线方程。使用切线方程y = mx + b，其中m是导数值，b是通过选定点计算得到的常量。\n\n在坐标系中画出函数曲线和切线。根据所得到的切线方程，在坐标系中绘制出对应于选定x值处的直线。\n\n\n需要注意的是，当你选择不同的x值时，会得到不同位置处的切线。所以你可以通过重复上述步骤来绘制多个切线，并观察它们在整个函数曲线上的分布和变化情况。\n给定了函数的曲线，如何画函数曲线的切线要画出函数曲线的切线，可以按照以下步骤进行：\n\n首先，选择一个点作为切点，该点应该位于函数曲线上。可以根据需要选择切点的位置。\n\n然后，计算函数在该点的斜率。可以使用微积分中的导数来计算斜率，即求函数在该点处的导数。\n\n使用斜率和切点来确定切线方程。切线方程可以表示为 y = mx + b 的形式，其中 m 是斜率，b 是常数项。\n\n根据确定的切线方程，在给定范围内绘制切线。可以选择一段范围，并根据切线方程计算相应的 x 和 y 值来绘制切线。\n\n\n重复以上步骤，可以在所需位置上画出多个切线。\n函数斜率的概念函数斜率是描述函数曲线在某一点上的变化率的概念。在数学中，斜率可以用来衡量函数图像上两点之间的变化程度。具体来说，对于一条曲线上的两个点A和B，斜率可以通过计算这两个点之间的纵坐标变化与横坐标变化的比值来得到。\n设函数为f(x)，点A的坐标为(x1, f(x1))，点B的坐标为(x2, f(x2))，则函数在点A和B之间的斜率可以表示为：\n斜率 = (f(x2) - f(x1)) / (x2 - x1)\n当两个点越接近时，这个比值越能够近似地描述曲线在该点附近的变化情况。因此，在一些情况下，我们也可以使用极限来定义一个函数在某一点上的斜率。\n需要注意的是，这里所讨论的斜率是指切线斜率。对于曲线上任意一点处存在无数条切线，每条切线都有一个不同的斜率。因此，在不同位置处，同一个函数具有不同的斜率。\n纵坐标变化除以横坐标的变化（dy/dx）   对边比上临边，得到斜率\n几何中的正切，是那个边比那个边正切是指直角三角形中，斜边和与直角相邻的边的比值。也就是说，正切等于直角三角形中对边与邻边的比值。\n几何学的中对边比临边，求的是什么在几何学中，对边比临边是指一个三角形中的两条边与其对应的两个内角的比值。这个比值被称为正弦。\n具体来说，对于一个三角形ABC，其中∠A是顶点A对应的内角，a是边BC的长度（也就是临边），b是边AC的长度（也就是对边），c是边AB的长度（也就是斜边）。那么，正弦定理可以表示为：\nsin A = b / c\n这个定理可以用来求解三角形中的各种未知量，例如已知两条边和它们之间的夹角，可以通过正弦定理计算出第三条边的长度。\n导数导数导数就是求函数曲线图像上，两个点之间，（x,y） 和（x1,y1）的这段曲线上两点的割线斜率求极限（dx无限小）， 就是求dy/dx， 几何意义是，对边比临边的正切比值，通过求曲线上两点割线斜率，求极限得出某一点的切线斜率。\n微分这两个点， 函数f(x) 微小变化量df(x)比上x的微小变化量dx，也表示导数：df(x)/dx。df(x) 这个f(x)函数的微小变化量，是函数f(x)的微分。dx，是x是微分。微小变化量。\n积分积分中的s就是sum，表示循环累加，很多时候Python的代码片段的解释，要比数学公式更直观，数学公式更简洁，两者都是求和， 都是表示一个动态计算的过程，代码可以更有空间感和方向感，也啰嗦一些。\nS(a…b)f(x)dx就是积分，求的是曲边梯形的面积。f(x)就是函数曲线某点之间的y：高，dx，是从x开始的x的变化量：长，高x长，就是函数曲线图像两个点之间，高x长的面积，把这些小的面积，最后累加求和，就是曲线下面的，曲边梯形的总面积，积分。\n导数的定义是什么导数的定义是一个函数在某一点的变化率，即函数在该点附近的斜率。对于一个函数f(x)，它在点x=a处的导数可以用以下极限来定义：\nf’(a) = lim┬(h→0)⁡((f(a+h) - f(a))/h)\n其中，h表示自变量x的增量，当h趋近于0时，表示取得该点附近的极限。这个极限就是函数f(x)在点x=a处的导数。导数表示了函数在该点附近的斜率，可以用来描述函数曲线在该点上升或下降的速度。\n","slug":"jinxing/函数的导数","date":"2024-03-14T06:15:59.716Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"苹果M1 macbook pro的显卡，相当于nvidia什么水平的显卡\n苹果M1芯片采用了自家设计的8核GPU，相对于Nvidia显卡来说，很难直接进行等级对比。然而，根据一些测试结果显示，M1芯片的GPU性能大致相当于Nvidia GTX 1050 Ti或者Nvidia GTX 1650显卡水平。请注意这只是一个粗略的比较，实际性能可能因应用程序和使用环境而有所不同。\n","slug":"jinxing/苹果M1 macbook pro的显卡，相当于nvidia什么水平的显卡","date":"2024-03-14T06:15:59.716Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"如何查看Linux的Java中的JVM的大小\n要查看Linux中Java应用程序的JVM大小，可以使用以下命令：\n\n使用top命令查看正在运行的Java进程的PID：\n1top\n使用jstat命令查看特定Java进程的内存使用情况，其中PID是第一步中找到的Java进程的PID：\n1jstat -gc PID\n使用jmap命令导出Java进程的堆转储，并使用wc和grep命令来计算堆大小：\n1jmap -heap PID | grep Heap | wc -l\n使用ps命令结合grep来查看Java进程的JVM参数：\n1ps aux | grep java\n\n通过以上步骤，您可以查看Linux中Java应用程序的JVM大小。\n执行jstat和jmap需要安装什么软件包\n要执行jstat和jmap命令，通常需要安装Java Development Kit (JDK) 软件包。这两个工具是JDK自带的性能监控和诊断工具，用于监控Java虚拟机的运行时状态和内存使用情况。要使用jstat和jmap命令，首先需要安装JDK，并将其添加到系统的环境变量中。\n","slug":"java/未命名","date":"2024-03-14T06:15:59.715Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"刚毕业的计算机专业大学生应该怎么找工作比较好？\n以下是一些建议：\n\n了解自己的技能和兴趣：首先要明确自己的技能和兴趣，确定自己想从事哪个领域或岗位。这有助于你更有针对性地寻找适合自己的工作。\n\n更新简历和求职信：编写一份精确、清晰、易读的简历和求职信。突出你的教育背景、实习经验和项目经验，并强调与目标工作相关的技能。\n\n利用校园资源：学校通常提供就业指导、招聘会等资源，利用这些资源寻找机会。参加招聘会并与雇主面谈，可以增加你与雇主直接接触的机会。\n\n网络招聘平台：注册并创建个人资料，上传简历，并定期查看最新职位信息。使用关键词搜索来找到适合你的工作，并在申请前仔细阅读职位要求。\n\n社交媒体：建立一个专业形象的社交媒体账号，并关注相关行业领域的公司和专业人士。通过发布有关技术动态、项目经验等内容来展示你对行业的热情和知识。\n\n寻找实习机会：如果你没有相关工作经验，可以寻找实习机会来积累经验。实习不仅可以让你学到更多实际操作的技能，还有可能转化为全职就业机会。\n\n主动联系公司：不仅要等待招聘信息，还可以主动联系你感兴趣的公司。发送个性化的求职信和简历，并解释你为何对该公司感兴趣以及如何能为其做出贡献。\n\n建立专业网络：与行业内的人建立联系，并参加相关行业的活动和会议。这样可以扩展人脉并了解更多就业机会。\n\n不断学习和提升技能：计算机行业变化快速，持续学习和提升技能是很重要的。参加培训课程、自学新技术等都有助于提高自己的竞争力。\n\n调整心态和坚持：找工作可能需要一些时间，但要保持积极的心态并坚持努力。不断优化自己的求职策略，并相信最终会找到适合自己的工作。\n\n\n希望以上建议对你有所帮助！祝你找到理想的工作！\n请把下面的建议，总结成三点最重要的，列出来。以下是一些建议：\n\n了解自己的技能和兴趣：首先要明确自己的技能和兴趣，确定自己想从事哪个领域或岗位。这有助于你更有针对性地寻找适合自己的工作。\n\n更新简历和求职信：编写一份精确、清晰、易读的简历和求职信。突出你的教育背景、实习经验和项目经验，并强调与目标工作相关的技能。\n\n利用校园资源：学校通常提供就业指导、招聘会等资源，利用这些资源寻找机会。参加招聘会并与雇主面谈，可以增加你与雇主直接接触的机会。\n\n网络招聘平台：注册并创建个人资料，上传简历，并定期查看最新职位信息。使用关键词搜索来找到适合你的工作，并在申请前仔细阅读职位要求。\n\n社交媒体：建立一个专业形象的社交媒体账号，并关注相关行业领域的公司和专业人士。通过发布有关技术动态、项目经验等内容来展示你对行业的热情和知识。\n\n寻找实习机会：如果你没有相关工作经验，可以寻找实习机会来积累经验。实习不仅可以让你学到更多实际操作的技能，还有可能转化为全职就业机会。\n\n主动联系公司：不仅要等待招聘信息，还可以主动联系你感兴趣的公司。发送个性化的求职信和简历，并解释你为何对该公司感兴趣以及如何能为其做出贡献。\n\n建立专业网络：与行业内的人建立联系，并参加相关行业的活动和会议。这样可以扩展人脉并了解更多就业机会。\n\n不断学习和提升技能：计算机行业变化快速，持续学习和提升技能是很重要的。参加培训课程、自学新技术等都有助于提高自己的竞争力。\n\n调整心态和坚持：找工作可能需要一些时间，但要保持积极的心态并坚持努力。不断优化自己的求职策略，并相信最终会找到适合自己的工作。\n\n\n最重要的三点建议如下：\n\n了解自己的技能和兴趣，确定自己想从事哪个领域或岗位。\n更新简历和求职信，突出与目标工作相关的技能和经验。\n利用校园资源，参加招聘会并与雇主面谈，利用网络招聘平台寻找适合自己的工作。\n\nXDR在安全系统里是什么系统\nXDR在安全系统中指的是扩展检测与响应（Extended Detection and Response）系统。XDR是一种集成多个安全工具和技术的综合性解决方案，旨在提供更全面、更智能的威胁检测和响应能力。它可以跨多个终端、网络和云环境进行威胁检测，并提供自动化的响应和修复措施，以加强组织的安全防御能力。XDR系统通常包括日志分析、行为分析、威胁情报、漏洞管理等功能，可以实现对潜在威胁的实时监控、快速识别以及有效应对。\n把下明天面的汉字加拼音。\n第二天早上，他去放羊，发现羊又少了一只。原来狼又从窟窿钻进去，把羊叼走了。他很后悔没有听街坊的劝告，心想，现在修还不晚。他赶紧堵上那个窟隆，把羊圈修的结结实实的。从此，他的羊再也没丢过。\ndì èr tiān zǎo shàng, tā qù fàng yáng, fāxiàn yáng yòu shǎo le yī zhī.第二天早上，他去放羊，发现羊又少了一只。yuánlái láng yòu cóng kū lóng zuān jìn qù, bǎ yáng jiāo zǒu le.原来狼又从窟窿钻进去，把羊叼走了。tā hěn hòuhuǐ méiyǒu tīng jiēfāng de quàngào, xīn xiǎng, xiànzài xiū hái bù wǎn. tā gǎnjǐn dūshàng nàgè kū lōng,他很后悔没有听街坊的劝告，心想，现在修还不晚。他赶紧堵上那个窟隆，bǎ yáng juàn xiū de jiéjiéshíshi de.把羊圈修的结结实实的。cóngxī, tā de yáng zài yě méi diū guò.从此，他的羊再也没丢过。\n嗯，说，说话第二天早上嗯，他去放羊然后这个发现羊肉少了一只嗯，\n","slug":"jinxing/HR","date":"2024-03-14T06:15:59.715Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"windows11 如何文字转语音\n在Windows 11上，你可以使用内置的文本到语音功能将文字转换为语音。以下是使用该功能的步骤：\n\n打开“设置”应用程序。你可以通过单击任务栏上的“开始”按钮，然后点击设置图标来打开它。\n\n在设置窗口中，点击左侧菜单中的“无障碍”选项。\n\n在“无障碍”选项卡下，找到并点击右侧面板中的“文本到语音”部分。\n\n在“文本到语音”页面中，你可以看到一个文本框，在此处输入你想要转换为语音的文字。\n\n在文本框下方，你可以选择不同的声音和语速。通过调整这些选项来自定义生成的语音。\n\n当你完成输入和设置后，点击页面底部的“播放”按钮即可开始将文字转换为语音。\n\n你还可以调整输出设备、音量和其他高级设置等选项。这些选项位于页面右上角的菜单中。\n\n\n通过以上步骤，你就可以在Windows 11上将文字转换为语音了。\nobsidian中有没有文字转语音的插件\n是的，Obsidian有一些插件可以实现文字转语音的功能。你可以尝试使用”Speech Synthesis”插件或者”Read Aloud”插件来实现将文字转换为语音的功能。这些插件可以帮助你在Obsidian中方便地进行文本朗读。\nobsidian插件，如何通过在浏览器中直接下载？\nWindows 11上有没有文字转语音的软件\n是的，Windows 11上有很多文字转语音的软件可供选择。一些常见的软件包括Microsoft OneNote、Windows Narrator、Balabolka和TextAloud。这些软件可以将文本转换为语音，并提供一些额外的功能，如调整语速和音调等。\nWindows11上最好， 最受欢迎的文字转语音的软件\n微软的edge浏览器如何修改区域，可以显示出来bing的ai功能\n要在Microsoft Edge浏览器中显示Bing的AI功能，您可以按照以下步骤修改区域设置：\n\n打开Microsoft Edge浏览器。\n\n单击右上角的菜单图标（三个水平点），然后选择“设置”。\n\n在设置页面的左侧导航栏中，单击“语言、区域和输入法”。\n\n在右侧窗格中，找到“区域”部分，并单击“更改日期、时间或区域格式”。\n\n在弹出的窗口中，选择“管理地点”选项卡。\n\n单击“更改系统区域设置”。\n\n选择您希望显示Bing的AI功能的目标区域。请注意，不是所有地区都支持该功能。\n\n单击“确定”按钮保存更改。\n\n关闭并重新打开Microsoft Edge浏览器以使更改生效。\n\n\n现在，当您使用Microsoft Edge浏览器访问Bing搜索引擎时，应该能够看到AI相关的功能和结果。请注意，具体的AI功能可能会因地区而异，并且可能需要使用支持该功能的特定语言进行搜索。\n","slug":"jinxing/windows11 如何文字转语音","date":"2024-03-14T06:15:59.715Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"cb22f82fe732b75010786dbf6cdb1be9","title":"DreamTalk When Expressive Talking Head Generation Meets Diffusion Probabilistic Models","content":"DreamTalk When Expressive Talking Head Generation Meets Diffusion Probabilistic Models阿里巴巴 DreamTalk能用人脸带表情说话\nDreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models\nhttps://huggingface.co/spaces/fffiloni/dreamtalk?continueFlag=8c6b6dc8b4c21a95d8200f5093660247\n","slug":"huaggingface/DreamTalk When Expressive Talking Head Generation Meets Diffusion Probabilistic Models","date":"2024-03-14T06:15:59.715Z","categories_index":"AIGC,huaggingface","tags_index":"huaggingface","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"USB3 .0 与SD存储卡之间的读取速度差多少？\nUSB3.0与SD存储卡之间的读取速度差异较大，主要取决于具体的设备和存储卡规格。一般来说，USB3.0接口的读取速度可以达到每秒5Gbps，而SD存储卡的读取速度则根据不同的规格和等级有所不同。\n相对而言，SD存储卡的读取速度一般较USB3.0接口慢。通常情况下，普通级别的SD存储卡读取速度约为每秒10-30MBps左右，高速级别的SD存储卡可以达到每秒90-100MBps左右。\n因此，USB3.0与SD存储卡之间的读取速度差异可能在几倍甚至更大。但需要注意的是，实际使用时还要考虑到设备、操作系统以及文件大小等因素对读写速度的影响。\nUSB3.0的U盘 与SD存储卡之间的速度差异\nUSB3.0的U盘和SD存储卡之间的速度差异主要取决于以下几个因素：\n\n接口速度：USB3.0接口的最大传输速度为5 Gbps，而SD存储卡的接口速度通常为UHS-I，最大传输速度为104 MB/s。因此，从接口速度上来看，USB3.0的U盘明显快于SD存储卡。\n\n存储介质速度：除了接口速度外，存储介质的读写速度也会影响整体传输速度。USB3.0的U盘通常采用闪存芯片作为存储介质，而SD存储卡则采用闪存芯片或者更高性能的SDXC/UHS-II规格。在相同规格下，闪存芯片读写速度较快，因此USB3.0的U盘可能具有更高的读写速度。\n\n设备兼容性：由于不同设备对USB3.0和SD存储卡规格的支持程度不同，对于某些设备来说，可能无法充分发挥USB3.0接口或SD存储卡的最大传输速度。因此，在某些特定设备上使用时，两者之间的实际差异可能不太明显。\n\n\n总体来说，USB3.0的U盘通常比SD存储卡具有更快的传输速度。在需要频繁读写大量数据的场景下，使用USB3.0的U盘可能会更加高效。然而，对于一般的数据存储和传输需求来说，SD存储卡已经足够满足大多数用户的需求。\nUSB2.0的U盘 与SD存储卡之间的速度差异\nUSB2.0的U盘和SD存储卡之间的速度差异主要取决于以下几个方面：\n\n接口速度：USB2.0接口的最大传输速率为480 Mbps（兆位每秒），而SD存储卡的接口速度可以根据不同的规格而有所不同，常见的有SDHC（High Capacity）和SDXC（Extended Capacity），它们的最大传输速率分别为25 Mbps和104 Mbps。因此，从接口速度上来说，USB2.0相对较快。\n\n存储介质：U盘通常使用闪存作为存储介质，而SD存储卡也是采用闪存技术。但是，不同品牌和型号的闪存芯片质量和性能可能存在差异，这可能会导致实际传输速度的变化。\n\n文件系统：文件系统也会影响读写速度。U盘通常使用FAT32或NTFS文件系统，而SD卡通常使用FAT32或exFAT文件系统。不同文件系统对于小文件和大文件的处理方式可能不同，因此可能会影响传输速度。\n\n\n综上所述，USB2.0的U盘相对于SD存储卡来说，在理论上具备更高的传输速率。然而，在实际应用中，由于各种因素的影响，实际速度差异可能会有所缩小。在选择存储设备时，除了考虑速度外，还应综合考虑其他因素，如容量、可靠性和价格等。\n","slug":"jinxing/USB3 与SD存储卡之间的速度差异","date":"2024-03-14T06:15:59.715Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"f73a8e23e6f6f669cf99c7dba8fa0722","title":"","content":"从原理上解释一下为什么：“不听老人言，吃亏在眼前！‘\n从心理学角度来解释，年长者通常经历了更多的人生阅历和经验积累，他们对事物的判断和决策更为成熟和准确。他们能够通过自己的经验教训来指导年轻人，帮助他们避免犯同样的错误。\n此外，年长者在社会中拥有更高的地位和威信，他们的建议往往具有权威性。因此，不听从年长者的意见可能导致缺乏正确的指导，而出现失误或吃亏。\n另外，年长者也具备更多的人际关系网络和社会资源，他们可以通过这些资源提供帮助和支持。如果不听从他们的建议，则可能失去了得到这些资源的机会。\n总之，“不听老人言，吃亏在眼前”这句话表达了尊重和借鉴前辈经验教训的重要性。年长者对我们来说是宝贵的财富，在做决策时应该谦虚地听取他们的意见，并根据需要加以参考和应用。\n从原理上解释一下为什么：“不听老人言，开心一整年！‘\n“不听老人言，开心一整年！”这句话的原理可以从两个方面解释。\n首先，老人的经验和智慧是通过多年的生活经历积累起来的。他们在各种情况下都可能有着宝贵的建议和指导。因此，听取老人的意见可以避免重复犯错，减少风险，并且能够更快地找到解决问题的方法。如果我们不听老人言，就可能会陷入自己不必要的错误中，从而导致不必要的痛苦和困扰。\n其次，老人往往具有更加平静和豁达的心态。他们对生活有着更全面、更深刻的理解。通过倾听他们的故事和观点，我们可以学到如何正确处理挫折和困难，并拥有更健康、积极的心态。这样一来，在遇到问题时我们就能更加从容地面对，并且能够更好地享受生活中美好的事物。\n综上所述，“不听老人言，开心一整年！”这句话之所以成立，是因为老人通常具有丰富的经验和智慧，在许多情况下能够给出宝贵建议；同时也因为他们的平和心态和积极态度可以影响我们的情绪和态度，使我们更加开心和满足。因此，听取老人的意见并尊重他们是一个值得推崇的行为。\n三仙献鼎局\n三仙献鼎局是指中国古代神话传说中的一个故事，主要涉及到三位神仙献上了自己的法宝鼎给玉皇大帝。\n故事中，有三位神仙分别是：东华帝君、南极仙翁和西方毗卢仙君。他们都是玉皇大帝的得力助手，拥有着强大的法力和神通。\n这三位神仙听说玉皇大帝需要一座冰铜鼎来供奉天地之间的灵气，于是分别动身前往三江之源、南海之滨和西海之畔寻找适合铸造鼎的材料。\n东华帝君找到了一块源自东海深处的寒铜；南极仙翁发现了一块取自南山峰顶的冰晶；西方毗卢仙君则在西岭山脚下找到了一块火山岩。\n他们将这些材料带回天宫后，共同努力将这些材料熔化并铸造成了一座美丽而庄重的冰铜鼎。这座鼎上刻有精美的图案和文字，象征着天地间的和谐与祥和。\n最后，三位神仙将这座冰铜鼎献给了玉皇大帝。玉皇大帝赞赏他们的努力和智慧，并将这座鼎放置在天宫的重要位置上，作为供奉天地灵气的器物。\n三仙献鼎局这个故事寓意着人与自然的和谐相处，也强调了团结合作的重要性。同时，它也反映了中国古代文化中对于神仙、法宝等神话元素的崇拜和尊重。\n科斯定理\n科斯定理（Coase’s theorem）是由英国经济学家罗纳德·科斯（Ronald Coase）于1960年提出的一个经济学理论。该理论主要探讨了在存在外部性的情况下，市场机制如何通过私人协商来实现资源的有效配置。\n科斯定理认为，当市场存在外部性时，如果交易成本较低且产权明确，受到外部性影响的各方可以通过私人协商来达成一种有效的资源配置方式，而无需政府干预。换句话说，只要交易成本较低且产权得到明确和保护，市场参与者可以通过自愿交易来最大化社会福利。\n科斯定理的核心思想是强调了私人协商在资源配置中的重要性。根据该定理，当市场参与者面对外部性问题时，他们可以通过协商、合同或谈判等方式来解决争议，并找到一种相对最优的解决方案。这种解决方案可能包括支付补偿、签订契约或重新划分产权等形式。\n然而，科斯定理并不意味着私人协商一定能够实现最优资源配置。在现实世界中，交易成本可能较高，产权可能不明确或无法得到有效保护，私人协商可能受到信息不对称、谈判能力差异等因素的影响。因此，政府在某些情况下仍需要干预，通过立法、监管等手段来纠正市场失灵和改善资源配置。\n总之，科斯定理强调了私人协商在解决外部性问题中的作用，并提出了一种理论框架来分析资源配置问题。然而，在实践中，需要综合考虑交易成本、产权保护和政府干预等因素来找到最优的资源配置方式。\n帕累托最优\n帕累托最优是指在资源有限的情况下，通过合理分配资源，使得至少有一方的利益不受损害，而其他方的利益能够最大化。这个概念源自于意大利经济学家维尔弗雷多·帕累托（Vilfredo Pareto）提出的“帕累托改进”原则。\n在帕累托最优的情况下，任何一方都无法通过调整资源分配来获得更多的利益，即已经达到了最优效果。这种情况下，只有通过减少某一方的利益或者增加其他方的利益才能实现资源再分配。\n帕累托最优常常用于经济学和社会福利领域，例如在税收政策中，通过合理调整税收负担来实现社会公平和效率的平衡；在资源配置上，通过合理分配资源来提高整体效益等。帕累托最优原则可以作为一种评估和指导社会政策和经济决策的依据。\n恩格尔系数\n恩格尔系数是一个经济学术语，用于衡量家庭或个人消费支出中食品支出所占比例的指标。它是由德国统计学家恩格尔（Ernst Engel）于19世纪提出的。\n恩格尔系数的计算方法是将食品支出除以总消费支出，并乘以100，以得到一个百分比。公式如下：\n恩格尔系数 = (食品支出 / 总消费支出) * 100\n恩格尔系数越高，表示家庭或个人在消费中用于购买食品的比例越大，说明其可支配收入相对较低；反之，恩格尔系数越低，则表示家庭或个人在消费中用于购买食品的比例较小，说明其可支配收入相对较高。\n恩格尔系数常被用作衡量贫困程度和经济发展水平的指标。通常情况下，随着经济发展和人民生活水平的提高，恩格尔系数会逐渐降低。这是因为随着收入增加，人们可以更多地购买非必需品和奢侈品，从而减少了食品支出所占比例。\n然而，在一些贫困地区或低收入家庭中，恩格尔系数可能会较高，表示大部分收入被用于满足基本的食品需求。因此，恩格尔系数也可以作为贫困程度和社会经济状况的一个指标。\ntransformer模型\nTransformer模型是一种基于自注意力机制的序列到序列模型，最初用于机器翻译任务。它由多个编码器和解码器层组成，每个层都包含了自注意力和前馈神经网络两个子层。\n在编码器中，输入序列首先通过自注意力机制进行编码，即计算每个位置与其他位置的相关性权重，从而获得每个位置的上下文表示。然后，在前馈神经网络中对上下文表示进行非线性变换。这样，编码器可以将输入序列转化为一组高维向量表示。\n在解码器中，目标序列的每个位置都通过自注意力机制获取其上下文信息，并与编码器的输出进行关联。然后，在前馈神经网络中对上下文表示进行非线性变换，并预测当前位置的输出。\n自注意力机制是Transformer模型的核心部分。它通过计算查询、键和值之间的相关性来获取位置之间的相互作用。这使得模型能够在没有显式对齐过程的情况下捕捉到长距离依赖关系。\n相比于传统的循环神经网络（RNN），Transformer模型具有更好的并行计算能力和更短的训练时间。它还能够处理长序列，并且不受序列长度的限制。因此，Transformer模型在自然语言处理和其他序列任务中取得了很大的成功。\n写一段Transformerj模型的Helloworld程序的Python代码的例子。\n下面是一个使用Transformer模型进行文本分类的示例代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import torchimport torch.nn as nnimport torch.optim as optimfrom torchtext.datasets import AG_NEWSfrom torchtext.data import Field, LabelField, BucketIterator# 定义模型参数embedding_dim = 256hidden_dim = 512output_dim = 4num_heads = 8num_layers = 6# 定义数据处理的Field对象text_field = Field(tokenize=&#x27;spacy&#x27;, lower=True)label_field = LabelField(dtype=torch.long)# 下载和处理数据集train_data, test_data = AG_NEWS.splits(text_field, label_field)label_field.build_vocab(train_data)train_iterator, test_iterator = BucketIterator.splits(    (train_data, test_data),    batch_size=64,    device=torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;))class TransformerModel(nn.Module):    def __init__(self, embedding_dim, hidden_dim, output_dim, num_heads, num_layers):        super(TransformerModel, self).__init__()        self.embedding_dim = embedding_dim                self.embedding = nn.Embedding(len(text_field.vocab), embedding_dim)        self.pos_encoding = PositionalEncoding(embedding_dim)                encoder_layer = nn.TransformerEncoderLayer(            d_model=embedding_dim,            nhead=num_heads,            dim_feedforward=hidden_dim,            dropout=0.5,            activation=&#x27;relu&#x27;        )        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)                self.fc1 = nn.Linear(embedding_dim, hidden_dim)        self.fc2 = nn.Linear(hidden_dim, output_dim)            def forward(self, text):        embedded_text = self.embedding(text) * math.sqrt(self.embedding_dim)        encoded_text = self.pos_encoding(embedded_text)        transformer_output = self.transformer_encoder(encoded_text)        pooled_output, _ = torch.max(transformer_output, dim=1)        logits = self.fc2(self.fc1(pooled_output))                return logits# 定义位置编码class PositionalEncoding(nn.Module):    def __init__(self, embedding_dim, max_len=5000):        super(PositionalEncoding, self).__init__()                position = torch.arange(0, max_len).unsqueeze(1)        div_term = torch.exp(torch.arange(0, embedding_dim, 2) * (-math.log(10000.0) / embedding_dim))                self.position_encoding = torch.zeros(max_len, embedding_dim)        self.position_encoding[:, 0::2] = torch.sin(position * div_term)        self.position_encoding[:, 1::2] = torch.cos(position * div_term)        def forward(self, x):        x += self.position_encoding[:x.size(0), :]                return x# 初始化模型model = TransformerModel(embedding_dim, hidden_dim, output_dim, num_heads, num_layers)# 定义损失函数和优化器criterion = nn.CrossEntropyLoss()optimizer = optim.Adam(model.parameters())# 训练模型for epoch in range(num_epochs):    model.train()    for batch in train_iterator:        optimizer.zero_grad()                text = batch.text        label = batch.label                output = model(text)                loss = criterion(output, label)                loss.backward()                optimizer.step()# 测试模型model.eval()with torch.no_grad():    for batch in test_iterator:        text = batch.text        label = batch.label                output = model(text)                # 进行预测等操作\n\n注意：上述代码中使用了torchtext库来加载和处理AG_NEWS数据集，如果没有安装该库，可以使用其他文本数据集或手动处理数据。另外，代码中的一些参数（如num_epochs）需要根据实际情况进行调整。\n","slug":"jinxing/不听 老人言","date":"2024-03-14T06:15:59.715Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"9418719c0649bc35464381494a75a244","title":"iMaotai预约","content":"iMaotai预约工具在 GitHub 上发现个宝藏项目，可帮你在 i茅台 App 上每日自动预约。  \nGitHub：github.com/oddfar/campus-imaotai  \n具有如下功能：  \n\n平台注册账号  \n添加多个用户  \n自动预约  \n门店选择（出货量最大，或附近位置）  \n自动旅行  \n首次旅行分享  \n获取申购耐力值  \n自定义时间/随机事件预约或旅行  \n申购结果消息推送  \n支持 Docker 一键部署\n\n","slug":"github/iMaotai预定工具","date":"2024-03-14T06:15:59.715Z","categories_index":"开源项目","tags_index":"github","author_index":"安全书"},{"id":"ffa4f73e59981c91bebef451824c2228","title":"Graylog库测试","content":"12print(&quot;Hello World&quot;)\n\n\n调用Graylog的Python，并进行授权访问。\n1from pygraylog.graylogapi import GraylogAPI\n\n\nObsidian的Kanban插件有什么用？\n","slug":"candylab/Graylog库测试","date":"2024-03-14T06:15:59.714Z","categories_index":"Sec,Graylog","tags_index":"安全数据运营","author_index":"安全书"},{"id":"3e5e0ad875e008f2f5596d741d0ac42f","title":"HFish蜜罐与SOC安全运营中心","content":"HFish蜜罐与SOC安全运营中心\n\n\n\n\n\n\n\n\nExcerpt作者：糖果\n\n0x01 传统蜜罐传统蜜罐在安全运营当中，起到防御与威胁发现的作用。蜜罐系统提供Web（WordPress等）服务模拟、及各种主机服务模拟，比如：ElasticSearch、FTP、Telnet、Redis等。 类似FTP、Telnet等高交互蜜罐，不只是开放各种协议服务的端口监听，还真实的模拟的服务用户的交互逻辑，当攻击者访问蜜罐仿真的服务，蜜罐系统会像真的用户访问FTP、Telnet服务一样， 响应用户的操作。\n0x02 反制与溯源随时蜜罐技术迭代发展，从传统蜜罐、高交互蜜罐、 发展具有成高阶形式功能的，具有反制溯源、欺骗防御、主动防御的综合服务仿真蜜罐信息系统。 构建安全防御系统，需要各种安全工具链提供支持，蜜罐系统是安全防御工具链中重要的工具，选用几款优秀的蜜罐系统，应用于安全运营实践过程，对防御工作很必要，蜜罐可以分别部署于内、外网环境当中，这一次介绍的是HFIsh。 在攻击的过程，蜜罐系统会接收攻击者的攻击输入信息，包括攻击用的系统及工具的信息，攻击者可能暴露的个人信息，可溯源反制的蜜罐系统，会根据这些信息，进行攻击者身份信息的关联溯源，根据攻击者系统工具的信息，实施基于对方可能存在漏洞的反制攻击。 如果攻击者可暴露给蜜罐系统的输入数据，不够充分有效，反制溯源就比较困难。\n0x03 蜜罐与防御体系融合HFish\n以HFish构建的蜜罐系统为例，下面是HFish蜜罐系统在实践过程中，一个系统关联图。\n\nHFish是一个具备典型新型蜜罐特征的蜜罐系统，同时提供、低交互、高交互、反制溯源功能。 蜜罐系统属于安全系统中的一个子系统，在安全运营过程中， 需要将蜜罐系统与整个安全防御体系进行融合，将蜜罐系统、TDP流量分析系统、SIEM事件管理系统、SOC运营系统进行协同，最后成为整SOC安全运营系统功能的一部分，与更多防御信息系统进行协防，比如HIDS系统等。 TDP：TDP和HFish同出一家，TDP是流量分析系统，同时提供HFish的接入功能，在HFish相对早期的版本，我们将HFish接入到TDP系统，尝试让HFish威胁日志接入数据库集群，并在某些安全活动使用。TDP对接HFish，接入数据是蜜罐威胁事件日志，并提供蜜罐结点的威胁的攻击统计、威胁事件告警检索功能。接入蜜罐日志后，并不将威胁日志中的IP与威胁情报进行关联，与威胁情报的关联，是在接入日志之前就完成了，所以需要在HFish中接入IP信誉库API。\n\nIP信誉库：在实践的过程中，蜜罐系统与HIDS系统，在判定IP的威胁时，用了同一套IP信誉库，与TDP不同的是， TDP有本地的威胁情报库，会远程下拉同步威胁情报，所以也没有查询上限的限制， 而其他系统需要通过API来完成IP研判工作，没有本地的威胁情报库，有API每天的调用上限次数限制。\n0x04 事件管理与运营管理SIEM：威胁事件管理系统用来处理，TDP接入的蜜罐威胁事件日志， 由TDP转发给SIEM或者，由HFish直接发给SIEM，蜜罐威胁日志成为多条威胁数据管道处理中的一条支流处理分支，然后由SIEM与SOC进行后续的交互，进行威胁的收敛研判。 \nSOC：安全防御信息系统中，有众多的子系统，SIEM通过数据管道完成威胁事件的聚合管理、数据的中继外发、威胁事件数据提供，SOC的一项功能是，完成威胁事件的收敛工作，并建立收敛后的事件与响应流程的联系， 产出可以是建立响应处理提案、各种形式的告警（邮件、群机器人等）、可视化统计、威胁定位检索等。\n0x05 蜜罐联动实践微步在运营HFish之后，HFish不断在升级，各防守单位人员，也加入使用的HFish蜜罐的用户中，配置要求低，上手快，还有可视化大屏幕，支持常见的蜜罐服务和一些比较新威胁服务模拟检测，与威胁情报社区联动，流量分析平台联动。HFish可以与SIP、X社区的联动，使用社区的威胁情报查询Key，进行威胁溯源，还可以与自家的流量威胁检测服务产品TDP进行联动。与TDP的联动最开始因数HFish的输出字段不确定，造成正则不确定，没法正确识别，HFish推送给TDP的告警，但后期这个问题都解决了。包括从本地数据库，迁移到使用云上MySQL也是没问题的，这样相当于分布式蜜罐的报警，可以聚合在TDP流量分析平台上，本地数据都放到云的MySQL上做集中管理。\n\n添加X社区的威胁查询APIKey与IP信誉库进行关联。\n\n申请的API有又上的权限。 \n大屏幕与TDP的4种视角不同，只有一种模式，但是看着还是很直观的。\n\nHFish支持分布式部署管理，支持与X社区联动，取威胁情报，支持与TDP流理分析平联动，关联攻击IP在内网的所有威胁事件，全流量网络连接分析，这些特性是别的单体蜜罐做不到的，提供的服务要比一般的蜜罐，不能与威胁情报联动，不能与流量分析平台联动相比，功能更丰富立体。下面是HFish提供的蜜罐服务，比之前模拟的服务要多很多，而且很接地气，基本覆盖了常见漏洞服务。\n\nHFish还提供威胁风险的检测识别能力，并且可以自己通过YARA，进行自定义检测规则的编写。\n自己在蜜罐后台上，创建检测规则。HFish与流量分析平台TDP联动 HFish可以将蜜罐的告警发送给TDP，进行威胁聚合，威胁关联。用户可从选择只看攻击蜜罐告警信息，也可以在TDP蜜罐监控界面，查看网络流量中，攻击蜜罐的源IP，所有的威胁事件告警信息，威胁情报，威胁名称等等。\n\n蜜罐上呈现是那些IP攻击了蜜罐，而TDP上可以展现出，攻击蜜罐的IP，在内网所有的威胁事件的信息，全流量通信信息。\n\nHFish蜜罐接入到TDP，需要创建一个数据接受监听，并通过正则进行解析，这个正则是随着HFish输出字段的明确，最后固定下来了的。\n0x06 总结所有子系统的威胁事件管理，可以类似HFish蜜罐接入SOC系统一样，将安全运营人员对蜜罐高频操作的威胁确认、统计、等高频常用工作，融合到SOC 系统中，形成子威胁系统在SOC系统中，对应安全运营角色（蜜罐操作者）的工作流程，不用登录蜜罐子系统，在SOC中集中完成蜜罐相关的安全响应处理工作。\n","slug":"candylab/soc","date":"2024-03-14T06:15:59.714Z","categories_index":"文章","tags_index":"","author_index":"安全书"},{"id":"3f78d971eabe4d648c246dd6ba6afdb2","title":"教你理解和构建GPT Tokenizer","content":"教你理解和构建GPT TokenizerOpen AI传奇研究员Andrej Karpathy的新课，教你理解和构建GPT Tokenizer。\n他可以把相当复杂的LLM概念用非常好理解的方式讲出来。希望了解LLM的强烈建议听一下他的课，包括一些历史课程。  \n用GPT-4翻译了一下这节课，感兴趣可以听一下。字幕文件下载和历史课程会放最后。  \n补充一下视频介绍：  \n分词器是大语言模型（LLM）处理流程中一个独立且关键的环节。它们有专属的训练数据集、采用特定的训练算法——字节对编码（Byte Pair Encoding），训练完成后，分词器能够执行两个核心功能：encode() 函数将普通文本字符串转换为词元，而 decode() 函数则能将词元还原为原始文本字符串。在这场讲座中，我们将一步步揭开 OpenAI GPT 系列分词器的构建过程。  \n我们将发现，许多大语言模型(LLM)表现出的异常行为和问题，其实都源于标记化(tokenization)这一环节。我们会针对这些问题进行详细讨论，探究标记化为何成为问题的关键所在，以及为什么最理想的情况是有人能够找到办法，完全去除这一处理阶段。\n00:00:00 intro: Tokenization, GPT-2 paper, tokenization-related issues00:05:50 tokenization by example in a Web UI (tiktokenizer)00:14:56 strings in Python, Unicode code points00:18:15 Unicode byte encodings, ASCII, UTF-8, UTF-16, UTF-3200:22:47 daydreaming: deleting tokenization00:23:50 Byte Pair Encoding (BPE) algorithm walkthrough00:27:02 starting the implementation00:28:35 counting consecutive pairs, finding most common pair00:30:36 merging the most common pair00:34:58 training the tokenizer: adding the while loop, compression ratio00:39:20 tokenizer/LLM diagram: it is a completely separate stage00:42:47 decoding tokens to strings00:48:21 encoding strings to tokens00:57:36 regex patterns to force splits across categories01:11:38 tiktoken library intro, differences between GPT-2/GPT-4 regex01:14:59 GPT-2 encoder.py released by OpenAI walkthrough01:18:26 special tokens, tiktoken handling of, GPT-2/GPT-4 differences01:25:28 minbpe exercise time! write your own GPT-4 tokenizer01:28:42 sentencepiece library intro, used to train Llama 2 vocabulary01:43:27 how to set vocabulary set? revisiting gpt.py transformer01:48:11 training new tokens, example of prompt compression01:49:58 multimodal [image, video, audio] tokenization with vector quantization01:51:41 revisiting and explaining the quirks of LLM tokenization02:10:20 final recommendations\nhttps://pan.quark.cn/s/60d51adb8ecc#/list/share\n\n","slug":"course/教你理解和构建GPT Tokenizer","date":"2024-03-14T06:15:59.714Z","categories_index":"课程","tags_index":"GPT","author_index":"安全书"},{"id":"d4d3965730bda512a6efdd0a5e371f72","title":"ElasticSearch数据库","content":"ElasticSearch是一个开源的分布式搜索和分析引擎，它是基于Apache Lucene构建的。它具有高可用性、可扩展性和实时性等特点。ElasticSearch被广泛应用于构建实时的、可扩展的全文搜索和分析系统。\n首先，ElasticSearch采用了分布式架构，可以将数据进行分片和复制，并在多个节点上进行存储和处理。这样可以实现高可用性和横向扩展，提供更好的性能和容错能力。\n其次，ElasticSearch具有快速的搜索速度，能够在毫秒级别内返回结果。这得益于它基于倒排索引的搜索方式以及并行处理能力。\n此外，ElasticSearch支持多种数据类型的搜索和分析。除了全文搜索之外，还支持结构化数据、地理位置数据等多种类型的查询。\n另外，ElasticSearch提供了灵活而强大的查询语言，可以进行复杂的查询操作。用户可以通过关键字匹配、范围查询、聚合等功能来满足不同场景下的需求。\n此外，ElasticSearch还具备实时分析能力。它可以对大规模数据进行聚合、统计和可视化，并支持实时更新。\n由于采用了分布式架构，ElasticSearch具有良好的可扩展性。用户可以根据需要增加或减少节点，并自动进行数据重新平衡。\n最后，ElasticSearch拥有丰富的第三方插件和工具，形成了一个庞大的生态系统。用户可以与各种其他系统进行集成，如Logstash、Kibana等。\n总而言之，ElasticSearch是一个功能强大、高性能的搜索和分析引擎，被广泛应用于日志分析、企业搜索、电子商务等领域。\nElasticSearch数据库介绍一下ElasticSearch数据库\nElasticSearch是一个分布式的开源搜索和分析引擎，基于Apache Lucene。它被广泛用于构建实时的、可扩展的全文搜索和分析系统。\n以下是ElasticSearch的一些特点：\n\n分布式架构：ElasticSearch采用分布式架构，可以在多个节点上进行数据分片和复制，从而实现高可用性和横向扩展。\n\n实时搜索：ElasticSearch具有快速的搜索速度，能够在毫秒级别内返回结果。\n\n多种数据类型支持：除了支持全文搜索之外，ElasticSearch还支持结构化数据、地理位置数据等多种数据类型。\n\n强大的查询语言：ElasticSearch提供了灵活而强大的查询语言，可以进行复杂的查询操作，包括关键字匹配、范围查询、聚合等。\n\n实时分析：除了搜索功能之外，ElasticSearch还具备实时分析能力。它可以对大规模数据进行聚合、统计和可视化，并支持实时更新。\n\n可扩展性：由于采用了分布式架构，ElasticSearch可以轻松地水平扩展。用户可以根据需要增加或减少节点，并自动进行数据重新平衡。\n\n大型生态系统：ElasticSearch拥有丰富的第三方插件和工具，可以与各种其他系统进行集成，如Logstash、Kibana等。\n\n\n总之，ElasticSearch是一个功能强大、高性能的搜索和分析引擎，适用于构建实时的、可扩展的全文搜索和分析系统。它被广泛应用于日志分析、企业搜索、电子商务等领域。\n","slug":"database/ElasticSearch数据库","date":"2024-03-14T06:15:59.714Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"43f90c12463554e00ec510131f646051","title":"Flink时间窗口","content":"Flink时间窗口Flink的部署与使用。\n给出一个FLink 1.15的Flink时间窗口的处理代码\n\n1234567891011121314151617181920import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.api.windowing.time.Time;public class WindowProcessing &#123;    public static void main(String[] args) throws Exception &#123;        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        DataStream&lt;String&gt; dataStream = env.socketTextStream(&quot;localhost&quot;, 9999);        dataStream.flatMap(new WordCountSplitter())                .keyBy(0)                .timeWindow(Time.seconds(10))                .sum(1)                .print();        env.execute(&quot;Window Processing Example&quot;);    &#125;&#125;\n\n在这个例子中，我们使用了一个10秒的时间窗口，并对每个窗口内的数据进行求和操作。WordCountSplitter是一个自定义的FlatMapFunction，用于将输入的字符串分割成单词并输出 (不包含在代码片段中)。最后，我们通过调用print()方法将结果打印出来。\n给出一段Flink 1.15处理读取Kafka并对应调整数据格式的代码\n123456789101112131415161718192021222324252627282930import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;public class KafkaStreamProcessing &#123;    public static void main(String[] args) throws Exception &#123;        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        Properties properties = new Properties();        properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);        properties.setProperty(&quot;group.id&quot;, &quot;flink-consumer-group&quot;);        FlinkKafkaConsumer&lt;String&gt; kafkaConsumer = new FlinkKafkaConsumer&lt;&gt;(&quot;topic-name&quot;, new SimpleStringSchema(), properties);                DataStream&lt;String&gt; kafkaDataStream = env.addSource(kafkaConsumer);        DataStream&lt;String&gt; processedDataStream = kafkaDataStream.map(new MapFunction&lt;String, String&gt;() &#123;            @Override            public String map(String value) throws Exception &#123;                // 对数据进行调整处理，例如格式转换等操作                return value.toUpperCase();            &#125;        &#125;);        processedDataStream.print();        env.execute(&quot;Kafka Stream Processing&quot;);    &#125;&#125;\n\n在这段代码中，我们首先创建了一个StreamExecutionEnvironment对象，并设置了Kafka的连接属性。然后创建一个FlinkKafkaConsumer对象来读取指定的Kafka主题中的数据。接着对读取到的数据进行处理，这里简单地将数据转换为大写字母，并使用processedDataStream.print()方法打印出来。最后调用env.execute()方法来执行Flink作业。\n给出一个Flink从Kafka队列中读取Nginx日志， 并统计日志PV数据的代码\n123456789101112131415161718192021222324252627282930313233343536373839404142import org.apache.flink.api.common.functions.FlatMapFunction;import org.apache.flink.api.java.tuple.Tuple2;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;import org.apache.flink.util.Collector;import java.util.Properties;public class NginxLogPVCounter &#123;    public static void main(String[] args) throws Exception &#123;        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        Properties properties = new Properties();        properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);        properties.setProperty(&quot;group.id&quot;, &quot;nginx-log-group&quot;);        FlinkKafkaConsumer&lt;String&gt; kafkaConsumer = new FlinkKafkaConsumer&lt;&gt;(&quot;nginx-logs&quot;, new SimpleStringSchema(), properties);        DataStream&lt;String&gt; nginxLogs = env.addSource(kafkaConsumer);        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; pvCounts = nginxLogs.flatMap(new LogPVCounter())                .keyBy(0)                .sum(1);        pvCounts.print();        env.execute(&quot;Nginx Log PV Counter&quot;);    &#125;    public static class LogPVCounter implements FlatMapFunction&lt;String, Tuple2&lt;String, Integer&gt;&gt; &#123;        @Override        public void flatMap(String log, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out) &#123;            // Assuming each log entry is in the format: timestamp client_ip request_url response_code            String[] tokens = log.split(&quot;\\\\s+&quot;);            if (tokens.length &gt;= 3) &#123;                String requestUrl = tokens[2];                out.collect(new Tuple2&lt;&gt;(requestUrl, 1));            &#125;        &#125;    &#125;&#125;\n\n这段代码实现了从Kafka队列中读取Nginx日志数据，统计每个请求URL的PV数据并输出。需要引入相关的Flink和Kafka依赖包。在代码中，假设每个日志条目是以空格分隔的格式，包含时间戳、客户端IP、请求URL和响应码。通过flatMap函数将每条日志拆分并提取请求URL信息，然后进行计数并累加，最后通过keyBy和sum函数实现对PV数据的统计。最后将结果打印出来。\n给出Flink读取Kafka队列数据的Java代码\n123456789101112131415161718192021222324import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;import java.util.Properties;public class KafkaReader &#123;    public static void main(String[] args) throws Exception &#123;        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        Properties properties = new Properties();        properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);        properties.setProperty(&quot;group.id&quot;, &quot;test-consumer-group&quot;);        FlinkKafkaConsumer&lt;String&gt; kafkaConsumer = new FlinkKafkaConsumer&lt;&gt;(&quot;topic-name&quot;, new SimpleStringSchema(), properties);        DataStream&lt;String&gt; stream = env.addSource(kafkaConsumer);        stream.print();        env.execute(&quot;Kafka Reader&quot;);    &#125;&#125;\n\n请注意替换代码中的”localhost:9092”为您的Kafka服务器地址，”test-consumer-group”为您的消费者组名称，以及”topic-name”为您要读取数据的主题名称。\n给出Flink的DataStream，基于Sink向ElasticSearch写入数据的Java代码\n12345678910111213141516171819202122232425262728293031323334353637383940import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink;import org.apache.http.HttpHost;import org.elasticsearch.client.Requests;import org.elasticsearch.common.xcontent.XContentBuilder;import java.util.ArrayList;import java.util.List;public class FlinkElasticsearchSink &#123;    public static void main(String[] args) throws Exception &#123;        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        // 设置数据源        DataStream&lt;String&gt; dataStream = ... // 设置数据源        List&lt;HttpHost&gt; httpHosts = new ArrayList&lt;&gt;();        httpHosts.add(new HttpHost(&quot;localhost&quot;, 9200, &quot;http&quot;));        ElasticsearchSink.Builder&lt;String&gt; esSinkBuilder = new ElasticsearchSink.Builder&lt;&gt;(                httpHosts,                new ElasticsearchSinkFunction&lt;String&gt;() &#123;                    public void process(String element, RuntimeContext ctx, RequestIndexer indexer) &#123;                        XContentBuilder jsonBuilder = ... // 构建要写入Elasticsearch的数据                        indexer.add(Requests.indexRequest().index(&quot;your_index&quot;).type(&quot;your_type&quot;).source(jsonBuilder));                    &#125;                &#125;        );        // 设置刷新配置        esSinkBuilder.setBulkFlushMaxActions(1);        dataStream.addSink(esSinkBuilder.build());        env.execute(&quot;Flink Elasticsearch Sink&quot;);    &#125;&#125;\n\n请注意，上述代码中的...部分需要根据实际情况进行替换和补充。在实际应用中，您可能需要从外部数据源读取数据，构建XContentBuilder对象以表示要写入Elasticsearch的数据，设置索引名称和类型等。\nDataStream的source、sink处理类之外，那个类是用于处理中间的数据，具体的回调函数名称是什么？\n处理中间数据的类是DataStream的operator类，具体的回调函数名称是processElement。\n给出DataStream的Operator类中processElement回调函数的使用案例的代码\n1234567891011121314151617181920212223242526272829import org.apache.flink.api.common.functions.MapFunction;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.api.functions.ProcessFunction;import org.apache.flink.util.Collector;public class ProcessElementExample &#123;    public static void main(String[] args) throws Exception &#123;        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        // 创建一个DataStream        DataStream&lt;Integer&gt; dataStream = env.fromElements(1, 2, 3, 4, 5);        // 使用ProcessFunction对DataStream进行处理        DataStream&lt;Integer&gt; processedStream = dataStream.process(new ProcessFunction&lt;Integer, Integer&gt;() &#123;            @Override            public void processElement(Integer value, Context ctx, Collector&lt;Integer&gt; out) throws Exception &#123;                // 在这里对每个元素进行处理                out.collect(value * 2);            &#125;        &#125;);        // 打印处理后的结果        processedStream.print();        env.execute(&quot;Process Element Example&quot;);    &#125;&#125;\n\n\n给出DataStream的Operator类对Kafka数据操作的代码实例。\n下面是一个使用Kafka作为数据源的DataStream操作示例代码：\n1234567891011121314151617181920212223242526272829import org.apache.flink.api.common.serialization.SimpleStringSchema;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;import java.util.Properties;public class KafkaDataStreamOperator &#123;    public static void main(String[] args) throws Exception &#123;        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();        Properties properties = new Properties();        properties.setProperty(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);        properties.setProperty(&quot;group.id&quot;, &quot;test-group&quot;);        FlinkKafkaConsumer&lt;String&gt; kafkaConsumer = new FlinkKafkaConsumer&lt;&gt;(&quot;test-topic&quot;,                new SimpleStringSchema(), properties);        DataStream&lt;String&gt; kafkaStream = env.addSource(kafkaConsumer);        // 对从Kafka读取的数据进行处理        DataStream&lt;String&gt; processedStream = kafkaStream.map(value -&gt; value.toUpperCase());        processedStream.print();        env.execute(&quot;Kafka Data Stream Operator&quot;);    &#125;&#125;\n\n在这个示例中，我们首先创建了一个Flink的执行环境env和用于连接到Kafka的配置属性properties。然后创建了一个FlinkKafkaConsumer实例，并使用addSource()方法将其添加到Flink流中。\n接下来，我们对从Kafka读取的数据进行处理，这里简单地将每条消息都转换为大写形式。最后，我们调用print()方法将处理后的数据打印出来，并执行Flink作业。\n请注意，上述示例中只是对从Kafka读取的数据进行了简单处理，实际应用中可以根据需求进行更复杂的操作。\n","slug":"database/Flink时间窗口","date":"2024-03-14T06:15:59.714Z","categories_index":"数据库","tags_index":"flink","author_index":"安全书"},{"id":"33c55ffd3c8f845bdd456e6a57948fae","title":"Graylog威胁日志处理","content":"Graylog威胁日志处理如何在Linux上安装Graylog系统\n要在Linux上安装Graylog系统，您可以按照以下步骤进行操作：\n\n安装Java运行时环境（JRE）：Graylog需要Java运行时环境来运行。您可以使用以下命令安装OpenJDK 8：\n12sudo apt-get updatesudo apt-get install openjdk-8-jre-headless\n导入Graylog GPG密钥：使用以下命令导入Graylog的GPG密钥，以便系统可以验证软件包的完整性：\n1234wget https://packages.graylog2.org/repo/packages/graylog-4.2-repository_latest.deb.sha256wget https://packages.graylog2.org/repo/packages/graylog-4.2-repository_latest.debsha256sum -c graylog-4.2-repository_latest.deb.sha256sudo dpkg -i graylog-4.2-repository_latest.deb\n安装Elasticsearch：Graylog使用Elasticsearch作为后端数据库。您可以使用以下命令安装Elasticsearch 7.x：\n1sudo apt-get install elasticsearch=7.x.x\n配置Elasticsearch：编辑/etc/elasticsearch/elasticsearch.yml文件并进行以下配置：\n12cluster.name: graylogaction.auto_create_index: false\n启动和启用Elasticsearch服务：\n12sudo systemctl enable elasticsearch.servicesudo systemctl start elasticsearch.service\n安装MongoDB：Graylog需要MongoDB来存储配置信息和元数据。您可以使用以下命令安装MongoDB：\n1sudo apt-get install mongodb-server\n安装Graylog服务器：使用以下命令安装Graylog服务器：\n1sudo apt-get install graylog-server\n配置Graylog服务器：编辑/etc/graylog/server/server.conf文件并进行以下配置：\n123rest_listen_uri = http://&lt;your_server_ip&gt;:9000/api/web_listen_uri = http://&lt;your_server_ip&gt;:9000/elasticsearch_hosts = http://127.0.0.1:9200\n启动和启用Graylog服务器：\n12sudo systemctl enable graylog-server.servicesudo systemctl start graylog-server.service\n访问Graylog Web界面：在浏览器中输入http://&lt;your_server_ip&gt;:9000，然后使用默认用户名和密码（用户名：admin，密码：admin）登录到Graylog Web界面。\n\n\n以上就是在Linux上安装Graylog系统的步骤。请确保按照要求配置每个组件，并检查日志以解决任何问题。\n","slug":"database/Graylog威胁日志处理","date":"2024-03-14T06:15:59.714Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"f265caf366478add089d1a27b17487ff","title":"chromadb","content":"chromadbchromadb是一种什么样的数据库，在什么场景使用chroma数据库。\nChromaDB是一种高性能的时间序列数据库，主要针对存储和分析大规模的时间序列数据。它被设计用于处理和查询实时数据，例如传感器数据、日志数据、度量指标等。\nChromaDB适用于许多场景，包括但不限于以下几个方面：\n\n物联网应用：由于物联网设备产生的海量传感器数据，ChromaDB可以快速存储和查询这些时间序列数据，并支持实时分析和可视化。\n金融领域：金融市场产生大量的交易数据和市场行情数据，ChromaDB可以帮助快速处理这些时间序列数据，并进行实时风险管理和决策支持。\n运营监控：对于需要实时监控系统状态、网络流量、服务器指标等运营数据的场景，ChromaDB可以提供高性能的存储和查询能力，并支持实时报警和事件触发。\n日志分析：对于大规模系统产生的日志数据，ChromaDB可以高效地存储和检索这些时间序列日志，并进行快速问题定位和故障排查。\n应用性能监控：通过收集应用程序产生的度量指标、性能统计等时间序列数据，ChromaDB可以提供实时监控和分析，帮助优化和调试应用程序。\n\n总而言之，ChromaDB适用于需要高性能存储和分析时间序列数据的场景，可以满足实时数据处理和查询的需求。\nChromaDB数据库如何与大语言模型Langchain进行结合， 对应的使用的Python代码是什么？\n要将ChromaDB数据库与大语言模型Langchain结合起来，可以使用以下Python代码：\n1234567891011121314151617from langchain import Langchainfrom chromadb import ChromaDB# 创建ChromaDB实例chroma_db = ChromaDB()# 创建Langchain实例langchain = Langchain()# 从ChromaDB数据库中获取数据data = chroma_db.get_data()# 将数据传递给Langchain进行处理和生成语言模型generated_text = langchain.generate_text(data)# 打印生成的文本print(generated_text)\n\n请注意，上述代码仅为示例，具体的实现可能会根据您的需求和具体情况有所不同。您需要确保安装了正确版本的langchain和chromadb库，并在代码中导入相应的模块。另外，您还需要根据实际情况进行适当的配置和参数设置。\n数据库如何使用，如何创建对应的数据库， 如何写入与读取数据，用Python语言进行实现表示。\n ChromaDB嵌入式数据库， 如何创建数据库，插入数据，查询数据库记录数据。\n要使用ChromaDB嵌入式数据库，您需要按照以下步骤进行操作：\n\n安装ChromaDB：首先，您需要下载并安装ChromaDB数据库。可以从官方网站或其他可靠来源获取安装程序。\n\n创建数据库：在ChromaDB中，可以通过使用CREATE DATABASE语句来创建一个新的数据库。例如，要创建名为”mydatabase”的数据库，您可以执行以下语句：\n1CREATE DATABASE mydatabase;\n连接到数据库：一旦创建了数据库，您可以使用连接字符串或其他适当的方法连接到该数据库。连接后，您将能够执行后续的插入和查询操作。\n\n插入数据：要向ChromaDB中的表中插入数据，您需要执行INSERT INTO语句。例如，要将数据插入名为”users”的表中，可以执行以下语句：\n1INSERT INTO users (name, age) VALUES (&#x27;John&#x27;, 25);\n查询数据：要从ChromaDB中检索数据记录，您可以使用SELECT语句。例如，要检索名为”John”的用户记录，可以执行以下语句：\n1SELECT * FROM users WHERE name = &#x27;John&#x27;;\n\n以上是使用ChromaDB嵌入式数据库创建、插入和查询数据的基本步骤。请注意，在实际应用程序中可能还需要进行其他配置和处理以适应特定需求。\n如何在Windows下安装ChromaDB数据库，安装后如何进入数据库创建一个数据库\n要在Windows下安装ChromaDB数据库，您可以按照以下步骤操作：\n\n下载ChromaDB数据库的安装程序。您可以从官方网站或开发者提供的其他来源下载安装程序。\n\n双击运行安装程序，并按照提示进行安装。您可能需要选择安装目录和其他选项。\n\n完成安装后，打开命令提示符或PowerShell控制台。\n\n在命令提示符或PowerShell中，输入chromadb并按Enter键运行ChromaDB。\n\nChromaDB将启动并监听默认端口（一般为8080）。\n\n\n现在，您已经成功安装了ChromaDB数据库。接下来，我们将进入数据库创建一个新的数据库：\n\n打开Web浏览器，并输入http://localhost:8080（如果您更改了默认端口，请相应地更改URL）。\n\nChromaDB Web界面将打开。在登录页面中，使用默认用户名和密码（通常为admin/admin）进行登录。\n\n成功登录后，您将进入ChromaDB的管理界面。从左侧导航栏中选择“Database”选项。\n\n在“Database”页面上，点击“Create New Database”按钮。\n\n在弹出窗口中，输入新数据库的名称，并选择其他相关配置选项（如存储引擎类型、分片策略等）。\n\n点击“Create”按钮创建新的数据库。\n\n\n现在，您已经成功创建了一个新的数据库。您可以在ChromaDB的管理界面中查看和管理这个数据库的数据和配置。\n翻译一下这段英文Chroma is the open-source embedding database. Chroma makes it easy to build LLM apps by making knowledge, facts, and skills pluggable for LLMs.\nChroma是一个开源的嵌入式数据库。通过为LLM（Language Learning Model）提供可插拔的知识、事实和技能，Chroma使构建LLM应用变得容易。\nChroma向量数据库，如何下载安装。\n要下载和安装Chroma向量数据库，可以按照以下步骤进行操作：\n\n在Chroma向量数据库的官方网站上找到下载页面。通常可以在官方网站的”下载”或”获取”部分找到相应链接。\n\n点击下载链接，选择合适的版本和操作系统。确保选择与您的计算机系统兼容的版本。\n\n下载完成后，找到下载文件并双击运行安装程序。根据安装程序的指示进行操作。\n\n在安装过程中，您可能需要选择要安装的组件和设置相关选项。按照您的需求进行选择。\n\n完成安装后，启动Chroma向量数据库软件。在开始菜单、桌面或安装目录中可以找到启动图标。\n\n第一次启动时，您可能需要进行一些初始化设置，如选择数据库存储位置、配置网络连接等。根据软件提供的指引完成设置过程。\n\n安装完成后，您可以通过Chroma向量数据库提供的界面或命令行工具来管理和使用数据库。根据软件提供的文档和教程学习如何使用该工具。\n\n\n请注意，在下载和安装任何软件之前，请确保从官方可信源获取，并遵循官方提供的安装指南。\n","slug":"database/chromadb","date":"2024-03-14T06:15:59.714Z","categories_index":"database,vector","tags_index":"chromadb","author_index":"安全书"},{"id":"1dd34b64279f97a4da3506fc15b8477a","title":"git查看远程分支更新了那些文件","content":"git查看远程分支更新了那些文件git用什么命令，可以不下载文件，就可以，查看远程分支更新了那些文件\n可以使用以下命令查看远程分支更新了哪些文件:\n12git fetchgit diff origin/&lt;branch_name&gt; --name-only\n\n这些命令将拉取远程分支的最新更新，并显示与本地分支的差异。通过 --name-only 选项，只会显示有哪些文件发生了变化，而不会下载这些文件。\ngit fetch是一个用于从远程仓库中获取最新提交的命令。它可以将当前分支或标签与远程仓库进行同步，并更新本地分支或标签。️\ngit fetch的功能是什么\n","slug":"git/git查看远程分支更新了那些文件","date":"2024-03-14T06:15:59.714Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"a4cc3e6497b185bdf26848e017238565","title":"AI换衣服OOTDiffusion","content":"AI换衣服OOTDiffusionOOTDiffusion：一个高度可控的虚拟服装试穿开源工具  \n测试了下，效果真的很不错😋  \n可以根据不同性别和体型自动调整，和模特非常贴合。也可以根据自己的需求和偏好调整试穿效果  \nOOTDiffusion支持半身模型和全身模型两种模式。\n项目：https://github.com/levihsu/OOTDiffusion?continueFlag=bce9ec7a1b53c96a82251a0fbd34b5f8\n Demo:https://ootd.ibot.cn/?continueFlag=bce9ec7a1b53c96a82251a0fbd34b5f8\n","slug":"github/AI换衣服OOTDiffusion","date":"2024-03-14T06:15:59.714Z","categories_index":"AIGC,gihub","tags_index":"OOTDiffusion","author_index":"安全书"},{"id":"aaf5766099e8206fd4b43f584166f61e","title":"编译C++项目使用OpenSSL库","content":"OpenSSL\n一些C/CPP项目，在代码中使用HTTPS协议访问网站，需要使用OpenSSL的.h原文件和SSL库，在编译的时候需要连接这两个资源。 \n在Mac OS上，默认安全的不是通常意义上的开源的OpenSSL， 需要我们手动通过brew进行安装。\n1brew install  openssl\n\n\n在CPP编译时要指明.h的位置和库文件的位置。通过-I和-L两个参数。 \n查看OpenSSL的.h文件位置、库文件的位置，使用命令，如下：\n1brew info openssl\n\n\n我们用一个CPP项目，开展示编译参数的使用。 \n1git clone https://github.com/AntiSomnus/iDict-cmd.git\n\n\ng++ -Os -m64 -std=c++14 idict_linux.cpp -o idict -lssl -lcrypto -v $LDFLAGS\n为了让主程序连接时，可以找到OpenSSL的-lssl这个参数，对应的库文件，加了$LDFLAGS这个参数。这个参数等同于，如下：\n1-L/opt/homebrew/opt/openssl\n\n这路径通过brew info openssl查看，结果类似，如下：\n12345678910111213141516171819202122232425262728293031323334==&gt; openssl@3: stable 3.0.7 (bottled) [keg-only]Cryptography and SSL/TLS Toolkithttps://openssl.org//opt/homebrew/Cellar/openssl@3/3.0.7 (6,454 files, 28.0MB)  Poured from bottle on 2023-01-13 at 11:02:26From: https://github.com/Homebrew/homebrew-core/blob/HEAD/Formula/openssl@3.rbLicense: Apache-2.0==&gt; DependenciesRequired: ca-certificates ✔==&gt; CaveatsA CA file has been bootstrapped using certificates from the systemkeychain. To add additional certificates, place .pem files in  /opt/homebrew/etc/openssl@3/certsand run  /opt/homebrew/opt/openssl@3/bin/c_rehashopenssl@3 is keg-only, which means it was not symlinked into /opt/homebrew,because macOS provides LibreSSL.If you need to have openssl@3 first in your PATH, run:  echo &#x27;export PATH=&quot;/opt/homebrew/opt/openssl@3/bin:$PATH&quot;&#x27; &gt;&gt; ~/.zshrcFor compilers to find openssl@3 you may need to set:  export LDFLAGS=&quot;-L/opt/homebrew/opt/openssl@3/lib&quot;  export CPPFLAGS=&quot;-I/opt/homebrew/opt/openssl@3/include&quot;For pkg-config to find openssl@3 you may need to set:  export PKG_CONFIG_PATH=&quot;/opt/homebrew/opt/openssl@3/lib/pkgconfig&quot;==&gt; Analyticsinstall: 333,606 (30 days), 736,709 (90 days), 2,116,153 (365 days)install-on-request: 86,899 (30 days), 300,347 (90 days), 1,318,084 (365 days)build-error: 280 (30 days)\n\n\n这些返回结果中，和.h头文件，库文件，最直接相关的两个参数：CPPFLAGS和LDFLAGS。在编译的时候直接用$进行引用就可以,顺序如下：\n123export CPPFLAGS=&quot;-I/opt/homebrew/opt/openssl@3/include&quot;   export LDFLAGS=&quot;-L/opt/homebrew/opt/openssl@3/lib&quot;g++ -Os -m64 -std=c++14 idict_linux.cpp -o idict -lssl -lcrypto -v $LDFLAGS $CPPFLAGS\n\n\n\n经过如上的操作，在 Mac上编译时用OpenSSL库，就很顺畅了。\n因为用到加解密模块，很多其他的软件，都可能依赖OpenSLL，特别是很多的C/CPP代码项目工程。\n","slug":"blog/openssl","date":"2024-03-14T06:15:59.713Z","categories_index":"文章","tags_index":"OpenSSL","author_index":"安全书"},{"id":"00bd71ac36adab9def7848f7249016dc","title":"手机代理软件","content":"向网友们询问手机代理软件，大家推荐的： proxyman、charless。\n","slug":"blog/proxyman","date":"2024-03-14T06:15:59.713Z","categories_index":"文章","tags_index":"大数据安全","author_index":"安全书"},{"id":"b81e5d0679173671c6afd090f05d79cb","title":"Graylog几种数据格式规范方法","content":"Graylog对数据格式规范有很几种手段，其中最实用的三种:Split、GROK、Regular。\n分割符号(Split)Split：这个不用多介绍，就是利用分隔符切字段，最好理解。\nJSONJSON: JSON格式也是最简单，几乎不用配置，设备发过来JSON格式，直接按JSON格式解开就行了。\nGROK模式GROK：属于模块化，分装了一些现成的正则表达式，相当于给固定模式正则表达式起了别名。\n1%&#123;IPV4:SrcIP&#125;\n通过这个GROK，获取某个字符串当中的IP。\n原则字符串，如下：\n110.10.10.01:5678(test)-&gt;10.10.01.05:1235(test),\n\n结果，如下：\n12SrcIP    10.10.10.01\n\n这其中的IPV4，用的就是GROK。\n正则表达式（Regular）GROK和Split的方法，都有自己的局限，而正则表达式，正弥补这两个方式的解决不了一些细节问题，或者能解决，但是比较麻烦。\n举例，在告警的IOC信息里，找到CVE号。\n原始数据,如下：\n1XXXXXXXXXXXXXXXXXXXXXXX(CVE-2011-5007)XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\n接下来要做的，就是在这个长字符串中，找到：CVE-2011-5007，用如下的正侧表达式实现。\n1(?i)(cve-\\d&#123;4&#125;-\\d&#123;4,7&#125;)\n\n结果：\n1CVE-2011-5007\n\n以上就是几种，比较常见的数所规范化的手段。\n取得[：]之间的数据。由我们自己创建的一些安全策略规则， 在发出的告警日志中，自定义输出的内容格式，比如我们假定要发送部门相关的信息：[DEP:IS]像这种加了标签的数据，也可以用正则表达式进行定位这部分信息字段，[DEP:IS]对应的正则表达式，如下：\n1DEP:(.+?)]\n\n这样就要以提取[DEP:IS]中的内容’IS’。\n如果想输出另外一个标签，比如[DB:MySQL]一样的模式就可以了。  想取出数据库类型，修改一下上面的正则表达式就行了。\n1DB:(.+?)]\n 规则很明显 ， 想加什么标签，在[:]中的:前面加标签名，在:符号加标签属性就行了。 \n创建一条访问域名的suricata规则， 对于访问abc.com域名进行告警。\n下面的代码片段可以帮助你在 Suricata 上创建一条告警规则，用于监测 abc.com 域名的访问并报警：\nalert tcp any any -&gt; $HOME_NET any (msg:”Traffic from abc.com”; content:”abc.com”; http_host; sid:1000001; rev:1;)\n其中，\n\n$HOME_NET 部分表示监测内网中的访问行为。\ncontent:&quot;abc.com&quot; 是用于匹配访问 abc.com 的 HTTP 请求 / 响应头中的域名内容。\nhttp_host 表示只检查 HTTP 请求/响应中的 host 头部。\nsid(规则 ID) 是一个辨识符，用于标识每条规则，便于日后查看这项规则的细节及更新。\nrev表示规则的版本号，在发生了规则调整时将其 +1 即可。\n\n如果你想要对所有访问 abc.com 的端口进行检测，可以将第一个协议 (‘TCP’) 改为 ‘Any’：\nalert any any any -&gt; $HOME_NET any (msg:”Traffic from abc.com”; content:”abc.com”; http_host; sid:1000001; rev:1;)\n","slug":"blog/regular","date":"2024-03-14T06:15:59.713Z","categories_index":"文章","tags_index":"Graylog,正则表达式,GROK,JSON,Split","author_index":"安全书"},{"id":"402564c39cfb4dc9fb7de384d537a2bc","title":"安全运营项目的工作方法","content":"作者：李瑞\n本文信息量巨大，阅读大约需要二十分钟左右，建议加关注收藏后阅读。\n日常工作中对接研发同学的一次漏洞答疑，写代码优化敏感数据的识别统计指标，处理应急响应，安全BP发起弱口令治理，日常的补丁管理，组织大型的国家级“HVV”专项，都属于典型的安全运营类的项目范畴。\n\n安全运营是工作的一部分我们做了大量的安全运营工作，这些事情以项目论起来有大有小，不同公司对这些从事这些一线运营工作的内容描述有“拿结果”、“push”、”落地”、“打法”、”主导”不同的说法，我比较认可“推动”的说法，通过运营专项推动工作达到预定的治理效果，”推“和”动“很形象地说明关于安全运营的主要工作：需要主动“推一推才动”，安全的特点确实是要做成一件事，合作方确实有很少的意愿去配合，所以需要有科学的办法去运营这些事情。\n零零总总完成工作总是很容易的，但是首先要理解它为什么能完成？顺利和困难是偶然还是必然？是无意做出的决策还是有意遵循了什么逻辑？做到”知其然然后知其所以然“很难，虽然明面上运营这类事情有PMO( Program Management Officer 项目管理办公室)参与协助，但是PMO仅仅是运营项目的支持者和协调者，领域负责人必须承担全部的责任，这就考验为达成安全运营效果所要求的技术能力、沟通技巧和组织能力，参考基层安全管理者需要具备的素质。 \n临近年底组织内经常用运营专项的实施效果来衡量OKR和KPI的完成情况。虽然各种的安全运营专项的是安全部门运营工作的重要组成部分，但是回头看做得好坏并不仅仅取决于技术来实现，也负责人具备一些项目管理和软技能，将安全目标和企业运营逻辑“黏合”起来。 \n本文不讨论任何技术细节，而是以安全行业工作特点为例，系统化思考安全运营的本质，重点从项目角度介绍开展工作的基本功，仅仅是作为“井底之蛙”将浅薄的经验整理沉淀，希望通过同大家交流得到反馈。\n安全工作的逻辑在正式进入对这个问题的分析和探讨之前，我们很有必要整理下为什么我们要做这些安全专项？背后的思考逻辑是什么？公司各个团队是如何运作划分的？为什么分配你负责一个项目？\n安全团队是怎么运作的首先科普将安全作为风险管理的重要概念，各家组织最上级的安全战略决策机构，不管他们叫做什么风险委员会、首席风险官，集团安全办之类的，根据业界最佳实践会为了达到风险治理的目标从组织层面划分了三道防线完成整体安全目标： \n第一道防线是业务部门自己，出现安全风险后，业务是第一责任人，安全团队承担同等责任，业务内部有负责一线研发、对接BP、专职安全测试的人员，保证一线和自己相关的层面不出现问题。\n第二道防线是管理具体风险的专业安全部门。比如各家公司的业务风控和安全部门，也是安全从业者聚集最多的部门，一般划分为数据安全、风控、产品和IT安全多个团队。他们负责隐私保护、安全工具、渗透测试技术和应急响应工单系统等，构成大家最为熟知的安全管理防御战线。\n第三道防线大家直接接触不多，但是有意无意都在配合，指承担审计、测评合规，做合规制度、监督、流程控制活动的部门，一般理解是为了”务虚“，实际上基本代表安全工作的目标。\n那为什么组织内要运营大量安全专项呢？扫帚不到，灰尘是不会自己消失的，各个安全专项通过主动治理完成法律合规、数据安全，配合达成组织要求的战略目标。但是对于将要完成安全运营项目的压力不用自己背，公司在运营层面已经搭建好相关的治理框架，会提供三个成熟的管理体系来支撑：\n风险管理\n风险管理通过风险的识别、改进、度量、处置来管理内外部风险。管理Owasp Top10风险，SRC复盘漏洞工作，日常黑白盒漏洞发现、添加拦截规则等工作。\n运营管理\n运营管理通过指标体系、监督改进、报告度量、绩效考核从运营层面保证组织和人员的投入。比如日常的数据采集分析、运营漏斗模型，同业务沟通反馈风控策略，答疑安全sdk的使用等工作。\n项目建设管理\n项目管理是指某些待建设的专项来支持安全治理，采用项目管理的标准方法论。比如通过改进应用程序设计和基础设施架构提升安全性，例子包括建设一个容器waf、搭建开源kms、制定iot安全审计流程规范、供应链安全管理等。\n公司根据上述的逻辑来划分组织架构，提供保障资源。这个前提开展安全运营工作的基本盘，你所有的合作，沟通，管理、反馈，安全运营涉及的闪转腾挪都是基于这些体系运转的。\n定义安全运营项目参考项目的定义，安全运营专项在组织层面的定义很清楚：由安全团队作为二、三道防线完成风险发现和指导技术和运营，敦促一道业务防线配合，达成安全目标而采取的运营管理要素的总和。说人话就是：除了技术之外，为达成安全的”做事逻辑和方法”，都可以归类为安全运营。\n例子一：发起域控安全加固运营的安全运营项目，那么它有明确和具体的要素：\n\n目标--解决某一领域风险（域系统）\n\n工作范围--风险治理范围（并不仅仅是域控服务器，还包括打印机、exchange服务，但不包括未加入域的机器）\n\n预算和时间质量要求--在攻击者利用之前修复和建设完成，保证无入侵视野盲区。\n\n例子二：入侵检测项目运营\n\n目标：具备入侵服务器的安全监测技术和管理系统\n\n工作范围：IDC和办公网的资产\n\n预算：有限\n\n时间和质量要求：依时间计划阶段性建设基础和纵深防御和感知能力\n\n项目运营的要点但是没有人是主动的“长期主义者”，我们天性很喜欢写个Poc弹出个计算器，但是安全运营一般是以月度、季度和年来计算的，很难像写代码一样马上出true或者false的运营结果（相反运营做得越好，永远不会有风险在真实坏境被体现，越没有正向反馈）。\n那么有什么框架可以帮助大家来梳理思路呢？就像编程有框架和范式一样，安全运营可以参考ISO27001和应急响应IIPDRR（Identify、Protect、Detect、Respond、Recover）的工作方法论，借鉴PDCA循环：通过计划（Plan）、实施（Do）,检查（Check）,处理（Action）来改善工作。\n安全专项首先了解目前的安全问题或风险，对风险进行根因分析，设定目标和计划，分工完成任务，最后对检查任务执行的效果，评估风险现状，不断改进，达到闭环。\n\n图片\n计划的计划为了避免忙于具体事务而疏于运筹，安全运营计划要在实施前提前起草，这并不只是书面的计划，起码要做到心中有数，计划按照过程分为启动、组织准备、执行、结束、评估复盘阶段，计划的内容包括确定阶段划分、交付结果、里程碑、分工、沟通和决策机制和闭环条件。制定的计划要张弛有度，定稿后要公布出去。\n简单的安全运营比如写一段代码提升url去重效率，也可以视为一个黑盒扫描运营中的子类小计划，只是大家平时视而不见，但其实遵循同样的计划的做事逻辑。复杂的安全运营项目的计划和开发、挖掘漏洞相比，不是可以独立加班搞定的，依赖于多个合作方的配合，所以刚启动时最好是有以周为颗粒度的计划，迅速让各参与方独立制定“小计划”配合建立工作节奏。\n\n计划要取得干系人认同干系人是解决问题的关键点，承担安全运营的效果，干系人划分可以参考RACSIC模型：\n谁负责（R = Responsible），负责执行任务的角色，具体负责操控项目、解决问题。\n谁批准（A = Accountable），对任务负全责的角色，只有经其同意或签署之后，项目才能得以进行。\n谁支持（S = Support），参与具体任务，协助R完成工作的角色。\n咨询谁（C = Consulted），在任务实施前或中提供指定性意见的人员。\n告知谁（I = Informed），及时被通知结果的人员，不必向其咨询、征求意见。\n简单说干系人就是做安全运营需要哪些人参与，他们对工作效果有直接的影响，是活生生的人，不是代码，不能被忽视。\n范围划定范围是工作要做那些事的边界，有时候对于要运营的范围存在没说清楚、没想清楚然后工作资源分配不均匀。\n举个例子：理想情况下去评估一个对外采供应商的产品评估安全风险，但是做着做着发现这个外采系统依赖了大量的第三方开源组件，越评估涉及事情越多，这时候要在采购合同担保明确安全责任范围，是将系统作为一个安全管理的整体，还是仅仅关注核心交付软件。\n\n“你无法管理你无法衡量的东西”，没有度量就没有管理，建议在确定工作范围后，第一要务是给出范围内的关键度量评价指标，明确治理的好和坏的评价标准，画出任务统计分析大盘，比如让大家看到一个安全运营的图表，不在横坐标和纵轴坐标的都是工作范围之外。一条优雅的曲线在接下来的工作可以说明很多事情，有些指标事后就不大容易收集得到，难以说清个人在项目中的工作价值。\n风险的风险这里的风险是指对处理”安全风险“中出现的“运营风险”进行管理，在解决这些漏洞威胁层面的风险时，运营方面经常出现项目管控风险，如同解决安全风险一样，影响安全运营项目达成的风险也依赖风险识别、分析、计划、监控的管理手段。一个安全项目的风险主要分为技术、管理、组织、外部四个方面，风险的应对措施也是大家熟悉的规避、转移、弱化、接受策略，项目的风险管理和安全漏洞的风险管理没什么不同。 \n假设要运营一个隐私保护的专项，那么技术“风险”可能是没有相关的隐私和数据安全计算平台、难以落地差分隐私技术、隐私保护技术要求过于超前等技术原因；\n\n管理风险：人力不足，人员都是从数据和业务安全转过来的，不熟悉隐私保护领域；\n\n组织风险:业务领导对隐私保护的优先级和安全给出的判断不一致；\n\n外部风险:《个人信息保护法》和GDPR之间的法律法规关系，业务接口人离职等。\n\n对于外部风险的处置方法你当然可以选择上面的四种策略之一--接受：不用管业务接口人会离职。\n\n运营方案尽量要评审组织一个大的运营项目，如为了解决主机登录问题推广jumper server跳板机在混合云架构，这时候不能片面相信技术可以拿来即用，要关键人参与进来评审，考虑落地时的性能、稳定性、目标。一般情况下质量、成本、时间永远无法达到平衡，改变的魔法是提高生产力，提前准备好靠谱的安全运营项目方案有助于事半功倍，可行性优先于必要性，主动征求他人意见能发现操作层面细节的盲区。\n除了技术方案，涉及到宣传、向上管理、跨部门的汇报也要集体决策，把控运营方案的可行性、普及性，多方配合做到心中有数。\n就像很遗憾在一个安全团队中并没有任何一个完整走SDL流程的产品一样，运营的方案评审总被主动忽略。原则是可以走得稳才能走得远，没有经过调查分析的方案就没有发言权，欢迎大家对方案吵架，吵完架后坚决执行。\n过程的过程实施运营任务时，并不仅仅要为了结果负责，还要保证过程的相对质量。过程的积累很多是文档类型，清晰的运营文档会带来很多优点：\n思考得更清楚，做事的方法论是”Think，Write，Speak，then Do“，你首先要想清楚怎么推行一件事，然后写出来，在写的过程中再次思考，确保你自己明白你要说和做的事情。降低沟通成本，一份有详细数据、附录、FAQ的材料胜过巧舌如簧，这类文档材料包括并不局限于会议材料、方案设计、代码、专项人员联系表、宣传材料。大家基于同一份材料进行争论才不会各说各话，培训和沟通的成本能大幅减低。历史追溯，要面向”离职“工作，以你的任务交接给别人他是否能理解的标准做事，持续运行的严格要求带来过程管理的完善性。良好的记录可以帮助查询当时的背景、决策依据，回忆是不可靠的，录屏、录音没人有耐心分析回溯。文档材料阅读更快，如果依赖当事人的口述通常失真且抓不到重点，过程材料可以搜索、复用、归档、查看历史版本。做到有法可依这里其实是属于项目管理的需求管理范畴，做安全运营隐含着要做的事情得符合制度法规要求，在运营层面可以适当整理、遵循相关的材料，以相关的制度体系作为运营工作的准绳。组织一般会制定四级文件制度，\n最上一层是公司的最高安全战略纲领或者最高安全和隐私政策，这个级别一般在运营层面不会涉及，由大老板去运营。\n二级文件一般是具体的标准和规范，这些材料都是开展工作的依据，如果工作中缺少大量的此类材料，甚至都没有公司层面《web系统上线规范》就要去运营一个web系统架构评审项目，建议补全后再全面实施运营。 \n三级文件是指南、流程、最佳实践之类的材料，，一般专项的负责人可以根据项目的情况发起新增和修改，在这个层面就是“有法可依”，不然治理时容易责任不清楚，或者责任方不清楚运营工作的评判标准是什么。 \n四级文件以模板、报告、汇报材料，就些在工作中涉及比较多，可以多积累作为安全专项的工作手册后续重复使用。细节材料的文档积累比代码更重要。\n一级：比如对于华为的全球网络安全与用户隐私保护委员会，由任正非签发的《关于构筑全球网络安全保障体系的声明》及《华为隐私保护总体政策》就属于一级实践框架。\n\n二级：比如字节跳动的信息安全委员会关联的安全风控部门整体负责信息安全与业务风控的建设、规划和管理工作。那么会有如《今日头条社区规范》，数据安全与隐私保护部门颁发的《字节跳动隐私保护政策》作为二级材料支撑。\n\n三级：比如《上云最佳安全实践》、《公司密码算法术语定义》等。\n\n四级：判断一个设计方案是否符合安全标准的checklist；一个会议沟通纪要等。\n\n如果没有这些材料会出现什么问题呢？比如我们要做一个http鉴权的安全治理，但是缺少公司层面的统一鉴权规范，那么这件事是做还是不做呢？是等着公司出规范指引，还是大家各自问政，使用五花八门的鉴权方案呢？缺少鉴权的二级规范文件，三级的文件自然无法引用，最终业务没有办法就鉴权方案这件事达成一致，安全也不知道该怎么评审现在的BA认证鉴权是否符合安全要求，最终运营项目宣告失败。\n沟通和组织图片\n找到对的人开展工作需要同不同层级的人打交道，就像新上任的CISO需要一张组织架构图、一张IT系统设计图一样，要项目顺利运营要摸清人际和部门的关系，他们分别负责什么，实线和虚线都要了解到。\n比如要做一个“云等保测评”的任务，需要同CIO、IT运营人员、开发人员、合规治理、咨询机构打交道，大家在一起合作任务时，的第一个难题一定是是：我不知道什么问题该找谁？等保测评发现的代码仓库审计日志问题，同一线开发沟通难以配合，但是他的直接上级却能完成配合改正，站位思考不一样。\n\n另外安全是并且只能是”自上而下“。有时候为了方便我们总想绕过流程，做一些“自下而上的事情”达成短期效果，长期来看是错的，虽然此时方便做成一件事情，但是掩盖了流程的混乱和决策机制，不利于建设透明、高效、信任的业务安全文化。\n沟通要明确找到对的人目的是达成沟通，需要与他人合作的运营项目时，我们面对的不再是代码，不是黑客，而是HR、工程技术人员、非安全领域领导，他们没有“读心术”，要大大方方说出来你要他们干什么事情，需要什么帮助，也要谦虚谨慎不懂就问，遇到分歧时耐心倾听，换位思考、坚持原则性问题的同时也要适当妥协，明白对方说话的意义，自己说出来的话也得直指问题本质。\n沟通时涉及要点是并不仅仅是一遍说，有的要求得和业务方反复说，反复澄清，不要高估非安全专业人员的对你要做的事情的理解力。\n汇报要得到决策上级分配给你一个项目时内心是最焦虑的，他从此将没有数据，没有进展，没有好消息也没有坏消息，犹如石沉大海，又如“肉包子打狗”。透明才能高效，汇报的目的是为了决策，经常出现的一个阻碍安全运营效果的事情是从事技术的一线人员对于一个风险处理没有办法做出决策，而有能力做出决策的人没有全面的信息。上级交付给其他人运营任务时，表示委托给你希望得到风险闭环，就不要在临近结束时给上级时不时的“惊喜”，宁可提前消除“期望”，也不要让“希望”破灭。 \n但也不是说事事都需要请示，那是传话筒。影响重大的，没有先例的，拿不准的要事先请示取得一致，有时候形势来不及的，要当机令断，但是要断得符合以往的工作风格，在事后要及时汇报清楚，看能否补救或者双方对齐情况。\n汇报要避免一切顺利的假象，上级的作用是协调资源提供帮助，让他看到目前的风险和应对措施更为重要，要平衡在上级心目中”你办事，我放心“的人设，也是及时汇报相互反馈。\n汇报尽量避免只有会议这一个方法，不然效率太低，尽量通过书面或者简报完成，会议一般有多人参会，你汇报的东西大家并不关心，浪费大家时间。另个原因是汇报应该表示事情实际的进展，如果上级需要得到项目的现状，为什么要等到日程表有空呢，周一发现的问题非要等周五开周会才暴露？\n进度的监控工作的进度依赖于团队的整体能力，技术是其一，大家都熟，管理是其二，需要探索。从项目的角度来看进度一般是难以把控的，只能监控，只有科学监控才能得到项目的准确进展。运营安全专项和写一个项目代码没有什么不同的，我们很熟DevOps的开发效率，需求变更、弹性部署概念，自然也知道实时的告警监控至关重要。进度有偏差是正常的，但是需要知道进度。\n除了自动化开发的指标能反馈项目的运营进度外，编制各种报告也是常见的管理工具，有口头汇报、简报、日周月季度等多种模板，依组织习惯有邮件、文档、IM多种形式。\n简报周报和月报简报是事情发生时帮忙相关人快速理解发生了什么和进度的文字内容。一般包含背景、影响、措施、并定期汇报。周会一般是输出周报，包含上周待办完成情况，工作范围、任务完成情况、问题对策和需要的帮助，还有下周计划。\n月报并不简单是周报的合并，最好对交付的进度设定里程碑目标，里程碑是完成工作的标志性时间，包括时间点、标志性、交付物、关闭条件，一般一个专项有多个里程碑作为checkpoint检查进度，然后调整计划。\n明确闭环标准在安全运营的生命周期里肯定能达成阶段性的效果，比如一个规则的漏报误报率低于30%，XDR基本建设完成，这时候需要结项评估，结项时仅仅比对当时规定的需求范围进行验收。\n不要一个事情永远做不完，明确deadline和验收标准，从不断完成小的专项积累建立成就感，有了信心可以不断尝试做更大的项目，达不到预定目标是正常，这不是背锅，学习型的团队从教训中得到收获，能避免重复犯错误。\n项目集的管理安全项目有其特有的不确定性、曲折性、复杂性、专业性，有时候会有零零总总多个项目齐头并进，互相关联，比如要运营推进一个域控补丁的管理，但是此时ITIL流程系统还未建立。从项目集角度并不仅仅关注工作如何完成的，更关心资源是否得到充分利用。项目集的要素和项目一致，包括整体进展计划，详细进展、里程碑描述、风险和问题。通过透视图、甘特图等工具能一目了然看到有延期和暂停的风险项目。\n平时运营时尽量有一双慧眼能发现新的安全运营点，扩大安全团队盘子避免内卷，孵化新的安全技术项目，然后规划立项到项目集里，尝试”无中生有“锻炼运营能力。\n怎么去开会笔者忙得时候大概每天都有两次以上的会议，不是在开会，就是在准备开会材料，或者落实会议的待办项，但是切实知道干活就得会开会。但是考虑到ROI，尤其是推动大范围的安全运营事项时的多方开会是个高成本的事情，多人开会需要对每个人发开会的工资，而且开会期间他得假装开会，不能做别的有价值的事情，然而实际上大家讨论要解决的安全问题可能并不值得花费举办多次会议的沉没和机会成本。\n开会的第一个要点是安排会议不要超过40分钟，不然大家会玩手机，问题不在参会者，在于时间的控制。人的天性是难以长期集中精力会疲劳，一旦疲劳会议的质量会直线下降，当然一个会议本身这么长已经表示项目出现了问题–之前各方的沟通已经不畅通需要对齐。\n开会的内容一般分为三种：\n运营前：\n核心指标的制定，如果误报率指标定得高了，说明漏报率指标有变动，困难是找到合适的指标，说清楚选取这个指标的逻辑，对应的反向指标是什么；计划在时间和任务上的拆解，是代码维度、应用维度、还是部门维度；如何达成运营目标的策略会议，是采用了新的技术方案，是增加了人力资源去运营专项，明白是怎么样完成工作任务的；如何保证项目进展的指标汇报，是统计大盘，还是通过周会晾晒指标。\n运营中：\n检查进度和质量，通过汇报或者定期会议；发现执行的问题和原因并处理；调整项目运营计划、指标。运营后：\n安全运营效果，进展总结，比如项目建设完成验收；下一步计划制定和调整，比如一个安全方案在内部灰度试点计划完成后的大范围实施计划；复盘和经验总结，比如专项复盘、绩效考核、述职汇报等。\n准备的准备开会是推动事情进展的必须项，但是要顺利达成进展，并不仅仅需要水平和经验，也需要事前周密的考虑和准备，对会议发生的情况和困难要一一想好对策，有了心理预期就比较准备，有了信心才能成事。自己都没有信心，怎么样合作伙伴相信你配合你做事呢？建议在开会前就写好会议纪要，开会就是想办法按照发起人的意愿分派工作，漫无目的的开会是集体划水。\n会前会中会后组织会议的目标是大家达成共识，开会的过程是达成统一思想，求同存异，结果是执行解决会上的问题。开会前收集明确议题、议程、相关材料和沟通好时间，确保关键人参会，要有礼貌”请“人开会而不是通知，因为有些事需要人家点头才能推行。在会下花的时间要多于会上，不要寄希望一次会议产生神奇的效果，所谓“功夫在诗外”，提前要和有分歧关键点达成共识想到解决的办法才能高效会议。\n会中要保持秩序，先说清楚要希望大家决策什么事情，议题含义，然后看材料讨论，要避免发散性的发言。会议保持紧张感是好事，每次发愁开会时当事人才会“如芒在背”传导工作压力。\n会后的待办任务要确保当事人理解任务的含义，要干什么，验收标准是什么，也一定要标注清楚责任人和完成时间。哪怕任务超期未能完成，落在纸面上的东西起码有人重视会给个说法。纪要在发出时找到当事人确认避免有分歧，损失以后合作的公信力。下次会议就首先以上次会议的待办项来开始。\n复盘的复盘\n图片\n复盘是常见的一种会议类型，对一个安全运营效果的复盘可能有SRC漏洞复盘、蓝军渗透测试复盘会议、公司通告等多种形式，一次复盘会议的效果好坏本身也是值得运营负责人总结经验教训的。在攻防层面大家都很菜，工作仓促应战难免有失误，纵深防御么:) 有了失误就追究责任不利于后续工作。复盘不是为了惩处甩锅，而是为了吸取经验教训，找到真正的根因点，尽量下次不犯错。\n虽然按照严格的复盘方法论要“对事不对人”，但是实际中是不可能的，事总是人做的，正是因为这样坦诚复盘机会很难得，要“刨根问底”才是负责任的态度。 \n大部分攻防案例的复盘，讨论到具体事情都是将“资源不足”作为根因，得到这个答案时证明一般没有掌握正确的工作方法–5Why分析，混淆了复盘根因和分配任务项的区别。复盘不应该是这样的，要考虑预期是什么？为什么不符合预期？还有没有别的办法？这些别的措施能阻止事情再次发生吗？复盘不在于问得问题多，而在于深入分析根因。\n举个复盘的例子：问什么客服部门的员工会点击钓鱼邮件输入账户密码，回答是我们没有预算和资源不够，然后列举一大堆原因：没有时间和精力覆盖到每个部门去宣传培训；客服人员流动大；业务部门对安全不重视。那经过培训的业务有没有点击钓鱼邮件？怎么确定培训有效果？人员流动和对安全不重视有什么数据支撑？\n\n也许深层次的根因是培训对于上规模的公司已经成了边际效应，投入更多的培训和宣传预算也阻止不了那么多的员工偶然性的中招，正确的做法不应该是增加培训预算，而是提高止损和发现能力。\n\nPPT和WORD这两类材料是开会或者推动运营工作的重要交付物，共同要求都是内容要精要，布局要精美，写作方法唯有多看材料，多练多思考才能进步。ppt和word各有优劣，看汇报对象是对语言还是文字更敏感。\nPPT好的材料要突出重点，弱化次要的信息，去掉任何无关的信息。有点技术会议上会用表情包那样的PPT，符合年轻人的风格，但是本质还是通过文字来铺排，信息量还是不够突出。好的材料要区分场合。对技术人员的演示可以有精确的描述，完整的具体和段落。但是面向多人的科普可以适当简化，反正会后他们再也不会看材料了：） \nppt作为材料汇报要有情感，看材料并不仅仅有理性思考，还有共鸣产生。在black hat、RSA等国外会议上的一些攻防相关的ppt，你不会记得他的实现细节，但会记得他提出来解决了让大家捉襟见肘的难点，这就是有共鸣相通的，不用花最多时间追求PPT里的花里胡哨，因为逻辑和数据OK，前面“宣称解决了，就是真的解决了，没人在乎”。\n同技术介绍类会议的PPT相比，给领导汇报的PPT的前几页首先不要解释技术难点和业务逻辑，要谈“实现效果”，领导关心取得的业绩成果而不是工作过程。\nWORDWORD的缺陷是不能指望大家逐字逐句去做阅读理解。大家都很忙，有时候大家可能只有在发起人讲开场白的间隙看下目录结构和待讨论内容。要讲结论和待决策内容在前面，然后按照逻辑铺排开来，引申材料放在附件索引。\nWORD的写作站位要放过读者，每个读者都在希望艰涩的技术讨论、可怕的大段代码，陌生的技术名词之间看到自己熟悉的内容：“谢天谢地终于找到我能懂的内容了，看来我不是这间会议室里的傻子”。本文就是在大量的项目管理名词之间穿插了大家日常安全工作的案例，希望你能理解笔者的苦心：）\n案例：不同场景下的五份材料笔者最近观察到一个典型的案例说明不同沟通场景下，对同一个话题，IDC内的零信任，不同沟通材料的底层协作逻辑如何不同。\n从时间顺序上来说首先有这篇文章《张欧：数字银行可信网络实践》，这是作为企业安全负责人角度，讲解内部的建设理念、思路和方案，重点是组织要达成的业绩和实现路径。\n而《ThreatSource：Google BeyondProd安全架构详解》这个PPT讲解的项目从安全架构师角度，同具体的一线开发人员交流技术细节和实现。\n《零信任实践分享》是介绍他山之石，以谷歌员工过来人的角度介绍理论和实践，所以适当忽略技术细节，重点是诠释“经验教训”。\n而《A Touch of BeyondProd》是从给同行分享普及这类技术，区分对各种技术决策的理解WHY，同类方案的选型WHT，要解决的问题和展望HOW。\n材料《生产网零信任，阿里云落地最佳实践》是阿里云安全的宣传文，讲了落地并实践了的什么方案，解决了生产网的隔离问题，给客户以信心。\n不同材料适合不同场景下的阅读人员。比对几份材料就会发现存在明显的异同，而这些材料讲得其实几乎是同一类安全运营项目！\n帮助别人开会参加合作方的会议要展示安全团队的风貌，是宣传安全理念的机会，要团结不要分裂，要阳谋不要阴谋。有时候一个专项任务会分解为多人承担的子任务，比如一个弱口令治理，可能有人负责数据统计分析、有人出技术方案、有人对接合作方“push”进展。专项负责人要尽量参加到这些会议中，哪怕实际手头有忙的事情，你的参会给小伙伴信心，有时候关键的一两句话可以显著推动事情的进展。\n如果小伙伴说错了，不严重的不需要抢过话题去纠正，大家都是在探索尽量靠近运营治理的目标，会后沟通明确下次就有经验了。\n遇到困难怎么办对项目有强烈责任心的人总能发现潜在风险，看得远想得透。遇到困难不要扛着，首先要寻求帮助，要相信团队的力量，个人思考有盲区，多方思考沟通总是能开阔思路。还要积极主动化劣势为优势，在工作中难免有难点，主动提出建设性的想法，先不要摆手推辞，事后有时候看来并没有当初看来那么难。\n项目进行过程中有时候让你生闷气吐槽，有时候让你绝望无助，有时候让你无地自容，不用慌，对于无能无力的事情坦然应对保持健康娱乐心态，合理承受压力稳定军心。\n要坚韧不拔，不达目的不罢休，任何项目只要立项了，只要没人赶你走就坚决不离开，熬着总能有收获。\n写在最后限于篇幅有些章节不能说透，但安全运营的实践同网络安全的特点一样没有银弹，这项工作只有言传身教或者让公司交学费。安全运营也可以很优雅，留给你适当空间可以大胆发挥根据自家的实际情况摸索，总而言之四个字：干就完了。\n在安全行业我们总是逆流而上，同旧世界不断PK，Fighting，工作惯性很强大，知易行难，要想成功需要主动克服痛苦才能引导变革，只有走在追寻更有价值和有意义的路上才能保持竞争优势，创新改变世界，愿读者们长期有耐心，做好一位安全运营的长期主义者。\n参考资料职业欠钱谈安全运营 https://www.zhihu.com/column/c_1161574152535855104\n《数据安全架构设计与实战》https://item.jd.com/12731728.html\n《用图表说话：麦肯锡商务沟通完全工具箱》https://item.jd.com/11324809.html\nPMBOK （美国的项目管理知识体系） https://baike.baidu.com/item/PMBOK/63635\n\n\n声明：转载于公众号《安全乐观主义》\n\n","slug":"blog/sec-operation","date":"2024-03-14T06:15:59.713Z","categories_index":"文章","tags_index":"安全运营","author_index":"安全书"},{"id":"3d4b7cd7c2f10275b6614520cd37bdce","title":"为什么Github返回304","content":"为什么Github返回304为什么Github的Git Page服务总是返回304状态码\n当客户端向GitHub服务器发出请求时，服务器会检查请求中的条件，如果满足以下条件之一，则会返回304状态码：\n\n客户端发送的请求是一个GET请求。\n请求中包含了一个有效的If-None-Match或If-Modified-Since头字段。\n服务器上的资源自上次请求以来没有发生变化。\n\n返回304状态码表示资源未修改，服务器不会返回实际的资源内容。相反，它将在响应头中包含一个空的响应体，并告诉客户端使用其缓存副本。\n这样做有几个好处：\n\n减少了网络流量：如果资源没有更改，客户端无需下载整个响应体，从而减少了数据传输量。\n提高性能：客户端可以直接使用缓存副本而无需进行额外的网络请求。\n减轻服务器负载：不必每次都生成和传输完整的响应体。\n\n总之，返回304状态码是为了优化性能和提高效率。04\n为什么Github的Git Page服务总是返回304状态码\nGitHub的Git Page服务返回304状态码是因为它采用了缓存机制。当用户访问一个网页时，GitHub会检查该网页是否已经缓存，并通过比较请求中的If-Modified-Since头部字段和服务器上文件的最后修改时间来确定是否需要返回新的内容。\n如果服务器上的文件没有发生变化，则会返回304状态码，表示客户端可以使用本地缓存。这样可以减少带宽和服务器负载，并提高页面加载速度。\n只有当服务器上的文件发生了变化，或者用户明确要求刷新页面时，GitHub才会返回新的内容和200状态码。\nGithub的 pages服务，为什么返回的页面是空白页面，上面什么也没有显示？\n有几个可能的原因导致Github Pages返回空白页面：\n\n没有正确配置Github Pages：在项目仓库的设置中，需要确保已启用Github Pages，并选择正确的分支和文件夹作为源代码和发布目录。\n\n没有正确设置主页文件：默认情况下，Github Pages会寻找一个名为index.html的文件作为主页。确保你的仓库中有一个正确命名的主页文件，并且其内容是有效的HTML代码。\n\n仓库没有发布任何内容：如果你的项目仓库中没有任何文件或代码，或者你还没有执行推送操作将本地更改推送到远程仓库，则Github Pages将返回空白页面。\n\n页面存在错误或缺失资源：检查你的主页文件以及它所引用的任何资源（例如CSS、JavaScript文件）是否存在错误或缺失。可以在浏览器的开发者工具中查看控制台日志以获取更多信息。\n\n缓存问题：在对项目进行更改后，可能需要等待一段时间才能看到更新后的页面。尝试清除浏览器缓存并重新加载页面。\n\n\n如果以上方法都无法解决问题，请检查Github Pages服务状态以确定是否存在服务器方面的问题。\n","slug":"blog/为什么Github返回304","date":"2024-03-14T06:15:59.713Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"970462af9140406189e4ed4cf7e0e5fd","title":"AIGC与SOC安全运营","content":"1print(&quot;Hello World!&quot;)\n\n安全SOC的是什么意思？\n安全SOC是指安全运营中心（Security Operations Center）的缩写，也被称为安全运维中心。它是一个专门负责监控、检测和应对网络安全威胁的组织机构或团队。安全SOC通过实时收集、分析和响应来自各种网络设备和系统的安全事件，以保护组织的信息资产免受攻击。这些安全事件可能包括入侵企图、恶意软件感染、数据泄露等。安全SOC通常由专业的安全分析师和工程师组成，利用高级安全工具和技术来进行威胁情报分析、漏洞管理、事件响应等工作，以确保网络环境的稳定与安全。\n安全SOC是指安全运营中心（Security Operations Center）的缩写。安全SOC是一个组织或团队，负责监测、检测和应对网络和信息系统中的安全事件和威胁。他们通过实时监控和分析网络流量、日志和其他安全数据，来识别潜在的攻击行为，并采取相应的措施进行应对和防御。安全SOC通常由一群专业的安全分析师、工程师和其他相关人员组成，他们使用各种工具和技术来保护组织的信息资产免受攻击。\nSOC是Security Operations Center的缩写，中文意思是安全运营中心。安全SOC是指一个组织内部或外部的团队，该团队使用一系列解决方案来持续监视并改进组织的安全体系结构，以防止、检测、分析和响应网络安全事件。简单来说，就是一个负责网络和信息安全的专业团队或机构。\n1test;now\n\n\n\n","slug":"candylab/AIGC与SOC安全运营","date":"2024-03-14T06:15:59.713Z","categories_index":"Sec,AIGC","tags_index":"AIGC","author_index":"安全书"},{"id":"e42ffa8033d0e0ddfb43671b814dcad7","title":"《孙维刚谈立志成才》","content":"《孙维刚高中数学》《孙维刚高中数学》，作者: 孙维刚。  \n有读者这么评价这本书：“神作，幸运地在高中低迷时期遇到了这本书，高一暑假研读了此书，从徘徊90分（满分150）连题目都未看得明白的水平下，高二第一次考试就120多（第二名只有70多）。我也不知道为什么，但感觉题目就是变简单了，后来想想应该还是因为学会了这本书的学习思路。绝对的神作”  \n作者介绍：  \n孙维刚，1938年出生，山东海阳郭城人，2002年1月因癌症扩散不幸逝世，享年63岁。  \n孙维刚生前为北京市数学特级教师，中国数学会理事，全国人大代表。在北京市第二十二中学任教40年。自1980年起，进行从初一接班直到高中毕业的六年一循环的教学教育改革试验，教数学，当班主任，教育教学效果突出，全国多种报刊及电视台均有报道。以1991-1997年的第三轮班为例，学生德智体全面发展，素质大幅度提高，全班40人全部升入大学，其中22人考进北京大学、清华大学。\n\n","slug":"books/《孙维刚高中数学》","date":"2024-03-14T06:15:59.713Z","categories_index":"books,publish","tags_index":"books","author_index":"安全书"},{"id":"e604b0d8d1d29173741514dc7fd16a43","title":"高风险应用的机器学习 负责任的人工智能方法","content":"高风险应用的机器学习 负责任的人工智能方法《Machine Learning for High-Risk Applications: Approaches to Responsible AI（高风险应用的机器学习:负责任的人工智能方法）》这本书，节选其中一句话“如果安全最大的敌人是复杂性，那么过度复杂的机器学习系统天生就不安全”。这本书既可以让监管机构或政策专业人士深入了解可用于遵守法律法规的标准AI技术在当下的状态，也可以让数据科学家、机器学习工程师和企业了解基于风险管理、网络安全、数据隐私和应用社会科学的负责任AI最佳实践。\n\n","slug":"books/高风险应用的机器学习 负责任的人工智能方法","date":"2024-03-14T06:15:59.713Z","categories_index":"出版物","tags_index":"图书","author_index":"安全书"},{"id":"b76df9c251409912cb1072a9ca12cafe","title":"机器学习量化交易","content":"机器学习量化交易电子书《ML for Trading》第二版地址：github.com/stefan-jansen/machine-learning-for-trading这本书旨在以一种实用且全面的方式展示机器学习如何为算法交易策略增加价值。它涵盖了从线性回归到深度强化学习的广泛机器学习技术，并演示了如何构建、回测和评估由模型预测驱动的交易策略。 ​​​\n\n","slug":"books/机器学习量化交易","date":"2024-03-14T06:15:59.713Z","categories_index":"出版物","tags_index":"图书","author_index":"安全书"},{"id":"c375fa17b4d17764627d1ce30f1b1a4a","title":"Nvidia RTX 4090与Nvidia A10显卡训练数据对比","content":"Nvidia RTX 4090与Nvidia A10显卡训练数据对比1卡4090与4卡A10，预测的时间差距，API响应时间， 同样的模型规模， 4090卡为0.25秒左右响应时间，A10的响应时间是0.45秒左右。  \n同样的 威胁样本数据。微调训练的时间：1卡4090为 1:45分 左右4卡A10为 4:32分 左右  \n4090微调训练的时间， 将近2小时。 A10微调时间，将近5个小时。 1卡4090与4卡A10比，同样威胁样本的训练时间，用4090快了3小时左右\nRTX 40901234567891011121314151617&#123;&#x27;train_runtime&#x27;: 7557.5791, &#x27;train_samples_per_second&#x27;: 6.351, &#x27;train_steps_per_second&#x27;: 0.397, &#x27;train_loss&#x27;: 0.41670124886433285, &#x27;epoch&#x27;: 25.76&#125;100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [2:05:57&lt;00:00, 2.52s/it]***** train metrics *****epoch = 25.76train_loss = 0.4167train_runtime = 2:05:57.57train_samples = 1863train_samples_per_second = 6.351train_steps_per_second = 0.397\n\nNvidia A1012345678910111213141516171819&#123;&#x27;train_runtime&#x27;: 17289.4791, &#x27;train_samples_per_second&#x27;: 11.105, &#x27;train_steps_per_second&#x27;: 0.174, &#x27;train_loss&#x27;: 0.1951921375890573, &#x27;epoch&#x27;: 103.0&#125;100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [4:48:09&lt;00:00, 5.76s/it]***** train metrics *****epoch = 103.0train_loss = 0.1952train_runtime = 4:48:09.47train_samples = 1863train_samples_per_second = 11.105train_steps_per_second = 0.174\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"blog/Nvidia RTX 4090与Nvidia A10显卡训练数据对比","date":"2024-03-14T06:15:59.712Z","categories_index":"AIGC,rtx4090","tags_index":"rtx4090","author_index":"安全书"},{"id":"898ea7cfc21533e8cdd79b533fcbfa66","title":"理解威胁情报与威胁数据分析","content":"1、如何理解威胁情报和数据分析在企业安全运营中心建设阶段中我们期望通过汇总大量的安全日志事件分析安全数据和威胁映射。获得攻击者所采用的各种攻击手段特别是遇到鱼叉攻击钓鱼邮件攻击这种问题时我们希望能够通过数据分析和挖掘的方式来追踪到对手的行为特征。基于类似的use case场景我们需要先理解各种安全数据的攻防模型以及数据类型。对此我们把类型设定在Windows主机并以Windows感染的邮件钓鱼场景为例说说威胁建模方法如下所示：\n\n理解网络威胁情报(Cyber Threat Intelligence)和威胁建模方法(Threat modeling security)的基础知识。\n在威胁情报体系中我们为了数据之间能够共享.在基于HTTPS的协议中定义了一种通用的共享格式叫TAXII。如下所示\nTAXII 专门用于支持以 STIX 为代表的 CTI (Cyber Threat Intelligence)信息交换机制，在数据分析领域甚至是威胁情报领域我们能通过统一的STIX数据格式，将怀疑、妥协和归因的所有方面通过对象和描述性关系清楚地表示。STIX 信息在2.1版本中定义了18个STIX域对象(SDO)如下所示：\nSTIX信息可以为分析师直观地表示钻石模型中所对应的信息。当我们在完成大数据安全分析平台数据分类分级治理阶段的时候就可以将STIX信息存储在数据仓库中供分析师使用。\n另外一个需要说明的方面是针对威胁情报中的钻石模型我们同样需要有所认识。由于攻击者的攻击是阶段性的所以CTI网络威胁情报将其以钻石模型来对应STIX的数据层级并以Json格式进行展示如图所示：\n从而构成了威胁情报数据共享映射关系金字塔\n2、如何理解威胁框架和威胁建模如上所述我们需要理解的第二个是Att&amp;ck攻击模型框架这个框架位于钻石模型的TTPs金字塔顶层在这里详细描述了攻击者的攻击手段和攻击阶段以及对应的唯一标识ID我们能够通过对攻击阶段的建模来进行相应安全设备攻击事件的相关映射如下所示：我们需要创建一个图层来进行威胁建模\n添加安全日志备注字段名称对其字段内容(value)进行攻击图层关系映射\n当攻击者进行钓鱼攻击时第一个所发生的事情应该是信息收集或者邮件钓鱼这里我们起一个本地的威胁建模环境并选择其攻击阶段的子攻击类型模拟TTp的对手行为\n\n\n如上所述我们可以通过一些标有ID编号的行为模拟攻击者采用的技术并给它们标注颜色，另外一个就是我们也可以通过ID区查询相关的技术手段和所关联到的APT组织\n\n\n最后在通过打分。对比攻击方法来寻找其行为相似性并和团队完成所有的分析行为报告\n作者大家好，我是伏念。\n一位大数据安全分析平台研发工程师和一位安全数据分析专家同时也是一位威胁建模专家。\n今天我们通过常见的攻防场景来围绕数据分析理解如何为企业设计威胁模型。\n为准备自研大数据安全分析平台的公司提供一些专业性上的帮助。\n\n","slug":"blog/attandck","date":"2024-03-14T06:15:59.712Z","categories_index":"文章","tags_index":"大数据安全","author_index":"安全书"},{"id":"32b9ddc7db8ff85b8d7bba8c3123eba0","title":"白帽子讲Web安全","content":"购买链接： 点击购买\n作者： 吴翰清内容简介：在互联网时代，数据安全与个人隐私受到了前所未有的挑战，各种新奇的攻击技术层出不穷。如何才能更好地保护我们的数据？《白帽子讲Web安全》将带你走进web安全的世界，让你了解Web安全的方方面面。黑客不再变得神秘，攻击技术原来我也可以会，小网站主自己也能找到正确的安全道路。大公司是怎么做安全的，为什么要选择这样的方案呢？你能在《白帽子讲Web安全》中找到答案。详细的剖析，让你不仅能“知其然”，更能“知其所以然”。 　　《白帽子讲Web安全》是根据作者吴翰清若干年实际工作中积累下来的丰富经验而写成的，在解决方案上具有极强的可操作性，深入分析了各种错误的解决方案与误区，对安全工作者有很好的参考价值。安全开发流程与运营的介绍，对同行业的工作具有指导意义。\n推荐理由：本书对Web安全各个方面都进行了较详细的分析，在掌握基本知识后阅读此书更佳。\n","slug":"blog/baimaozijianganquan","date":"2024-03-14T06:15:59.712Z","categories_index":"书籍","tags_index":"Web安全,电子工业出版社","author_index":"安全书"},{"id":"bcd4403de43b8cbd12066144ee39876d","title":"绕过CDN查找真实IP方法","content":"相信大家平时在做渗透测试时，经常会碰到部署了CDN的网站，我们有时候想要获取某站的源站ip，方法有很多，今天我给大家总结一下，赠人玫瑰，手有余香。\nCDN简介：CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。\n域名解析过程:传统访问：用户访问域名–&gt;解析IP–&gt;访问目标主机CDN模式：用户访问域名–&gt;CDN节点–&gt;真实IP–&gt;目标主机\n验证网站有无CDN方法:利用“全球Ping”快速检测目标网址是否存在CDN，如果返回域名解析对应多个 IP 地址多半是使用了 CDN,如果得到的IP归属地是某CDN服务商，或者每个地区得到的IP地址不一样则说明可能存在CDN，可用以下几个网站检测！http://ping.chinaz.comhttp://ping.aizhan.com/http://www.webkaka.com/ping.aspx\n\n方法总结：1.查询历史DNS记录：查看 IP 与 域名绑定的历史记录，可能会存在使用 CDN 前的记录，相关查询网站有：DNS查询：https://dnsdb.io/zh-cn/微步在线：https://x.threatbook.cn/在线域名信息查询：http://toolbar.netcraft.com/site_report?url=DNS、IP等查询：http://viewdns.info/CDN查询IP：https://tools.ipip.net/cdn.phpSecurityTrails平台：https://securitytrails.com/domain/www.baidu.com/history/aIP138:http://site.ip138.com\n2.利用MX记录（邮件查找）：查看由网站发送的邮件原文，寻找Received参数信息。\n3.利用网站漏洞：目标敏感文件泄露，例如：phpinfo之类的探针、GitHub信息泄露等；XSS盲打，命令执行反弹shell，SSRF等。\n4.查询子域名：毕竟 CDN 还是不便宜的，所以很多站长可能只会对主站或者流量大的子站点做了 CDN，而很多小站子站点又跟主站在同一台服务器或者同一个C段内，此时就可以通过查询子域名对应的 IP 来辅助查找网站的真实IP。IP138:http://site.ip138.com（查询地址同方法1）Google 搜索，例如：用语法”site:baidu.com -www”就能查看除www外的子域名。子域名扫描器\n5.网络空间引擎搜索：常见的有以前的钟馗之眼，shodan，fofa搜索。以fofa为例，只需输入：title:“网站的title关键字”或者body：“网站的body特征”就可以找出fofa收录的有这些关键字的ip域名，很多时候能获取网站的真实ip。钟馗之眼：https://www.zoomeye.org/Shodan：https://www.shodan.io/FOFA：https://fofa.so/\n6.利用HTTP标头：借助SecurityTrails这样的平台，任何人都可以在茫茫的大数据搜索到自己的目标，甚至可以通过比较HTTP标头来查找到原始服务器。特别是当用户拥有一个非常特别的服务器名称与软件名称时，攻击者找到你就变得更容易。如果要搜索的数据相当多，如上所述，攻击者可以在Censys上组合搜索参数。假设你正在与1500个Web服务器共享你的服务器HTTP标头，这些服务器都发送的是相同的标头参数和值的组合。而且你还使用新的PHP框架发送唯一的HTTP标头（例如：X-Generated-Via：XYZ框架），目前约有400名网站管理员使用了该框架。而最终由三个服务器组成的交集，只需手动操作就可以找到了IP，整个过程只需要几秒钟。例如，Censys上用于匹配服务器标头的搜索参数是80.http.get.headers.server :，查找由CloudFlare提供服务的网站的参数如下：\n180.http.get.headers.server:cloudflare\n\nhttps://censys.io/ipv4\n7.利用SSL证书：(1).我们可以利用空间引擎进行 SSL 证书探测，搜索语句：\n1443.https.tls.certificate.parsed.extensions.subject_alt_name.dns_names:www.baidu.com\n\nhttps://censys.io/ipv4\n(2).还有一种方式，就是搜集 SSL 证书 Hash，然后遍历 ip 去查询证书 hash，如果匹配到相同的，证明这个 ip 就是那个 域名同根证书的服务器真实 ip。简单来说，就是遍历 0.0.0.0/0:443，通过 ip 连接 https 时，会显示证书。当然，也可以用 censys 等引擎，baidu.com证书的搜索查询参数为：parsed.names:baidu.com 只显示有效证书的查询参数为:tags.raw:trusted 攻击者可以在Censys上实现多个参数的组合，这可以通过使用简单的布尔逻辑来完成。组合后的搜索参数为：\n1parsed.names: baidu.com and tags.raw: trusted\n\nCensys将向你显示符合上述搜索条件的所有标准证书，以上这些证书是在扫描中找到的。\n要逐个查看这些搜索结果，攻击者可以通过单击右侧的“Explore”，打开包含多个工具的下拉菜单。What’s using this certificate? &gt; IPv4 Hosts此时，攻击者将看到一个使用特定证书的IPv4主机列表，而真实原始 IP就藏在其中。\n你可以通过导航到端口443上的IP来验证，看它是否重定向到xyz123boot.com？或它是否直接在IP上显示网站？隐藏服务具有SSL证书，要查找它使用的IPv4主机，只需将”SHA1 fingerprint”（签名证书的sha1值）粘贴到Censys IPv4主机搜索中，即可找到证书，使用此方法可以轻松找到配置错误的Web服务器。\n8.用网站返回内容：如果原始服务器IP也返回了网站的内容，那么可以在网上搜索大量的相关数据。浏览网站源代码，寻找独特的代码片段。在JavaScript中使用具有访问或标识符参数的第三方服务（例如Google Analytics，reCAPTCHA）是攻击者经常使用的方法。或者说用title，毕竟竟每个网站的title基本上都是独一无二的。以下是从HackTheBox网站获取的Google Analytics跟踪代码示例：ga（’create’，’UA-93577176-1’，’auto’）;可以使用80.http.get.body：参数通过body/source过滤Censys数据，不幸的是，正常的搜索字段有局限性，但你可以在Censys请求研究访问权限，该权限允许你通过Google BigQuery进行更强大的查询。Shodan是一种类似于Censys的服务，也提供了http.html搜索参数。搜索示例：https://www.shodan.io/search?query=http.html%3AUA-32023260-1\n9.Nslookup查询：查询域名的NS记录、MX记录、TXT记录等很有可能指向的是真实ip或同C段服务器。\n10.全网扫描（不推荐）:需要找 baidu.com网站的真实 IP，我们首先从 apnic 获取 IP 段，然后使用 Zmap 的 banner-grab 扫描出来 80 端口开放的主机进行 banner 抓取，最后在 http-req 中的 Host 写baidu.com。\n11.F5 LTM解码法:当服务器使用F5 LTM做负载均衡时，通过对set-cookie关键字的解码真实ip也可被获取，例如：Set-Cookie: BIGipServerpool_8.29_8030=487098378.24095.0000，先把第一小节的十进制数即487098378取出来，然后将其转为十六进制数1d08880a，接着从后至前，以此取四位数出来，也就是0a.88.08.1d，最后依次把他们转为十进制数10.136.8.29，也就是最后的真实ip。12.其他：使用ddos消耗完CDN账号流量使其回源；等；\n希望本文能对你有所帮助，谢谢。\n不要等夕阳西下时才对自己说，想当初、如果、要是，之类的话！不为别人，只为做一个连自己都羡慕的人。\n本文转载自天乐博客：http://blog.tianles.com/96.html\n","slug":"blog/cdn-ip","date":"2024-03-14T06:15:59.712Z","categories_index":"文章","tags_index":"安全技术","author_index":"安全书"},{"id":"cb9d1e5e022c207d55ccf114e6e4aa69","title":"一种小语言Edgelang","content":"找回了当时测试时用OpenResty Edgelang的代码。\n1234567891011121314151617uri contains &quot;SQL&quot;=&gt;\tset-upstream(&#x27;HoneyPot_1&#x27;);\t\treq-header(&quot;Content-Type&quot;) contains &quot;multipart/form-data&quot;,\treq-header(&quot;Content-Type&quot;) !contains rx&#123;^multipart/form-data[\\s\\S]+&#125; =&gt;\twaf-mark-evil(message: &quot;CVE-2017-5638 Struts&quot;, level: &quot;super&quot;),\tset-upstream(&#x27;HoneyPot_2&#x27;);uri(&quot;/shop&quot;), client-province(&#x27;Guangdong&#x27;),\tua-is-mobile() =&gt;\tlimit-req-rate(key: client-addr, target-rate: 5 [r/s], reject-rate: 10 [r/s]), limit-resp-data-rate(441 [mB/s]);uri(&quot;/shop&quot;), client-country(&quot;US&quot;) =&gt;\tlimit-req-rate(key: client-addr, target-rate: 5 [r/s], reject-rate: 10 [r/s]), sleep(0.5);req-header(“Content-Type”) contains “multipart/form-data”,req-header(“Content-Type”) !contains rx&#123;^multipart/form-data[\\s\\S]+&#125; =&gt;\twaf-mark-evil(message: &quot;CVE-XXX-XXX &quot;, level: &quot;super&quot;),\n\n","slug":"blog/edgelang","date":"2024-03-14T06:15:59.712Z","categories_index":"文章","tags_index":"OpenResty","author_index":"安全书"},{"id":"70e08f36c56f78f54175b098fc27d77a","title":"ElasticSearch最大返回结果量大小设置","content":"123curl -H &quot;Content-Type: application/json&quot; -XPUT &#x27;http://192.168.0.5:9205/_all/_settings?preserve_existing=true&#x27;  -d &#x27;&#123;  &quot;index.max_result_window&quot; : &quot;100000&quot;&#125;&#x27;\n","slug":"blog/elasticsearch","date":"2024-03-14T06:15:59.712Z","categories_index":"文章","tags_index":"ElasticSearch","author_index":"安全书"},{"id":"3141f157b979681af7ded27775c68b78","title":"Clickhouse的Docker版本查询","content":"Clickhouse的Docker版本查询。\n123select service, count(service) as cnt from x_main_all where date &gt; &#x27;2021-01-01&#x27;  and date &lt;&#x27;2022-01-27&#x27;    group by service  order by cnt desc limit 1000;select product, count(product) as cnt from x_main_all where date &gt; &#x27;2021-01-01&#x27;  and date &lt;&#x27;2022-01-27&#x27;    group by product  order by cnt desc limit 1000;docker run -it --rm yandex/clickhouse-client -h xxx.cn --port 9000 -m -u username --password passwd -d usern\n\n\n\n","slug":"blog/clickhouse","date":"2024-03-14T06:15:59.712Z","categories_index":"文章","tags_index":"ClickHouse","author_index":"安全书"},{"id":"286f44c415f4bbbe2e2949b688d0fc20","title":"iptables限制IP访问","content":"设定主机可访问的端口。\n123456iptables -I INPUT -s 192.168.0.5 -p tcp --dport 80 -j ACCEPTiptables -D INPUT -s 192.168.0.5 -p tcp --dport 80 -j ACCEPTiptables -I INPUT -s 192.168.0.5 -p tcp --dport 27017 -j ACCEPTiptables -I INPUT -s 192.168.0.5 -p tcp --dport 27017 -j ACCEPTiptables -I INPUT -s 127.0.0.1 -p tcp --dport 27017 -j ACCEPTiptables -I INPUT -s 192.168.0.5 -p tcp --dport 27017 -j ACCEPT\n","slug":"blog/iptables","date":"2024-03-14T06:15:59.712Z","categories_index":"文章","tags_index":"iptables,linux","author_index":"安全书"},{"id":"87b14f55648ecfc38c289ee95a9a3dbf","title":"SSH解决The authenticity of host xxx can't be established.","content":"通道机突然出现了链接不上的情况，最后就直接在SSH的IP约束检查去掉。\n修改配置文件1vim /etc/ssh/ssh_config\n\n\n添加不检查主机的约束的选项12StrictHostKeyChecking noUserKnownHostsFile /dev/null\n\n","slug":"blog/jumperserver","date":"2024-03-14T06:15:59.712Z","categories_index":"文章","tags_index":"运维记录","author_index":"安全书"},{"id":"f3a58d7983b04fd188af08c13ef8079c","title":"将自动驾驶作为 AGI 的一个案例来研究《Self-driving as a case study for AGI》","content":"将自动驾驶作为 AGI 的一个案例来研究《Self-driving as a case study for AGI》Andrej Karpathy 是 OpenAI 的创始成员之一，并且 Andrej Karpathy 的另一个身份是特斯拉前 AI 高级总监、自动驾驶 Autopilot 负责人，那这篇文章的很多观点就值得一看了！  \n一、AGI 的定义  \n首先是他对 通用人工智能（AGI）的定义：首先，它是一个完全自主的系统，即它可以独立运行，几乎不需要或完全不需要人类的监督。其次，它能在大多数具有经济价值的工作中独立运作。  \n基于这样的对 AGI 的定义，自动驾驶可以作为一个很好的 AGI 的早期案例，借助自动驾驶的发展来预览通用人工智能带来的影响和普通民众对它的感受。  \n二、辅助自动化驾驶和工具型 AI  \n然后在自动化驾驶的历程中，在真正实现全自动化自动驾驶之前，其实是从辅助驾驶开始的，就像我们现在程序员们用的 GitHub Copilot，或者微软集成到 Office 的 Copilot，这些都是辅助作用的工具型 AI。  \n在辅助驾驶或者辅助 AI 中，人类主要承担监督角色，可以随时接管驾驶或者下达指令。这个阶段 AI 在某些领域的表现甚至超过人类，比如辅助驾驶中的跟车或紧急制动，或者是编程中一些具体模块的实现，但是整体上或者一些场景上还不足，需要人类干预。  \n三、全自动化驾驶  \n随着技术的发展，完全自动化终究会到来，就像现在的 Waymo 汽车，已经实现了完全自动化驾驶，在旧金山打车，可以直接叫一辆 Waymo 车，而不是 Uber，一辆无人驾驶的汽车会来接你，带你前往目的地。  \n\n\n\n\n\n\n\n\n\n注：Waymo 前身为 2009 年成立的自动驾驶项目，目标为完全自动驾驶。2016 年，该项目从 Google 独立出来，成为 Alphabet 公司旗下的子公司 Waymo。  \n虽然现在已经有了全自动化驾驶的 Waymo，但还是有很多人选择 Uber 或者其他方式打车，因为一方面很多人还不知道有 Waymo，另一方面 Waymo 的供应也不足，只有旧金山和凤凰城在运行，并且 Waymo 也还受制于硬件和政策法规上面的约束无法马上扩大运营规模。  \n所以 Andrej Karpathy 认为，通用人工智能也会是类似的过程 - 有些人或公司会立即采用，但许多人可能 1) 不了解这些技术，2) 知道后可能不信任，3) 即使信任，也更倾向于与人类合作。  \n此外，需求大于供应，通用人工智能 (AGI) 也会因为开发者的自我约束、法规限制以及资源短缺（比如需要建设更多 GPU 数据中心）而受到限制。  \n想想现在的 ChatGPT 也是类似的，很多人每天都在大量使用，而很多人从来没有用过 ChatGPT 甚至都还不知道它的存在，另外现在受制于 GPU 算力的约束，最强大 GPT-4 也无法放开了给大家使用，我日常就会经常遇到超过 3 小时 40 条的限制。  \n四、社会对自动化驾驶的反应  \n另外从自动驾驶可以看到的一个角度就是社会大众对于自动驾驶的反应，在几年前，大家还在纷纷讨论和怀疑自动驾驶的可行性，甚至有很多恐慌和不确定的声音。但现在，自动驾驶不再遥不可及，你已经可以花钱去乘坐完全自动驾驶的 Waymo 出租车。然而，这个变化似乎并没有引起太多人的关注。当 Waymo 的自动驾驶车辆在旧金山街头行驶时，你会发现许多人对此感到好奇。他们先是惊讶地盯着看，然后很快就继续他们的生活。  \n可能当自动驾驶技术在其他行业得到应用时，世界并不会发生翻天覆地的变化。大多数人甚至可能刚开始都没意识到这个变革。即使意识到了，他们可能只是好奇地看一眼，然后无动于衷，态度从否认到接受各不相同。有些人可能会因此感到不满，做出一些反抗行为，就像有人曾经在 Waymo 车辆上放置交通锥以示抗议一样。  \n五、自动化驾驶会导致司机失业吗？  \n大家对通用人工智能讨论的最多的还是对工作职位的影响，害怕 AI 会替代自己的工作。在自动驾驶领域，Waymo 显然取代了司机的工作。但同时，它也创造了许多此前看不见的新职位——比如帮助收集神经网络训练数据的人工标注员、远程协助遇到问题的车辆的技术支持人员、负责建造和维护车队、地图等的工作人员。为了制造这些高度仪器化、高科技的汽车，一个涵盖各种传感器和相关基础设施的全新产业也随之诞生。  \n与此类似，工作本身也在发生变化：一些工作会消失，许多新的工作机会也会出现。这更像是对工作的一次重组或改造，而不仅仅是简单的消除，尽管消除部分可能更为显著。长远来看，总体的工作数量可能会减少，但这个过程比人们初看时想象的要缓慢得多。  \n六、一家独大还是百花齐放  \n几年前，自动驾驶领域涌现出众多公司。但今天，随着人们逐渐意识到这一领域的技术难度和挑战（按照我对当前人工智能及整体计算技术的看法，这个挑战刚好处于可实现的边缘），相关企业已经大幅度整合。在这之中，Waymo 已经率先展示了功能完备的自动驾驶技术。然而，仍有诸如 Cruise、Zoox、Tesla 等公司紧随其后。  \n自动驾驶行业在 ~2015 年那样经历了快速增长和扩张，但最终只有少数几家公司在激烈竞争中存活下来，AI 领域也可能会经历类似的变化。在这一过程中，将会大量使用工具型 AI（例如：目前的二级自动驾驶辅助系统 ADAS 特性），甚至出现一些开放平台（例如：Comma）。  \n七、对未来通用人工智能的展望  \n通用人工智能并不会导致失控或者毁灭，相反，它更像是目前正在快速发展的自动驾驶技术，这是经济中一个重要的、正在改变社会的自动化分支。  \nAGI 的发展是逐步的，社会既是观察者也是参与者。其扩展在多方面受到限制，包括对教育有素的人力资源、信息、材料和能源的监管和资源的限制。世界不会因此崩溃，而是在适应、变化和重新构建中前行。  \n以自动驾驶为例，交通的自动化将使道路更安全，城市空气将变得更清新，交通更为畅通，而路边的停车场和停车车辆将逐渐消失，让出更多空间给行人。  \n期待看到 AGI 在各个领域带来的类似变革。\nAndrej Karpathy 发表的一个推文，他说他早年发布了一段micrograd代码和说明讲解反向传播，但是没什么人关心，后来他做了一期视频，然后就迎来了爆炸性增长，其实代码还是一样的，甚至只有200行，并且有详细的注释。  \n很多时候我们懂某个技术就会觉得这件事很简单没必要多说，但对于不懂的人来说，要搞懂其实蛮不容易的。摘录最后两段：  \n“作为技术人员，我们往往有一种偏见，认为只要发布了代码、论文或成品，加上了注释和Readme，一切就都足够了。如果人们不参与，我们可能会认为是作品本身不够好。但实际上，人们即使是在同一领域的专家，也可能因为不想投入时间和精力的门槛而远离你的作品。你可能就这样，因为没有充分降低接触门槛，而错失了那份作品本身潜在的10倍甚至100倍的价值。\n简言之，先是创造，然后是让更多人能够轻松地接触和理解。📈 你内心的某些声音可能会告诉你这不必要，但这是错误的观念。”  \n我经常回想的一个观察很有启示性：  \n\n刚发布micrograd仓库时，它引起了一些关注，但随后似乎进入了停滞期，没多少人再关心。  \n后来，我制作了一段视频，展示如何从零开始构建它，这个仓库立刻迎来爆炸性增长，成为学习反向传播算法的重要参考资料。\n\n这个现象很有趣，因为micrograd的代码从一开始到结束都没变，它已经在GitHub上搁置了好几个月。这段代码对我而言很清晰（因为是我写的），只有约200行，而且我在.py文件和Readme中做了充分的注释，我本以为它已经足够明了自解了。我为能通过这样精简的代码讲解反向传播而自豪——它极大地简化了复杂性，仅用一页代码就揭示了自动微分引擎的精髓。但似乎别人并不这么看，我也就没太放在心上，继续前进了。  \n问题在于，它的障碍实际上是“仅仅”因为可访问性。当我制作并分享了那个视频，展示如何一步步构建和解析它时，对这段完全相同代码的兴趣和参与度几乎增长了百倍。这不仅吸引了领域新手，他们需要详尽的介绍和讲解，甚至连我那些更有技术背景的朋友们，我认为他们如果愿意花时间仔细看，也能理解它，但之前他们被初次接触的障碍所阻。  \n作为技术人员，我们往往有一种偏见，认为只要发布了代码、论文或成品，加上了注释和Readme，一切就都足够了。如果人们不参与，我们可能会认为是作品本身不够好。但实际上，人们即使是在同一领域的专家，也可能因为不想投入时间和精力的门槛而远离你的作品。你可能就这样，因为没有充分降低接触门槛，而错失了那份作品本身潜在的10倍甚至100倍的价值。  \n简言之，先是创造，然后是让更多人能够轻松地接触和理解。📈你内心的某些声音可能会告诉你这不必要，但这是错误的观念。\n","slug":"article/将自动驾驶作为 AGI 的一个案例来研究《Self-driving as a case study for AGI》","date":"2024-03-14T06:15:59.712Z","categories_index":"AIGC","tags_index":"AGI","author_index":"安全书"},{"id":"fd165f0a919a60a4a60b85447d472c1b","title":"为什么随着年龄增长，我们感觉时间似乎流逝得更快","content":"为什么随着年龄增长，我们感觉时间似乎流逝得更快为什么随着年龄增长，我们感觉时间似乎流逝得更快 [译]  \n原文：Why time seems to pass faster as we age作者：Paras Chopra  \n用200字，总结下面文本内容的总体概要。\n1/ 这种感觉让我非常着迷。  \n作为一个 36 岁的人，我感觉一年的时间比我还是个孩子或青少年时要短得多。  \n这似乎是宇宙间的不公——我们的寿命更短了，而每一年过得也更快了。  \n2/ 但为什么会这样呢？  \n我初步认为，这是进化如何塑造我们的大脑成为一个高效存储装置的不幸副作用。  \n3/ 我们的大脑本质上是一个预测机器。  \n它的主要任务是构建一个世界模型，以此来获得生存和繁衍的优势。  \n4/ 能预测现象意味着能控制它，从而拥有力量。因此，我们的大脑痴迷于预测事物的走向。  \n它渴望能预见如何找到伴侣、赚钱的方式、什么能让人发笑等等。  \n5/ 同时，它追求效率。  \n如果某件事已经发生过，再次关注它并记住它有何意义呢？  \n重复存储是低效的，因此大脑倾向于只关注并记忆那些新奇和令人惊讶的事物。  \n6/ 对孩子来说，一切都是新奇和令人惊讶的。  \n世界是一个充满学习机会的地方，因此大脑在记忆方面进行大量更新。  \n你生日、假期、学校日子的完整记录，都被铭记。  \n7/ 每天都有新奇的信息涌现，因此大脑极为关注，你就会感觉一天中有很多“时间片段”。  \n这些丰富的信息被存储起来，使得即使是回顾，那些日子也似乎更加漫长。  \n8/ 随着年龄的增长，新奇的事物仅仅成为旧记忆上的一小片“补丁”。  \n为什么要存储你第 N 次假期的完整细节，而不是简单地记录下它与第一次的不同之处呢？  \n9/ 换句话说，随着我们年龄的增长，我们的记忆和注意力成了它们过去的低保真版本。  \n随着生活中的模式开始自我重复，我们注意到并记住的“时间片段”变得越来越少，越来越粗糙。  \n10/ 因此，如果有人问你生命中的时间都去哪儿了，你回想起来，大部分记忆都与童年有关，近期的记忆却寥寥无几。  \n这就是为什么时间感觉像是积累在了过去，而不是近现在。  \n11/ 让你感觉时间加速的主要罪魁祸首是可预测性。  \n你的日子越可预测，你就越会觉得它们短暂。  \n12/ 来做个思想实验。  \n如果你有一份稳定的工作，你可以在脑海中进行一整年的时间旅行，发现每一天都差不多。  \n但如果我让你想象在一个外国大学攻读梵语博士学位，你将无法想象你的日子会是什么样子。  \n13/ 因此，可预测性不仅影响我们对当前时间的感知，也影响对未来时间的预期。  \n在童年时，假期因为充满了新奇信息，因此它让人觉得充实而漫长。  \n现在，你第 N 次去某个地方旅行就感觉短多了，因为你知道将会发生什么。  \n14/ 那么，我们该如何行动，以减缓时间的流逝呢？  \n我能想到的唯一方法是打破日常的可预测性，主动寻找（大量的）惊喜。  \n参与那些你完全不了解的项目。  \n15/ 不幸的是，随着年龄的增长，进化让我们更倾向于避免探索和冒险。  \n我们的大脑倾向于更多地利用我们已经较好理解的世界，而不是鼓励我们去探索更多。  \n但这正是让你的岁月匆匆流逝的原因。  \n16/ 你需要问自己：  \n你想如何度过一生？  \n是简单地活得久，还是让每一刻都活得充实和精彩？  \n对自己来说，哪种生活更为重要。  \n17/ 有趣的是，让时间放慢的解决方案不是无聊（正如我曾以为的）。  \n无聊是一种消极状态。解决方法是勇敢地投身于未知的领域。  \n也就是说，  \n要么是身体上的旅行，体验不同的文化和环境，做一些从未尝试过的活动；  \n要么是心灵上的旅行，阅读、学习新技能、挑战自我。  \n18/ 注意，我们非常擅长掌握模式/建立预测模型。  \n一旦我们弄清楚了游戏的获胜条件或故事情节，我们就会兴趣全无。  \n19/ 因此，存在的危机实际上是对生活的一种预警。  \n拥有所有预测模型的大脑会问：这就是生活的全部吗？  \n但它错了——这只是它选择的生活的全部。  \n20/ 它无法预测的（彻底）不同的生活会让大脑保持警觉。  \n这里的关键词是“彻底”。变化越小，记忆留存的时间就越短。\n原文： https://invertedpassion.com/why-time-seems-to-pass-faster-as-we-age/?continueFlag=97e5d64eb4dd3f025802bb96b687f8e5\n译文：https://baoyu.io/translations/life/why-time-seems-to-pass-faster-as-we-age?continueFlag=97e5d64eb4dd3f025802bb96b687f8e5\n","slug":"article/为什么随着年龄增长，我们感觉时间似乎流逝得更快","date":"2024-03-14T06:15:59.712Z","categories_index":"翻译","tags_index":"翻译","author_index":"安全书"},{"id":"c18ab594e9ce6d9a99343419fe75f5b8","title":"《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》","content":"《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》  \n作者列举了他日常使用 ChatGPT 的用法  \n\n应用案例 - 编程和控制台工具  \n\n\n编写 ffmpeg/ImageMagick 命令行  \n写小段脚本（Python、Javascript）  \n编写正则表达式  \n用不同的语言/框架重写代码片段  \n制作 LaTeX 图表与表格  \n数据转换与可视化呈现  \n从图像和图表中提取数据  \n\n\n应用案例 - 语言、图像和知识  \n\n\n英语语法纠错  \n精简和重塑段落  \n将想法转化为文字  \n总结文章  \n总结 YouTube 视频  \n解释学习过程中遇到的错误  \n翻译  \n私人导师  \n生成图像 - 音乐封面  \n生成图像 - 灵感集和参考资料  \n创意头脑风暴 - 挑选标题和主题  \n知识库  \n\n作者的结论：  \n从我之前的描述中，你可能已经明白，我并不经常把大语言模型 (LLM) 当作搜索工具或知识库来使用。  \n我不会用它们来完整地自动处理一个任务，它们也不是我生活中的自动化工具。  \n我不依赖生成式 AI 来取代我的创造力。  \n我更喜欢与它们进行互动，我的决策和专注始终贯穿于这个过程。  \n大语言模型并没有让我一夜之间成为超级程序员。  \n那些认为大语言模型和自动化可以替代员工的 CEO 和 AI 界的意见领袖，我认为他们的想法很短视。  \n但是。  \n大语言模型给了我极大的快乐，我非常享受与它们的互动。  \n它们激发了我对所参与的每件事情的兴趣和热情 - 对我来说，它们不仅仅是一个工具或自动化的替代品，而是一个充满乐趣的助手，帮助我学习和进步。  \n至少在过去十年中，没有任何技术能像现在这样让我感到这么多快乐和敬畏。  \n虚拟现实？让人不适和恶心。增强现实？让你时刻被工作、通知和广告所困扰。加密货币？无用，滋生犯罪，充斥着欺诈。Web3？只不过是资本家的小把戏，试图将我们的生活完全商品化。过去的十年，我们见证了太多被过分吹噜的平庸技术。  \n但是，在我看来，AI 才是真正的下一个（或者说已经是当前的）重大飞跃。我现在所讲的只是大语言模型，还没提到机器学习已在计算机图形和视觉等领域带来的革命性变化。对我而言，大语言模型和生成式 AI 的魅力不在于商业或生产力，而在于它们的趣味性和愉悦感 - 是的，技术应该是有趣的，令人享受的。我想重温我七岁时的那种兴奋，当时我正在探索 DOS、Windows 3.11，学习 Turbo Pascal 编程，并且开始接触 Web 1.0，制作我的第一个“无用”HTML 主页。我们的价值不应该只是在于提高生产力和为资本增值。这也是为什么我坚信，应该发展和推广开源大语言模型，让全球每个人都能平等地接触这些技术（最好是在他们自己的本地设备上，不受任何公司的控制）。  \n尽管对大语言模型存在一些技术上和社会上的担忧和批评，我仍然保持乐观态度。这些问题看起来是可以解决的，而且这样做是值得的。大语言模型会继续进步，但即便它们不再有太大的变化，我也会满足于现有的模型，因为它们已经在很大程度上丰富了我的生活。我希望这篇文章能展示给你大语言模型的这些乐趣，并鼓励你以新的方式去体验和享受它们。  \n原文：网页链接译文：网页链接\n","slug":"aigc/《我每天是如何使用 ChatGPT 的（从科学家和开发者的视角）》","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"881c384c3508fc861c9aa3fdea5ed55f","title":"如何配置一个rsync服务","content":"如何配置一个rsync服务如何配置一个linux上的rsync服务\n要在Linux上配置rsync服务，您需要执行以下步骤：\n\n安装rsync：在终端中执行以下命令以安装rsync：\n1sudo apt-get install rsync\n配置rsync服务：打开rsync配置文件，可以使用任何文本编辑器来编辑该文件：\n1sudo nano /etc/rsyncd.conf\n在配置文件中添加以下内容：\n1234567891011   [module_name]   path = /path/to/folder  # 要同步的文件夹路径   comment = My Rsync Module   uid = username  # 可选：以指定用户身份运行rsync服务   gid = groupname  # 可选：以指定组身份运行rsync服务   read only = false  # 可选：设置为true以只读模式启用rsync服务4. 保存并关闭文件。5. 创建一个系统用户（如果需要）：   如果您在上一步中指定了uid和gid参数，请确保在系统中创建相应的用户和组。使用以下命令来创建用户和组（将username和groupname替换为您的用户名和组名）：\n sudo adduser username –disabled-password –gecos “” &amp;&amp; sudo usermod -aG groupname username\n 1234567sudo adduser nobody --disabled-password --gecos &quot;&quot; &amp;&amp; sudo usermod -aG nobody nogroup6. 启动并启用rsync服务：    使用以下命令启动rsync服务，并将其设置为开机自动启动：\n sudo systemctl start rsync &amp;&amp; sudo systemctl enable rsync\n 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556577. 配置防火墙规则（如果需要）：    如果您的Linux系统上启用了防火墙，您需要确保允许rsync流量通过。使用适当的防火墙命令（如ufw）来配置规则。现在，您已经成功配置了rsync服务。其他计算机可以使用rsync客户端连接到该服务，并同步文件。介绍一下什么是rsync服务rsync服务是一种远程数据同步工具和协议，它可以在本地和远程服务器之间高效地同步文件和目录。rsync使用差异算法来比较源文件和目标文件的差异，并只传输需要更新的部分，因此可以大大减少数据传输量和网络带宽的消耗。rsync服务通常由一个服务器端和多个客户端组成。服务器端负责存储源文件和目录，并提供对这些文件和目录的访问权限。客户端通过rsync协议连接到服务器端，并根据需要从服务器上下载或上传文件。rsync服务具有以下特点：1. 高效性：rsync使用差异算法，只传输需要更新的部分，因此可以大大减少数据传输量和时间消耗。2. 安全性：rsync支持加密传输，并且可以通过SSH等安全协议进行身份验证，保护数据的机密性和完整性。3. 灵活性：rsync可以处理各种类型的文件、目录结构和操作系统平台，同时支持增量备份、镜像同步、远程复制等多种功能。4. 自动化：rsync支持脚本编程，可以通过定时任务或其他自动化工具进行定期备份、同步等操作。5. 容错性：rsync具有断点续传功能，在网络中断或其他异常情况下，可以恢复传输的进度，确保数据的完整性。总之，rsync服务是一种高效、安全、灵活和可靠的远程数据同步工具和协议，广泛应用于文件备份、数据同步、网站镜像等场景。Vmware workstation在linux的命令行里， 加载Vmware workstation 设置的共享文件夹的命令是什么？在Linux的命令行中，加载Vmware Workstation设置的共享文件夹的命令是：sudo vmhgfs-fuse .host:/ /mnt/shared上述命令将共享文件夹挂载到/mnt/shared目录下。请确保已经安装了open-vm-tools软件包，并且已经启动了vmware-tools服务。sudo apt install open-vm-toolsvmhgfs-fuse这个命令是什么意思vmhgfs-fuse是一个用于在Linux中挂载VMware共享文件夹的命令。VMware共享文件夹允许在虚拟机和主机之间共享文件和目录。通过使用vmhgfs-fuse命令，可以将共享文件夹挂载到Linux文件系统中，使得虚拟机可以访问主机上的文件和目录。如何在Vmware workstation中的linux的终端命令虚拟机查看Vmware workstation设置的共享文件夹要在Vmware Workstation中的Linux终端命令虚拟机中查看Vmware Workstation设置的共享文件夹，可以按照以下步骤进行操作：1. 在Vmware Workstation中，确保虚拟机已经启动并处于运行状态。2. 在Linux虚拟机的终端中，使用以下命令来挂载共享文件夹：\nsudo mount -t vmhgfs .host:/ /mnt/shared\n123   这将把共享文件夹挂载到/mnt/shared目录下。3. 使用以下命令来查看挂载的共享文件夹：\nls /mnt/shared\n12345678910111213141516171819现在，您应该能够在Linux虚拟机的终端中看到Vmware Workstation设置的共享文件夹。windows的共享目录要在Vmware Workstation中的Linux虚拟机中查看Windows共享目录，需要进行以下步骤：1. 确保Windows主机和Linux虚拟机之间已经建立起网络连接。可以通过ping命令来测试两者之间的网络连通性。2. 在Windows主机上创建一个共享目录。右键点击要共享的文件夹，选择“属性”，然后切换到“共享”选项卡，点击“高级共享”按钮，在弹出窗口中勾选“共享此文件夹”，并设置一个共享名称。3. 在Linux虚拟机中安装并启动Samba客户端软件。在终端中输入以下命令以安装Samba客户端：\nsudo apt-get updatesudo apt-get install smbclient\n124. 使用smbclient命令来连接和查看Windows共享目录。在终端中输入以下命令：\nsmbclient -L //windows主机IP地址 -U windows用户名%密码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869   其中，windows主机IP地址是指Windows主机的IP地址，windows用户名和密码是具有访问权限的Windows用户的凭据。5. 输入以上命令后，将会显示可用的共享目录列表。如果成功连接到了Windows主机，您可以使用cd命令进入特定的目录并使用ls或dir命令查看其中的文件和子目录。请注意，以上步骤假设您已经正确设置了网络连接并具有适当的权限来访问Windows共享目录。要在Vmware Workstation中查看Windows的共享目录，可以按照以下步骤操作：1. 确保在Vmware虚拟机中安装了Windows操作系统，并且已经设置好了网络连接。2. 在Vmware Workstation的主界面上，选择要查看共享目录的虚拟机，并点击&quot;编辑虚拟机设置&quot;。3. 在虚拟机设置对话框中，选择&quot;选项&quot;标签页，并点击&quot;共享文件夹&quot;。4. 在共享文件夹设置对话框中，点击右上角的&quot;+&quot;按钮添加一个共享文件夹。5. 在添加共享文件夹对话框中，选择要共享的Windows目录，并指定一个名称和路径。确保勾选了&quot;自动连接到此虚拟机&quot;和&quot;只读&quot;(如果需要)选项。点击&quot;确定&quot;完成设置。6. 在Windows虚拟机中启动Windows操作系统。7. 打开资源管理器，在地址栏中输入以下格式的路径：\\\\vmware-host\\shared folders\\&lt;名称&gt;，其中&lt;名称&gt;是前面在共享文件夹设置中指定的名称。例如：\\\\vmware-host\\shared folders\\myshare。8. 按回车键，即可访问到该共享目录下的文件和文件夹。通过以上步骤，您就可以在Vmware Workstation中查看并访问到Windows的共享目录了。vmware workstation如何与windows 10共享剪贴板要在VMware Workstation和Windows 10之间共享剪贴板，您需要执行以下步骤：1. 确保您的虚拟机和主机系统都安装了VMware Tools。如果尚未安装，请在虚拟机菜单中选择“安装VMware Tools”选项。2. 在虚拟机中，转到“编辑”-&gt;“首选项”菜单。3. 在Preferences窗口中，选择“共享剪贴板”选项卡。4. 在“共享剪贴板”选项卡中，选择要启用的剪贴板类型。您可以选择将剪贴板从主机传输到虚拟机、从虚拟机传输到主机或双向传输。5. 点击“确定”保存更改并关闭窗口。6. 重新启动虚拟机以使更改生效。现在，您应该能够在VMware Workstation和Windows 10之间共享剪贴板了。开机启动服务sudo systemctl daemon-reloadsudo systemctl enable rsync在centos系统下，如何配置systemctl的rsync配置文件cc在CentOS系统下，要配置systemctl的rsync配置文件，可以按照以下步骤进行：1. 打开rsync服务的配置文件`/etc/rsyncd.conf`，使用root权限进行编辑。2. 在配置文件中添加需要同步的目录和相关设置。例如：\n[module_name]path = /path/to/sync/directorycomment = Rsync module for syncing directoryuid = rsyncgid = rsyncread only = nolist = yesauth users = usernamesecrets file = /etc/rsyncd.secrets\n123453. 保存并关闭配置文件。4. 创建用于rsync身份验证的secrets文件。使用以下命令创建并编辑secrets文件：\nsudo touch /etc/rsyncd.secretssudo chmod 600 /etc/rsyncd.secretssudo vi /etc/rsyncd.secrets\n1235. 在secrets文件中添加身份验证信息。格式为`username:password`，例如：\nusername:password\n123456. 保存并关闭secrets文件。7. 修改secrets文件的权限，使其只对root用户可读写：\n sudo chmod 600 /etc/rsyncd.secrets\n 1238. 启动rsync服务并设置为开机自启动：\n sudo systemctl start rsyncd.service sudo systemctl enable rsyncd.service\n 1234567891011121314151617181920212223242526272829以上就是在CentOS系统下配置systemctl的rsync配置文件的步骤。下面这段话，产生的原因是什么rsync.service: Main process exited, code=exited, status=203/EXEC这段话发生的原因是rsync.service服务的主进程异常退出，退出代码为203/EXEC。这通常是由于执行rsync命令时发生了错误，可能是由于命令参数错误、权限问题或文件损坏等引起的。需要查看详细的错误日志或重新执行命令以获取更多信息来确定具体的原因。下面这段话是什么原因造成的sync error: error in file IO (code 11) at clientserver.c(995) [Receiver=3.0.9]这段话是一个错误消息，说明在进行文件同步时出现了文件IO错误。具体原因可能是由于客户端和服务器之间的通信问题导致的。rsync: failed to create pid file /var/run/rsync.pid这个真正的原因是/var/run中的rsync.pid没有删除rsync如何进行对/data0目录的同步使用rsync进行对/data0目录的同步，可以使用以下命令：\nrsync -avz /data0/ 目标服务器IP地址:/data0/\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152其中，`-avz`选项表示以归档模式进行同步，保留文件的属性、权限等信息，并启用压缩传输。`/data0/`是源目录的路径，`目标服务器IP地址:/data0/`是目标服务器上的目录路径。请将&quot;目标服务器IP地址&quot;替换为实际的目标服务器IP地址。下面的问题是什么原因造成kex_exchange_identification: read: Connection reset by peerrsync: connection unexpectedly closed (0 bytes received so far) [sender]rsync error: unexplained error (code 255) at io.c(226) [sender=3.1.3]这个错误通常是由于与远程服务器的连接中断导致的。可能的原因包括网络问题、服务器故障、防火墙配置等。下面的问题是什么原因造成,如何解决下面的问题。auth failed on module aigc from UNKNOWN (10.185.55.34): invalid challenge response问题原因是授权失败，可能是由于模块aigc的挑战响应无效所致。要解决这个问题，可以尝试以下几个步骤：1. 检查网络连接：确保网络连接正常并且IP地址正确。确保与模块aigc通信的网络是可访问的。2. 检查授权信息：验证授权凭据是否正确。确保提供的身份验证信息（用户名和密码）是正确的，并且没有任何拼写错误或其他格式问题。3. 检查模块配置：检查模块aigc的配置文件，确保没有任何错误或缺失的配置项。特别注意与身份验证相关的配置项，如挑战响应设置等。4. 更新软件版本：如果可能，尝试更新模块aigc的软件版本。有时候该问题可能是由于已知的软件漏洞或错误引起的，更新到最新版本可能会修复这些问题。5. 联系技术支持：如果以上步骤都没有解决问题，建议联系模块aigc的技术支持团队寻求帮助。他们可以提供更具体和针对性的指导来解决此问题。下面的问题是什么原因造成,如何解决下面的问题。ERROR: password file must not be other-accessiblersync error: syntax or usage error (code 1) at authenticate.c(196) [Receiver=3.1.3]这个问题的原因是密码文件具有其他用户可访问的权限。这可能是因为密码文件的权限设置不正确或密码文件存储在其他用户可以读取的位置。要解决这个问题，可以采取以下步骤：1. 检查密码文件的权限设置。确保只有所有者可以读取和写入密码文件，而其他用户无法访问它。可以使用chmod命令来更改权限设置。2. 确保密码文件存储在安全的位置，只有授权用户可以访问。避免将密码文件存储在公共目录或其他用户可访问的位置。3. 如果使用rsync命令时指定了密码文件，请确保密码文件路径正确并且该文件具有正确的权限设置。4. 如果仍然遇到问题，请尝试重新生成密码文件，并确保按照正确的方式进行配置和使用。请注意，在解决此问题之前，确保您对系统拥有足够的权限，并且了解对系统进行更改可能会产生的影响。解决方法sudo chmod 600 pwd.txt\nsudo groupadd nogroup\n12345678Linux如何添加一个用户组，组名为nogroup在Linux中，可以使用以下命令来添加一个名为nogroup的用户组：\nsudo groupadd nogroup\n12345678910111213这将创建一个名为nogroup的用户组。下面这句话什么意思， 怎么解决ERROR: password file must be owned by root when running as root这句话的意思是，如果以root身份运行时，密码文件必须由root所有。要解决这个问题，可以按照以下步骤操作：1. 以root身份登录到系统。2. 找到密码文件的位置。通常情况下，密码文件位于/etc目录下。3. 使用chown命令更改密码文件的所有者为root：\nsudo chown root:root /path/to/password/file\n12   其中，/path/to/password/file是密码文件的路径。4. 确保密码文件的权限正确设置为只有root用户可以读写：\nsudo chmod 600 /path/to/password/file```\n\n现在再次尝试以root身份运行程序或命令。应该不再出现”ERROR: password file must be owned by root when running as root”错误信息了。\n\n\n这然话什么意思，怎么解决rsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1663\n这个错误提示意味着在使用rsync命令进行文件传输时，有一些文件或属性未能成功传输。错误代码23表示发生了一些错误。\n要解决这个问题，你可以尝试以下几种方法：\n\n检查目标目录是否有足够的权限来接收文件。确保你有足够的权限来写入目标目录。\n\n检查源文件是否存在或是否被其他进程占用。确保源文件存在并且没有被其他进程锁定。\n\n使用-v选项运行rsync命令以获取更详细的错误信息。命令可能会提供更多有关未传输文件或属性的信息，从而帮助你找到问题所在。\n\n检查rsync版本是否过旧。如果是，请尝试升级到最新版本以解决可能的bug或问题。\n\n如果你正在复制符号链接，请确保-r选项已正确设置，以便复制链接指向的内容而不是链接本身。\n\n\n如果以上方法都无法解决问题，你可以尝试在rsync命令中添加–ignore-errors选项，以忽略部分错误并继续进行传输。但请注意，在某些情况下，这可能会导致数据丢失或不完整。\n最后，请参考rsync的文档和在线资源，寻找更多关于代码23错误的解决方案和调试技巧。\nnohup.out文件是什么文件\nnohup.out文件是一个文本文件，它记录了使用nohup命令运行的程序的输出信息。当使用nohup命令在后台运行一个程序时，该程序的所有输出（包括标准输出和标准错误）都会被重定向到nohup.out文件中。这个文件通常位于当前工作目录下，可以用来查看程序的输出信息以及错误信息。\ncrontab设置程序10分钟跑一次\n要在crontab中设置一个程序每10分钟运行一次，你可以按照以下步骤操作：\n\n打开终端或命令提示符窗口。\n输入以下命令以编辑当前用户的crontab文件：crontab -e\n在打开的文件中添加一行新的cron表达式来指定程序运行的频率。例如，如果你的程序名为myprogram.py，你可以使用以下表达式：*/10 * * * * /path/to/python /path/to/myprogram.py这个表达式会在每小时的第0、10、20、30、40和50分钟运行一次。注意替换/path/to/python为你机器上python解释器的路径，替换/path/to/myprogram.py为你程序文件的实际路径。\n保存和关闭文件（具体方法取决于你使用的编辑器）。\n\n现在，你已经成功将这个程序设置为每10分钟运行一次。\n","slug":"aigc/如何配置一个rsync服务","date":"2024-03-14T06:15:59.711Z","categories_index":"linux","tags_index":"rsync","author_index":"安全书"},{"id":"0214cb41e71f0a070ee24d319de60be5","title":"矢量数据库","content":"什么是𝗩𝗲𝗰𝘁𝗼𝗿 𝗗𝗮𝘁𝗮𝗯𝗮𝘀𝗲?什么是𝗩𝗲𝗰𝘁𝗼𝗿 𝗗𝗮𝘁𝗮𝗯𝗮𝘀𝗲?  \n随着基础模型的兴起，矢量数据库迅速流行起来。事实上，矢量数据库在大型语言模型上下文之外也很有用。  \n当谈到机器学习时，我们经常处理向量嵌入。矢量数据库的创建是为了在使用它们时表现特别好：  \n➡️ 存储。  \n➡️ 正在更新。  \n➡️ 正在检索。  \n当我们谈论检索时，我们指的是以嵌入在同一潜在空间中的向量的形式检索与查询最相似的向量集。这种检索过程称为近似最近邻居（ANN）搜索。  \n这里的查询可以是像图像这样的对象的形式，我们希望为其找到类似的图像。或者，它可能是一个我们想要检索相关上下文的问题，这些上下文稍后可以通过LLM转换为答案。  \n让我们来看看如何与矢量数据库交互：  \n𝗪𝗿𝗶𝘁𝗶𝗻𝗴/𝗨𝗽𝗱𝗮𝘁𝗶𝗻𝗴 𝗗𝗮𝘁𝗮.  \n1.选择要用于生成矢量嵌入的ML模型。2.嵌入任何类型的信息：文本、图像、音频、表格。用于嵌入的ML模型的选择将取决于数据的类型。3.通过嵌入模型运行数据，获得数据的矢量表示。4.将附加元数据与矢量嵌入一起存储。该数据稍后将用于对ANN搜索结果进行预滤波或后滤波。5.矢量数据库分别对矢量嵌入和元数据进行索引。有多种方法可用于创建矢量索引，其中一些方法是：随机投影、乘积量化、局部敏感哈希。6.矢量数据与矢量嵌入的索引和连接到嵌入对象的元数据一起存储。  \n𝗥𝗲𝗮𝗱𝗶𝗻𝗴 𝗗𝗮𝘁𝗮.  \n7.针对矢量数据库执行的查询通常由两部分组成：  \n➡️ 将用于人工神经网络搜索的数据。例如，您想要查找相似图像的图像。  \n➡️ 元数据查询，以排除预先已知的具有特定质量的矢量。例如，如果您正在寻找类似的公寓图像，则排除特定位置的公寓。  \n8.根据元数据索引执行元数据查询。它可以在人工神经网络搜索过程之前或之后进行。9.您使用用于将数据写入Vector DB的相同模型将数据嵌入到Latent空间中。10.应用ANN搜索过程并检索一组矢量嵌入。用于人工神经网络搜索的常用相似性度量包括：余弦相似性、欧氏距离、点积。  \n一些流行的矢量数据库：Qdrant，Pinecone，Weviate，Milvus，Faiss，Vespa。\n\n","slug":"aigc/矢量数据库","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"124bb865c7cb77ee9606b987c0e9b277","title":"长文本能力会不会杀死RAG","content":"长文本能力会不会杀死RAG随着 Gemini 超100万上下文的推出，推特上关于长文本能力会不会杀死RAG的讨论还是挺多的。围绕 RAG vs 长文本的成本的讨论还比较多，例如图1，但也有说法认为，长文本的成本会慢慢下降。  \n看到一个还不错的长推特评论，来自 Snorkel AI 首席执行官Alex Ratner（注：请自行判断其观点可信度）：  \n「简要看法：  \n\nRAG 仍将用于复杂的生产系统  \n较长的上下文模型将占用较简单/预生产的用例  \n无论如何，关键的一步仍然是–根据良好的数据调整LLM 系统。  \nRAG仍将用于复杂的生产系统  \n\n正如许多人指出的那样，从成本、延迟和规模的角度来看，RAG仍然是胜出的。更持久的是：RAG方法是模块化的。因此，对于更复杂、规模化和/或生产环境，RAG可能会继续存在。\n\n较长的上下文模型将吞噬较简单/预生产的用例  \n\n然而，长上下文模型肯定会占用大量的简单用例和预生产开发（今天的很多AI）。  \n特别是考虑到 post-transformer（例如 SSM 架构）的进展情况…  \n\n关键步骤仍然是在良好的数据上调整LLM系统  \n\n无论是微调/对齐 LLM 还是 LLM + RAG 系统，关键在于您使用的数据以及您如何开发它！」\n","slug":"aigc/长文本能力会不会杀死RAG","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC,rag","tags_index":"RAG","author_index":"安全书"},{"id":"94a35c942b1e4d4bd9646732d214e01d","title":"《我们这一代人的机会是什么？》","content":"《我们这一代人的机会是什么？》作者：Rey\n1998年前后，搜狐新浪网易、BAT相继成立，中国互联网时代开启，伴随而来的还有风险投资；  \n1998年事业单位停止福利分房，开启房地产市场化时代；  \n1998年亚洲金融危机，中国增发特别国债加强基建，开始大规模基础设施建设时代，拉动经济增长的第一辆马车开启；  \n2001年中国加入世贸组织，开启大出口时代，拉动经济的第二辆马车开启；  \n这四匹马奔跑了二十年，造就了3亿中产阶级，上千万的富豪，无数的创业机会，梦想是这个时代的主旋律，2010~2020这十年更是人类历史上最繁荣的十年，没有非典与新冠，也没有伊拉克战争与俄乌战争，全球化越来越紧密，移动互联网吞噬一切，中国的房地产以每年20%的速度在增值。  \n但是今天，互联网不增长了、伴随的VC没地方投钱了、甚至由于中美贸易战，美国VC的钱都撤走了，房子卖不动了、该建设的基建都建设完了、出口也被G7制裁了，这四匹马都瘸了。至于消费这匹马，没有前面这四匹马赚钱，口袋空瘪瘪的，未来预期也不可控，谁还敢消费呢？  \n这就是我们这一代人的时代背景，我们不禁要问，我们这一代人的机会在哪里？特别是年轻人的机会在哪里？因为年轻人还不能躺平，也没有资本躺平呀。我分析了一些机会点：  \n1、短视频依然有红利，但那不属于产品人  \n2020年的短视频会像2010年的移动互联网一样吞噬一切，只要一个领域还没有知名的IP，那个领域就还有机会，说明机会窗口还没有关闭，比如我要在海外办公司，其实我并不知道找谁，因为我不知道谁靠谱，这存在着很大的信息差，我需要一个可信任的人操办这些事情，如果你的短视频能做到让我认识你，我的订单就是你的；再比如我要买保险，我也不知道应该信任谁。比起一个机构，我们更愿意相信一个活生生的人，这是IP的独特价值，如果你有做IP的能力，短视频是一个好的选择。  \n不过，短视频全是流量运营的事情，里面没有做产品、做技术的机会，2021年我们在抖音做MCN的时候就发现了这一点。现在抖音上唯一可以产品化的就是数据参谋类产品，比如蝉妈妈、考古加。  \n2、生物科技是硬核科学，也不存在产品定义的机会  \n都说21世纪是生物科技的时代，我认为是对的，其一是刚需，健康与排除孤独，是人类一直追求，但一直都没有办法解决的问题；其二是AI、大数据与生物科技的结合，提供了一条新的解题路径，很多生物问题可以“计算”出来。  \n但是，生物科技是硬核科学，他需要的是技术，不是产品定义的能力，产品经理的能力模型跟苹果公司类似，从来不发明任何新技术，只根据用户需求整合需要的技术。  \n当一个领域在比拼技术的时候，更需要的还是数学家、科学家、工程师，而不是产品经理，我们能把产品做得更高效、更简单、价格更低、体验更好，但我们没有办法将语音识别率从97%提升到99%，将OCR的能力从99.0%提升到99.7%，生物科技同理。  \n3、如果你不做AI，可能就真的没有机会了  \n提交YC的项目，70%已经与AI相关，这反映了全球创业的趋势。这还是要回归到用户需求，1994年是世界互联网的元年，2011年是移动互联网的元年，这么多年过去了，该被满足的需求都被满足得差不多了。在未来的日子里，非AI的领域，可能只有社交与游戏还能产生千万DAU、百万DAU的可能性，其他领域都不太可能了。  \nAI对我们来说，只是一种工具，区块链也是工具，技术其实都是工具，我们武器库里的工具越多，我们解决某个问题就越彻底，可能很多以前没有办法解决的问题，通过AI就能解决得很好，比如妙鸭相机，他是通过AI解决海马体拍证件照很麻烦、价格很贵的问题，如果没有AI，这个问题是解决不了的。  \nAI的技术已经可用了，目前需要的是洞察，看一些以前没有AI的时候，没法解决的问题，现在能不能通过AI解决，能不能解决得更好。  \n4、做一个5人小团队，永远都有机会  \n做小而美的事情，永远都是有机会的，放弃过去的宏大叙事，回归个体户的思维，找到一个极度细分的领域做好、做精、能守得住，当营收多一些，能Cover多一个人工资的时候，那就多增加一个人，不行的时候，就裁掉一个人，永远保持精干的小团队。  \n优势永远都是一点一滴积累的，打磨一个小而美的产品永远不是一件简单的事情，这样的事情是不会有VC支持的，这就意味着要靠自己，自负盈亏，这就需要你极度有耐心，要做好3年、5年没有正向收入的可能性，最好还是先业余做，等看到希望以后再辞职全力去做，这样的路径是最顺畅的。  \n5、出海，到竞争还不充分的地方去  \n“未来已来，只是空间分布不均匀”，美国、中国、其他地方，这是不同的世界，地区与地区之间存在着时间差，移动互联网在中美竞争很充分，但不意味着世界其他地方竞争也很充分，这里就是机会。  \n我的选择是什么，5＞3＞4。\n","slug":"article/《我们这一代人的机会是什么？》","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"d513b66cf42e1723c2bda6d425c5b9ed","title":"Sora 和之前 Runway 那些在架构上有啥区别呢","content":"Sora 和之前 Runway 那些在架构上有啥区别呢Sora是基于Diffusion Transformer模型的生成式模型，融合了扩散模型和Transformer架构，能有效处理含噪点的图像输入并逐步预测出更清晰的图像版本。与传统Token预测不同，Sora预测序列中的下一个Patch，使OpenAI在处理大规模图像和视频数据时取得显著进展。由于基于Patch而非全帧训练，Sora无需裁剪任何大小的视频或图片，输出质量更高。结合Diffusion Transformer架构，OpenAI为训练Sora倾注更多数据和资源，取得惊人效果。\n问：Sora 和之前 Runway 那些在架构上有啥区别呢？  \n答：简单来说 Runway 是基于扩散模型（Diffusion Model）的，而 Sora 是基于 Diffusion Transformer。  \nRunway、Stable Diffusion 是基于扩散模型（Diffusion Model），扩散模型（Diffusion Model）的训练过程是通过多个步骤逐渐向图片增加噪点，直到图片变成完全无结构的噪点图片，然后在生成图片的时候，基于一张完全噪点的图片，逐步减少噪点，直到还原出一张清晰的图片。  \n文本模型像 GPT-4 则是 Transformer 模型。Transformer 则是一套编码器和解码器的架构，将文本编码成数字向量，然后解码的时候从数字向量还原出文本。  \nSora 则是一个融合了两者的 Diffusion Transformer 模型。通过 Transformer 的编码器 - 解码器架构处理含噪点的输入图像，并在每一步预测出更清晰的图像版本。编码器负责对含噪点的输入进行编码，而解码器则负责生成更清晰图像的预测。  \nGPT-4 被训练以处理一串 Token，并预测出下一个 Token。Sora 不是预测序列中的下一个文本，而是预测序列中的下一个“Patch”。  \n在文本预测生成中，基本单位是 Token，Token 很好理解，就是一个单词或者单词的一部分。Patch 的概念相对不那么好理解，不过今天看到一篇文章，作者举了个很好的例子。  \n想象一下《黑暗骑士》的电影胶片，将一卷胶片绕在一个金属盘上，然后挂在一个老式电影院的投影机上。  \n你把电影胶卷从盘中展开，然后剪下最前面的 100 帧。你挑出每一帧——这里是小丑疯狂大笑，那里是蝙蝠侠痛苦的表情——并进行以下不同寻常的操作：  \n你拿起一把 X-acto 精细刻刀，在第一帧电影胶片上剪出一个变形虫状的图案。你像处理精密仪器一样小心翼翼地用镊子提取这片形似变形虫的胶片，然后安全地保存起来。之后，你处理下一帧：在接下来的胶片上切出同样位置、同样形状的变形虫图案。你再次用镊子小心地取出这个新的变形虫形状的胶片——形状与前一个完全相同——并将其精确地放置在第一个之上。你这样做，直到完成所有的 100 帧。  \n你现在有了一个色彩斑斓的变形虫，沿着 Y 轴扩展。这是一座可以通过投影机播放《黑暗骑士》的小片段的胶片塔，就好像有人在投影机前握着拳头，只让电影的一小部分影像从拳心通过。  \n然后，这座胶片塔被压缩并转化为所谓的“Patch”——一种随时间变化的色块。  \nPatch 的创新之处——以及 Sora 之所以显得如此强大——在于它们让 OpenAI 能够在大量的图像和视频数据上训\n练模型，从而生成更清晰、更真实的图像。通过融合扩散模型和Transformer架构，Sora能够有效处理含噪点的图像输入，并逐步预测出更清晰的图像版本。与传统的Token预测不同，Sora预测序列中的下一个Patch，这种创新使得OpenAI在处理大规模图像和视频数据时取得了显著进展。通过将两种不同的架构结合在一起，Sora展现了强大的生成能力和潜力。练 Sora。想象一下从每一个存在的视频中剪出的 Patch——无尽的胶片塔——被堆叠起来并输入到模型中。  \n以前的文本转视频方法需要训练时使用的所有图片和视频都要有相同的大小，这就需要大量的预处理工作来裁剪视频至适当的大小。但是，由于 Sora 是基于“Patch”而非视频的全帧进行训练的，它可以处理任何大小的视频或图片，无需进行裁剪。  \n因此，可以有更多的数据用于训练，得到的输出质量也会更高。例如，将视频预处理至新的长宽比通常会导致视频的原始构图丢失。一个在宽屏中心呈现人物的视频，裁剪后可能只能部分展示该人物。因为 Sora 能接收任何视频作为训练输入，所以其输出不会受到训练输入构图不良的影响。  \n在结合前面提到的 Diffusion Transformer 架构，OpenAI 可以在训练 Sora 时倾注更多的数据和计算资源，从而得到令人惊叹的效果。  \n另外 Sora 刚发布视频时，能模拟出咖啡在杯子里溅出的液体动力学，以至于有人以为是连接了游戏引擎，但实际上 Sora 还是基于生成式模型，这是因为 Sora 在训练时，使用了大量的视频数据，这些视频中包含了大量的物理规则，所以 Sora 能够模拟出液体动力学。这类似于 GPT-4 在训练时，使用了大量的代码来作为训练数据，所以 GPT-4 能够生成代码。  \n有两篇论文：《Scalable Diffusion Models with Transformers》网页链接《Patch n’ Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution》网页链接  \n包含更多专业细节。\n","slug":"aigc/sora/Sora 和之前 Runway 那些在架构上有啥区别呢","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC,sora","tags_index":"sora","author_index":"安全书"},{"id":"8498990ea0518320f72ae9f350cc7d26","title":"宇宙探索编辑部-关于Sora讨论","content":"宇宙探索编辑部-关于Sora讨论很荣幸受 邀请，今天和她以及《宇宙探索编辑部》副导演吕启洋（Ash）一起聊聊了一下当前火爆的话题 Sora，看 Sora 如何改变我们的生活。  \n我把技术相关的一些问题整理成了文字，希望能够帮助大家更好地理解 Sora。我将问题大约整理成了四类：  \n\nSora 的技术科普  \nSora 产品相关问题  \nSora 的价值和应用  \nSora 有关的八卦闲聊  \n\n注意，这里的回答都是我个人的观点，一部分也借鉴了大家在帖子中讨论的结果，很多答案不一定准确，仅供参考。也欢迎指正其中错误或者提出不同观点。  \n** Sora 的技术科普  \n*** Sora 是什么？能干什么？  \n简单来说，Sora 是一种能用文本生成最长 60 秒视频的技术，也可以用来生成图片，因为图片本质上是一帧的视频。  \n*** Sora 跟之前的 AI 视频生成工具有什么升级？跟市面上其他的例如 Runway、Pika、SVD 这些 AI 视频生成工具有什么区别？  \n“之所以 Sora 引发极大关注，主要在于它生成视频质量要比之前的高很多，不仅时间最长能到 60 秒，而且它可以支持镜头切换、画面人物和背景稳定、很高画质。  \nPika 是基于 Diffusion 模型，把图片和视频训练成毫无意义的马赛克图片，再从空白马赛克图片能反向扩散生成图片和视频，有两种主要模式，一种是基于图片关键帧扩展成视频，例如已有视频的风格变换；一种是对视频的训练，但是由于显卡限制，只能一次训练特定分辨率的几秒视频，一次也只能生成几秒钟的视频。  \nLLM、ChatGPT 是 Transformer 模型，预测 Token 生成文本内容，Token 可以理解为字和词。  \nSora 则是基于 Diffusion Transformer 模型，结合了扩散模型和 Transformer 模型，不过它是预测生成的不是文本 Token，而是“时空补丁（spacetime patches） ”，可以理解为一个几帧（一秒不到）的视频的一个小块。  \n主要优势是训练的时候不受视频和显卡约束，生成的时候也更加多样，可以灵活组合时空补丁。”  \n*** 使用成本：现在可以生成 60 秒视频，60 秒视频的成本是多少？对算力有什么要求？  \n现在”DALL-E 3 HD Image 价格 $0.08；Runway Gen-2 价格是$0.05/秒。  \nSora 没有公布相关数据，纯猜测：Sora 的推理大约需要 ~8xA100，生成视频预估一秒一分钟，半小时成本约 ~$10”  \n*** 有可能可以生成音乐（音频）么？如果不行难点在哪？  \n未来应该是可以的，现在没有是因为：  \n\n需要根据视频中的环境、物体类型、物体之间的碰撞、所在位置发出不同的声音  \n需要多种声源叠加  \n音乐不仅要质量高，还需要和视频中的场景融合  \n人物对白需要和人物的位置、口型、表情对齐  \n\n** Sora 产品相关问题  \n*** 是否需要建模还是通过其他方式使用？什么时候能落地商用？  \n不需要本地搭建，预计会提供两种方式：ChatGPT 集成、API 调用；但生成视频的成本偏高、耗时也比较长；可能会限制次数或者提供更高一档的订阅。  \n预计三个月到半年内会逐步放开。  \n*** 在不同的时间使用相同的要求语，会生成相同的视频吗？能支持后续微调修改或者输入更确定的边界条件生成么？当前模型架构有能力支持这些么？  \n同样的提示词每次都不会相同，但是 seed 相同应该可以做到相似；  \nSora 支持图片生成视频和视频生成视频，但人物是否可以做到一致还需要产品发布后才能下结论。  \n*** 什么时候可以生成更长时间的视频，比如 30 分钟、60 分钟甚至更长？  \n生成视频时间越长对显存要求越高，但是按照现在技术发展的速度，乐观估计 1 年后应该可以到 5-10 分钟，30 分钟 60 分钟预计在 3-5 年的时间。  \n*** 生成视频的版权归谁？  \n根据图片生成的规则来推测，应该是归创作者所有，但是生成的作品本身不能侵权。  \n*** 虚拟 vs 现实：如何判断那些视频是拍的？哪些是 Sora 做的？以后还有啥会是真的呢？深度伪造问题：会不会更容易被诈骗，如何反诈？  \n现在的视频都有水印，未来应该会有检测工具。  \n另外仔细看是能看出视频中不符合逻辑的地方，例如蚂蚁只有 4 条腿，人的手会变形等等。  \n我们其实早已经历过：照片不是真的、电视不是真的、电影不是真的，人民群众的鉴别水平也会同步提升。  \n伪造和鉴别伪造是长期攻防战。  \n*** Sora 接下来的发展前景演进趋势？  \n\n成本降低（更快更便宜）；  \n质量提升（时长、画质、镜头切换、一致性、符合物理规律）；  \n新的能力：声音、和 GPT 的融合，完全的多模态；  \n\n*** 能不能用来做动画片？  \n短片完全没问题，复杂场景和更长时间的还不行，未来可期。  \n** Sora 的价值和应用  \n*** Sora 有哪些应用场景？实用性有多大？商业应用价值？  \n我从四个方面总结了 Sora 的价值和应用：  \n\n首先它能放大了普通人的表达能力，张小龙说汽车是双腿的延伸，ChatGPT 就是双手的延伸，Sora 就是我们表达的综合延伸，也就是传说中的“嘴替”  \n\n这意味着我们可以更好的来表达自己的想法，不再受限于自己的写作能力、画画能力、摄影能力、视频剪辑能力，甚至是演讲能力。  \n\nSora 是一种低成本的视频工具  \n\nSora 将极大的降低了视频制作的成本，这意味着更多的人可以用更低的成本来制作视频，这对于视频创作者来说是一个很大的利好。  \n\n新的人机交互方式，动态生成视频  \n\nSora 已经演示了生成我的世界这样游戏的能力，也许未来我们可以用 Sora 来动态生成游戏的剧情、任务、场景。另外，我们也可以让 Sora 动态对新闻、文章生成视频，而不需要去阅读。  \n\n情感上的寄托  \n\n生成已故亲人的视频，保留他们的记忆。数字伴侣。  \n*** Sora 赚钱逻辑在哪里？  \n取决于围绕 Sora 创造的价值：  \n\n情感价值：卖课缓解焦虑、提供娱乐、情感寄托  \n艺术价值：微电影  \n内容价值：小说二创、卖素材、教学、讲故事、游戏生成、广告  \n生态价值：Prompt、更加易用小工具、绕过限制  \n降本增效：快速 MVP 验证想法、广告、电商、电影分镜  \n\n*** 普通人怎么用好？如何利用 Sora 做点副业？  \n\n用起来，学会怎么用，知道它能做什么，边界在哪里  \n选一个适合自己的方向，提前准备好相关素材或者开发项目  \n技术人员可以准备开始筹备产品、工具：收集 Prompt、基于 API 二次开发  \n\n** Sora 有关的八卦闲聊  \n*** 名字真的是起源于天元突破的 op 空色デイズ吗？  \n我倾向于是。  \n*** 现在的热度是 (为了融资、股价) 的概念炒作？还是真实有用的？  \n真实有用，可以马上应用到短视频，例如 OpenAI 在 Tiktok 的账号，视频以假乱真  \n*** 您在网上看到或者听说的一些比较夸张脱离实际的说法？  \n“Sora”关键原材料之—马来酰亚胺树脂来自于四川绵阳一家公司。Sora 懂物理Sora 连接了游戏引擎Sora 是 AGI 的关键里程碑，几年内就能实现 AGI  \n*** 在全球顶尖公司之间 Sora 的竞争力如何？中国在这个领域的发展情况？在中国做这个的公司有哪些？中国和欧美的差距在哪里？  \nOpenAI 已经投入了一年多，领先业界半年到一年，甚至更多，具体体现在：  \n\n技术的领先，目前技术还没公开，其他公司要破解需要时间  \n大模型的优势，他们有最先进的模型可以帮助训练，例如自动生成高质量的视频标注中国应该很快能追赶上——人才、数据、算力都有，但是只有少数大厂才有机会，对人才、数据、算力要求都太高  \n\n目前不清楚是否中国公司已经有做这个方向的，但是字节、阿里、腾讯、百度在 AI 视频领域都有深厚积累  \n中国和欧美的差距主要在于对 AI 技术方向上的把握，但这也不仅仅是中国的问题，目前全世界所有其他公司都跟随 OpenAI 的步伐；另外就是算力上还不能完全自给自足。  \n*** 新一次产业革命？有网友指出，短短几年内，被追捧的高热度“划时代”技术有 web3、区块链、元宇宙、谷歌眼镜、波士顿机器人、vision pro、chatgpt 等等，这次确认要再次划时代了吗？  \n看怎么定义吧，从文本生成视频领域来说，一定是划时代的！真正的文本生成视频领域的 GPT 时刻。  \n\nChatGPT 文本生成  \nStable Diffusion、MIdJourney、DALL-E 图像生成  \nSora 文本生成视频  \n\n*** Sora 在硅谷的体感热度？在业内的真实反响？目前 AI 视频生成赛道的创业者、投资者们心态如何，将会如何应对？  \n\n反响热烈，正面评价居多  \n预计 Diffusion 方向会比较难拿到投资  \n创业者需要重新考虑方向，例如视频编辑、转向基于 Sora 的接口开发应用  \n\n*** 跟芯片有什么关系？  \n未来几年视频生成会继续热门，继续需要大量的算力，也就是需要大量的显卡，但未来显卡应该不会只有 NVIDIA 一家独大，应该会有更多的公司参与进来，这样的话，显卡的供应会更充足，价格会更加合理，性能也会更高。  \n** 总结  \n","slug":"aigc/sora/宇宙探索编辑部-关于Sora讨论","date":"2024-03-14T06:15:59.711Z","categories_index":"笔记","tags_index":"sora","author_index":"安全书"},{"id":"02714eaa9a3a0c3a59b53d39d32c1d22","title":"如何用 gfpgan进行图像的人脸修复","content":"如何用 gfpgan进行图像的人脸修复如何用 gfpgan进行图像的人脸修复\n要使用gfpgan进行图像的人脸修复，可以按照以下步骤进行：\n\n安装gfpgan：首先，你需要安装gfpgan模型。你可以在gfpgan的GitHub页面上找到模型和代码并按照说明进行安装。\n\n准备输入图像：准备一张需要修复的人脸图像。确保图像的尺寸适合模型的要求（通常为256x256像素）。\n\n运行修复脚本：使用gfpgan提供的修复脚本运行修复过程。你可以在gfpgan的GitHub页面上找到示例代码和说明。将输入图像作为参数传递给修复脚本，并指定输出文件夹。\n\n等待修复完成：等待修复过程完成。这可能需要一些时间，具体取决于你的计算机性能以及输入图像的大小和复杂度。\n\n查看修复结果：一旦修复完成，你可以在输出文件夹中找到修复后的图像。使用任何图像查看器或编辑器打开它，并检查结果是否符合预期。\n\n\n请注意，gfpgan只能对已经存在的人脸进行修复，不能从其他地方恢复缺失的人脸部分。此外，虽然gfpgan可能会产生令人印象深刻的结果，但并不能保证每个输入图像都会得到完美的修复。因此，在使用gfpgan进行人脸修复时，理解和管理预期结果非常重要。\ngfpgan进行图像人脸修复的命令是什么？\ngfpgan进行图像人脸修复的命令是：\n1python demo.py --input_dir &lt;input_directory&gt; --gpu 0\n其中，&lt;input_directory&gt;是包含待修复图像的文件夹路径，--gpu 0表示使用GPU进行加速。\n如何在Python中调用gfpgan\n要在Python中调用gfpgan，需要按照以下步骤进行操作：\n\n首先，确保已经安装了Python和PyTorch。可以使用以下命令检查是否已安装PyTorch：\n1python -c &quot;import torch; print(torch.__version__)&quot;\n如果显示了PyTorch的版本号，则表示已经成功安装。\n\n下载gfpgan的代码库。可以从其GitHub页面上找到代码库的链接，并使用git clone命令将其克隆到本地。\n1git clone https://github.com/TencentARC/GFPGAN.git\n进入GFPGAN目录，并安装所需的Python依赖项。可以使用以下命令来完成此操作。\n12cd GFPGANpip install -r requirements.txt\n下载预训练的权重文件。gfpgan提供了多个预训练模型，可以从其GitHub页面上下载相应的权重文件。将下载的权重文件放入GFPGAN目录中。\n\n在Python脚本中导入gfpgan并使用它进行图像增强。可以使用以下代码片段作为示例：\n123456789101112import torchfrom gfpgan import GFPGAN# 加载预训练模型和权重model = GFPGAN(config=&#x27;path/to/config.yaml&#x27;, checkpoint=&#x27;path/to/checkpoint.pth&#x27;)# 读取输入图像并进行图像增强input_image = Image.open(&#x27;path/to/input_image.jpg&#x27;)enhanced_image = model.enhance(input_image)# 保存增强后的图像enhanced_image.save(&#x27;path/to/enhanced_image.jpg&#x27;)\n注意：需要将’path/to/config.yaml’和’path/to/checkpoint.pth’替换为实际的配置文件和权重文件的路径。\n\n\n通过上述步骤，就可以在Python中成功调用gfpgan，并使用它进行图像增强。\n一定要用阿里的源安装 tb-nightly\npython -m pip install tb-nightly -i https://mirrors.aliyun.com/pypi/simple\n1python -m pip config set global.index-url https://mirrors.aliyun.com/pypi/simp\n\npython -m pip config list\nglobal.index-url=’https://mirrors.aliyun.com/pypi/simple&#39;","slug":"aigc/sd/如何用 gfpgan进行图像的人脸修复","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC,gfpgan","tags_index":"gfpgan","author_index":"安全书"},{"id":"aa6f0cb3af6190b915086c9ddb3c891c","title":"安装GFPGAN修复人脸图像","content":"安装GFPGAN修复人脸图像老照片修复利器GFPGAN，该模型为腾讯2021年开源的一个用于图片人脸复原修复的GAN模型；我们都有很多老照片，很多很久以前用两三百万像素拍的照片或原文件丢失了，只剩下压缩文件或QQ空间里面的老照片，现在一些App也支持老照片修复但往往效果不太理想或都需要收费；这时可以使用GFPGAN对相片进行修复复原；  对GFPGAN模型进行微调或许很多人没有相应的条件进行，可使用GFPGAN提供的预训练模型，该预训练模型参数输出的修复效果对比原图还算是基本可用；\n安装GFPGAN  由于安装GFPGAN与使用GFPGAN时会下载对应的预训练模型参数等文件比较大等最好设置相应的代理上网;  可在cmd命令行设置代理，此代理为临时的，也可设置git代理：\n1set https_proxy=http:&lt;span class=&quot;hljs-comment&quot;&gt;//127.0.0.1:10809&lt;/span&gt;\n\n  GFPGAN可直接下载GFPGAN压缩包或通过git clone下载，然后进入GFPGAN的安装目录下，如：D:\\software\\dev\\github\\GFPGAN，并将下载的GFPGAN项目放到D:\\software\\dev\\github\\GFPGAN\\venv\\Scripts\\目录中；\n  在命令行执行如下指令安装GFPGAN依赖：\n12345pip install basicsr facexlib pip install -r requirements.txt  python setup.py develop 完成GFPGAN的安装； 如需对背景进行优化增强需安装Real-ESRGAN pip install realesrgan\n\n\n\n可以看到运行GFPGAN除了下载自身的GFPGANv1.3预训练模型外还下载了残差神经网络模型、ParseNet模型；\nGFPGAN使用  进入GFPGAN目录执行如下命令即可：\n1python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 \n\n参数： -i 图片或目录的路径 -s 最终图片上采样比例 -o 图片输出路径\n执行完后GFPGAN将 inputs/whole_imgs目录中的图片修复并输出到results目录中；\n  图片的对比如下： 效果还是相对可以除了处理面部外还对头发进行的修复；\n修复前图：\n修复后图：\n  该模型作者提出了精密设计的GFPGAN模型，模型在一个单向前向传播过程能够实现真实性和保真性的平衡。GFPGAN由一个退化移除模块（U-Net）和一个预训练的GAN模块（StyleGAN2）。通道分离空间特征转换层（Channel-Split Spatial Feature Transform，CS-SFT）以由粗到细的方式将两个模块的隐向量结合。具体论文如下：\n","slug":"aigc/sd/安装GFPGAN修复人脸图像","date":"2024-03-14T06:15:59.711Z","categories_index":"AIGC,gfpgan","tags_index":"gfpgan","author_index":"安全书"},{"id":"a431978375ccc7ec0d62892221bc874e","title":"高级增加检索LlamaIndex","content":"高级增加检索LlamaIndex高级检索增强生成（RAG）技术解决了原始RAG管道的局限性。  \n最近一项关于RAG的调查将先进的RAG技术分为检索前、检索和检索后优化。最新文章概述了先进的RAG技术：  \n🦙 预检索包括滑动窗口、增强数据粒度、添加元数据或优化索引结构等技术，如句子窗口检索。  \n🦙 检索包括优化嵌入模型（例如，微调）或混合搜索等高级检索技术  \n🦙 后期检索包括重新排序或提示压缩。  \n我们还使用LlamaIndex实现了一个简单的RAG管道，然后使用以下方法将其增强为高级RAG管道：  \n*语句窗口检索（作为检索前的优化）*混合搜索（作为检索优化）*重新排序（作为检索后优化）\nPaper: https://arxiv.org/pdf/2312.10997.pdfJupyter Notebooks:  https://github.com/weaviate/recipes/tree/main/integrations/llamaindex/retrieval-augmented-generation\n","slug":"aigc/rag/高级增加检索LlamaIndex","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,RAG","tags_index":"RAG","author_index":"安全书"},{"id":"d25d0abd46cf8087337426c11032fc8d","title":"ComfyUI Deploy","content":"ComfyUI Deploy你可以选择使用原始的 ComfyUI 界面，或者使用他们生成的 API，自己的前端界面。  \n很容易就可以吧 ComfyUI 的工作流变成产品，比如直接搞个 SVD 视频生成的服务。 SVD 效果是好，对普通人来说门槛还是高。其实只需要上传图片点确定就行。  \n使用步骤：  \n1）安装这个服务的 ComfyUI 插件2）去网站申请对应的 Key3）本地 ComfyUI 中选择你的工作流填入 Key 上传4）去网站新建一台机器，选择你的工作流运行就行\nhttps://github.com/BennyKok/comfyui-deploy?tab=readme-ov-file&amp;continueFlag=22d463803a5e9fe20c66258db2d14df1\n","slug":"aigc/sd/ComfyUI Deploy","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,comfyui","tags_index":"comfyui","author_index":"安全书"},{"id":"5ffd5ba2715e0bed5ed2f623a352bd78","title":"DDColor老相片上色","content":"DDColor老相片上色GitHub 上一款可实现照片级真实感的图像着色工具：DDColor。  \n它不仅可以为历史黑白老旧照片提供生动自然的着色，还可以对动漫游戏中的风景进行着色或重新着色，变为逼真的现实生活风格！  \nGitHub：github.com/piddnad/DDColor  \n又是一款 AI 老旧照片智能上色的工具，可开源免费使用。 ​​​\n\n\n","slug":"aigc/sd/DDColor老相片上色","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"19c727e75f2f0cb1d867a34d15d56761","title":"RuntimeError  cannot import name 'compare_version' from torchmetrics.utilities.imports","content":"RuntimeError  cannot import name ‘compare_version’ from torchmetrics.utilities.imports1、RuntimeError: cannot import name ‘_compare_version’ from ‘torchmetrics.utilities.imports’需要降级一下torchmetrics包,运行\n\nconda install torchmetrics==0.11.4\n\n2、orch is not able to use GPU; add –skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check说明torch的版本与cuda版本冲突，此时pytorch并不能使用GPU。\n执行下面指令\n\npython\nimport torch\ntorch.cuda.is_available()\n\n会输出False\n这时候可以试着从pytorch官网复制对应版本指令重新安装一遍torch，\n如果还不行的话就再建虚拟环境重新跑一遍脚本\n3 执行bash start.sh的时候卡在 installing clip先执行\n\npip install clip\n\n再执行一遍bash start.sh\n4 执行bash start.sh的时候卡在 installing open_clip先执行\n\npip install open_clip_torch\n\n再执行一遍bash start.sh\n","slug":"aigc/sd/RuntimeError  cannot import name 'compare_version' from torchmetrics.utilities.imports","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"ed477efabbdcc1e4972b40b8c2d2acc6","title":"PhotoMaker老照片风格AI","content":"PhotoMaker老照片风格AI腾讯和南开推出的这个PhotoMaker有意思！  \n功能  \n\n根据文本提示制作照片  \n生成带艺术品/老照片风格的照片  \n风格化照片（比如油画或者拉通风格）  \n改变年龄或者性别  \n混合多个人的特征生成新照片  \n\nPhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding（通过堆叠 ID 嵌入定制逼真的人体照片）  \n项目：photo-maker.github.io论文：huggingface.co/papers/2312.04461代码：github.com/TencentARC/PhotoMakerDemo：huggingface.co/spaces/TencentARC/PhotoMaker  \n论文摘要：  \n文本到图像生成的最新进展在根据给定文本提示合成逼真的人类照片方面取得了显着进展。然而，现有的个性化生成方法无法同时满足高效率、有前途的身份（ID）保真度和灵活的文本可控性的要求。  \n在这项工作中，我们介绍了PhotoMaker，一种高效的个性化文本到图像生成方法，它主要将任意数量的输入 ID 图像编码为堆栈 ID 嵌入，以保存 ID 信息。这种嵌入作为统一的ID表示，不仅可以全面封装同一输入ID的特征，而且可以容纳不同ID的特征以便后续集成。这为更有趣且具有实际价值的应用铺平了道路。  \n此外，为了推动 PhotoMaker 的训练，我们提出了一个面向 ID 的数据构建管道来组装训练数据。  \n在通过所提出的管道构建的数据集的滋养下，我们的 PhotoMaker 表现出了比基于测试时微调的方法更好的 ID 保存能力，同时提供了显着的速度改进、高质量的生成结果、强大的泛化能力和广泛的应用程序。\n","slug":"aigc/sd/PhotoMaker老照片风格AI","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,github","tags_index":"github","author_index":"安全书"},{"id":"19993987f6eafbcc9039e2103d625600","title":"StableDiffusion的Python命令工具","content":"StableDiffusion的Python命令工具下面这些stablediffusion的.py的python语言命令行脚本工具都是什么作用，可以用来做什么相关的任务处理。custom_code.py outpainting_mk_2.py postprocessing_gfpgan.py prompts_from_file.py img2imgalt.py poor_mans_outpainting.py postprocessing_upscale.py sd_upscale.py loopback.py postprocessing_codeformer.py prompt_matrix.py xyz_grid.py\n根据文件名，以下是每个脚本的大致功能和相关任务处理：\n对于上文中提出的.py工具，分别给出实际使用的例子，命令操作的具体参数。\n\ncustom_code.py：可能是一个自定义的Python代码文件，用于特定任务的定制化处理。\n\noutpainting_mk_2.py：用于图像修复或扩展任务，可以将输入图像的边界进行扩展或修复。\n\npostprocessing_gfpgan.py：用于后处理生成对抗网络（GAN）生成的图像，可能包括去噪、增强对比度等操作。\n\nprompts_from_file.py：从文件中读取提示（prompts）作为GAN生成图像的输入，用于定制化生成特定主题或风格的图像。\n\nimg2imgalt.py：可能是一个用于图像转换任务的工具，可以将一种类型的图像转换为另一种类型。\n\npoor_mans_outpainting.py：类似于outpainting_mk_2.py，但可能采用了简化的方法来进行图像修复或扩展。\n\npostprocessing_upscale.py：用于对低分辨率图像进行放大处理，以提高其质量和细节。\n\nsd_upscale.py：类似于postprocessing_upscale.py，也可能是用于对低分辨率图像进行放大处理的工具。\n\nloopback.py：可能是一个循环反馈神经网络（RNN）相关的工具或脚本，用于序列数据预测和生成任务。\n\npostprocessing_codeformer.py：用于后处理CodeFormer模型生成的代码，可能包括格式化、优化或修改。\n\nprompt_matrix.py：用于生成GAN图像的提示矩阵，可以通过该矩阵来控制生成图像的特定属性或风格。\n\nxyz_grid.py：可能是一个用于生成三维坐标网格的工具，用于可视化、计算或其他相关任务。\n\n\n\ncustom_code.py的实际使用例子：可以用来处理特定任务，比如对一批数据进行清洗、筛选或转换。命令操作的具体参数可以根据具体任务而定，比如输入文件路径、输出文件路径、需要执行的操作等。\n\noutpainting_mk_2.py的实际使用例子：可以用于修复或扩展图像边界。命令操作的具体参数可以包括输入图像路径、修复或扩展的方式（比如使用什么算法或模型）、输出图像路径等。\n\npostprocessing_gfpgan.py的实际使用例子：可以用于对GAN生成的图像进行后处理，比如去噪、增强对比度等。命令操作的具体参数可以包括输入图像路径、需要执行的操作（去噪、增强对比度等）、输出图像路径等。\n\nprompts_from_file.py的实际使用例子：可以从文件中读取提示作为GAN生成图像的输入，用于定制化生成特定主题或风格的图像。命令操作的具体参数可以包括提示文件路径、GAN模型路径、输出图像路径等。\n\nimg2imgalt.py的实际使用例子：可以用于将一种类型的图像转换为另一种类型。命令操作的具体参数可以包括输入图像路径、转换类型（比如将彩色图像转换为黑白图像）、输出图像路径等。\n\npoor_mans_outpainting.py的实际使用例子：类似于outpainting_mk_2.py，但采用了简化的方法来进行图像修复或扩展。命令操作的具体参数可以类似于outpainting_mk_2.py，包括输入图像路径、修复或扩展的方式、输出图像路径等。\n\npostprocessing_upscale.py的实际使用例子：可以对低分辨率图像进行放大处理，以提高其质量和细节。命令操作的具体参数可以包括输入图像路径、放大倍数、输出图像路径等。\n\nsd_upscale.py的实际使用例子：类似于postprocessing_upscale.py，也是用于对低分辨率图像进行放大处理的工具。命令操作的具体参数可以类似于postprocessing_upscale.py，包括输入图像路径、放大倍数、输出图像路径等。\n\nloopback.py的实际使用例子：可能是一个循环反馈神经网络（RNN）相关的工具或脚本，用于序列数据预测和生成任务。命令操作的具体参数可以根据具体任务而定，比如输入数据文件路径、训练模型还是生成预测结果等。\n\npostprocessing_codeformer.py的实际使用例子：用于后处理CodeFormer模型生成的代码，可能包括格式化、优化或修改。命令操作的具体参数可以包括输入代码文件路径、需要执行的后处理操作、输出代码文件路径等。\n\nprompt_matrix.py的实际使用例子：用于生成GAN图像的提示矩阵，可以通过该矩阵来控制生成图像的特定属性或风格。命令操作的具体参数可以包括提示矩阵文件路径、GAN模型路径、输出图像路径等。\n\nxyz_grid.py的实际使用例子：可能是一个用于生成三维坐标网格的工具，用于可视化、计算或其他相关任务。命令操作的具体参数可以根据具体任务而定，比如网格大小、坐标范围、输出结果文件路径等。\n\n\n在StableDiffusion中，如何用poor_mans_outpainting.py进行对一个图片的操作，给出具体使用的例子。\n在StableDiffusion中，使用poor_mans_outpainting.py对一张图片进行操作的具体步骤如下：\n\n首先，在命令行中切换到StableDiffusion的根目录。\n\n然后执行以下命令来对图片进行处理：\n1python poor_mans_outpainting.py --input_path path_to_input_image --output_path path_to_output_image\n其中，path_to_input_image是输入图片的路径，path_to_output_image是输出图片的路径。\n例如，如果要对名为”input.jpg”的图片进行处理，并将结果保存为”output.jpg”，则可以执行以下命令：\n1python poor_mans_outpainting.py --input_path input.jpg --output_path output.jpg\n执行完上述命令后，程序会自动运行，并将处理后的图片保存到指定的输出路径中。\n\n\n请注意，在执行该命令之前，请确保已经安装了StableDiffusion，并且已经准备好了输入图片。\n","slug":"aigc/sd/StableDiffusion的Python命令工具","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,stablediffusion","tags_index":"stablediffusion","author_index":"安全书"},{"id":"bdda9d4455d88287c491dfc58f813d57","title":"SD安装笔记","content":"SD安装笔记./webui.sh –server-name=0.0.0.0 –listen –device-id 1\nset COMMANDLINE_ARGS=–share\n/etc/apt/sources.list.d/cuda-ubuntu2204-12-2-local.list如果要删除nividia驱动，这个源必须删除。\nwget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.runsudo sh cuda_12.2.0_535.54.03_linux.run\n run文件删除，是成功率比较大的\nhttps://developer.nvidia.com/cuda-12-2-0-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=22.04&amp;target_type=runfile_local \nCUDA的下载页面\nsudo vim /etc/modprobe.d/blacklist-nouveau.conf\nblacklist nouveauoptions nouveau modeset=0\nsudo update-initramfs -u\nlsmod | grep nouveau\n禁用nouveau\nsudo ubuntu-drivers devices \n查看已经安装的驱动\n\n\n\n\n\n\n\n\n\n\n\nimport torchtorch.version‘2.1.0+cu121’torch.cuda.is_available()\n\n\n查看Torch版本\n\n\n\n\n\n\n\n\n\n\n\nimport torchtorch.version‘2.1.0+cu121’torch.cuda.is_available()\n\n\n查看Torch版本\nhttps://blog.csdn.net/zxdd2018/article/details/127705627\ncuDNN的安装\nsudo apt-get -f install修复依赖问题，但是大多数的时候不太好用， 还是得删除了，重新装最干净\nsudo apt-get upgrade\ncannot import name ‘_compare_version‘ from ‘torchmetrics.utilities.imports‘\nhttps://zhuanlan.zhihu.com/p/619901627比较全的安装CUDA的方法。\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\npip config set global.index-url https://mirrors.aliyun.com/pypi/simple\n还是不行，然后换成下面的命令：\npip install open-clip-torchopen-clip-torch 使用 阿里的镜像好用\n–xformers–reinstall-torch\nsudo .run –silent –driver\nCUDA_VISIBLE_DEVICES=0,1,2,3 python launch.py  –share\nNo module ‘xformers’. Proceeding without it.\n12pip install xformers==0.0.16pip install xformers-0.0.23.post1\n\n装0.0.16版本，装高版本的没法用。\n12345678910111213141516171819Installing collected packages: torch, xformersAttempting uninstall: torchFound existing installation: torch 1.13.1+cu117Uninstalling torch-1.13.1+cu117:Successfully uninstalled torch-1.13.1+cu117Attempting uninstall: xformersFound existing installation: xformers 0.0.16Uninstalling xformers-0.0.16:Successfully uninstalled xformers-0.0.16\n\n1set COMMANDLINE_ARGS=--xformers\n\nwebui.sh –xformers\n","slug":"aigc/sd/SD安装笔记","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,stablediffusion","tags_index":"stablediffusion","author_index":"安全书"},{"id":"c868babc1c65104169ae5472bbed5139","title":"Exception Error while deserializing header HeaderTooLarge","content":"Exception Error while deserializing header HeaderTooLargeException Error while deserializing header HeaderTooLarge这个问题就是模型文件不对，要不就是一个模型文件也没有，默认的也没有，要不就是文件损坏了。好一个好的模型， 或者通用的模型就行了。\n如何用LlamaIndex和lanchain实现RAG\n要使用LlamaIndex和lanchain实现RAG，您可以按照以下步骤进行操作：\n\n首先，确保您已在lanchain上安装了LlamaIndex的合约。可以通过使用truffle等工具来完成合约的部署和配置。\n\n在LlamaIndex合约中，定义一个结构体来表示RAG（Red, Amber, Green）指标。该结构体可以包含指标名称、权重和评级等属性。\n\n添加适当的函数来创建、更新和查询RAG指标。例如，您可以添加一个名为”createRAG”的函数来创建新的RAG指标，并将其保存到LlamaIndex中。\n\n实现一个评估函数，该函数将接收一组数据，并根据预定义的规则计算出相应的RAG评级。该评估函数可以使用任何适用于您的案例的算法和规则。\n\n可选地，您还可以添加其他功能，如查询特定时间范围内的所有RAG指标或根据某些条件过滤它们等。\n\n\n请注意，上述步骤只是一个示例，并且具体实现可能因项目需求而有所不同。\n如何用LlamaIndex和lanchain实现RAG，给出具体的Python代码\n要使用LlamaIndex和lanchain实现RAG（Red, Amber, Green）指标，你可以按照以下步骤进行操作：\n\n首先，安装LlamaIndex和lanchain的Python库。你可以使用pip命令来安装它们：\n\n12pip install llamaindexpip install lanchain\n\n\n导入所需的库：\n\n12from llamaindex import LlamaIndexfrom lanchain import LanchainClient\n\n\n创建一个LanchainClient对象，用于与lanchain区块链进行交互。你需要提供lanchain节点的URL：\n\n1client = LanchainClient(&#x27;http://localhost:8545&#x27;)\n\n\n创建一个LlamaIndex对象，并使用LlamaIndex的calculate_rag()函数来计算RAG指标。你需要提供一个合约地址、合约ABI和调用合约函数所需的参数。这里假设你已经部署了一个名为”YourContract”的合约，并且该合约有一个名为”calculateRAG()”的函数，该函数不需要任何参数：\n\n1234567891011121314contract_address = &#x27;0x1234567890abcdef&#x27;contract_abi = [    &#123;        &quot;constant&quot;: True,        &quot;inputs&quot;: [],        &quot;name&quot;: &quot;calculateRAG&quot;,        &quot;outputs&quot;: [],        &quot;payable&quot;: False,        &quot;stateMutability&quot;: &quot;view&quot;,        &quot;type&quot;: &quot;function&quot;    &#125;]rag_index = LlamaIndex.calculate_rag(client, contract_address, contract_abi, &#x27;calculateRAG&#x27;)\n\n\n打印RAG指标值：\n\n1print(&quot;RAG指标值：&quot;, rag_index)\n\n以上就是使用LlamaIndex和lanchain实现RAG指标的一个简单示例。请注意，你需要根据你的具体情况修改代码中的合约地址和ABI。\n","slug":"aigc/sd/Exception Error while deserializing header HeaderTooLarge","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,stablediffusion","tags_index":"stablediffusion","author_index":"安全书"},{"id":"788fc4b111d85045ae1a3809496f77e4","title":"StableDiffusion运行多显卡上","content":"StableDiffusion运行多显卡上相当于SD的 CUDA_VISIBLE_DEVICES。\nwebui-user.sh中加入export参数。\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\n./stable-diffusion-webui/webui.sh –listen –device-id 1这样运行，SD可以同时使用显卡0和显卡1.\nCUDA_VISIBLE_DEVICES=0,1,2,3 python launch.py  –share\nCUDA_VISIBLE_DEVICES=1 python launch.py  –share\ncmd_args.py    –device-id \ndevice-id参数是在cmd_args.py文件中出现的。 \nos.environ.get(‘CUDA_VISIBLE_DEVICES’)Python文件中会用这个参命令取得用户的设置，GPU数。\n","slug":"aigc/sd/StableDiffusion运行多显卡上","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,stablediffusion","tags_index":"stablediffusion","author_index":"安全书"},{"id":"8747ef0d16269716383dce49ed9490df","title":"backgroundremover抠图AI","content":"backgroundremover抠图AI背景卸妆？自动移除图像背景的神器：backgroundremover  \n该项目通过 AI 技术，可自动移除图片和视频中的背景。它使用起来十分简单，可以直接在线上传图片或视频，然后选择保留物体的类别，可以是人物或事物，稍等片刻即可下载处理后的结果。\nhttps://github.com/nadermx/backgroundremover\n","slug":"aigc/sd/backgroundremover抠图AI","date":"2024-03-14T06:15:59.710Z","categories_index":"sd,photo","tags_index":"photo","author_index":"安全书"},{"id":"d13a5c9a8aa284d1c3ac76431f3b538b","title":"llamaindex-cli命令工具的使用","content":"llamaindex-cli命令工具的使用llamaindex-cli是一个命令行工具，用于在LlamaIndex上查询加密货币的价格和市值数据。以下是llamaindex-cli命令的使用方法和示例：\n\n安装llamaindex-cli：首先需要安装llamaindex-cli工具。可以使用以下命令进行安装：\n1npm install -g llamaindex-cli\n查询加密货币价格：可以使用price命令查询特定加密货币的当前价格。例如，要查询比特币（BTC）的价格，可以运行以下命令：\n1llamaindex price BTC\n查询加密货币市值：可以使用marketcap命令查询特定加密货币的当前市值。例如，要查询以太坊（ETH）的市值，可以运行以下命令：\n1llamaindex marketcap ETH\n查询多个加密货币价格：可以一次性查询多个加密货币的价格。例如，要查询比特币（BTC）、以太坊（ETH）和莱特币（LTC）的价格，可以运行以下命令：\n1llamaindex price BTC ETH LTC\n查询所有支持的加密货币列表：可以使用list命令查看所有支持的加密货币列表。例如，要获取所有支持的加密货币列表，可以运行以下命令：\n1llamaindex list\n\n这些是llamaindex-cli的一些基本用法和示例。使用这些命令，可以方便地在命令行中查询加密货币的价格和市值数据。\n添加新文章，用英语怎么说\nAdd a new article.\n添加了一系列关于AIGC的文章，用英文怎么说\nA series of articles has been added.\n添加了一系列关于AIGC的文章，用英文怎么说\nI have added a series of articles about AIGC.\n","slug":"aigc/sd/llamaindex-cli命令工具的使用","date":"2024-03-14T06:15:59.710Z","categories_index":"AIGC,llamaindex-cli","tags_index":"llamaindex-cli","author_index":"安全书"},{"id":"3821cbe723791c750780b1a12e2a0049","title":"Langchain与RAG","content":"Langchain与RAGhttps://tnblog.net/hb/article/details/8200#LangChain%E8%B0%83%E7%94%A8\n","slug":"aigc/langchain/Langchain与RAG","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"b2e6f88df47e562821a91f15dc8e651f","title":"如何用LangChain对正篇PDF进行润色","content":"如何用LangChain对正篇PDF进行润色要使用LangChain对正篇PDF进行润色，可以按照以下步骤进行操作：\n\n首先，将正篇PDF文件转换为可编辑的文本格式。可以使用OCR（Optical Character Recognition）软件或在线服务来实现这一步骤。OCR可以将PDF中的文字提取出来，并保存为可编辑的文本文件。\n\n登录LangChain的平台或使用LangChain提供的API，上传转换后的文本文件。LangChain是一种人工智能驱动的语言处理平台，可以对文本进行自动润色和校对。\n\n使用LangChain提供的功能来润色文本。LangChain具有多种功能，例如语法纠错、词汇替换、句子重组等。根据需要选择适当的功能来改进文本质量和流畅度。\n\n完成润色后，将修订后的文本重新保存为一个新的文件。\n\n最后，将新生成的文本文件转换回PDF格式。可以使用PDF编辑器或在线转换服务将修订后的文本重新保存为PDF文件。\n\n\n请注意，LangChain是一个虚构的名称，在实际操作中可能需要使用其他类似的语言处理工具或服务来完成对正篇PDF的润色。\n如何用LangChain对正篇word文章的内容进行润色，并修改错别字，给出实现的Python代码\n要用LangChain对正篇word文章的内容进行润色和修改错别字，可以使用以下步骤：\n\n安装LangChain库：在命令行中运行以下命令安装LangChain库。\n\n1pip install langchain\n\n\n导入所需的库和模块：\n\n12from langchain import LangChainimport docx\n\n\n加载要处理的Word文档：\n\n1doc = docx.Document(&#x27;path_to_word_document.docx&#x27;)\n\n\n创建LangChain实例并初始化：\n\n12lc = LangChain()lc.initialize()\n\n\n遍历Word文档中的每个段落：\n\n12345678for para in doc.paragraphs:    text = para.text        # 通过LangChain进行润色和修改错别字    corrected_text = lc.correct(text)        # 更新段落文本为修正后的文本    para.text = corrected_text\n\n\n保存更新后的Word文档：\n\n1doc.save(&#x27;path_to_save_updated_document.docx&#x27;)\n\n完整代码示例：\n12345678910111213141516171819202122from langchain import LangChainimport docx# 加载Word文档doc = docx.Document(&#x27;path_to_word_document.docx&#x27;)# 创建并初始化LangChain实例lc = LangChain()lc.initialize()# 遍历每个段落并进行润色和修改错别字处理for para in doc.paragraphs:    text = para.text        # 通过LangChain进行润色和修改错别字处理    corrected_text = lc.correct(text)        # 更新段落文本为修正后的文本    para.text = corrected_text# 保存更新后的Word文档doc.save(&#x27;path_to_save_updated_document.docx&#x27;)\n\n请将代码中的path_to_word_document.docx替换为实际的Word文档路径，然后运行该代码即可对文档内容进行润色和修改错别字处理，并保存更新后的文档。\n","slug":"aigc/langchain/如何用LangChain对正篇PDF进行润色","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"3c41505139efb74f1661916f145c7f5e","title":"llamaindex-cli rag","content":"llamaindex-cli ragLlama Index隆重推出了RAG CLI， 一个极其简单的命令行工具，允许您对本地计算机上的任何文件进行 RAG。\n倒是一个可以在本地体验RAG的好项目！#知识科普接龙#\n索引包括 glob 模式的任何文件，llamaindex-cli rag –files “./docs/**/*.rst\n要搜索，只需执行llamaindex-cli rag –question “What is LlamaIndex?”`\n使用我们的 IngestionPipeline 和 QueryPipeline 抽象构建，可实现高效、高性能的数据索引和检索。该指南还向您展示了如何根据自己的需求自定义逻辑！\n博客文章： blog.llamaindex.ai/introducing-the-llamaindex-retrieval-augmented-generation-command-line-tool-a973fa519a41文档：docs.llamaindex.ai/en/stable/use_cases/q_and_a/rag_cli.html\n","slug":"aigc/langchain/llamaindex-cli rag","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC","tags_index":"llamaindex-cli","author_index":"安全书"},{"id":"cf3ae125b94c92a05016e1e5aae14eba","title":"开始构建类似 ChatGPT","content":"开始构建类似 ChatGPT教你从零开始构建类似 ChatGPT 的大语言模型。  \n在 GitHub 上发现一本《Build a Large Language Model (From Scratch)》书籍。  \n作者将带你从头开始构建一个类似 GPT 语言模型，这过程让你了解如何创建、训练和微调大型语言模型 (LLMs)！  \n在线阅读：livebook.manning.com/book/build-a-large-language-model-from-scratch/welcome/v-3/涉及源码：github.com/rasbt/LLMs-from-scratch  \n书籍主要分为 8 大章节，如下：  \n第 1 章：了解大语言模型（LLM）解析第 2 章：介绍文本数据处理技巧第 3 章：通过编程实现注意力机制（Attention Mechanisms）第 4 章：从零开始实现类似 GPT 模型第 5 章：对未标注数据进行预训练第 6 章：针对文本分类的模型微调第 7 章：结合人类反馈进行模型微调第 8 章：在实践中使用大语言模型\n","slug":"aigc/llm/开始构建类似 ChatGPT","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC","tags_index":"book","author_index":"安全书"},{"id":"80343fe751072d14380c6c808291386e","title":"模型微调","content":"模型微调模型微调和增加检索的区别是什么， 什么场景适用模型进行微调，什么场景更适合适用增加检索RAG进行处理？\n模型微调和增加检索的区别在于它们的目标和方法。\n模型微调是指在一个预训练的模型基础上，使用特定的数据集进行再训练，以适应特定的任务或领域。通过微调模型，可以使其更好地适应目标任务，并提升性能。模型微调适用于以下场景：\n\n当已有的预训练模型与目标任务或领域相关性较高时，可以通过微调来提升性能。\n当可用于微调的数据集较大时，可以更充分地利用这些数据来优化模型。\n\n增加检索（retrieval-augmented generation, RAG）是一种结合检索和生成的方法，在生成文本时利用检索到的信息进行辅助。RAG 模型首先使用一个预训练的编码器将输入文本编码成向量表示，并使用这个向量进行检索。然后，在生成阶段，根据检索到的相关信息来引导生成过程。增加检索适用于以下场景：\n\n当需要根据一些特定问题或主题来生成文本时，可以使用增加检索来获取相关信息并引导生成。\n当需要在生成过程中引入外部知识或约束条件时，可以利用增加检索来实现。\n\n总之，在选择模型微调还是增加检索时应考虑任务的特点和需求。模型微调更适用于直接优化模型性能的场景，而增加检索更适用于需要引入外部信息来辅助生成的场景。\n","slug":"aigc/llm/模型微调","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC","tags_index":"llama","author_index":"安全书"},{"id":"ba1b40adefccb80b7453716eb9f031b1","title":"书生・浦语 2.0（InternLM2）大语言模型正式开源","content":"书生・浦语 2.0（InternLM2）大语言模型正式开源Github：[https://github.com/InternLM/InternLM]\nHuggingFace：[https://huggingface.co/internlm]\nModelScope：[https://modelscope.cn/organization/Shanghai_AI_Laboratory]\n","slug":"aigc/llm/书生・浦语 2.0（InternLM2）大语言模型正式开源","date":"2024-03-14T06:15:59.709Z","categories_index":"InternLM2","tags_index":"InternLM2","author_index":"安全书"},{"id":"da3e1a2feb54da7d27a471dfb5b9de32","title":"Ubuntu20下安装LangChain","content":"Ubuntu20下安装LangChainUbuntu20下安装LangChain的具体操作过程是什么\n要在Ubuntu 20上安装LangChain，可以按照以下步骤进行操作：\n\n打开终端，使用以下命令更新系统软件包列表：\n1sudo apt update\n安装依赖软件包。LangChain需要一些依赖软件包来运行。运行以下命令来安装这些依赖项：\n1sudo apt install build-essential libtool autotools-dev automake pkg-config libssl-dev libevent-dev bsdmainutils python3\n下载并编译LangChain源代码。首先，创建一个目录来存储源代码，并进入该目录：\n12mkdir langchaincd langchain\n\n然后，使用Git命令克隆LangChain的GitHub存储库：\n1git clone https://github.com/LangChain/LangChain.git\n\n进入源代码目录：\n1cd LangChain\n\n配置并编译源代码：\n1234./autogen.sh./configure --disable-tests --disable-bench --with-incompatible-bdb --with-gui=nomakesudo make install\n\n\n完成安装。运行以下命令以确保安装成功：1langchaind --version\n\n","slug":"aigc/llm/langchain/Ubuntu20下安装LangChain","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"53a25fe229b631c447bd468734e04066","title":"向Langchain提交文件到知识库里","content":"向Langchain提交文件到知识库里要向Langchain提交文件到知识库里，可以按照以下步骤进行操作：\n\n首先，确保你已经注册并登录了Langchain的平台账户。\n\n在登录后，找到页面上方的导航栏或菜单中的“知识库”选项，并点击进入。\n\n在知识库页面中，你可以浏览已有的文件和文章，也可以使用搜索功能查找相关内容。如果你想提交一个新的文件，则需要点击页面上方的“提交”或“上传”按钮。\n\n在提交文件的界面中，可能会要求填写一些相关信息，例如文件名称、描述、标签等。请根据实际情况填写这些信息。\n\n然后，在界面中找到一个用于上传文件的按钮或区域，并点击它。这通常是一个“选择文件”或“上传文件”的按钮。\n\n选择你要提交的文件，并等待上传完成。在上传过程中，请确保你选择了正确的文件，并检查一遍以确保没有错误。\n\n上传完成后，系统可能会对你进行一些确认操作，例如显示一个预览界面或要求你再次确认提交。请按照提示进行操作，并确保一切都正确无误。\n\n最后，点击确认按钮或类似选项来完成文件的提交。系统会对你的请求进行处理，并将该文件添加到知识库中。\n\n\n请注意，在具体操作过程中可能会有一些细微的差别，这取决于Langchain平台的具体设计和功能。因此，如果你在使用过程中遇到任何问题，请参考平台提供的帮助文档或联系他们的客户支持部门寻求进一步协助。\n通过LangChain向知识库添加pdf文件，丰富本地知识库，给出具体的添加代码的Python程序源吗\n要向知识库添加PDF文件，您可以使用以下Python代码示例：\n1234567891011121314151617181920from langchain import LangChain# 创建LangChain客户端client = LangChain()# 设置API密钥，用于验证身份client.set_api_key(&quot;YOUR_API_KEY&quot;)# 指定PDF文件路径pdf_file_path = &quot;path/to/your/pdf/file.pdf&quot;# 读取PDF文件内容with open(pdf_file_path, &quot;rb&quot;) as file:    pdf_content = file.read()# 将PDF内容添加到知识库response = client.add_pdf_to_knowledge_base(pdf_content)# 打印响应结果print(response)\n\n请注意，您需要将YOUR_API_KEY替换为您的实际API密钥。此外，确保已安装并正确配置了LangChain Python SDK。\n","slug":"aigc/llm/langchain/向Langchain提交文件到知识库里","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC,langchain","tags_index":"langchain","author_index":"安全书"},{"id":"cfb4d1b86fdb40bad53c9ad03918951d","title":"ChatGLM运行在多块显卡上","content":"ChatGLM运行在多块显卡上ChatGLM如何运行在多块显卡上\nChatGLM是一个基于GPT-3的模型，由于GPT-3模型本身的特性，它无法直接在多块显卡上运行。GPT-3是一个非常大的模型，需要大量的计算资源和内存来训练和运行。\n然而，可以使用分布式训练和推理技术来在多块显卡上运行类似GPT-3的模型。这种技术可以将模型的训练或推理工作负载分布到多块显卡上，并通过高效的通信机制进行协调和同步。\n具体来说，在训练阶段，可以使用数据并行或模型并行等技术将模型参数和梯度分布到多个显卡上进行计算，并通过同步机制更新模型参数。在推理阶段，可以将输入数据分成多个批次，在每个批次上并行地计算，并最后合并结果。\n当然，实现这样的分布式训练和推理需要一定的技术和资源支持。通常需要使用深度学习框架（如TensorFlow、PyTorch等）提供的分布式训练工具或库，并且需要一台或多台配备多块GPU的服务器来支持多块显卡同时工作。\n总结起来，虽然ChatGLM本身无法直接在多块显卡上运行，但通过使用分布式训练和推理技术，可以在多块显卡上并行地训练和推理类似GPT-3的模型。\n","slug":"aigc/llm/chatglm/ChatGLM运行在多块显卡上","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC,ChatGLM","tags_index":"ChatGLM","author_index":"安全书"},{"id":"9a40a6a39b959d0093a5b06c499bf410","title":"Mixtral-8x7B中文","content":"Mixtral-8x7B中文Chinese-Mixtral-8x7B：中文Mixtral-8x7B，基于Mistral发布的模型Mixtral-8x7B进行了中文扩词表增量预训练】’Chinese-Mixtral-8x7B’ GitHub: github.com/HIT-SCIR/Chinese-Mixtral-8x7B\n\n","slug":"aigc/llm/ollama/Mixtral-8x7B中文","date":"2024-03-14T06:15:59.709Z","categories_index":"AIGC,Mixtral-8x7B","tags_index":"Mixtral-8x7B","author_index":"安全书"},{"id":"5dbff0739f191878f7dbf26373a2837f","title":"Whisper如何在Mac上安装","content":"Whisper如何在Mac上安装Whisper如何在Mac上安装\n要在Mac上安装Whisper，可以按照以下步骤进行操作：\n\n打开终端应用程序（位于”应用程序”文件夹的”实用工具”文件夹中）。\n安装Homebrew，一个Mac包管理器。在终端中输入以下命令并按下回车键：/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;\n安装Python。在终端中输入以下命令并按下回车键：brew install python\n安装Whisper。在终端中输入以下命令并按下回车键：pip install whisper\n等待安装完成。一旦安装完成，你就可以在Mac上使用Whisper了。\n\n请注意，这些步骤假设你已经正确设置了Python和pip，并且已经安装了Homebrew。如果你还没有安装这些工具，请先按照它们的官方文档进行安装和设置。\n另外，这些步骤也假设你已经具备一定的技术知识和经验。如果你不确定如何执行这些步骤，建议寻求更详细的指导或寻求专业人士的帮助。\n如何使用Whisper\n要使用Whisper，您需要按照以下步骤进行操作：\n\n下载和安装Whisper应用程序：您可以从官方网站或应用商店下载和安装Whisper应用程序。它可用于多个操作系统，包括Windows，Mac，iOS和Android。\n\n创建账户：在安装完成后，打开Whisper应用程序并创建一个新账户。您需要提供一些个人信息，并设置一个安全的密码来保护您的账户。\n\n密钥管理：创建账户后，Whisper将生成一个私钥和公钥对。私钥是您的身份验证凭证，而公钥是其他人用来加密消息并发送给您的凭证。\n\n添加联系人：在Whisper中发送消息之前，您需要添加联系人。可以通过他们的公钥或电话号码来添加联系人。\n\n发送消息：要发送消息，请选择要发送给的联系人，并输入要发送的消息内容。可以选择加密消息以增加安全性。\n\n接收消息：当有人向您发送加密消息时，您将在接收到通知。打开Whisper应用程序并查看接收到的消息。\n\n安全性设置：为了增强安全性，您可以设置密码保护应用程序或启用指纹识别（如果设备支持）等功能。\n\n\n请注意，在使用Whisper之前，请确保与其他用户共享公钥以便彼此之间能够加密和解密消息。\n写一段使用Whisper的Python代码\n要使用Whisper，首先需要安装Graphite和Carbon。然后，可以使用Python的whisper模块来操作Whisper数据库。\n下面是一个简单的示例代码，用于创建一个Whisper数据库并写入一些数据：\n123456789101112131415import whisper# 定义Whisper数据库的存储路径和保留策略path = &#x27;/path/to/whisper/database.wsp&#x27;retentions = [(60, 1440)]  # 保留1天的数据，每分钟一个数据点# 创建Whisper数据库whisper.create(path, retentions)# 写入数据timestamp = int(time.time())values = [(timestamp, 10), (timestamp + 60, 20), (timestamp + 120, 30)]  # 数据点的时间戳和值whisper.update_many(path, values)print(&quot;数据已写入Whisper数据库。&quot;)\n\n这段代码首先导入了whisper模块，并定义了Whisper数据库的存储路径和保留策略。然后，使用whisper.create()函数创建了一个新的Whisper数据库。接下来，通过whisper.update_many()函数将一组数据点写入到数据库中。\n请注意，在实际使用中，可能需要根据具体需求调整保留策略、时间戳和值等参数。此外，还可以使用whisper.fetch()函数读取数据、whisper.info()函数获取数据库信息等。\n希望对你有所帮助！\n用whisper写一段Python代码， 把文字变成语音mp3文件。\nimport whisper\ntext = “Hello, how are you?”whisper.tts_to_file(text, “output.mp3”)\n正确的安装方式安装\n1pip install git+https://github.com/openai/whisper.git\n\n升级\n1pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git\n\n\n使用下载中型模型，提高准确率。\n whisper audio.mp3 –model medium\n语音翻译成汉字\n1234import whispermodel = whisper.load_model(&quot;base&quot;)result = model.transcribe(&quot;audio.mp3&quot;)print(result[&quot;text&quot;])\n\n\n\n\nWhisper 运行的时候，出现下面这些提示，如何解决？FP16 is not supported on CPU; using FP32 instead\n这个提示意味着你在使用Whisper时尝试使用FP16（半精度浮点数）运行，但是你的CPU不支持这个功能。因此，Whisper将自动使用FP32（单精度浮点数）代替。\n要解决这个问题，你有几个选择：\n\n忽略这个提示：如果你的模型可以在FP32下正常工作，那么你可以继续使用它。这个警告只是提醒你正在使用较低的精度。\n\n更换设备：如果你希望利用FP16的优势，可以考虑使用支持FP16计算的GPU或TPU。将任务迁移到支持FP16的硬件上可能需要一些额外的配置和调整。\n\n更新库版本：确保你所使用的Whisper库版本是最新的。有时候，在更新库版本后，某些问题可能会得到解决。\n\n\n总之，在大多数情况下，忽略这个警告并继续进行工作是安全的。但如果你希望获得更高的性能并且有适当的硬件支持，那么考虑采取上述措施来解决问题。\nWhisper 如何在Mac系统下， 以GPU模式下运行，如何进行配置。要在Mac系统下以GPU模式运行Whisper，首先需要确保你的Mac电脑配备了支持GPU计算的显卡。然后按照以下步骤进行配置：\n\n安装CUDA：首先，你需要在你的Mac上安装CUDA工具包。前往NVIDIA官方网站下载适用于Mac的CUDA驱动程序，并按照安装向导进行安装。\n\n安装CuDNN：CuDNN是一个针对深度神经网络加速的库，也是Whisper所需的。前往NVIDIA官方网站下载适用于Mac的CuDNN库，并按照安装向导进行安装。\n\n安装Python环境：Whisper是一个基于Python开发的框架，所以你需要在你的Mac上安装Python环境。可以选择使用Anaconda、Miniconda或者直接从Python官方网站下载并安装。\n\n创建虚拟环境：建议使用虚拟环境来管理Whisper及其相关依赖库。打开终端，并使用以下命令创建一个新的虚拟环境：\n1conda create -n whisper python=3.7\n激活虚拟环境：创建完成后，使用以下命令激活虚拟环境：\n1conda activate whisper\n安装Whisper：在激活的虚拟环境中，使用以下命令安装Whisper：\n1pip install whisper\n配置GPU支持：在你的Python代码中，可以通过设置WHISPER_BACKEND环境变量来启用GPU支持。例如，在你的代码中加入以下行：\n12import osos.environ[&quot;WHISPER_BACKEND&quot;] = &quot;gpu&quot;\n\n现在，你已经成功配置了Whisper在Mac系统下以GPU模式运行的环境。你可以使用该框架进行深度学习任务，并利用GPU加速计算。\nWhisper 如何在Mac系统下， 以CPU模式下运行，如何进行配置。下面的问题为什么会产生，如何进行解决？\nNotImplementedError: Could not run ‘aten::empty.memory_format’ with arguments from the ‘SparseMPS’ backend. This could be because the operator doesn’t exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobil\ne, please visit https://fburl.com/ptmfixes for possible resolutions. ‘aten::empty.memory_format’ is only available for these backends: [CPU, MPS, Meta, Qua\nntizedCPU, QuantizedMeta, MkldnnCPU, SparseCPU, SparseMeta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conju\ngate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, Aut\nogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer\n, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMod\ne, PythonDispatcher].\n这个错误是由于在使用PyTorch的SparseMPS后端时，尝试调用’aten::empty.memory_format’操作符而导致的。\n解决这个问题的方法有几种：\n\n检查是否使用了正确的PyTorch版本和安装了正确的后端。确保使用的PyTorch版本支持SparseMPS后端，并且已正确安装和配置。\n\n如果你是Facebook员工，在移动设备上使用PyTorch，可以访问提供的链接（https://fburl.com/ptmfixes）获取可能的解决方案。\n\n如果你正在进行自定义构建过程，请确保在选择/自定义构建过程中没有忽略’aten::empty.memory_format’操作符。检查构建过程中是否存在任何错误或遗漏。\n\n如果以上方法都无法解决问题，可以考虑尝试其他可用的后端或降级到支持’aten::empty.memory_format’操作符的后端。\n\n\n总之，要解决这个问题，需要确保正确配置和安装PyTorch，并检查所选择的后端是否支持所需操作符。\nreturn t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\nNotImplementedError: Could not run ‘aten::empty.memory_format’ with arguments from the ‘SparseMPS’ backend. This could be because the operator doesn’t exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobil\ne, please visit https://fburl.com/ptmfixes for possible resolutions. ‘aten::empty.memory_format’ is only available for these backends: [CPU, MPS, Meta, Qua\nntizedCPU, QuantizedMeta, MkldnnCPU, SparseCPU, SparseMeta, SparseCsrCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conju\ngate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, Aut\nogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer\n, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMod\ne, PythonDispatcher].\n1whisper test.mp3 --model base --device cpu --language zh\n\n\nbrew install portaudio\nMac系统上的MP3播放工具:mpg123.直接brew install mpg123就行了， 命令行播放声音。 ​​​\n《The Calculus Life Saver》翻译成中文叫什么\n《微积分救星》\nwhisper 如何将一段中文语音.wav 文件的内容反应成中文 \n如何用 mpg123把.wav 转换成.mp\nmpg123是一个命令行音频播放器，不能直接将.wav文件转换成.mp3格式。要使用mpg123将.wav文件转换为.mp3格式，你需要先安装lame编码器，并将其与mpg123结合使用。\n以下是在Linux系统上使用mpg123和lame将.wav文件转换为.mp3的步骤：\n\n确保你的系统已安装mpg123和lame。如果没有安装，可以通过以下命令进行安装：\n1sudo apt-get install mpg123 lame\n打开终端并导航到包含.wav文件的目录。\n\n使用以下命令将.wav文件转换为.raw格式：\n1mpg123 -w output.raw input.wav\n这将把input.wav文件转换为output.raw文件。\n\n使用lame编码器将.raw文件转换为.mp3格式。使用以下命令：\n1lame -h output.raw output.mp3\n这将把output.raw文件转换为output.mp3文件。\n\n\n现在，你已成功地用mpg123和lame将.wav文件转换为.mp3格式。可以通过运行以下命令来验证：\n1file output.mp3\n这应该显示输出文件的详细信息，包括它的音频编码类型。\ndu 命令 显地文件大小时， 从大到小排序，用什么选项\n可以使用du命令的-h选项来显示文件大小，并使用-r选项来按照文件大小从大到小排序。具体命令如下：\ndu -hr 文件路径\n下面的问题怎么解决untimeError: Failed to load audio: dyld[66592]: Library not loaded: /opt/homebrew/opt/libvmaf/lib/libvmaf.1.dylib\n这个错误是由于缺少libvmaf库引起的。要解决此问题，可以尝试以下几种方法：\n\n检查是否已正确安装libvmaf库。可以使用Homebrew（如果已安装）执行以下命令来安装libvmaf：\n1brew install libvmaf\n如果已经安装了libvmaf，并且仍然出现此错误，请尝试重新安装它，使用以下命令：\n1brew reinstall libvmaf\n如果上述方法都没有解决问题，可以尝试更新Homebrew并升级所有软件包，使用以下命令：\n12brew updatebrew upgrade\n如果问题仍然存在，可能是由于库的路径不正确导致的。可以尝试通过设置DYLD_LIBRARY_PATH环境变量来指定正确的库路径。例如，假设libvmaf库位于/opt/homebrew/opt/libvmaf/lib/目录下，则可以执行以下命令：\n1export DYLD_LIBRARY_PATH=/opt/homebrew/opt/libvmaf/lib/\n最后，如果以上方法都没有解决问题，可能需要重新编译并安装相关软件包以修复依赖关系。\n\n\n请注意，在执行任何更改之前，请确保备份您的数据，并确保您具有适当的权限和了解相关软件包管理工具的操作。\nwhisper 依赖这个库，需要安装，如果过程发现找不到库文件，可以重新装一下。brew reinstall libvmaf\n\n打开终端并输入以下命令：sudo dockerd -d --log-level=4。这将启动docker服务，并在后台运行。\n如果您想要在Mac上使用Docker Desktop，可以通过在终端中输入以下命令来安装：sudo curl -sfO https://get.docker.com/mac/stable/dockerd_latest.dmg | diskutil mount /Volumes/DockerForMac/DockerForMac.dmg。\n如果您想要在Mac上使用Docker Compose，可以通过在终端中输入以下命令来安装：sudo curl -sfO https://get.docker.com/mac/stable/docker-compose_latest.dmg | diskutil mount /Volumes/DockerForMac/DockerForMac.dmg。\n如果您想要在Mac上使用Docker Machine，可以通过在终端中输入以下命令来安装：sudo curl -sfO https://get.docker.com/mac/stable/docker-machine_latest.dmg | diskutil mount /Volumes/DockerForMac/DockerForMac.dmg。️如何在Mac上启动docker服务\n\nLinux如何Umount一个磁盘在Linux系统中，可以使用umount命令来解除磁盘的 mount 状态。具体步骤如下：\n\n首先确保已经将磁盘添加到了 /dev/sdX 中，其中 X 代表磁盘的序号（例如，/dev/sdb1）。\n然后使用以下命令解除磁盘的 mount 状态：sudo umount /dev/sdX。在这个命令中，/dev/sdX 代表要解除的磁盘序号。\n如果您想要将磁盘重新添加到系统中，可以使用以下命令：sudo mount /dev/sdX /mnt。在这个命令中，/dev/sdX 代表要添加的磁盘序号，而 /mnt 是将其挂载到的目录。\n\n需要注意的是，如果您想要解除多个磁盘的 mount 状态，可以使用以下命令：sudo umount /dev/sdX1 /dev/sdX2 /dev/sdX3 ...。在这个命令中，每个 /dev/sdX 代表要解除的磁盘序号。️\n如何umount /dev/vdb\n要卸载/dev/vdb设备，可以使用umount命令。以下是在Linux系统中卸载/dev/vdb设备的步骤：\n\n首先，使用以下命令查看挂载点和正在使用的设备：\n1mount | grep /dev/vdb\n这将显示与/dev/vdb相关的挂载点和设备。如果没有显示任何内容，则表示该设备没有被挂载。\n\n如果有挂载点与/dev/vdb相关联，请确保没有任何进程正在使用该设备。可以使用以下命令来查看正在使用设备的进程：\n1fuser -m /dev/vdb\n如果有输出结果，则表示有进程正在使用该设备。需要终止这些进程或等待它们完成后才能卸载。\n\n确认没有任何进程在使用该设备后，可以使用以下命令卸载/dev/vdb：\n1umount /dev/vdb\n如果成功卸载了/dev/vdb，则不会有任何输出。如果失败，则会显示错误消息。\n\n\nLinux如何查看，当前都自动开启那些服务，用什么命令可以看可以使用systemctl status命令来查看当前自动开启的服务。\n如果需要查看所有服务，可以使用systemctl list命令。️\n下面问题造成的原因是什么，umount: /data0: target is busy. 如何解决这个问题\n造成这个问题的原因是挂载点（/data0）目前仍然被某个进程或程序使用，导致无法卸载。\n要解决这个问题，可以按照以下步骤操作：\n\n首先，确认你没有任何正在使用挂载点的进程。可以使用以下命令查看占用该挂载点的进程：\n1lsof | grep /data0\n如果有输出结果，则表示有进程正在使用该挂载点。\n\n如果确认有进程在使用该挂载点，可以尝试终止占用该挂载点的进程。找到对应的进程ID（PID），并使用以下命令结束该进程：\n1kill -9 &lt;PID&gt;\n如果无法终止占用该挂载点的进程，可以尝试重新启动系统，以确保所有相关的程序和进程都被重置。\n\n在重新启动后，再次尝试卸载挂载点：\n1umount /data0\n\n如果以上步骤仍然无法解决问题，可能需要进行更深入的排查和处理。\nfstrim -a这条命令的作用是什么\nfstrim -a命令的作用是对所有已挂载的文件系统进行TRIM操作。TRIM是一种用于固态硬盘(SSD)的操作，它通知SSD哪些数据块不再使用，从而可以提高SSD的性能和寿命。通过运行fstrim -a命令，可以定期地清理文件系统中不再使用的数据块，以确保SSD能够保持最佳性能状态。\nWhisper ASR Webservice的API如何用Python语言进行调用\n要使用Python语言调用Whisper ASR Webservice的API，可以按照以下步骤进行：\n\n安装Python的requests库：运行pip install requests命令来安装。\n\n导入requests库：在Python脚本中导入requests库，以便发送HTTP请求。\n\n构建HTTP请求头：根据Whisper ASR Webservice的API文档，构建正确的HTTP请求头。通常，包括Content-Type和Authorization等字段。\n\n构建API请求参数：根据需要发送给Whisper ASR Webservice的数据，构建API请求参数。通常，包括音频文件、采样率、音频格式等。\n\n发送POST请求：使用requests库发送带有正确HTTP请求头和API请求参数的POST请求。可以使用requests.post()函数来发送请求，并将返回结果保存在一个变量中。\n\n处理响应结果：根据Whisper ASR Webservice返回的响应结果进行处理。通常，可以通过访问响应对象的status_code属性获取状态码，并通过访问响应对象的json()方法获取JSON格式的响应体。\n\n\n以下是一个示例代码，演示如何使用Python调用Whisper ASR Webservice的API：\n123456789101112131415161718192021import requests# 构建HTTP请求头headers = &#123;    &#x27;Content-Type&#x27;: &#x27;audio/wav&#x27;,    &#x27;Authorization&#x27;: &#x27;Bearer &lt;your_token_here&gt;&#x27;&#125;# 构建API请求参数data = open(&#x27;&lt;path_to_audio_file&gt;&#x27;, &#x27;rb&#x27;).read()# 发送POST请求response = requests.post(&#x27;&lt;api_url&gt;&#x27;, headers=headers, data=data)# 处理响应结果if response.status_code == 200:    result = response.json()    # 处理返回的结果    print(result)else:    print(&#x27;请求失败：&#x27;, response.status_code)\n\n请确保将&lt;your_token_here&gt;替换为您的访问令牌，并将&lt;path_to_audio_file&gt;替换为音频文件的路径。将&lt;api_url&gt;替换为Whisper ASR Webservice的API URL。\n注意：以上代码仅供参考，实际使用时请根据具体需求进行修改。\n","slug":"aigc/Whisper如何在Mac上安装","date":"2024-03-14T06:15:59.708Z","categories_index":"AIGC","tags_index":"whisper","author_index":"安全书"},{"id":"77ed20ae201c3c7dc5957973d20f4a5c","title":"AI Agents 地图","content":"AI Agents 地图A16z 消费领域合伙人 Olivia Moore 整理的 AI Agents 地图。  \n她将 Agents 定义为跨系统工作并为用户执行任务的 bots。  \n3 月份，Agents 这一概念通过Auto-GPT 成为主流，一个月内就在 Github 上获得了 50k 颗星 + 排名第一。  \n接下来是 BabyAGI ， 然后是 AgentGPT 和 Godmode 。  \n这催生了一波新的代理产品—— HyperWriteAI 、 MultiON_AI 、 Minion AI、 lindy.ai 是先行者。  \n无数的黑客马拉松得以举办，但大多数 Agents 仍处于“demo”阶段，应用程序仅处于 Beta 测试阶段。  \n她预测明年这种情况会发生变化。  \n一些引人注目的团队一直在迭代有效的 Agents，并即将推出。另外，现有产品正在升级。  \n她正在关注的一些公司： Induced AI、 Minion AI、 Continua AI 、 Autotab 、Zeta Labs。\n","slug":"aigc/AI Agents 地图","date":"2024-03-14T06:15:59.708Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"45cf7b3c88a23623be0195c6597a4bdf","title":"Gradio","content":"用Gradio实现一个调用一个REST API，访问的的API地址是http://10.211.6.6:8081/gelf，参数a=1,b=2，返回字段有3个field1, field2, field3, 三个字符的类型都是字符串类型，返回3条数据,结构如下：\nfiled1, filed2,field3a,b,c,d,e,fh,i,j\n用Gradio交结果分页显出来，用二维表格的形式显示， 给同具体体Gradio实现的Python代码\n下面是使用Gradio实现的Python代码：\n12345678910111213141516171819202122232425262728import gradio as grimport requestsdef rest_api_call():    url = &quot;http://10.211.6.6:8081/gelf&quot;    params = &#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;    response = requests.get(url, params=params)    data = response.json()    return datadef display_results(page):    data = rest_api_call()    start_index = (page - 1) * 3    end_index = page * 3    results = data[start_index:end_index]        table_data = [[&quot;field1&quot;, &quot;field2&quot;, &quot;field3&quot;]]    for result in results:        table_data.append([result[&quot;field1&quot;], result[&quot;field2&quot;], result[&quot;field3&quot;]])        return table_datainputs = gr.inputs.Number(label=&quot;Page&quot;, default=1, minimum=1, maximum=2)outputs = gr.outputs.Table(header=[&quot;field1&quot;, &quot;field2&quot;, &quot;field3&quot;])interface = gr.Interface(fn=display_results, inputs=inputs, outputs=outputs)interface.launch()\n\n运行这段代码后，将会在浏览器中打开一个页面，可以输入页码来查看对应的数据。默认显示第一页的结果，可以在输入框中修改页码，然后点击”Submit”按钮获取对应页码的数据。数据以二维表格的形式显示在页面上。\n","slug":"aigc/Gradio","date":"2024-03-14T06:15:59.708Z","categories_index":"AIGC,Gradio","tags_index":"Gradio","author_index":"安全书"},{"id":"86c416bb6fe0d33b8f210e37684d77c0","title":"AI按理说应该最擅长理工，为啥先冲击文艺行业？","content":"AI按理说应该最擅长理工，为啥先冲击文艺行业？这个问题的可能答案会是什么呢？文艺行业确实是首先被波及的行业，这是因为AI应用已经在这个行业达到及格线，而且“AI容错率”高并且“人力AI成本差”大导致的。目前阶段，这样的行业就是非常利于AI应用的行业。  \nAI应用及格线我们先谈下AI应用的特殊之处。某项AI技术是否能应用，跟AI技术的应用效果关系比较大，而且这种关系还不是线性的，而是非线性的。就是说，干一件事情，如果AI的准确率如果达不到一个门槛值，比如80分，那么这项AI技术就是完全不可用的，而不是说50分的技术有50分的用处，90分的技术有90分的用处，所以是非线性的，必须要达到门槛数值，也就是及格线，才能应用，而且往往这个及格线是比较高的。就是说AI在某个行业应用，要么0分，要么一定超过及格线比如80分。大模型以及AIGC这波技术进展，和之前几波比如“深度学习”那波是不太一样的，之所以和之前不太一样，一方面跟大模型确实在很多方面效果好有关系，在很多方面超过了应用的及格线，以前没超过及格线的时候，它尽管还行，但是应用得分就是0，就是不可用的。现在很多行业可以用AI了，从不可能到了可能。但这只是次要的一方面，更主要的一方面在于：我们目前还没有看到基座大模型的效果天花板在哪里，接下来至少2年时间，它一定会稳步提高效果的，只要你给大模型更多高质量数据，并推大模型规模就行。如果这样，那么未来基座模型能力一定越来越强，现在所有其它AI方向的繁荣比如Agent、多模态、具身、具体应用这些，都是以强大的基座模型为核心依托的。随着基座能力越来越强，AI会跳过越来越多行业应用的及格线，使得原先不可应用AI的行业变得可以应用AI了，这必然带来AI的广泛应用。这是我一直对这一波AI浪潮报以乐观的主要原因，只有哪天我们发现Scaling law失效了，或者短期可能面临的问题是：可用的数据已经不够了，我觉得才需要去讨论AI是否泡沫太大的问题，在此之前，我不认为这是一个值得讨论的问题。对于某个行业，我们假设AI已经达到及格线了（不同行业及格线可能是不同的），那么在这个基础上考虑什么样的条件影响了AI应用的时间早晚或者普及程度。我认为主要有两个原因：“AI容错率”以及“人力AI成本差”。\nAI容错率  \n使用AI做事情你不能期望它能百分之百不出差错，这里就带来一个问题：这个行业的产品能在多大程度上容忍AI的错误结果？我们可以把它称为“AI容错率”，不同行业的AI容错率差异很大，某个行业的AI容错率越高，则会越早地广泛应用AI技术与产品。我们知道现阶段的大模型有着严重的“幻觉”问题，就是事实上明明应该是A，它非要说是B。大模型的幻觉本质如何见仁见智，有人觉得这是大模型的缺陷需要修正，也有人觉得“大模型的幻觉是种Feature，而不是Bug”。此问题我们暂且不论，且来看看不同行业的AI容错率。艺术创作行业比如写小说、画图、做电影，AI容错率非常之高，有时甚至是“反向容错”，就是说错得越离谱看着越有创造性。艺术创作领域没有“是对是错”这种标准答案，只有通过表现是否独特体现出是否有创造性，越独特越有创意。AI生成作品的所谓“错”，指的往往是非常规，超出普通人的想象力。超一流的艺术家思维模式、看世界的角度和普通人是截然不同的，所以这是为何超一流的艺术家很多都以疯掉作为人生结局的内在原因。所以在这种需要创意的领域，AI错得越离谱可能效果越好。艺术行业是极端容忍AI错误的，处于“AI容错率”另外一个极端的是“自动驾驶”。自动驾驶容错率是极低的，0.001%的错误率行吗？如果使用AI产品的用户基数比较大，比如1亿人，0.001%的错误率会造成多少交通故障？甚至生命危险？你可以算算，往少了算1000起，这个谁能接受？没人能承担这个后果。而且用户基数越大，对“AI容错率”的要求越高，这就很要命了，这不是规模效应，是“反规模效应”。所以我一直认为自动驾驶是个非常严苛的AI应用场景，大模型对它的帮助应该很有限，幻觉问题不解决可能没有出头之日。\n其它行业，对“AI容错率”要求基本处于艺术行业和自动驾驶这两个极端之间，To C的产品容错率就高一些，To B的产品容错率就低一些，大致如此。  \n人力AI成本差大模型目前还无法广泛应用的另外一个重要问题是使用AI成本太高，尽管制作GPT 4这种模型需要上亿美金起步，但是制造大模型成本和使用大模型成本比，大模型使用成本低更重要，毕竟制作是一次性的，算是固定成本，而人人都可以用AI，这是个变化成本。未来能否极大降低大模型的使用成本，对于大模型应用是否能全面铺开来说，是至关重要的。（大模型使用成本每12到16个月降低10倍，所以大模型应用未来还是可期的）从AI使用成本角度，我们来分析下不同行业的可能应用发展情况。假设每个行业现在都采取人力，那么不同行业的人力成本是不一样的，简而言之，行业平均工资越高，人力成本越高。假设AI和人能以相同水平解决职业问题，人力成本假设是H=10万／年，使用AI的成本假设是A=5万／年，那么两者的差值就是H-A=5万／年，这个H-A就是“人力AI成本差”。很明显，当AI使用成本比人力高的时候，“AI人力成本”是负数，没人有动力去用AI来代替人；只有当AI使用成本低于人力成本，AI技术才会被应用，而“AI人力成本差”越大，则企业拥有者越有动力去应用AI，两者基本成正比关系，甚至可能是指数关系，这是很自然的，人性如此。完成一个产品需要消耗越多劳动，这体现在对同一个水平劳动者来说，完成作品所需要投入的时间，时间越长，人力成本就越高。从模态角度来说，人力成本由高到低应该是：长视频&gt;短视频&gt;长文&gt;图片&gt;短文。你想想制作视频或者画一个艺术类的图，对于普通人来说，以前可能想都不敢想，现在用AI工具，制作成本降低了多少？就是几句话加几秒钟的时间。\n而随着技术的快速发展，AI使用成本会极速下降，但是人力完成任务的成本长周期内是比较稳定的，尽管降低速度也很慢。所以，对大多数行业来说，人力AI成本差会越来越大，虽然这可能会带来很多社会问题，但是，没办法，趋势如此，无法逆转，不接受也得接受，与其抗拒，不如拥抱，先利用好AI工具，把自身效率先提起来。  \n除此外，还有一些相对次要的因素，比如To C类的AI应用，因为用户基数比较大，所以感知到AI作用的人就多，对此谈论的人就越多，传播范围也比较大；To B或者 To Science类AI应用用户基数少，所以即使有反响也往往局限在小圈子内，感知到的人少，传播面小，这也是为何会有这种感觉的原因之一。  \n考虑AI的行业应用作用，需要结合以上三点综合考虑，总体而言：在AI技术能力达标的已有行业里，AI效果越好的、AI容错率越高的、人力AI成本差越大的行业，则会越早越快地进行AI普及与人力替代。这也解释了之前比较流行的说法：我们本来以为AI会先替我们做打扫房间、买东西送菜这种体力劳动，但是事实上与我们想的相反，大模型来了首先替代的反而是中等程度的脑力劳动。这是因为，高等脑力劳动目前AI效果还没达标、体力劳动人做起来成本低，而中等脑力劳动正好完美符合这些条件：AI效果在某些方面能力和人差不太多了，使用AI的“人力AI成本差”也比较大\n","slug":"aigc/AI按理说应该最擅长理工，为啥先冲击文艺行业？","date":"2024-03-14T06:15:59.708Z","categories_index":"AIGC,weibo","tags_index":"weibo","author_index":"安全书"},{"id":"bc3e68a199458a681f2c7fe3b421bbd6","title":"gpt4all","content":"gpt4all1pip install gpt4all\n\n\nEmbeddings翻译成中文为“嵌入”，是指将一个数据集或模型的特征值映射到一个更小的向量空间内的过程。在计算机自然语言处理领域中，Embeddings 通常被用来表示文本、图像或其他数据类型的特征，并使得模型能够更好地理解这些特征。️Embeddings翻译成中文，翻译成计算机自言语言处理的专业词汇️\n12345from gpt4all import GPT4All, Embed4Alltext = &#x27;The quick brown fox jumps over the lazy dog&#x27;embedder = Embed4All()output = embedder.embed(text)print(output)\n\n\nhttps://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All.__init__\n~/.username/.cache/gpt4all/ggml-all-MiniLM-L6-v2-f16.bin\ngit clone https://github.com/nomic-ai/gpt4all\nhttps://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf\n123pip install -U langchainpip install gpt4all\n\n\n12345from langchain.embeddings import GPT4AllEmbeddings gpt4all_embd = GPT4AllEmbeddings() query_result = gpt4all_embd.embed_query(&quot;This is test doc&quot;) print(query_result)\n\n\n1pip install langchain sentence_transformers\n\n\n\n\n\n\n123456from langchain.embeddings import HuggingFaceEmbeddingsembeddings = HuggingFaceEmbeddings()text = &quot;This is a test document.&quot;query_result = embeddings.embed_query(text)print(query_result [:3])\n1embeddings = HuggingFaceEmbeddings(model_name=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;)\n\n\nsentence-transformers/all-MiniLM-L6-v2\nsentence_bert_config.json\nmodules.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [00:00&lt;00:00, 836kB/s]config_sentence_transformers.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00&lt;00:00, 254kB/s]README.md: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10.6k/10.6k [00:00&lt;00:00, 12.6MB/s]sentence_bert_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00&lt;00:00, 130kB/s]config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571/571 [00:00&lt;00:00, 703kB/s]pytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 438M/438M [06:21&lt;00:00, 1.15MB/s]/home/parallels/miniconda3/envs/rag/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n#https://abetlen.github.io/llama-cpp-python/\n#%pip uninstall -y llama-cpp-python#%pip install –upgrade llama-cpp-python\n12345678910111213from langchain.embeddings import LlamaCppEmbeddingsllama = LlamaCppEmbeddings(model_path=GPT4ALL_MODEL_PATH)%%timetext = &quot;This is a test document.&quot;​query_result = llama.embed_query(text)CPU times: user 12.9 s, sys: 1.57 s, total: 14.5 sWall time: 2.13 s%%timedoc_result = llama.embed_documents([text])CPU times: user 10.4 s, sys: 59.7 ms, total: 10.4 sWall time: 1.47 s\n\n\n\nnc监听端口，如何可以指定IP\n要指定IP地址来监听端口，可以使用以下命令：\n1nc -l &lt;IP地址&gt; &lt;端口号&gt;\n\n例如，要在IP地址为192.168.1.100上监听端口8888，可以运行以下命令：\n1nc -l 192.168.1.100 8888\n\n这将使nc程序在指定的IP地址和端口上启动监听。\n","slug":"aigc/langchain/GPT4all Embeddings","date":"2024-03-14T06:15:59.708Z","categories_index":"gpt4all","tags_index":"gpt4all","author_index":"安全书"},{"id":"c8a161f78cff976f698872281578706e","title":"ChaGLM3在多显卡上运行","content":"ChaGLM3在多显卡上运行在明确是16位量化的时候，用ChatGLM项目中的utils文件的load_model_on_gpus方法，进行对model的配置， num_gpus=4,意思是说在4块显卡上运行。from utils import load_model_on_gpus\nmodel = load_model_on_gpus(model_name, num_gpus=4)\n1234if quantize == 16:model = load_model_on_gpus(model_name, num_gpus=4)else:model = AutoModel.from_pretrained(model_name, device_map=&quot;auto&quot;,trust_remote_code=True).half().quantize(quantize).cuda()\n\n\n\n运行的时候，用命令参数 -d，指定所在运行的显卡。\n1parser.add_argument(&#x27;--device&#x27;, &#x27;-d&#x27;, help=&#x27;device， -1 means cpu, other means gpu ids&#x27;, default=&#x27;0&#x27;)\n\n\n1python fastapiGPU.py -d 0,1,2,3\n\n相当于SD的 CUDA_VISIBLE_DEVICES。\nwebui-user.sh中加入export参数。\nexport CUDA_VISIBLE_DEVICES=0,1,2,3\n./stable-diffusion-webui/webui.sh –listen –device-id 1这样运行，SD可以同时使用显卡0和显卡1.\nCUDA_VISIBLE_DEVICES=0,1,2,3 python launch.py  –share\nCUDA_VISIBLE_DEVICES=1 python launch.py  –share\ncmd_args.py    –device-id \ndevice-id参数是在cmd_args.py文件中出现的。 \n","slug":"aigc/ChatGLM/ChatGLM3在多显卡上运行","date":"2024-03-14T06:15:59.708Z","categories_index":"AIGC,chatglm3","tags_index":"chatglm3","author_index":"安全书"},{"id":"406b641de940a6e95a960364da29d8e1","title":"git在命令行模式下不支持中文显示乱码","content":"1git config --global core.quotepath false\n\n","slug":"zhihu/git在命令行模式下不支持中文显示乱码","date":"2023-03-15T04:39:31.000Z","categories_index":"","tags_index":"","author_index":"安全书"},{"id":"809b84876322fff2ab4810eef75c2b8c","title":"《墨守之道》Web服务架构设计与实践|计算机网络安全技术","content":"购买链接： 点击购买\n编辑推荐\n\n1. 独特视角解析网络攻防之道本书借鉴了墨家思想，从多个方面解读Web安全的攻防原理，不仅涉及Web服务与安全的基础理论，也讲解了很多时下热门的安全技术，例如复载均衡、WAF、日志审计、蜜罐等。\n2. 实用案例探秘企业级安全之道本书案例丰富，适合读者边学边进行实践参考，能够为安全领域的研发人员、运维人员、高校师生、培训机构提供更全面的技术指导和学习素材。\n3. 原理解析深入浅出，经典案例有源码配套本书由资深的安全从业者和高校老师编写，融合了产业界和学界对网络信息安全的深度思考和实践，书中的典型案例还有配套的源码文件提供，方便读者使用。 \n内容简介\n\n近年来，信息技术的广泛应用极大地促进了社会进步，也方便了人们的工作和生活，随之而来的网络安全问题日益突显。如何构建安全可靠的网络环境，如何与时俱进地把新技术纳入网络安全防护的实践当中，成为网络安全工作者的重要课题。 本书聚焦于 Web 服务常用的安全技术，以案例形式展示 Web 服务所面临的威胁，并给出了丰富多样的解决方案。本书由浅入深地介绍了 Web 安全的相关主题，包括 Web 应用程序基础理论、Web服务器与负载均衡、HTTPS和CDN的安全问题、Web服务的安全因素、如何保护Web服务、WAF原理与实践、Web日志审计、蜜罐技术、大数据时代的Web安全、网络安全解决方案等内容。 本书适合网络安全领域的研发人员、运维人员、高校师生、培训机构等群体阅读参考。\n作者简介\n\n\n盛洋，新浪网高级安全与开发工程师，长期从事企业信息系统开发与嵌入式系统开发。在进入互联网信息安全领域之后，他将企业级信息安全工程方法与对嵌入式系统高性能的要求融入互联网安全信息系统的开发实践中，深度参与了互联网企业云服务防护实践和安全信息系统的构建。他还是《安全客》季刊的作者，FreeBuf安全智库指导专家顾问及“年度作者”。他也是一名活跃的技术博主，运营公众号“糖果的实验室”。 \n李华峰，信息安全顾问和自由撰稿人，FreeBuf安全智库指导专家顾问，多年来一直从事网络安全渗透测试方面的研究工作，在网络安全部署、网络攻击与防御以及社会工程学等方面有十分丰富的教学和实践经验。他还是一位高产的技术作者，已出版多本原创著作和译著，为学界和业界的网络安全教学和实践提供了助力。他经常通过公众号“邪灵工作室”给大家分享图书相关的资料和实用的技术指南\n","slug":"blog/mozidao","date":"2022-01-12T18:00:36.000Z","categories_index":"书籍","tags_index":"Web安全,人民邮电出版社,安全图书","author_index":"盛洋"},{"id":"b238dfff9a4ad98958466b32fff58555","title":"Moonscript如何显示复选框","content":"Moonscript如何显示复选框\n12345678&quot;/checkbok&quot;: =&gt;    @url_for: =&gt;    @html -&gt;       form method: &quot;POST&quot;, action: @url_for(), -&gt;        input type: &quot;hidden&quot;,          name: &quot;csrf_token&quot;, value: @csrf_token        input type: &quot;checkbox&quot;, name: &quot;username&quot;        input type: &quot;checkbox&quot;, name: &quot;password&quot;\n\n","slug":"old_topic/2016-09-17-394","date":"2017-09-11T04:50:18.000Z","categories_index":"topic","tags_index":"lua,moonscript","author_index":"安全书"},{"id":"115099973459c927aa591417c477a73c","title":"关于","content":"友情赞助！~\n \n\n\n\n\n关注本站作者：\n微博账号：糖果lua\n","slug":"old_topic/2016-09-17-103","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"4e932e195ef501e41ad67f12814a88d1","title":"有意思的脚本moonscript","content":"这是一个测试\n这又是一个测试\n新测试\n想看看lua到底有什么web框架，为了找到和openresty有点关系的框架，就找到了lapis，lapis是可以在openresty上跑的，更有意思的是，lapis可以使用moonscript,moonscript是一位叫做leafo的人写的。moonscript是基于用lua的lpeg库来写的。\n","slug":"old_topic/2016-09-17-100","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"b4445ca5bb585105ce99f8d1e2a341b6","title":"Lua的WEB开发框架Lapis","content":"在过去的一段时间里，使用Lua语言开发WEB程序。原因是因为我们需要写一个WEB的防火系统，其中的一个实现方案是 Openresty＋lua的方案。\nOpenresty是一种高性能的WEB服务器程序，和Nginx有着很深的渊源，简单的理解的就是Openresty 使用了Nginx的核心模块，外加了其他的一些服务部件，最主要的是Openresty支持使用Lua编写WEB程序，来处理用户的请求，也真是因为这个原因，被我们选做WEB防火墙的一个实现方案。\n其实，写这个文档的目的，不是单纯的追求说明一下Lua的WEB程序怎么编写，还有Lapis框架如何使用，如果是这个目的来看，可以直接去独Lapis的英文文档，从学习和实用角度来看也是效率最高的。\n而这篇文档的目的，是想通过Lua语言和Lapis框架来做个实践，从设计角度和实现角度，来分析实际的WEB开发，我们都需要解构出那些任务，以一个怎样相对共同的标准来看，那些语言工具或是框架的设计，能更好的完成WEB开发工作。（WEB防火墙系统）\n 这些标准和设计的原则，其实是具有共性的，甚至和语言都是无关的，语言作为一种工具，哪种语言的特性是有力于我们的想法和任务的实现才是我们关心的重点。在这一点上和那些信奉PHP是世界上最好的语言的同志，还是有有些差异。\n当下的WEB开发分为前段开发和后端开发，而这种划分是，有的是从完成任务的人的来划分的。而对我们来讲，无论是WEB的前端还是后端，都是一个整完的任务集合。在以往的过去，人们为了更好的分解开发任务，常常提了一个很重要的软件设计模式，MVC模式，是否支持MVC开发也成为衡量一个WEB框架的标准。\n对我们来讲，无论是不是WEB程序，都会涉及到，程序有输入和输出，还有中间的业务数据处理。而对于WEB程序来说，有一个比较固定的BS模式，用户通过浏览器browser发送http协议的格式数据给WEB server。\n1.WEB程序的输入。 \n\nWEB程序的输入，最主要的数据源来自于用户的请求，WEB程序存在的一个主要的意义就是响应用户的交互。取得用户的输入数据事关紧要。（框架应提供的服务）\n而对于服务器本地运行的WEB程序，输入也可能来自于数据库，本地文件，其他协议传过来的数据，（比如RabbitMQ的STOMP协议数据）\n2.WEB程序的输出。 \n\nWEB请求可以分为静态的请求和非静态的请求，静态的请求譬如，对静态HTML的请求，对图片文件的请求。非静态的请求，譬如数据库请求和一些在后端服务器的运算和数据处理等。而我们重点的讲的应该是动态的WEB程序，而重点的重点是，当后端程序接受输入数据，处理后要再次呈现给用户。（框架应提供的服务）\n3.WEB程序的数据业务处理。 \n\n当取得输入后，程序需要的任务就是对数据的处理，这是动态WEB程序很重要的工作内容。在取得同样的数据的前提下，这时候往往就能体现出一个语言的效率和一个框架解决问题设计的合理性。\n所以说，语言本身，和语言的框架都对这个效率有影响，之后会用C语言CGI，LUA和Python进行对比说明。WEB框架会用Lua lapis和Python的Django,Tornado,Flask比较说明。\n经过归纳总结，一个WEB框架至少需要有一下的特性，也基于这三点展开讨论。\n1.便捷的取得用户提交的数据。\n2.可以提供模板渲染模块给用户显示反馈数据。\n3.WEB提供足够充分的部件解决WEB数据处理的问题。\n下面，Lapis。\n==============================================\n现在是2017年2月，以上这些字都是很久之前写的，Lapis很好，但经过几个阶段，决定重新写一个建单的类似于Flask这种框架，来支持某些业务，这部分内容可能之后会被命令为Hi Lua。\n2017/03/02\n==============================================\n实际上，Lapis框架是由MoonScript而写的，针对MoonScript语言与Lapis框架的实践的文章，都汇集到了一个专题网站 MoonScript 这个网站上。\n而HiLua框架一些基本性文章发布到了另一个网站 CandyLab\n相关的内容还在增加变更中。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接。\ncat ***.log ​​​​\n","slug":"old_topic/2016-09-17-104","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"70c113f1b89df0b719f9ae169720a491","title":"Lua功能模块之“加密”","content":"作者：糖果\n在Lua开发的世界中，有很多开源的模块，分布在一些网站（比如开普勒项目），github上，有的都已经配置好了，可以向python的pip工具一样，只不过在lua世界中使用luarocks安装工具快速的安装。\n我们在开发的工作中，难免要对一些数据进行加密处理，而加密模块的使用有是就必不可少。\n在lua官方的WIKI列表中就列出了，很多lua程序写的加密库，这写加密库有的是用纯lua写的，也有用lua调用C的程序实现加密。不过有些时候甄选这些库还是需要花一些时间精力，只是需要测试一下这是加密算是否是好用的\n这是lua组织列出的一览列表。\nhttp://lua-users.org/wiki/CryptographyStuff\n说一下为什么要加密，我们面临的任务是什么！我们现在面临的任务是，要对一段字符串进行sha256算法加密。\n我们从列表中选出了几个支持sha256加密的包，并说明一下这几个工具包。\n1.SecureHashAlgorithm和SecureHashAlgorithmBW\n这个工具包是支持sha256加密的，而且是纯lua方法的实现，问题是，这两个包分别依赖lua5.2和lua5.3。\n而我们系统的运行环境是lua5.1，因为大部分的生产环境都是lua5.1，因为历史原因暂时没法改变。如果要把5.2的程序移植到5.1下运行，还需要移植一个lua5.2才独有的包，这是lua5.2升级之后才有的部件：bit32,而在lua5.3中又将这个部件去掉了,移植的动力不大，暂时不使用这个包。\n2.Lcrypt\n这个包不是纯lua的实现，底层加密用的是C语言，而且额外还有依赖另外另个工具包 libTomCrypt和libTomMath，这两个包的官网已经被和谐了，github上有源码，所以要想让这个包正常运行需要手动make安装3个源码工程，还是算了，有时间的时候再装好测试一下，先暂时不用。\n网站：http://www.eder.us/projects/lcrypt/\n3.LuaCrypto\n这个包的安装用的是luarocks，就比较简单了 luarocks install luacrypto ，我们选用这个包进行加密处理。\nLuaCrypto其实是openssl库的前端lua调用，依赖openssl，openssl库显然会支持sha256加密，相对也比一般的第三方实现更可靠。\n写一个简单的加密程序：\nlocal crypto = require(“crypto”)\nlocal hmac = require(“crypto.hmac”)\nlocal ret = hmac.digest(“sha256”, “abcdefg”, “hmackey”)\nprint(ret)\nret的返回结果是，如下这个字符串。\n704d25d116a700656bfa5a6a7b0f462efdc7df828cdbafa6fbf8b39a12e83f24\n我们需要改造一下代码，在调用digest的时候指定输出的形式是raw二进制数据形式，然后在编码成base64的数据形式。\nlocal ret = hmac.digest(“sha256”, “abcdefg”, “hmackey”,rawequal)\nprint(ret)\n这时候的输出结果是：\ncE0l0RanAGVr+lpqew9GLv3H34KM26+m+/izmhLoPyQ=\nlua-base64使用的是下面的库，lua库就是这样，有很多功能程序有很多的实现，并且很多非官方的第三方实现。\nhttps://github.com/toastdriven/lua-base64\n=============================================================\n同样的我们再写一个php的测试程序：\n\n\nret的返回结果是，如下这个字符串。\n704d25d116a700656bfa5a6a7b0f462efdc7df828cdbafa6fbf8b39a12e83f24\n没有确认php的hash_hamc是否底层调用的也是openssl的加密算法，至少从目前的测试结果来看，两种语言加密返回的结果是一致的。\n我们同样需要改造一下php代码的调用加密的方式：\n\n\n函数调用的最后一个参数，true表示用raw二进制形式输出，false是以16进制字符串的形式输出。\n最后的结果是：\ncE0l0RanAGVr+lpqew9GLv3H34KM26+m+/izmhLoPyQ=\n=============================================================\n我们测试一下python的sha256加密：\nimport hmac\nimport base64\nimport hashlib\nret = base64.b64encode(hmac.new(‘hmackey’, ‘abcdefg’, hashlib.sha256).digest())\nprint(ret)\n最后的输出结果是：\ncE0l0RanAGVr+lpqew9GLv3H34KM26+m+/izmhLoPyQ=\n通过这次测试我们会发现，lua的库很多都是第三方程序员实现的，并且有很多的实现版本，而php和python的库，相对更统一。\n如果你真的花了时间去了解lua，能驾驭lua，可以有精力去解决前期遇到的问题，排除库的匹配查找的问题，lua处理的效率会慢慢的展现出来，在之后我们会举出例子来说明lua的好处和不足。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-106","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"91b599411eb2c81aa42989cad4814460","title":"Lapis安装与项目创建","content":"Lapis是程序员leaf写的一个lua语言的WEB框架，目前已经发布了1.3版本。要求的服务器开发环境是Openresty，而且支持moonscript,这个moonscript语言类似于Javascript的coffescript。起到的作用是，可以用简短moonscript实现你的任务，然后通过翻译程序把moonscript翻译成lua语言。\nLapis还提供了命令行工具，用来管理nginx实例的启动，关闭，重新加载。\n1.安装luarocks.\n在Lua语言生态工具中，有一个类似于Python的Pip一样的引用管理工具，叫做Luarocks。这个工具可以方便的安装，目前在Lua世界中很多的软件包。而如果正好使用的Linux是Ubuntu系统，使用sudo apt-get install luarocks就可以安装Luarocks了。\n2.Lapis的安装:\n当在Linux系统上安装完luarocks之后，使用如下命令就可以安装lapis:\nluarocks install lapis\n因为lapis是在有openresty基础上运行，我们假设现在openresty已经安装好了。而lapis提供了命令行程序，提供了快捷的方式创建nginx工程实例和配置文件，并且可以通过lapis命令行，管理服务。\n3.创建工程。\nlapis命令行的名字是“lapis”\n我们在shell环境下运行lapis命令航工具。\nlapis help\n这条命令显示lapis都有哪些子功能，首先我们先用命令创建一个lua的WEB工程。\nlapis new\n命令执行后，会在当前目录创建一个空应用，会生成三个文件。\napp.moon\nmime.types\nnginx.conf\napp.moon是自动生成的一个moonscript脚本，可以通过程序翻译成lua程序。\nmime.types是文件类型描述汇集，会在nginx.conf中include包含进去。\nnginx.conf就是典型的nginx配置文件。\n目前这个阶段可能最需要讲的一下就是nginx.conf文件。[code]worker_processes $;error_log stderr notice;daemon off;\nevents {\n  worker_connections 1024;}\nhttp {\n  include mime.types;\n  server {\nlisten $&#123;&#123;PORT&#125;&#125;;\n\nlua_code_cache $&#123;&#123;CODE_CACHE&#125;&#125;;\n\nlocation / &#123;\n\n  default_type text/html;\n\n  content_by_lua &#39;\n\n    require(&quot;lapis&quot;).serve(&quot;app&quot;)\n\n  &#39;;\n\n&#125;\n\nlocation /static/ &#123;\n\n  alias static/;\n\n&#125;\n\nlocation /favicon.ico &#123;\n\n  alias static/favicon.ico;\n\n&#125;\n\n  }}[/code]include mime.types；就是引用mime类型文件之前已经说了。\nlisten $;\n定义监听的端口， PORT变量的设置，会在之后说明，如果在config文件中设置PORT变量。\nlua_code_cache $;\ncode cache的设置也是可以在config文件中配置的。lua_code_cache 设定成on，每次编辑修改lua程序的时候，服务会自动的重载入，这在调试环境下也很有用，省去的重启的麻烦。\n剩下的就是三个路由\n location / {\n这是一个根路由，输入网址后第一个被定为到的页面处理定义。\n content_by_lua ‘\n    require(&quot;lapis&quot;).serve(&quot;app&quot;)\n\n  &#39;;\n\n这就话就是lua lapis程序的入口，location“/”的意思，你只要是输入服务器的IP：PORT,而不指定其他任何后缀，比如：127.0.0.1/，都会调用执行lapis应用（简单说，任何的请求都会执行app.lua脚本，只要在nginx.conf没有同名locate定义。），就是当前工程目录下app.lua的脚本。\nlocation /static/ {\n这定义了工程静态文件的位置，用于存放CSS,image,js等静态文件的位置。\nlocation /favicon.ico {\n这是一个图片，输入127.0.0.1/favicon.ico,就会在浏览器中显示出。设定我们的服务在前台运行。\nerror_log stderr notice;\n这是在设定，log输出重定向输出到屏幕上。\ndaemon off;\n这么设定对程序员调试很有用，而在实际的生产环境中，可以关掉此选项。配置文件基本注释完了。启动服务。\nlapis server\n用这条命令来启动一个ningx实例服务，用当前的目录的nginx.conf.lapis会在下面的目录，去搜索openresty的nginx执行文件。\n“/usr/local/openresty/nginx/sbin/“\n“/usr/local/opt/openresty/bin/“\n“/usr/sbin/“\n“”\n停止服务，用ctrl + c，或是使用命令lapis term 。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-105","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"eee148716a9215b54bf73647adde1c1f","title":"Django的Static静态文件目录设定","content":"作者：糖果\nDjango的静态文件设定，与Nginx的static设定方式存在差异，需要在对应应用的setting文件中进行配置，配置的内容如下：\n12345678910SITE_ROOT=os.path.join(os.path.abspath(os.path.dirname(__file__)),&#x27;..&#x27;)STATIC_ROOT = os.path.join(SITE_ROOT,&#x27;static&#x27;)STATIC_URL=&#x27;/static/&#x27;STATICFILES_DIRS = (    (&quot;css&quot;, os.path.join(STATIC_ROOT,&#x27;css&#x27;)),    (&quot;js&quot;, os.path.join(STATIC_ROOT,&#x27;js&#x27;)),   (&quot;img&quot;, os.path.join(STATIC_ROOT,&#x27;img&#x27;)),)\n\n在工程的Static目录下，只要添加一个新的静态目录，需追加定义到”STATICFILES_DIRS”中。\n","slug":"old_topic/2016-09-17-102","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"c275b3b66a0c53930718bc2fb02605c5","title":"Lua功能模块之“CURL”","content":"作者：糖果\nCurl是一个WEB开发常用的工具，直接用官网的翻译\ncurl是一个开源的命令行工具，也是一个库，用于传输URL语法的工具，支持DICT, FILE, FTP, FTPS, Gopher, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMTP, SMTPS, Telnet and TFTP等。\n在lua中，curl就是以库的形式存在的，安装过程比较简单：sudo luarocks install luacurl。\n另外，curl还是支持代理的方式访问主机，这个很有用，之后会用一个模拟DDOS攻击程序说明他的用处。\n这一次，我们用一个和SAE云平台相关的机能，说明pycurl的使用。\n简单的说明一下，SAE云平台是国内较早的云开开放平台之一，经过多年的积累，有广大的用户基础，提供便利的开发平台，最近开放了一个实时LOG查询功能。用户可以通过其对外开放的REST API，查询自己运行在云平台上的APP产出的LOG。\n文档说明：\n接入流程概述：\n1.计算取得安全签名 。\n2.向指定URL发送HTTP的GET请求，请求之前要根据官网的文档要求，填充HTTP header信息，如果没有准备的填充信息，会被视为无效请求。\n3.取得返回的LOG信息，如果需要还可以对，返回LOG进行显示格式化。\n技术栈：\n依赖关联，此模块使用了几个常用的LUA库：\ncrypto：加密包，用于sha256运算。\nbase64:base64格式的转换处理。\ncrypto,base64在之前的章节有过介绍。\nluacurl：HTTP工具包，此处用于向服务器发送HTTP请求。\nsocket：luasocket是调用socket api的，但此程序只是用于取得系统时间，用作当时间戳。\n另外，国内的云风老师，因为觉得luasocket过于大了，不是很喜欢（QQ群里他自己说的…），他又写了一个lsocket，可以在github中找到，lsocket有一个sample,是使用lsocket实现了一个Http Server。\n多说一句，Lua的库不像python或是php等语言，Lua的很多库都是第三方个人实现的，需要一个寻找和甄别的过程，使用之前，确认一下也很必要。\n下面是具体的代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465local crypto = require(&quot;crypto&quot;)local hmac = require(&quot;crypto.hmac&quot;)local curl = require(&quot;luacurl&quot;)local socket = require(&quot;socket&quot;)require(&#x27;base64&#x27;)ALOG = &#123;&#125;TIME_STAMP = nilLOG_PATH = nilSAE_LOG_HOST = &#x27;g.sae.sina.com.cn&#x27;SAE_ACCESSKEY = &#x27;XXXXXXXX&#x27;SAE_SECRETKEY = &#x27;XXXXXXXXXXXXXXXXXXXXXXXXX&#x27;function ALOG.request()    local auth_info = ALOG.get_sec_token()    local header_info = &#123;         &#x27;Host: &#x27;..SAE_LOG_HOST,         &#x27;Accept: text/plain&#x27;,         &#x27;x-sae-accesskey: &#x27;..SAE_ACCESSKEY,         &#x27;x-sae-timestamp: &#x27;..TIME_STAMP,         &#x27;Authorization: &#x27;..auth_info     &#125;    local url = &#x27;http://&#x27;..SAE_LOG_HOST..LOG_PATH    local c = curl.new()    c:setopt(curl.OPT_URL, url)    c:setopt(curl.OPT_HEADER, false)    c:setopt(curl.OPT_HTTPHEADER,       table.concat(header_info,&quot;\\n&quot;))    local t = &#123;&#125;    c:setopt(curl.OPT_WRITEFUNCTION, function(param, buf)    table.insert(t, buf)    return #buf    end)    assert(c:perform())    return table.concat(t)endfunction ALOG.get_sec_token()    local header = &#123;     &#x27;GET&#x27;,     LOG_PATH,     &#x27;x-sae-accesskey:&#x27;..SAE_ACCESSKEY,     &#x27;x-sae-timestamp:&#x27;..TIME_STAMP,    &#125;    data_str = table.concat(header, &#x27;\\n&#x27;)    local ret = &#x27;SAEV1_HMAC_SHA256 &#x27;..to_base64(hmac.digest(&quot;sha256&quot;, data_str,SAE_SECRETKEY,rawequal))    return retendfunction ALOG.get_log_info(service, date, ident, fop, format)    LOG_PATH = &#x27;/log/&#x27;..service..&#x27;/&#x27;..date..&#x27;/&#x27;..ident..&#x27;.log&#x27;..&#x27;?&#x27;..fop    TIME_STAMP = math.ceil(socket.gettime())    local log_info = ALOG.request()    return log_infoendlocal service = &#x27;http&#x27;local date = &#x27;2015-07-31&#x27;local ident=&#x27;1-access&#x27;local meta = ALOG.get_log_info(service, date, ident, &#x27;head/0/1&#x27;, true)print(meta)return meta\n\n\n在云平台上可以运行，python,php,python的脚本。目前是不支持lua的，以后是否支持不得而知。\n因为将一个系统，分解成不同的子系统，一部分的功能是用lua实现，一部分的功能是用python实现，而系统之间的通信使用RPC通信，由lua端向python发送RPC，服务器端再接收RPC接收，必然会产生LOG。我们就在log端将实时的log取出，分析执行过程，这就是这段代码的意义。\n关于Pycurl使用代理的案例，之后单起一篇说明，另外会将C实现代码的关键截取出来说明上层LUA与底层代码的功能。\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-107","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"f95942805ad9929705bec3ec56164a8b","title":"Lua中脚本中加载C语言的.SO共享库","content":"作者：糖果\n在Lua中，可以使用loadlib的方式直接的加载C语言写的库，如同加载.lua文件一样。C写的模块可以做一些对效率要求相对比较高的模块，或是一些底层操作。下面举例\n说明：\n第一步：创建C模块文件。\nfoo.h头文件\n12345678#ifndef foo_h__#define foot_h__extern void foo(lua_State* L);#endif\n\nfoo.c实现文件\n1234567#include &lt;stdio.h&gt;#include &quot;lauxlib.h&quot;void foo(lua_State* L)&#123;    puts(&quot;Hello, I&#x27;m a shared library&quot;);&#125;\n\n第二步：创建.o文件。\n1gcc -c -Wall -Werror -fpic foo.c -I/usr/include/lua5.1\n\n注意一下的是.h文件中包含了”lauxlib.h”文件，所以要在编译的时候加上-I选项，后面追加.h文件的路径。\n第三步：创建.so文件。\n1gcc -shared -o libfoo.so foo.o\n\n如此操作后，”.so“文件就完成了生成，在使用libfoo.so动态库的时候，有以下几种方式让Lua找到库文件。\na). 设置LD_LIBRARY_PATH环境变量。\n1export LD_LIBRARY_PATH=/home/username/foo:$LD_LIBRARY_PATH\n\nb). 复制库文件到系统目录。\n12sudo cp /home/coding/workspace/libfoo.so /usr/libldconfig \n\n用ldconfig更新一下缓冲，然后看是否生效。\n1ldconfig -p | grep foo\n\n(也可以看一下.so文件是否关联到其他的库。ldd XXX{XXX为非lua文件，可以含有main函数的C程序。}\nc). 把.so文件放到当前目录。\n第四步：在lua中加载.so库。\ntest.lua文件。\n12f = package.loadlib(&quot;libfoo.so&quot;, &quot;foo&quot;)f()\n\n以上，就是如何创建.so共享库，然后在Lua加载调用的过程，使用Lua版本是Lua5.15, 开发环境是在coding.net的WEB IDE的terminal终端环境。\n之前so库，是没有传递参数的，下面我们用一个简单传参的例子来说明问题，然后以Makefile的形式编译共享程序。\n首先要定义就是.h文件，定义最常见的接口add, sub。\n123456789101112131415#ifndef __tangguo_h__#define __tangguo_h__#include &quot;lua.h&quot;#include &quot;lualib.h&quot; #include &quot;lauxlib.h&quot;extern int add(lua_State* L);extern int sub(lua_State* L);static luaL_Reg libtangguo[] = &#123;    &#123;&quot;add&quot;, add&#125;,    &#123;&quot;sub&quot;, sub&#125;,    &#123;NULL, NULL&#125;&#125;;  #endif \n\nluaL_Reg 这个结构体相对很重要，下面是引用这个结构全的原型：\n1234typedef struct luaL_Reg &#123;  const char *name;  lua_CFunction func;&#125; luaL_Reg;\n\n主要的元素:一个函数名字符串，另外一个是lua_CFunction的函数指针。在定义时地函数最后要用两个NULL,作业结构体数据的结尾。\nType for arrays of functions to be registered byluaL_register.name is the function name and func is a pointer to the function.Any array of luaL_Reg must end with an sentinel entry in which both name and func are NULL. \n\n\nlua_CFunction函数指针原型定义，如下：\n1typedef int (*lua_CFunction) (lua_State *L);\n\n下面是函数体的实体部分，所有函数的接口定义都是遵循lua_CFunction指针函数的原型定义，形参都是lua_State* L。\n123456789101112131415161718192021222324#include &quot;tangguo.h&quot;int sub(lua_State* L) &#123;    double op1 = luaL_checknumber(L, 1);    double op2 = luaL_checknumber(L, 2);    lua_pushnumber(L, op1 - op2);    return 1;&#125;int add(lua_State* L) &#123;    double op1 = luaL_checknumber(L, 1);    double op2 = luaL_checknumber(L, 2);    lua_pushnumber(L, op1 + op2);    return 1;&#125;int luaopen_libtangguo(lua_State* L)&#123;    luaL_openlibs(L);    const char *libName = &quot;libtangguo&quot;;    luaL_register(L, libName, libtangguo);    return 0;&#125;\n\n\n涉及到lua调用c语言，面对的一个课题是，如何在c函数中取得lua传递的对数，如果将计算结果，返回给lua程序。在这种最常见的add、sub函数例子都数字运算，我们用luaL_checknumber这个函数，原型如下：\nlua_Number luaL_checknumber (lua_State *L, int narg);\nChecks whether the function argument narg is a numberand returns this number. \n\n检查函数的参数是不是数字，返回这个数字。第一个参数是入参的状态机，第二个参数是lua调用c函数时，形参列表里第几个形参。\n还有一个比较重要的函数，luaopen_libtangguo，这函数是用来注册这此函数。\nluaL_register\nlua_pushnumber\n为了更好的适应编译环境，生成一个简单的Makefile， 需要注意的是LUALIB的定义要与你自己的环境相符。主要的参数是就是-I来指定.h的位置，-L用来定义用了那些库。\n默认的编辑选项是要提定平台。\n1make linux\n\nMakefile文件如下。\n12345678910111213141516171819LUALIB=-I/usr/include/lua5.1 -L/usr/local/lib -ldl -lm.PHONY: all win linuxall:        @echo Please do \\&#x27;make PLATFROM\\&#x27; where PLATFORM is one of these;        @echo win linuxwin:linux: libtangguo.solibtangguo.so : tangguo.c        #gcc --shared -Wall -fPIC -O2 $^ -o $@ $(LUALIB)        gcc --shared -fPIC -O2 $^ -o $@ $(LUALIB)clean:        rm -f libtangguo.so\n\n编译后会在当前目录生成.so文件，我们要以把.so文件复制到/usr/lib下\n1sudo ldconfig\n\n\n我们来测试一下库是否工作，用package.loadlib直接了复对应的函数指钍。\n1234567local aadd = package.loadlib(&quot;libtangguo.so&quot;, &quot;add&quot;)local asub = package.loadlib(&quot;libtangguo.so&quot;, &quot;sub&quot;)local ret = aadd(1,5)print(ret)local ret = asub(6,3)print(ret)\n\n输出的结是：\n3\n6\n后记：涉及到lua调用c语言，面对的一个课题是，如何在c函数中取得lua传递的对数，如果将计算结果，返回给lua程序。\n源码地址：\n","slug":"old_topic/2016-09-17-109","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"834dc1c98ae0dfc3f6c8b6dfa350a594","title":"如何创建部署WSGI类型的（Django, Tornado, Flask）Python应用","content":"作者：糖果\n第一部分：安装必要工具。 \n\n1.因为这是部署Python开发环境，所以安装pip可以简化一些软件的安装过程。（PIP对应Lua的luarocks） \n\n1sudo apt-get install python-pip\n\n安装三个Python框架\n123sudo pip install flasksudo pip install django==1.5.1sudo pip install tornado==3.1.1\n\n2.安装Gunicorn，这是运行Python的WSGI HTTP服务。 \n\n1sudo pip install gunicorn\n\n3.Virtualenv, 安装这个是因为，在部署Django的时候，使用了不同的版本。 \n\n1sudo pip install virtualenv\n\n第二部分：创建部署应用。 \n\n1.创建一个WSGI类型的Tornado应用。 \n1234567891011121314151617import tornado.webimport tornado.wsgiclass MainHandler(tornado.web.RequestHandler):    def get(self):        self.write(&quot;My source code in the MoPaas server by python Tornado!&quot;)settings = &#123;    &quot;debug&quot; : True,    &quot;static_path&quot;: &quot;static&quot;,&#125;#####urls = [    (r&quot;/&quot;, MainHandler),]app = tornado.wsgi.WSGIApplication(urls, **settings)\n\n启动这个服务： \n1gunicorn -w 4 torapp:app -b 0.0.0.0:8888\n\n2.创建一个Flask应用。 \n\n12345678from flask import Flaskapp = Flask(__name__)@app.route(&quot;/&quot;)def hello():    return &quot;My source code in the MoPaas server by python Tornado!&quot;if __name__ == &quot;__main__&quot;:    app.run()\n\n启动这个服务： \n1gunicorn -w 4 server:app -b 0.0.0.0:8888 --log-level debug\n3.创建Django应用。 \n\nDjango是一个比较大的WEB应用，创建各部署的过程，稍微复杂一些。 \n\n创建工程  \n1django-admin.py startproject hotdoc\n\n创建应用 \n1python manage.py startapp verp\n创建数据库表 \n1python manage.py syncdb\n启动工程 \n1gunicorn hotdoc.wsgi:application -b 0.0.0.0:8888\n\n需要在修改工程目录下的settings.py在INSTALLED_APPS中加入，verup和gunicorn： \n\n12345678910INSTALLED_APPS = (    &#x27;django.contrib.admin&#x27;,    &#x27;django.contrib.auth&#x27;,    &#x27;django.contrib.contenttypes&#x27;,    &#x27;django.contrib.sessions&#x27;,    &#x27;django.contrib.messages&#x27;,    &#x27;django.contrib.staticfiles&#x27;,    &#x27;verup&#x27;,    &#x27;gunicorn&#x27;)\n\n以上，本地开发环境是没问题的。 \n这些步骤也可以用virtualenv新创建一个虚拟环境完成，本地创virtualenv可以目前在WEB IDE上没有测试通过，理论上说，如果coding的WEB IDE是基于Docker的，virtualevn也应该好用。 \n\n1234mkdir ~/environments/virtualenv ~/environments/tutorial/cd  ~/environments/tutorial/binsource bin/activate\n\n目前的Paas平台上的Python服务就是WSGI形式的应用，比如Mopaas，不同的是，在SAE上有些现成的例子。Mopaas需要自己从头写，这三个例子在Mopaas生产环境下都运行测试通过。在coding.net的WEB IDE也可成功运行。 \n\n\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-110","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"e724a88ffa1659f5de4d93477c189f2b","title":"《Lua游戏AI开发指南 --- Lua调用C/C++函数》","content":"作者：糖果\n\n\n\n\n\n\n\n\n\nExposing C++ functions to Lua takes place through a process called function binding. Any bound functions exposed to Lua become accessible either as a global function or as a function available through a package. Packages in Lua are similar to namespaces in C++ and are implemented as a global table within Lua.\n\n通过暴漏C++函数给Lua的过程，叫做函数绑定。任何绑定函数暴漏给Lua成为一个可访问的全局函数，或是作为可用的包函数。Lua中的Packages(包)类似于C++中的命名空间，作为一个类似全局表被实现的。\n\n\n\n\n\n\n\n\n\nFunction binding \n\nAny function exposed to Lua must fit the lua_CFunction declaration. A lua_CFunction declaration takes in the Lua virtual machine and returns the number of return values pushed onto the Lua stack: \n\n\n\nFunction binding(函数绑定)\n任何函数暴漏给Lua对应的必须要有lua_CFunction声明。lua_CFunction声明取得Lua虚拟机和返回数字的返回到栈上。\nlua.h\n1typedef int (*lua_CFunction) (lua_State *L);\n例如，C++的GetRadius函数暴漏在沙盒中，是被定义在LuaScriptBingdings.h头文件中的，如下：\nLuaScriptBindings.h\n1int Lua_Script_AgentGetRadius(lua_State* luaVM);\n\n\n\n\n\n\n\n\n\n\nThe actual function implementation is defined within the LuaScriptBindings.cpp file and contains the code for retrieving and pushing values back to the stack. The GetRadius function expects an agent pointer as the first and only parameter from Lua and returns the radius of the agent. The Lua_Script_AgentGetRadius function first checks the stack for the expected parameter count and then retrieves the userdata off the stack through a helper function within the AgentUtilities class. An additional helper function performs the actual work of calculating the agent’s radius and pushes the value back onto the stack:\n实际的函数实现是别定义在LuaScriptBindings.cpp文件中，和接受与推送值入栈的代码。GetRadius函数期待\n\n一个”agent”指针作为唯一的一个从lua来的参数，并且将”agent”返回。Lua_Script_AgentGetRadius函数首先检查栈中期待的参数个数和接受的“userdata”（用户数据） 通过AgentUilities类中的助手函数出栈。另外的一个助手函数执行实际的agent半径计算工作，然后将值入栈。\nLuaScriptBindings.cpp\n12345678910111213141516171819int Lua_Script_AgentGetRadius(lua_State* luaVM)&#123;if (lua_gettop(luaVM) == 1)&#123;Agent* const agent = AgentUtilities::GetAgent(luaVM, 1);return AgentUtilities::PushRadius(luaVM, agent);&#125;return 0;&#125;\n\n\n\n\n\n\n\n\n\nTo bind the function to Lua, we define a constant array that maps the function’s name within Lua to the C function that should be called. The array of function mappings must always end with a null luaL_Reg type struct. Lua uses a null luaL_Reg type struct as a terminator when processing the function map:\n\n绑定函数到Lua，我们定义了一个常量数组映射，从Lua中的函数名称和应该被调用的C函数。这个函数数组映射，比如总是一个以null结尾的Lual_Reg类型的结构体。当处理函数map时，Lua使用null做为luaL_Reg类型结构的结束标记。\nAgentUtilities.cpp\n12345678910const luaL_Reg AgentFunctions[] =&#123;&#123; &quot;GetRadius&quot;, Lua_Script_AgentGetRadius &#125;,&#123; NULL, NULL &#125;&#125;;\n\n\n\n\n\n\n\n\n\n\nThe actual function binding to the Lua virtual machine takes place in the luaL_register helper function. The register function binds the table of function names to their corresponding C callback function. The package name is specified at this step and will be associated with each function within the mapping:\n\n实际的函数绑定虚拟机发生在luaL_register助手函数。 助手函数绑定了函数名table表，到他们对应C回调函数。包名在这一步指定，并且在映射中关联到每个函数。\nAgentUtilities.cpp\n12345678void AgentUtilities::BindVMFunctions(lua_State* const luaVM)&#123;luaL_register(luaVM, &quot;Agent&quot;, AgentFunctions);&#125;\nNote（注意）\n\n\n\n\n\n\n\n\n\nIf NULL is passed in as the package name, Lua requires that a table be at the top of the Lua stack. Lua will add the C functions to the Lua table at the top of the stack.\n如果包名传成空，Lua会从栈顶导入映射表。Lua会添加C函数到栈顶的Lua table表中。\n\n\n\n\n\n本文译自David Young《Lua游戏AI开发指南》一书。\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-111","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"d2f132ef110c84c89c3b0cacf76afe24","title":"《程序设计实践》-前言","content":"Preface\nHave you ever…\n你是否曾经\nwasted a lot of time coding the wrong algorithm?\n浪费了大量的时间，写了一个错误的算法。\nused a data structure that was much too complicated?\n采用的数据接结构过于复杂？\ntested a program but missed an obvious problem?\n测试过的程序，却遗漏了明显的问题？\nspent a day looking for a bug you should have found in five minutes?\n五分钟解决的BUG，却消耗一天？\nneeded to make a program run three times faster and use less memory?\n希望你的程序能事半功倍，快速而省内存？\nstruggled to move a program from a workstation to a PC or viceversa?\n努力的将程序辗转切换于开发环境和生产环境之间？\ntried to make a modest change in someone else’s program?\n尝试对程序做适度的变更？\nrewritten a program because you couldn’t understand it?\n因为模棱两可，而重写一个程序？\nWas it fun?\n乐在其中吗？\n　　 These things happen to programmers all the time. But dealing with such problems is often harder than it should be because topics like testing,debugging, portability,performance, design altematives, and style–the practice of programming–are not usually the focus of computer science or programming courses. Most programmers learn them haphazardly as their experience grows, and a few never learn them at all .In a world of enormous and intricate interfaces,constantly changing tools and languages and systems, and relentless pressure for more of everything, one can lose sight of the basic principles–simplicity,clarity, generality–that form the bedrock of good software. One can also overlook the value of tooIs and notations that mechanize some of software creation and thus enlist the computer in its own programming.\n    这些事发生在整个程序员的生涯过程中。但是处理类似问题经常比较困难，因为一些课题，像测试，调试，移植，性能，交互设计，和风格---编程实践---并不总是将焦点集中在计算机科学或者是教学上完成。有许多的程序员都是在，偶然的机会和杂乱的荆棘中前行，有人并未真正的学习过他们这些，都在野蛮生长。在一个庞杂瞬息万变的世界，工具，语言，系统都日新月异，还有更多周遭无情的压力。一个人可以忽略基本的原则---简单，明了，通用---构成了优秀软件的基石。 可以忽略用符号工具去机械性软件创造，驾驭计算机自我编程。\n\n　　 Our approach in this book is based on these underlying,interrelated principles,which apply at all levels of computing. These include simplicity, which keeps programs short and manageable; clarity, which makes sure they are easy to understand,for people as well as machines; generality,which means they work well in a broad range of situations and adapt well as new situations arise; and automation, which lets the machine do the work fOr us,freeing us from mundane tasks. By looking at computer programming in a variety of languages, from algorithms and data structures through design, debugging,testing, and performance improvement, we can illustrate universal engineering concepts that are independent of language, operating system, or program In ing paradigm.\n    在这本书中我们的力图， 基于最根本的相关原则，适应于所有级别的处理。 包括简单， 保持程序的短小可管理，清晰， 确保他们容易理解， 不仅人还有机器。一般来说， 意味着在一个广泛的情况范围内可以很好的工作， 并可以适应新的情况发生。 并且自动化， 让机器完成我们的工作，让我们从事务性的工作中解放出来， 放眼看各种计算机语言，从算法和数据结构到设计，调试，测试，性能改进， 我们阐述的一般性工程概念不依赖于语言， 操作系统或是程序规范。 \n\n　　 This book comes from many years of experience writing and maintaining a lot of sotiware, teaching programming courses, and working with awide variety of programmers. We want to share lessons about practical issues,to pass on insights from our experience, and to suggest ways for progran1mers of a1I levels to be more proficient and productive.\n    这本书源于许多年的写作经验和大量的软件维护，教授计算机课程，并且工作于广泛领域的程序员，我们要共享关于实践课题的课程。通过我们的经验的视角， 启发所有级别的程序员提高生产性（多产熟练），\n\n　　 We are writing for several killds of readers. If you are a student who has taken a programming course or two and would like to be a betterprogrammer, this book will expand on some of the topics fOr which there wasn’tenough time in school. If you write programs as part of your work. but in support of other activities rather than as the goal in itself, the informationwill help you to program more effectively. If you are a professional programmer who didn’t get enough exposure to such topics in school or who wotlId like are fresher, or if you are a software manager who wants to guide your staff inthe right direction, the material here should be of value.\n     我们的受众多，书使用面积广泛， 如果你是学生，可以通过一两个编程课程成为更好的编程者，这本书扩展了很多学校没时间完成的主题。 如果写程序是你的工作， 但还有有其他的活动，而不单是目标本身（工作不是单纯的编程）。 这个信息可以让你的程序更高效。 如果你职业程序员， 没有吸收足够的在校课程， 或是像个初学者， 或者你是个软件经理，想指引你的雇员奔向真确的方面， 这里的材料都应该很有价值。\n\n　　 We hope that the advice will help you to write better programs. The only prerequisite is that you have done some programming, preferably in C, C++or Java. Of course the more experience you have, the easier it will be; nothing can take you from neophyte to expert in 21 days. Unix and Linux programmers will find some of the examples more famiIiar than will those who have used only Windows and Macintosh systems, but programmers from any environrnent shou1d discover things to make their lives easier.\n    我们希望这建议可以帮助你写出更好的程序。前提是你编写过一些程序，最好是C，C++或是JAVA.当然你有更多的经验，事情就变得更简单，没有什么可以让你在21天后成从新手到专家。Unix和Linux程序员会找到一些例子，比只使用Windows和Macintosh系统的更熟悉。但是程序员可从任何的环境中发掘事物，从而让他们的生活更简单。\n\n　　 The presentation is organized in to nine chapters, each focusing on one major aspect of programming practice.\n    这书一共有9章，每一章都着眼于编程实践的一个主要方面。\n\n　　 Chapter 1 discusses programming style. Good style is so important to good programming that we have chosen to cover it first. Well-written programs are better than badly–written ones–they have fewer errors and are easier to debug and to modify-so it is important to think about style from the beginning. This chapter aIso introduces an important theme in good programming,the use of idioms appropriate to the language being used.\n    第一章讨论了编程的风格，良好的风格对优秀的程序员来说很重要，这是我们首要覆盖的一方面，好的编程比坏的编程，差别在很少有错误，并且容易调试和修改，可想而知，好的风格对初学者来说很重要。这一章也介绍了一个重要的主题就是，使用恰当的语言风格进行良好的编程。\n\n　　 Algorithms and data structures, the topics of Chapter 2. are the core of the computer science curriculum and a rnajor part of programming courses. Since most readers will aIready be familiar with this material, our treatment is intended as a brief review of the handful of algorithms and datastructures that show up in almost every program. More complex algorithms anddata structures usually evolve from these building blocks, so one shouId master the basics.\n    第二章节讲的是算法和数据结构，是计算机科学的核心部分，也是编程课程的主要部分。因为大多书的读者已经熟悉这些材料，我们的处理方针是，概要性的回顾少数的算法和数据结构， 这几乎出现在每个程序中，而更复杂的算法和数据结构，通常也是有这些发展构筑而成，应该作为基础掌握。\n\n　　 Chapter 3 describes the design and implementation of a smallprogram that illus-trates algorithm and data structure issues in a realistic setting. The program is implemented in five languages; cornparing the versions shows how the same data structures are handled in each, and how expressiveness and pertbrmance vary across a spectrum of languages. 　　 Interfaces between users, programs, and parts of programs are fundamentaI in programming and much of the success of software is determined by how well interfaces are designed and implemented.\n    第三章描述的是设计和实现一个小的程序，举例说明现实中的算法和数据结构的课题。 程序用了五种语言实现，比较展示了不同版本的语言是如何的处理相同的数据结构的， 如何表现不同语言的程序表达能力。在用户和程序之间是界面，是程序编写的基础部分。很多软件的是否成功，也取决于如何设计更好的设计界面，并将其实现的。\n\nChapter 4 shows the evolution of a small library for parsing a widely used data format. Even though the example is small, it illustrates many of the concerns of interface design f abstraction, information hiding, resource management, and error handling. Much as we try to write programs correctly the first time, bugs, and therefore debugging, are inevitable.\n    第四章，展示了一个广泛被使用的数据格式的解析库的演化过程，这个例子非常小，阐述了很多用户界面设计的抽象观点， 信息隐藏，资源管理，还有错误处理 。更多的时候我倾向于在第一时间写出正确的程序，不过出现bug和调试bug又在所难免的。\n\nChapter 5 gives strategies and tactics for systematic and effective debugging. Among the topics are the signatures of common bugs and the importance of “numerology,” where patterns in debugging output often indicate where a problem lies.Testing is an attempt to deve1op a reasonable assurance that a program is working correctly and that it stays correct as it evolves.\n    第五章是系统化高效调试的战术战略。 话题围绕着鲜明常见的bug和重要的“命理学”， 调试的模式输出，经常是直接指向问题所在行。测试是合理的确保开发的程序可以工作的正确，并且正确的演变。\n\nThe emphasis in Chapter 6 is on systematic testing by hand and machine. Boundary condition tests probe at potential weak spots. Mechanization and test scaffolds make it easy to do extensive testing with modest effort. Stress tests provide a different kind of testing than typical users do and ferret out a different class of bugs.Computers are so fast and cornpilers are so good that many programs are fast enough the day they are written. But others are too slow, or they use too much memory, or both.\n    重点是在第六章，是手动和机器的系统测试。 边界测试探寻潜在的薄弱点。机械化和测试脚手架是大量的测试变得简单合理有效。压力测试提供了和典型的用户测试不一样的测试，可以刺探出不同类别的bug. 计算机神速，编译器优秀，他们写的很多的许多程序都足够的快，但是其他方面却很慢，或者是他们使用了很多的内存，或者两者共存。\n\nChapter 7 presents an orderly way to approach the task of making a program use resources effcientIy, so that the program remains correct and sound as it is made more efficient.\n    提出一种有序的方式处理任务，确保程序使用的资源有效。所以程序保持正确，或是听起来让他更有效果了。\n\n    Chapter 8 covers portability. Successful programs live long enough that their environment changes, or they must be moved to new systems or new hardware or new countries. The goal of portability is to reduce the mainntenance of a program by minimizing the amount of change necessary to adapt it to a new environment.　　 Computing is rich in languages, not just the general-purpose ones that we use for the bulk of programming, but also many specialized languages that focus on narrow domains.\n\n    第八章涵盖的是可移植性。成功的程序生命力强，以至于他们的环境改变，哪怕是他们必须迁移到新的系统或是新的硬件，或是新的国家语言。全球化和可移植性，能减少程序维护量，做最小的变动，适应新的环境变化。 计算语言丰富， 我们使用的大部分程序都是多用途的。但也有很多特殊的语言聚集在窄领域。\n\n    Chapter 9 presents several examples of the importance of notation in computing, and shows how we can use it to simplify programs, to guide implementations,and even tO help us write programs that write programs.\n\n    第九章提出了一些重要的计算“记法”的例子， 展示我们可以使用其使编程简单， 引导实现， 甚至是助我们编程一臂之力。\n\n　　 To talk about programming, we have to show a lot of code. Most of the examples were written expressly for the book, although some small ones were adapted from other sources. We’ve tried hard to write our own code we1l, and have tested it on half a dozen systems directly from the machine-readable text.More information is available at the web site f Or The\n    讨论编程， 我们有大量的代码， 大多数的程序都明确写在了书上，虽然其中一些源于她源。 我们努力把我们的代码写好， 并经过测试，在半打系统上可直接处理这些文本，更多的可用信息在网站上。\n\n    Practice Of Programming:\n\n    http: //tpop. aw1. com\n\n    编程实践。\n\n　　 The majority of the programs are in C, with a number of examples inC++ and Java and some brief excursions into scripting languages. At the lowest level, C and C++ are almost identical and our C programs are valid C++ programs as well. C++and Java are lineal descendants of C, sharing more than a little of its syntax and much of its efficiency and expressiveness, while adding richer type systems and libraries.In our own work, we routinely use aIl three of these languages, and many others. The choice of language depends on the problem: operating systems are best writt Cn in an efficient and unrestrictive language like C or C++, quick prototypes are often easiest in a command interpreter or a scripting language like Awk or Perl; for user interfaces, Visual Basic and Tcl/Tk are strong contenders, along with Java.\n    主要的编程语言还是C， 还有一定数量的C++和Java程序，还有一些脚本语言的摘要。 在底层 C和C++几乎是相同的，C和C++都很好，C++和JAVA都是C的衍生语言， 共享了一些小的语法和更多有效的表达式， 又添加了丰富的系统库， 在我们的工作中， 三种语言通常都使用， 许多其他方面， 选择语言依赖于面向的问题，操作系统最好用C写更高效，并且不受约束，就像C，C++，完成快速原型经常使用最简单的命令解释型或是脚本语言，像Awk或是Perl, 完成用户界面就用，VB和Tcl/T ，是JAVA非常强劲的竞争对手。\n\n　　 There is an important pedagogical issue in choosing a language for our examples.Just as no language soIves all problems equal1y well, no single language is best for presenting aIl topics. Higher-level languages preempt some design decisions. lf we use a lower-level language, we get to consider alternative answers to the questions, by exposing more of the detaiIs, we can talk about them better. Experience shows that even when we use the facilities of high-Ievel languages, it’s invaluable to know how they relate to lower-level issues, without that insight, it’s easy to run into performance problems and mysterious behavior. So we will often use C for our examples, even though in practice we might choose something else.\n    最重要的一个课题就是选择语言，对于我们就是个例子。 没有任何语言可以很好的解决所有的问题。没有一个单独的语言能最好的表述所有主题。高级语言取代了一些设计决策。我们使用低级语言，要知其然，并知其所以然。通过引出很多的细节，更便于讨论。 经验显示，甚至是当我们使用了高级语言或设备， 知道底层原理也大有裨益，如果这些含混了， 很容易陷入性能问题和对莫名其妙，诡异行为的不解。 所以我们经常使用C做例子， 尽管在实践过程中还有其他的选择。\n\n　　 For the most part, however, the lessons are independent of any particular programming language. The choice of data structure is affected by the language at hand; there may be few options in some languages while others might support a variety of alternatives. But the way to approach making the choice will be the same. The details of how to test and debug are different in different languages, but strategies and tactics are similar in all. Most of the techniques for making a program efficient can be applied in any language.\n    大部分的，但是课程不依赖其他任何的特定编程语言，某种程度上讲，选择的数据结构是受语言影响的，某些语言支持寡少，某些语言支持的富足，但都殊途同归。如果测试和调试的细节在不同的语言中有差异，但是所有的战略战术异曲同工，大多数的技术让程序有效，适用任何语言。\n\n　　 Whatever language you write in. your task as a programmer iis to do the best you can with the tools at hand. A good programmer can overcome a poor language or a clumsy operating system, but even a great programming environment will not rescue a bad programmer. We hope that, no matter what your current experience and skill, this book will help you to prograhi better and enjoy it more. We are deepIy grateful to friends and colleagues who read drafts of the manuscript and gave us many helpful comments. Jon Bentley, Russ Cox, JohnLakos, John Linderman, Peter Memishian, Ian Lance Taylor, Howard Trickey, andChris Van Wyk read the manuscript, some more than once, with exceptional care and thoroughness.\n    无论你用什么语言写，程序员都用手中最好的工具去完成任务。一个好的程序员可以克服差劲的语言和糟糕的操作系统，但是好的开发环境也无法拯救一个坏的编程者。我们希望的是，无关你当前的水平程度， 这本书将会更好的帮助你编程，并乐在其中。我们深深的感谢朋友和同事们，阅读草稿和原稿，给了我们很多妙语良言的点拨，从而受益匪浅。Jon Bentley, Russ Cox, JohnLakos, John Linderman, Peter Memishian, Ian Lance Taylor, Howard Trickey, andChris Van Wyk 阅读了原稿，如琢如磨，反复推敲。\n\n　　We are indebted to Tom Cargi1l, Chris Cleeland, Steve Dewhurst, EricGrosse,Andrew Herron, Gerard Holzmann, Doug Mcllroy, Paul McNamee, PeterNelson,Dennis Ritchie, Rich Stevens, Tom Szymanski, Kentaro Toyama, John Wait,DanielC. Wang, Peter Weinberger, Margaret Wright, and Cliff Young forinvaluable comments on drafts at various stages. We also appreciate good adviceand thoughtful suggestions from Al Aho, Ken Arnold, Chuck Bigelow, JoshuaB1och, Bill Coughran,Bob Flandrena, Renee French, Mark Kernighan, Andy Koenig,Sape Mullender, Evi Nemeth, Marty Rabinowitz, Mark V. Shaney, BjarneStroustrup, Ken Thompson, and Phil Wadler. Thank you all.\n   我们要感谢Tom Cargi1l, Chris Cleeland, Steve Dewhurst, EricGrosse,Andrew Herron, Gerard Holzmann, Doug Mcllroy, Paul McNamee, PeterNelson,Dennis Ritchie, Rich Stevens, Tom Szymanski, Kentaro Toyama, John Wait,DanielC. Wang, Peter Weinberger, Margaret Wright, 和Cliff Young forinvaluable comments on drafts at various stages. We also appreciate good advice和 thoughtful suggestions from Al Aho, Ken Arnold, Chuck Bigelow, JoshuaB1och, Bill Coughran,Bob Flandrena, Renee French, Mark Kernighan, Andy Koenig,Sape Mullender, Evi Nemeth, Marty Rabinowitz, Mark V. Shaney, BjarneStroustrup, Ken Thompson 和 Phil Wadler，谢谢你们！\n\n　　Brian W Kernighan\n　　Rob Pike\n本文译自Brian W. Kernighan和Rob Pike的《程序设计实践》一书的前言部分。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-108","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"878333f17299242d2af5675db3efb934","title":"《Lua游戏AI开发指南 --- C/C++中调用Lua函数》","content":"C/C++ calling Lua functions\nThe sandbox hooks into the Lua script through three predefined global Lua functions:\nSandbox_Initialize, Sandbox_Cleanup, and Sandbox_Update. When the sandbox is first\nattached to the corresponding Lua script, the Sandbox_Initialize function is called. Each\nupdate tick of the sandbox will also invoke the Sandbox_Update function in the Lua script.\nWhen the sandbox is being destroyed or reloaded, the Sandbox_Cleanup function will\nhave an opportunity to perform any script-side cleanup.\nIn order for C++ to call a Lua function, the function must be retrieved from Lua and\npushed onto the stack. Function parameters are then pushed on top of the stack, followed\nby a call to lua_pcall, which executes the Lua function. The lua_pcall function\nspecifies the number of arguments the Lua function receives, the number of expected\nreturn values, and specifies how to handle errors:\nlua.h\n123456789101112131415161718int lua_pcall(lua_State* luaVM, int numberOfArguments,int numberOfResults, int errorFunction);For example, the Agent_Initialize Lua script function is called in the AgentUtilitiesclass in the following manner:Agent.luafunction Agent_Initialize(agent)...end\n\nFirst, the Lua function is retrieved from Lua by name and pushed onto the stack. Next, the\nagent itself is pushed as the only parameter to the Agent_Initialize function. Lastly,\nlua_pcall executes the function and checks whether it succeeded successfully; otherwise,\nan assertion is raised by the sandbox:\nAgentUtilities.cpp\n12345678910111213141516171819202122232425262728void AgentUtilities::Initialize(Agent* const agent)&#123;// Retrieves the lua virtual machine the agent script is// running on. lua_State* luaVM = agent-&gt;GetLuaVM();lua_getglobal(luaVM, &quot;Agent_Initialize&quot;);// Agent_Initialize accepts one parameter, an Agent.AgentUtilities::PushAgent(luaVM, agent);// Execute the Agent_Initialize function and check for// success.if (lua_pcall(luaVM, 1, 0, 0) != 0)&#123;assert(false);&#125;&#125;\n\n\n\n“C/C++中调用Lua函数”\n Lua脚本的沙盒钩子是通过预先定义了三个全局的Lua函数：\n1.Sandbox_Initalize。\n2.Sandboxk_Cleanup。\n3.Sandbox_Update。\n当沙盒首次载入对应的Lua脚本，Sandbox_Initialize函数被调用。每次有所更新，沙盒调用脚本中内Sandbox_Update函数。当沙盒初建，或重新载入时，Sanbox_Cleanup函数，有机会执行任何脚本端的清理工作。\nC++调用Lua函数，函数要从Lua中取得，并入栈，其参数要入栈顶，之后，用lua_pacall执行对应Lua函数。lua_pcall指定Lua函数接受的参数个数，返回值个数和容错处理。\nlua.h\n123int lua_pcall(lua_State* luaVM, int numberOfArguments,int numberOfResults, int errorFunction);\n\n\n例如，“Agent_Initialize”脚本函数，被在“AgentUtilities”类中调用，脚本如下：\nAgent.lua\n12345function Agent_Initialize(agent)...end\n\n\n首先，用函数名取得Lua函数，并入栈。\n然后，”agen”作为唯一参数，赋给Agent_Initialize函数。\n最后，用lua_pcall执行函数，并验证是否成功；\n其他情况，会抛出一个沙盒的失败断言“assert(false)”。\nAgentUtilities.cpp\n12345678910111213141516171819202122232425262728293031void AgentUtilities::Initialize(Agent* const agent)&#123;“取得一个agent脚本的运行虚拟机。”// Retrieves the lua virtual machine the agent script is running on. lua_State* luaVM = agent-&gt;GetLuaVM();lua_getglobal(luaVM, &quot;Agent_Initialize&quot;);// Agent_Initialize accepts one parameter, an Agent.“Agent_Initialize函数接收的参数，“agent”。”AgentUtilities::PushAgent(luaVM, agent);“执行Agent_Initialize函数，并验证是否成功。”// Execute the Agent_Initialize function and check for success.if (lua_pcall(luaVM, 1, 0, 0) != 0) &#123;assert(false);&#125;&#125;\n\n本文译自David Young《Lua游戏AI开发指南》一书。\n翻译：糖果\nPS:转载到其它平台请注明作者姓名及原文链接。\n别动我代码可以不\n","slug":"old_topic/2016-09-17-112","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"1e5b544e537ce9e8013f8d5d976629a9","title":"Openresty的Lua定时器（计划任务）","content":"在系统中有一类需求是：周期性的执行某些任务，利用定时的timer去实现这种操作。\nOpenresty为Lua提供了这种机制实现的API，通过设定timer来完成这种类似计划任务功能。\n下面，就是一个典型的Openresty的timer API的使用例子：\n实现思路是，通过一个timer设定调用一个函数，在函数内部还有一个循环递归的timer调用，调用函数自身，实现周期性的函数执行。\n–此函数的主要的目的是6秒钟的时间，对redis中某Key，进行数值累加。\n123456789101112131415local handlerfunction handler(premature, params)--定时执行一个redis的累加计数操作。RedisCommon.add()--递归的timer，重复调用handler函数。local ok, err = ngx.timer.at(6, handler, &quot;params-data&quot;)        ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok, &quot; err:&quot;, err)end\n–第一次设定timer，调用hander函数。\n12345678910local ok, err = ngx.timer.at(6, handler, &quot;params-data&quot;)ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok, &quot; err:&quot;, err)if not ok then        ngx.log(ngx.ERR, &quot;err:&quot;, err)end\n\ntimer一般用于，定时去服务器上取一些数据，或是定时扫描本地文件是否有变动，根据目地不同功能也不一样。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-114","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"9aeff2cf84352e0facabfc6256b648d7","title":"LUA与STOMP协议","content":"作者：糖果\nSTOMP协议是一种简单的消息文本协议。协义本身简单明了，用消息头定义和消息体数据传输。\nRabbitMQ做为一种队列中间件，提供了STOMP协议的支持，我们可以通过STOMP协议向队列发送消息。下面的例子中，我们将使用LUA程序向RabbitMQ发送消息， 通过Python程序读取消息。\nsend.lua文件\n12345678local client = require &quot;stomp&quot;local mq, err = client:new()local ok, err = mq:connect(&quot;127.0.0.1&quot;, 61613)local msg = &quot;say hi!&quot;local headers = &#123;&#125;headers[&quot;destination&quot;] = &quot;/queue/test&quot;headers[&quot;app-id&quot;] = &quot;APP&quot;local ok, err = mq:send(info_json, headers)\n\n对上面的代码说明一下：\n连接时候RabbitMQ的IP是本机的127.0.0.1， STOMP协议的服务的端口是默认的61613。\n在headers的头定义部分，指明了我们发送信息的目的地“/queue/test“名字为Test的队列。\n其实可以深入到STOMP的LUA的实现内部，仔细研究一下是如何实现，如何直接通过sock，发送数据帧到服务器，可以作为独立的章节。\n与LUA不同，Python对STOMP协议支持的比较好，不需要甄别第三库，然后再选择使用。用pythonstomp就好。\nreceive.py文件\n12345678910111213141516171819202122232425262728import stompimport timeimport sysimport randomimport jsonclass MyListener(stomp.ConnectionListener):    def on_error(self, headers, message):        print(&#x27;received an error %s&#x27; % message)    def on_message(self, headers, message):        for k,v in headers.iteritems():            print(&#x27;header: key %s , value %s&#x27; %(k,v))        print(&#x27;received message\\n %s&#x27;% message)conn=stomp.Connection([(&#x27;127.0.0.1&#x27;,61613)])conn.set_listener(&#x27;somename&#x27;,MyListener())conn.start()conn.connect(wait=True)message=&#x27;say hi!&#x27;dest = &#x27;/queue/test&#x27;headers=&#123;&#x27;seltype&#x27;:&#x27;mandi-age-to-man&#x27;,&#x27;type&#x27;:&#x27;textMessage&#x27;,&#x27;MessageNumber&#x27;:random.randint(0,65535)&#125;metadata = []info_json = json.dumps(metadata)conn.send(body=info_json, destination=&#x27;/queue/test&#x27;)conn.disconnect()\n\n\n接受程序和发送程序的主要流程区别是：要在接受端注册监听回调程序。\n上面的\n12conn.set_listener(&#x27;somename&#x27;,MyListener())conn.start()\n\n这两行代码就是注册监听类，在队列上有消息的时候，就会调用监听回调。\non_message。发生错误的时候调用。on_error函数。\n具体的实现不完全列出来，针对一般的STOMP连接过程，列出”连接“和\n发送的”消息包”的数据结构，结构采用的是LUA语法，table类型定义的。\n共计二帧的数据：\n123456789101112131415161718connect_frame = &#123;  &quot;CONNECT\\n&quot;,  &quot;accept-version:1.2\\n&quot;,  &quot;login:guest\\n&quot;,  &quot;passcode:guest\\n&quot;,  &quot;host:/\\n&quot;,  &quot;\\n\\n&quot;,  &quot;\\0&quot;&#125;send_frame = &#123;  &quot;SEND\\n&quot;,  &quot;destination:/queue/test\\n&quot;,  &quot;app-id:APP\\n&quot;,  &quot;\\n&quot;,  &quot;say hi!\\n&quot;,  &quot;\\0&quot;&#125;\n\n包体的第一个字段“CONNECT,SEND”都是协议的命令，剩下的是说明字段。文字不能把所有的问题和协议都描述清楚，可参考以下网站：http://stomp.github.io/stomp-specification-1.1.html\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-117","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"94c79648b27c71adf58b46e7d0e952fe","title":"WEB IDE环境运行Lua网页应用","content":"作者：糖果\n如Python和Ruby一样，Lua也可以创建WEB应用，之前提过的一个Lua WEB框架\n这次就在WEB IDE环境下，部署一下LuaWEB的运行环境，并创建一个Lua WEB应用。\n第一步：安装WEB服务器， Openresty。\n1).下载安装包\n1wget https://openresty.org/download/ngx_openresty-1.7.10.1.tar.gz\n\n2).解压\n1tar xzvf ngx_openresty-1.7.10.1.tar.gz\n3).安装依赖包\n1234567sudo apt-get install libreadline-devsudo apt-get install libncurses5-devsudo apt-get install libpcre3-devsudo apt-get install libssl-devsudo apt-get install perlsudo apt-get install makesudo apt-get install build-essential\n\n3).配置与安装\n1234cd xzvf ngx_openresty-1.7.10.1./configuremakemake install\n\n4).配置环境变量\n12export PATH=/usr/local/openresty/nginx/sbin:$PATHnginx -v\n\n第二步：安装Lapis\n1).安装luarocks\n1sudo apt-get install luarocks\n\n2).安装lapis框架。\n1sudo luarocks install lapis\n\n第三步：创建Lua Web应用。1).创建Lapis工程。\n1lapis new tangguo\n\n2).创建app.lua\n1234local lapis = require &quot;lapis&quot;  local config = require(&quot;lapis.config&quot;)       local app = lapis.Application()         app:match(&quot;/&quot;, function(self)                                                                               return &quot;Hi Lapis!&quot;                                                                          end)                                                                                                return app\n\n3).创建config.lua(设置IP:端口,数据库连接账号)\n12local config = require(&quot;lapis.config&quot;)                                                              config(&quot;development&quot;, &#123;                                                                                  port = 8000,                                                                                        mysql = &#123;                                                                                       host = &quot;0.0.0.0&quot;,                                                                               user = &quot;root&quot;,                                                                                  password = &quot;&quot;,                                                                                  database = &quot;&quot;                                                                                  &#125;                    &#125;) \n4).启动服务\n1lapis server\n完成以上步骤后，我们就创建了就一个简单的Lua Web程序。此程序在Coding的WEB IDE运行，通过测试。下面是实际的运行效果地址：（1小时左右后地址失效）\n1https://qqbsel-8000-lhfxjz.box.myide.io/\n\n\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-113","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"e071224e90a59c391520b50afdda50c7","title":"Lua Lapis的模板系统etlua","content":"作者：糖果\n主流的WEB开发框架都有模板系统，或是支持第三方的模板插件。Lua Lapis也不例外，也有自己的模板系统，叫做etlua。\n说到模板系统，另外要提一下静态资源的问题，模板的话难免要使用css、js、image这种静态文件，为了扫除一部分障碍先说一下Openresty是如何设定静态目标的。（相对Django相对要简单很多。）\n123location /static/ &#123;                                                                                                                                                             alias static/;                                                                                                                                                              &#125;\n\n在nginx.conf中加入这句话就可以了，在用lapis命令创建工程的时候就已经默认加入了。\n对比看一下django对static的配置。\nDjango的静态文件设定，与Nginx的static设定方式存在差异，需要在对应应用的setting文件中进行配置，配置的内容如下：\n123456789101112131415SITE_ROOT=os.path.join(os.path.abspath(os.path.dirname(__file__)),&#x27;..&#x27;)STATIC_ROOT = os.path.join(SITE_ROOT,&#x27;static&#x27;)STATIC_URL=&#x27;/static/&#x27;STATICFILES_DIRS = (    (&quot;css&quot;, os.path.join(STATIC_ROOT,&#x27;css&#x27;)),    (&quot;js&quot;, os.path.join(STATIC_ROOT,&#x27;js&#x27;)),   (&quot;img&quot;, os.path.join(STATIC_ROOT,&#x27;img&#x27;)),)\n\n在工程的Static目录下，只要添加一个新的静态目录，需追加定义到”STATICFILES_DIRS”中。\n下面就是Lapis使用模板的例子。\n1.创建工程。\n123mkdir tangguocd tangguolapis new \n\n创建一个新工程后，系统创建了三个文件。\n1app.moon mime.types nginx.conf\n\n具体文件的内容功能不介绍了，之前一篇已经写过了。\n2.创建模板目录与模板文件。\n使用lapis模板，要在默认生成的目录构成的基础上，新创建一个目录：”views” 目录 。\n1mkdir views\n之后所有的ETLUA模板文件，都会发到这个目录中。\n1cd views\n\n我们创建一个最简单的模板文件。\n12touch index.etluaecho &quot;say hi&quot; &gt; index.etlua\n\n12index.etluasay hi\n\n\n3.创建后端LUA代码。\n让Lapis Lua代码支持模板，只要在原有的app.lua中加入一个“开关”和一段处理代码。\na).  加入一行代码，打开etlua支持。\n1app:enable(&quot;etlua&quot;)\n\nb).加入对应的路入处理代码，此处的处理是什么都不做，只渲染一表模板网页。\n12345app:match(&quot;/index&quot;, function(self)                                                                                                    --这就是LUA Web的风格，只需要一句，Lapis就会去views       --目录下找到index.etlua，然后进行渲染显示。        return &#123; render = &quot;index&quot;&#125;                                                                                             end)\n\n\n总结：\n以上基本上是最简单的Lapis模板创建流程了。\n回到tangguo目录下，运行lapis server。\n打开浏览器，输入http://127.0.0.1:8000，就会在浏览器上显示文本“say hi”。\nPS:在用VIM编辑.etlua文件的时候，默认是不显示语法高亮的，打开高亮需要在第一行加入：\n\n\n\n\n\n\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-119","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"ae80098b451be0ee99995547baaebc08","title":"MoonScript脚本开发简介","content":"Coffescript是一种中间的脚本，可以把这种脚本翻译成JavaScript。而MoonScript，是可以翻译成lua语言的中间脚本。\n本文简单的介绍的：\n\n如何在VIM中，实现MoonScript语法高亮。 \n如何简单的编译MoonScript脚本。\n\n1.安装MoonScript1sudo luarocks install moonscript\n\n2.创建.moon源文件app.moon\n1234lapis = require &quot;lapis&quot;   class extends lapis.Application     &quot;/&quot;: =&gt; &quot;Welcome to Lapis #&#123;require &quot;lapis.version&quot;&#125;!&quot; \n\n\n3.安装MoonScript语法高亮的插件。3-1.下载vim的bundle插件管理程序。\n1git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle\n\n\n3-2.创建.vimrc配置文件。\n1vim ~/.vimrc\n\n\n3-3. 编辑.vimrc文件内容。\n123456set nocompatible                                                                                                                      filetype off                                                                                                                          set rtp+=~/.vim/bundle/vundle/                                                                                                        call vundle#rc()                                                                                                                                      Bundle &#x27;leafo/moonscript-vim&#x27;                                                                                                         syntax enable \n\n\n3-4.进入VIM，安装bundle插件。\n1vim +BundleInstall\n\n\n3-5.翻译成lua脚本,并运行。\n12moonc app.moonlua app.lua\n\n\n\n按照如上步骤操作后:\n\n可以用moonc命令翻译.moon脚本到.lua脚步。\nvim支持moonscript的语法高亮检查。\n\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\nhttp://www.lua.ren\n","slug":"old_topic/2016-09-17-115","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"320b17a08211ddc564acc990b3ffd7ba","title":"DokuWiki系统介绍与部署安装","content":"作者：糖果\nhttp://www.lua.ren\nDokuWiki\n这个Wiki系统之前都没有用过，因为最近一个机会使用了DokuWiki，感觉Wiki系统也大有内容。XML-RPC, Atom协议，Wiki的进化越来越强大。DokuWiki是一个轻量级的 Wiki系统。对说需求不是过于复杂的发布任务来说，足以满足。\nDoku是一个开源的PHP项目。\n在github上的连接:\n因为是PHP项目需要一个PHP的开发环境，这个暂略。\n不过因为安装过程中，会涉及到某些目录的权限修改问题，需要提一下Apache2, 我们采用的Web服务器是Apache，因为是Ubuntu系统，方便的使用了apt-get的安装方式。\n第一步：安装apahce2\n1sudo apt-get install apache2\n\n以apt-get安装的时候，创建了一个www-data的用户组。在安装dokuwiki的时候，需要把一些目录所属权限改成www-data。\n第二步：下载DokuWiki。\n把DokuWiki的源文件下载到/var/www/目录下。\n1git clone https://github.com/splitbrain/dokuwiki\n\n解压，移到目录，在/var/www目录下，创建wiki子目录。\n第三步：修改目录权限。\n需要把DokuWiki根目录下的三个目录权限进行修改。\n修改data目录的权限。\n123456chmod -R 775 data/chown -R www-data:coding data/cd datachmod 2775 &#123;attic,cache,index,locks,media,meta,pages,tmp&#125;chown www-data:coding &#123;attic,cache,index,locks,media,meta,pages,tmp&#125;\n修改conf目录的权限。\n12chmod -R 775 conf/chown -R www-data:coding conf/\n\n第四步：配置Apache配置文件。\n12cd /etc/apache2/sites-enabledsudo vim 000-default.conf\n\n修改监听地址和端口，改成0.0.0.0:80。\n&lt;VirtualHost 0.0.0.0:80&gt;\n修改DocumentRoot,指向DokuWiki的目录。\nDocumentRoot  /var/www/wiki \n重起Apache2。\n1sudo service apache2 restart\n\n第五步：\n安装DokuWiki。\nhttp:XXX.XXX.XXX.XXX/install.php\n安装提示安装可以了。\nDokuWiki支持RPC访问，RPC访问权限设定。\n之后介绍的如何通过客户端程序调用DokuWiki的RPC接口API。\n原文来至糖果室实验室\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-120","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"f8bbe799e3bbd9198fe4b47a5760cfc6","title":"Lua的MD5库","content":"作者：糖果\ncrypto.evp也支持md5,因环境问题，我们采用md5。\n第一：安装。\n1sudo luarocks install md5\n\n\n第二：测试\ntest.lua\n123md5=require&quot;md5&quot;val = md5.sumhexa(&quot;test string&quot;)print(val)\n\n目前来看，这个md5库比较稳定，可以优先选择。\n第三：注意的地方\n如何在解释器(在命令行中，直接输入lua)\n1md5=require&quot;md5&quot;\n\n在引用的时候，不要写成 local md5=require”md5”。\n因为lua local变量的作用域，生存周期的问题，这样声明，在下一 行 “&gt;print(md)”\n得到的结果是nil，显而易见的是，如果nil，后面的调用都没法进行了。\n没有local修饰 md5：md5=require”md5”\nmd5打印出来，才是一个table类型的值，之后的sumhexa才可成功调用。\n底层调用的如下：\n1/usr/local/lib/lua/5.1/md5/core.so\n\n在centos上，安装core.so、des56.so的位置是\n1/usr/lib/lua/5.1/md5\n\nmd5.lua\n1/usr/local/share/lua/5.1\n\ncentos比较麻烦，推荐使用ubuntu\n最后如果遇到复杂的环境问题，就将md5.lua des56.so core.so 复制到当前目录（luarocks install md5产生，也有可能luarocks安装后不生md5.lua，这种就luarocks在centos上的bug,因为.lua是源主件，直接从别的机器制过来…）\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-121","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"00c93259923cc318f00ee1ff616c73ad","title":"GoTTY简介：共享字符终端，变网页应用","content":"作者：糖果\n一.简介。\nGoTTY是一个用Go语言开发的工具，这个工具可以把你的Uinx系列操作系统的命令字符终端，共享成普通的网页应用展示出来。\n使用tmux工具进行终端分屏。\n二.安装。\n安装用两种方式：\na).安装目标机器上有GO开始环境。\n1$ go get github.com/yudai/gotty\n\nb).下载执行文件。\n1https://github.com/yudai/gotty/releases\n下载对应版本的执行文件，运行就可以了。\n三.运行。\n运行GoTTY，其实就意味着，在目标机上启动的一个WEB应用服务，这个服务映射监听了指IP和端口数据，并把本地的terminal终端信息，发送给请求者，\n在远端通过浏览器返问GoTTY服务的用户，就会在她的浏览器网页上，看到你共享的服务器的终端页面。\ngotty 有三个参数：\na 指定地址\np 指定端口\nw 允许用户，授权客户端写TTY。\n我们在Coing上，通过GoTTY分享一个tmux的Web IDE终端：\n1./gotty -a 0.0.0.0 -p 8000 -w tmux\n\n\n1.png\n我们在在浏览器中输入地址：https://qqbsel-8000-kchszv.box.myide.io/\n终端下面的绿条，表示运行tmux，按ctrl+b,再按” 进行分屏幕。\n2.jpg\n在上下窗口分别运行htop、dstat。\n3.png\n我们可以在浏览器中看到分享出来的tmux分屏效果！\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-122","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"6f09c7b7e8900bc4f645404ba465a39b","title":"使用VNC访问VPS的XWindows桌面","content":"作者：糖果\n一般的VPS都提供不SSH得登录方式，通过terminal操作服务器， 除了这种方式，还有让VPS拥有XWindows的Desktop操作模式。\n在这里概要的总结一下，如何用VNC访问VPS上的Linux桌面系统。\n 1：首先要给linux安装桌面系统，VPS使用的是CentOS系统。\n1yum groupinstall &quot;X Window System&quot; &quot;Desktop&quot;\n\n如何不安装这个组件，VNC登陆系统后，看的是黑屏。\n2.安装VNC Server服务。\n1yum install tigervnc-server\n\n使用VNC的客户访问服务器，服务器端必须运行vncserver服务。\nA.查看服务是否安装\n安装之后，我们使用chkconfig | grep vnc 查看一下服务列表中，是否已经添加了这个服务。\nB.启动服务\n1sudo service vncserver start\nC.查看服务是否启动了。\n1netstat -plunt \n\n\n\n\n5901 5902 6001 这三个端口就是vncserver的监听端口，说明服务已经运行。\nD.修改配置文件。\nVNC有一个配置文件在/etc/sysconfig/vncservers目录下。\n文件里是两个定义变量, 其实一看就能明白，默认也是不用改了。\nE.设置VNC密码。\nVNC Viewer访问远程系统的时候，需要输入密码，就在服务器端设置。\nvncpasswd\n按提示输入两次密码就好。\n3.使用VNC Viewer登陆运程系统。\nA.下载地址\n下载一个合适版本的客户端。\nB.使用客户端进入运程系统。\nVNC Server就是VPS的IP地址，结尾要加”:1”\n 之后，按提示输入之前设置的密码，就可以登陆系统了。\n12function test()end\n\n原文连接\n","slug":"old_topic/2016-09-17-124","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"24bcb0d528509f76dbffa1fbd58c1141","title":"使用ZeroBrane远程在线调试Openresty, Nginx的Lua程序","content":"作者：糖果\nZeroBrane是一个开源的Lua编辑器IDE,自带Lua运行程序和基本的库。最主要的一点，就是ZB可以远程在线的调试，nginx或是openresty上运行的lua脚本。\n在编辑方面可以和VIM及插件互补，多去一句，如果花点时间，给VIM按装补全插件，目录插件，tmux, tup，在分屏状态下，vim还是不错的，其实也可以把ZB的远程调试功能，也做插件，让VIM可以进行远程在线调试。\n毕竟把系统的Log打的很全，如果可以在线调试，给WEB服务上运行的脚本程序下断点，对调试工作，也大有裨益。\n下面就开始介绍，ZB如何进行在线调试。\n1.下载ZB。\nhttps://github.com/pkulchenko/ZeroBraneStudio\n里面有一个.sh文件，就是在linux上运行ZB的启动程序。因为我们的Lua WEB程序在VPS上，运行ZB需要给VPS安装Desktop，用VNC连上去。可以参考另外一篇文章。\n图片：1.jpg \n这是运行起来的ZB界面，这个已经进入的调试工作状态。\n2.创建一个Lapis工程，使用如下的命令：\n1lapis new\n\n关于lapis更具体工程创建，也可以参考别一篇文章。\n图片：2.png \n创建工程后，会自动的创建一些文件，在这些文件中关键的文件有：\nnginx.conf（OpenResty的配置文件）\ntest.lua （我们准备调试的主程序）\nmobdebug.lua（ZB开源工程中自带的程序，需要拷贝到当前目录。lualibs/mobdebug）\nsocket.lua（ZB开源工程中自带的程序，需要拷贝到当前目录。lualibs/ ）\n3.修改配置文件。\nnginx.conf\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051worker_processes $&#123;&#123;NUM_WORKERS&#125;&#125;;error_log stderr notice;daemon off;pid logs/nginx.pid;events &#123;  worker_connections 1024;&#125;http &#123;  include mime.types;  lua_package_path &#x27;/usr/home/coding/ide/zerob/lualibs/?/?.lua;/usr/home/coding/ide/zerob/lualibs/?.lua;;&#x27;;  lua_package_cpath &#x27;/usr/home/coding/ide/zerob/bin/clibs/?.so;;&#x27;;  server &#123;    listen $&#123;&#123;PORT&#125;&#125;;    lua_code_cache $&#123;&#123;CODE_CACHE&#125;&#125;;    location / &#123;      default_type text/html;      content_by_lua_file &#x27;test.lua&#x27;;    &#125;    location /static/ &#123;      alias static/;    &#125;    location /favicon.ico &#123;      alias static/favicon.ico;    &#125;  &#125;&#125;\nlua_package_path和 lua_package_cpath，这两个变量是关键的，需要指向你实际ZB的目录。\nlapis自动生成的工程配置文件中，location下面使用的是content_by_lua，直接运行lua语句\n此处，我们直接引用lua文件，改用content_by_lua_file。\n4.创建调试程序。\ntest.lua\n123456789require(&#x27;mobdebug&#x27;).start(&#x27;127.0.0.1&#x27;)tmp_str = &quot;Debug&quot;print(&quot;Lua Lapis&quot;)ngx.say(&quot;Openresty&quot;)require(&#x27;mobdebug&#x27;).done()\n\n可以实现远程调试，很关健的一点就是引用了mobdebug.这个模块，这里的127.0.0.1就是openresty\n服务运行地址。\n5.起动IDE，执行调试。\n我们IDE菜单上的project-&gt; project directory-&gt; choose选择打开，我们这个工程的目录，\n选set from current file, 把工程中的test.lua作为当前要处理的文件。\n下面关键的一点，在project 菜单里，一定要点选 “Start Debugger Server”。\n图片：3.jpg \n国为选中后，ZB就会在后面开一端口监听：\n图片：4.jpg \n注意这个8172就是为调试准备的。\n图片：5.jpg \n远行WEB服务：lapis server\n图片：6.jpg \n下面这张图，就回到了最开始的那张图。\n图片：7.jpg \n我们在浏览器中输入：127.0.0.1:8080\n程序进入状态。\n我们进入Remote console标签页，进行在线调试，直接使用openresy的库函数ngx.say\n图片：8.jpg \n单步下一句，把程序中的tmp_str的内容打到，openresty服务器的控制台上。\n图片：9.jpg \n图片：11.jpg \n我们可以通过自己写一个函数，把输出重定向到文件里，看着更方便。\n使用shit-enter，还可以进行多行输入代码输入。\n我们结束调试，就会看到ngx.say打印的内容出现在网页上。\n图片：12.jpg \n下篇是如何用ZB在线调试Lua WEB程序。\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n致敬英文作者：Paul Kulchenko\nhttp://notebook.kulchenko.com/zerobrane/debugging-openresty-nginx-lua-scripts-with-zerobrane-studio\n","slug":"old_topic/2016-09-17-126","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"41d81acfc6ba0ec970d542063973ecdd","title":"配置VIM的插件补全功能---(在WEB IDE中)","content":"VIM提供了很多的第三方插件，足可以把VIM武装成强大的开发IDE，这次抛砖引玉，介绍一下在coding的WEB IDE环境下，家法配置VIM插件，补全插件。\n1.进入VIM管理目录。\n1cd ~/.vim\n\n2.创建工作目录。\n1mkdir neo\n\n3.下载插件。\n123wget https://github.com/Shougo/neocomplcache.vim/archive/master.zipunzip master.zip\n\n4.解压复制文件。\n12cd neocomplcache.vim-mastercp -r autoload doc plugin vest  ../ \n\n5.配置.vimrc文件\n12vim ~/.vimrclet g:neocomplcache_enable_at_startup = 1\n\n\n\n如果是在coding有default环境下，按如上方法安装，再次打开VIM，就会看到自到补全效果。例如可以输入关键字:”function”。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-116","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"a7008d71061814b111858c062823c704","title":"Lua Lapis安装与项目创建","content":"Lapis是程序员leafo写的一个lua语言的WEB框架，目前已经发布了1.3版本。要求的服务器开发环境是Openresty，而且支持moonscript,这个moonscript语言类似于Javascript的coffescript。起到的作用是，可以用简短moonscript实现你的任务，然后通过翻译程序把moonscript翻译成lua语言。\nLapis还提供了命令行工具，用来管理nginx实例的启动，关闭，重新加载。\n1.安装luarocks.\n在Lua语言生态工具中，有一个类似于Python的Pip一样的引用管理工具，叫做Luarocks。这个工具可以方便的安装，目前在Lua世界中很多的软件包。而如果正好使用的Linux是Ubuntu系统，使用sudo apt-get install luarocks就可以安装Luarocks了。\n2.Lapis的安装:\n当在Linux系统上安装完luarocks之后，使用如下命令就可以安装lapis:\n1luarocks install lapis\n\n\n因为lapis是在有openresty基础上运行，我们假设现在openresty已经安装好了。而lapis提供了命令行程序，提供了快捷的方式创建nginx工程实例和配置文件，并且可以通过lapis命令行，管理服务。\n3.创建工程。\nlapis命令行的名字是“lapis”\n我们在shell环境下运行lapis命令航工具。\n1lapis help\n\n这条命令显示lapis都有哪些子功能，首先我们先用命令创建一个lua的WEB工程。\n1lapis new\n命令执行后，会在当前目录创建一个空应用，会生成三个文件。\n12345app.moonmime.typesnginx.conf\napp.moon是自动生成的一个moonscript脚本，可以通过程序翻译成lua程序。\nmime.types是文件类型描述汇集，会在nginx.conf中include包含进去。\nnginx.conf就是典型的nginx配置文件。\n目前这个阶段可能最需要讲的一下就是nginx.conf文件。\n1234567891011121314151617181920212223242526272829303132333435363738394041worker_processes $&#123;&#123;NUM_WORKERS&#125;&#125;;error_log stderr notice;daemon off;events &#123;  worker_connections 1024;&#125;http &#123;  include mime.types;  server &#123;    listen $&#123;&#123;PORT&#125;&#125;;    lua_code_cache $&#123;&#123;CODE_CACHE&#125;&#125;;    location / &#123;      default_type text/html;      content_by_lua &#x27;        require(&quot;lapis&quot;).serve(&quot;app&quot;)      &#x27;;    &#125;    location /static/ &#123;      alias static/;    &#125;    location /favicon.ico &#123;      alias static/favicon.ico;    &#125;  &#125;&#125;\n\n1include mime.types；\n就是引用mime类型文件之前已经说了。\n1listen $&#123;&#123;PORT&#125;&#125;;\n定义监听的端口， PORT变量的设置，会在之后说明，如果在config文件中设置PORT变量。\n1lua_code_cache $&#123;&#123;CODE_CACHE&#125;&#125;;\ncode cache的设置也是可以在config文件中配置的。lua_code_cache 设定成on，每次编辑修改lua程序的时候，服务会自动的重载入，这在调试环境下也很有用，省去的重启的麻烦。\n剩下的就是三个路由\n1location / &#123;\n这是一个根路由，输入网址后第一个被定为到的页面处理定义。\n12345content_by_lua &#x27;       require(&quot;lapis&quot;).serve(&quot;app&quot;)     &#x27;;\n这就话就是lua lapis程序的入口，location“/”的意思，你只要是输入服务器的IP：PORT,而不指定其他任何后缀，比如：127.0.0.1/，都会调用执行lapis应用（简单说，任何的请求都会执行app.lua脚本，只要在nginx.conf没有同名locate定义。），就是当前工程目录下app.lua的脚本。\n1location /static/ &#123;\n这定义了工程静态文件的位置，用于存放CSS,image,js等静态文件的位置。\n1location /favicon.ico &#123;\n这是一个图片，输入127.0.0.1/favicon.ico,就会在浏览器中显示出。设定我们的服务在前台运行。\n1error_log stderr notice;\n这是在设定，log输出重定向输出到屏幕上。\n1daemon off;\n这么设定对程序员调试很有用，而在实际的生产环境中，可以关掉此选项。配置文件基本注释完了。启动服务。\n1lapis server\n用这条命令来启动一个ningx实例服务，用当前的目录的nginx.conf.lapis会在下面的目录，去搜索openresty的nginx执行文件。\n1234567&quot;/usr/local/openresty/nginx/sbin/&quot;&quot;/usr/local/opt/openresty/bin/&quot;&quot;/usr/sbin/&quot;&quot;&quot;\n停止服务，用ctrl + c，或是使用命令\n1lapis term\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接。\n","slug":"old_topic/2016-09-17-128","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"a3d9eef1ee8531e66bae4c92ae915df4","title":"Lua的MongoDB驱动汇总","content":"作者：糖果\n较常见的Lua的MongoDB的驱动除了官方提供的MongoRover，还有可Openresty集成的驱动lua-resty-mongol。不过在用ZBStudio调试的时候，设置断点，用lua-resty-mongol操作mongodb的时候，会发生不应该出的异常，在线调试的时候，可以考虑用别的库替代，还有一个是5.2以上使用的luamongo，在云风老师的博客上提过这个驱动，还提到一个纯lua实现的库mongo, 最后一个是云风的作品，下面是5个项目的地址。\n1.Resty的驱动，ZBStudio调试有问题（也可能是偶然，后续可再尝试）\n1https://github.com/bigplum/lua-resty-mongol\n\n\n2.官方的驱动，不用启动oprensty服务，可单独运行，依赖libbosn和mongoc库。\n1https://github.com/mongodb-labs/mongorover\n\n3.需要lua5.2以上。\n1https://github.com/moai/luamongo\n\n4.纯Lua实现。\n1https://github.com/daurnimator/mongol\n\n5.云风的实现，很有学习参考价值。\n1https://github.com/cloudwu/lua-mongo\n\n平时本地调试用的是mongorover, 因为用起来非常的自然…\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。http://www.lua.ren\n原文来至于糖果实验室\n","slug":"old_topic/2016-09-17-129","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"b03c3afe71339c53664b24cdf7511d2e","title":"以“99”结尾，奇数价格定价的来由。","content":"the answer to the origin of this strategy is unclear. [3]  There are 3 different theories of its history:\n这个答案的最开始渊源并已经不很清楚了。关于这个，有三种不同的历史说法。\n1.Marketers (such as RH Macy) of mid 1800s tried to ambush their competitors in highly price sensitive goods.\n1800年代中叶市场人员（列如RH Macy公司）试图去伏击竞争对手的高价格紧俏货品，采用的一种手段。\n2.Melville Stone of Chicago Daily News priced his paper at 1 cent. However, given that cents were not in common use then, he coaxed local shops into odd pricing so that his customers will have the pennies to spend on his paper.   \nMelvile Stone给芝加哥新闻日报的定价是1美分，然而，鉴于美分并不常用，他诱使当地商店使用奇数价格的定价，迫使消费者就范，使用商店消费找回的零钱买他的报纸。\n3.As Quora User suggested, it was a cash control mechanism due to the arrival of the cash register. \n像Quora用户建议的那样， 这是因收银机来临而起的一种现金控制机制。\nWhy do they continue to do odd pricing?\n为什么他们继续用奇数定价？\nCustomers see odd numbers as correctly priced rather than whole numbers. They tend to think that a rational process is involved in the pricing and go with the pricing. On the other hand, with whole pricing, some customers perceive that they are being gouged.\n1.消费者认为看到的奇数价格比整数价格更准确。（认为这种价格合理）他们更倾向于有合理定价过程的定价。另一方面，一些消费这可能认为整数定价隐含有一种欺骗。\nOdd pricing also sends a psychological cue that the good is priced to the lowest possible.\n2.奇数价格也发出一种心理暗示，可能这是最底的好价格了。\nIn the earlier days, competitors in commodity products tried to gain more market share by pricing a penny or two lower than their competitors.\n3.在过于的时日，竞争对手为了或得更大的市场份额，总是比对手价格底那么一点。\nVarious researches indicate that customers are swayed more by the most significant first digits of a price tag and sometimes by the last digit. In one research done in 1997 they found that 90% of the prices end with either 9 or 5. However, as customers are subconsciously getting used to these odd prices, other companies like Wal-mart favor more of pricing ending with .98 to stay out of the crowd.\n各种研究表明，消费者总是受到价格的第一个数字，有时是最后一个数字的影响。1997年一项研究他们发现，90%的定价都是9或是5结尾，消费者潜意识里习惯接受了这种奇数定价，而其他公司像沃尔马，钟爱以98定价结尾，而张显与众不同。\n","slug":"old_topic/2016-09-17-118","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"440f944a15eacd750d61d670fceb563d","title":"普通用户使用SUDO安装程序","content":"1.添加用户 \n\n可以用adduser和useradd来添加用户，用userdel来删除用户。\n最简单的命令：\n1sudo adduser test\n会自动同名组，创建/home/test/，从etc/skel/复制文件，并设定密码和相关初始身份信息\n原始一点的命令：\n12sudo useradd -mk /home/test2 -s /bin/bash test2sudo passwd test2\n\n如果将此步骤分解一个一个来做：\n12345sudo mkdir /home/test3sudo useradd -d /home/test3 -s /bin/bash test3sudo chown test3:test3 /home/test3sudo cp /etc/skel/* /home/test3sudo passwd test3\n\n删除用户：\n12sudo userdel testrm -rf /home/test\n\n2.登录普通用户，sudo使用root权限的设置: \n\n进入超级用户su - \n修改sudoers配置文件的属性\n1chmod u+w /etc/sudoers\n\n编辑sudoers文件\n在root ALL=(ALL) ALL下面加一行\n1newusername ALL=(ALL) ALL \n\n退出修改文件属性\n1chmod u-w /etc/sudoers\n\n之后就可以sudo XXX(命令) 执行了。\n在Openresty运行的时候，如用普通用户起动lapis服务，是没有权限访问80端口的,需要使用sudo lapis server的方式，在普通用用户下访问。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\nhttp://www.lua.ren\n","slug":"old_topic/2016-09-17-130","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"d4821869c1f22a5f8395c793ca14a30c","title":"LUA通过授权方式登录Redis","content":"作者：糖果\n123456789101112require &quot;redis&quot;local redis = require &#x27;redis&#x27;local client = redis.connect(&#x27;127.0.0.1&#x27;, 6379)local auth_flg = client:auth(&quot;这里是你的密码&quot;)if not auth_flg then        print(&quot;Auth NG!!!&quot;)end\n\nwww.lua.ren\n","slug":"old_topic/2016-09-17-131","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"222b2df1d56a571ace7dc7573b0f68fd","title":"LUA如何遍历返回的JSON数据","content":"作者：糖果\n代码如下：\n12345678910111213141516171819202122232425function get_json_key(key)        if not key then                return        end        local json_var = client:get(key)        if not json_var then                return        end        local var = json.decode(json_var)        return varendfunction main()        local list = get_json_key(&quot;temp_xxx_key&quot;)        local tmp_ip = &#123; ip &#125;        local new_flg = true        for key, var in pairs(list) do                if var[1] == ip then                  new_flg = false                  break                end        endend\n\n\n值得注意的一点是，lua的json库不是唯一，有json,cjosn,josnrpc等，本篇使用的标标准的用luarocks安装的json库，不同的库调用方式也是不一样的。\n下面是一位网友的问题：遍历所有的table元素。\n1234567891011fc_info = [&#123;&quot;daytext&quot;:&quot;Cloudy&quot;&#125;，&#123;&quot;daytext&quot;:&quot;Cloudy&quot;&#125;，&#123;&quot;daytext&quot;:&quot;Cloudy&quot;&#125;]local data = cjson.decode(sampleJson);local length = table.getn(fc_info)for i=1,length do\t\t\t\tsay(&quot;daytext=====&quot;..fc_info[i][&quot;daytext&quot;])end\t","slug":"old_topic/2016-09-17-132","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua,lua json,lua循环,lua循环遍历","author_index":"安全书"},{"id":"a924894efc1b5c05addcec2e153c3f2f","title":"关于 OPENRESTY 的两三事","content":"编辑：糖果\n基础原理Nginx 采用的是 master-worker 模型，一个 master 进程管理多个 worker 进程，基本的事件处理都是放在 woker 中，master 负责一些全局初始化，以及对 worker 的管理。\n每个 woker 使用一个 LuaVM，当请求被分配到 woker 时，将在这个 LuaVM 里创建一个 coroutine。协程之间数据隔离，每个协程具有独立的全局变量 _G。\n关于 LUA_CODE_CACHE关闭 lua_code_cache 时，require 的处理方式是每次都强制重新加载和解析，也就是说，你对代码的任何修改的效果，都将在上传后立即体现。\n开启 lua_code_cache 时，在同一个 LuaVM 中，模块将在首次加载并解析后被缓存，之后再次 require 将直接返回缓存的内容。换句话说，同一 worker 上的所有请求将共享已加载的模块，任意一个请求对于模块属性的修改，都将影响到同一 worker 上的其他请求。\n不应使用模块级的局部变量以及模块属性，存放任何请求级的数据。否则在 lua_code_cache 开启时，会造成请求间相互影响和数据竞争，产生不可预知的异常状况。\n关闭 lua_code_cache 会极大的降低性能，在生产环境中应开启 lua_code_cache 。\n虽然开发环境中关闭 lua_code_cache 会有一些便利性，但我强烈建议开启 lua_code_cache ，与线上保持一致，以减少不必要的差异性问题和额外测试需求。\n开启 lua_code_cache 时，可用 nginx -s reload 或 kill -HUP masterPID 方式热重载代码，无需重启 Nginx。\n关于 PATH 和 CPATHOpenResty 会将它的 lib 目录加入 package.path 和 package.cpath，但你的项目目录需要自己处理。\n在入口文件中，将项目目录加入 package.path 和 package.cpath 是不可取的。因为 lua_code_cache 开启时，package 模块是同一 worker 上所有请求共享的，如果无条件追加，package.path 和 package.cpath 将不断变长，并最终导致内存溢出。\n以下是我采用的解决方案：\n1234567891011121314151617local ok, app = pcall(require, &quot;core.app&quot;)if ok then    app:run()else    local rootPath = ngx.var.document_root    if not (package.path:find(rootPath)) then        package.path = package.path .. &quot;;&quot; .. rootPath .. &quot;/?.lua;;&quot;    end    if not (package.cpath:find(rootPath)) then        package.cpath = package.cpath .. &quot;;&quot; .. rootPath .. &quot;/?.so;;&quot;    end    require(&quot;core.app&quot;):run()end\n\n关于 LUA-RESTY-MYSQL 和 LUA-RESTY-REDIS不应使用模块级的局部变量以及模块属性，存放 resty.mysql 和 resty.redis 实例。否则，在 lua_code_cache 开启时，同一 worker 的所有请求将共享该实例，造成数据竞争问题。建议将 resty.mysql 和 resty.redis 实例存放到 ngx.ctx 中。\n不能在 require 过程中实例化 resty.mysql 和 resty.redis 实例，否则会报错。例如，模块返回一个 function，此 function 直接或间接调用实例化 resty.mysql 和 resty.redis 的代码，将会导致报错。\n在首次查询时实例化是一个比较好的解决方案：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798local mysql = require(&quot;resty.mysql&quot;)local exception = require(&quot;core.exception&quot;)local dbConf = require(&quot;config.mysql&quot;)local sysConf = require(&quot;config.system&quot;)local MySQL = &#123;&#125;--- 获取连接---- @return resty.mysql MySQL连接-- @error mysql.socketFailed socket建立失败-- @error mysql.cantConnect 无法连接数据库-- @error mysql.queryFailed 数据查询失败function MySQL:getClient()    if ngx.ctx[MySQL] then        return ngx.ctx[MySQL]    end    local client, errmsg = mysql:new()    if not client then        exception:raise(&quot;mysql.socketFailed&quot;, &#123; message = errmsg &#125;)    end    client:set_timeout(3000)    local options = &#123;        user = dbConf.USER,        password = dbConf.PASSWORD,        database = dbConf.DATABASE    &#125;    if dbConf.SOCK then        options.path = dbConf.SOCK    else        options.host = dbConf.HOST        options.port = dbConf.PORT    end    local result, errmsg, errno, sqlstate = client:connect(options)    if not result then        exception:raise(&quot;mysql.cantConnect&quot;, &#123;            message = errmsg,            code = errno,            state = sqlstate        &#125;)    end    local query = &quot;SET NAMES &quot; .. sysConf.DEFAULT_CHARSET    local result, errmsg, errno, sqlstate = client:query(query)    if not result then        exception:raise(&quot;mysql.queryFailed&quot;, &#123;            query = query,            message = errmsg,            code = errno,            state = sqlstate        &#125;)    end    ngx.ctx[MySQL] = client    return ngx.ctx[MySQL]end--- 关闭连接function MySQL:close()    if ngx.ctx[MySQL] then        ngx.ctx[MySQL]:set_keepalive(0, 100)        ngx.ctx[MySQL] = nil    endend--- 执行查询---- 有结果数据集时返回结果数据集-- 无数据数据集时返回查询影响，如：-- &#123; insert_id = 0, server_status = 2, warning_count = 1, affected_rows = 32, message = nil&#125;---- @param string query 查询语句-- @return table 查询结果-- @error mysql.queryFailed 查询失败function MySQL:query(query)    local result, errmsg, errno, sqlstate = self:getClient():query(query)    if not result then        exception:raise(&quot;mysql.queryFailed&quot;, &#123;            query = query,            message = errmsg,            code = errno,            state = sqlstate        &#125;)    end    return resultendreturn MySQL\n\n使用 set_keepalive(max_idle_timeout, pool_size) 替代 close() 将启用连接池特性。set_keepalive 的意思可以理解为，保持连接，并将连接归还到连接池内。这样在下次连接时，会首先会尝试从连接池获取连接，获取不成功才会创建新的连接。在高并发下，连接池能大大的减少连接 MySQL 和 Redis 的次数，明显的提升性能。\n使用模块缓存静态数据利用 lua_code_cache 开启时模块会被缓存的特性，我们可以使用模块来缓存静态数据，其效率接近于将数据缓存在内存中。\n存储方法：\n1234567891011121314local exception = require(&quot;core.exception&quot;)local mysql = require(&quot;core.driver.mysql&quot;)--- 实现示例，可以根据项目情况，完善后封装在数据查询层local function makeCityCache()    local citys = mysql:query(&quot;SELECT * FROM `data_city` WHERE 1&quot;)    local cityData = &#123;&#125;    for _, city in ipairs(citys) do        cityData[city.id] = city    end    package.loaded[&quot;cache.city&quot;] = cityDataend\n\n读取方法：\n12345678910--- 实现示例，可以根据项目情况，完善后封装在数据查询层local function getCityCache(id)    local ok, cacheData = pcall(require, &quot;cache.city&quot;)    if ok then        return cacheData[id]    end    return nilend\n\n清理方法：\n1234--- 实现示例，可以根据项目情况，完善后封装在数据查询层local function clearCityCache()    package.loaded[&quot;cache.city&quot;] = nilend\n\n关于 OPENRESTY 的两三事火星梅梅 | 5 八月, 2013 | OpenResty, 爱 Coding | 2条评论基础原理Nginx 采用的是 master-worker 模型，一个 master 进程管理多个 worker 进程，基本的事件处理都是放在 woker 中，master 负责一些全局初始化，以及对 worker 的管理。\n每个 woker 使用一个 LuaVM，当请求被分配到 woker 时，将在这个 LuaVM 里创建一个 coroutine。协程之间数据隔离，每个协程具有独立的全局变量 _G。\n关于 LUA_CODE_CACHE关闭 lua_code_cache 时，require 的处理方式是每次都强制重新加载和解析，也就是说，你对代码的任何修改的效果，都将在上传后立即体现。\n开启 lua_code_cache 时，在同一个 LuaVM 中，模块将在首次加载并解析后被缓存，之后再次 require 将直接返回缓存的内容。换句话说，同一 worker 上的所有请求将共享已加载的模块，任意一个请求对于模块属性的修改，都将影响到同一 worker 上的其他请求。\n不应使用模块级的局部变量以及模块属性，存放任何请求级的数据。否则在 lua_code_cache 开启时，会造成请求间相互影响和数据竞争，产生不可预知的异常状况。\n关闭 lua_code_cache 会极大的降低性能，在生产环境中应开启 lua_code_cache 。\n虽然开发环境中关闭 lua_code_cache 会有一些便利性，但我强烈建议开启 lua_code_cache ，与线上保持一致，以减少不必要的差异性问题和额外测试需求。\n开启 lua_code_cache 时，可用 nginx -s reload 或 kill -HUP masterPID 方式热重载代码，无需重启 Nginx。\n关于 PATH 和 CPATHOpenResty 会将它的 lib 目录加入 package.path 和 package.cpath，但你的项目目录需要自己处理。\n在入口文件中，将项目目录加入 package.path 和 package.cpath 是不可取的。因为 lua_code_cache 开启时，package 模块是同一 worker 上所有请求共享的，如果无条件追加，package.path 和 package.cpath 将不断变长，并最终导致内存溢出。\n以下是我采用的解决方案：\n1234567891011121314151617local ok, app = pcall(require, &quot;core.app&quot;) if ok then    app:run()else    local rootPath = ngx.var.document_root     if not (package.path:find(rootPath)) then        package.path = package.path .. &quot;;&quot; .. rootPath .. &quot;/?.lua;;&quot;    end     if not (package.cpath:find(rootPath)) then        package.cpath = package.cpath .. &quot;;&quot; .. rootPath .. &quot;/?.so;;&quot;    end     require(&quot;core.app&quot;):run()end\n\n关于 LUA-RESTY-MYSQL 和 LUA-RESTY-REDIS不应使用模块级的局部变量以及模块属性，存放 resty.mysql 和 resty.redis 实例。否则，在 lua_code_cache 开启时，同一 worker 的所有请求将共享该实例，造成数据竞争问题。建议将 resty.mysql 和 resty.redis 实例存放到 ngx.ctx 中。\n不能在 require 过程中实例化 resty.mysql 和 resty.redis 实例，否则会报错。例如，模块返回一个 function，此 function 直接或间接调用实例化 resty.mysql 和 resty.redis 的代码，将会导致报错。\n在首次查询时实例化是一个比较好的解决方案：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798local mysql = require(&quot;resty.mysql&quot;)local exception = require(&quot;core.exception&quot;)local dbConf = require(&quot;config.mysql&quot;)local sysConf = require(&quot;config.system&quot;) local MySQL = &#123;&#125; --- 获取连接---- @return resty.mysql MySQL连接-- @error mysql.socketFailed socket建立失败-- @error mysql.cantConnect 无法连接数据库-- @error mysql.queryFailed 数据查询失败function MySQL:getClient()    if ngx.ctx[MySQL] then        return ngx.ctx[MySQL]    end     local client, errmsg = mysql:new()     if not client then        exception:raise(&quot;mysql.socketFailed&quot;, &#123; message = errmsg &#125;)    end     client:set_timeout(3000)     local options = &#123;        user = dbConf.USER,        password = dbConf.PASSWORD,        database = dbConf.DATABASE    &#125;     if dbConf.SOCK then        options.path = dbConf.SOCK    else        options.host = dbConf.HOST        options.port = dbConf.PORT    end     local result, errmsg, errno, sqlstate = client:connect(options)     if not result then        exception:raise(&quot;mysql.cantConnect&quot;, &#123;            message = errmsg,            code = errno,            state = sqlstate        &#125;)    end     local query = &quot;SET NAMES &quot; .. sysConf.DEFAULT_CHARSET    local result, errmsg, errno, sqlstate = client:query(query)     if not result then        exception:raise(&quot;mysql.queryFailed&quot;, &#123;            query = query,            message = errmsg,            code = errno,            state = sqlstate        &#125;)    end     ngx.ctx[MySQL] = client    return ngx.ctx[MySQL]end --- 关闭连接function MySQL:close()    if ngx.ctx[MySQL] then        ngx.ctx[MySQL]:set_keepalive(0, 100)        ngx.ctx[MySQL] = nil    endend --- 执行查询---- 有结果数据集时返回结果数据集-- 无数据数据集时返回查询影响，如：-- &#123; insert_id = 0, server_status = 2, warning_count = 1, affected_rows = 32, message = nil&#125;---- @param string query 查询语句-- @return table 查询结果-- @error mysql.queryFailed 查询失败function MySQL:query(query)    local result, errmsg, errno, sqlstate = self:getClient():query(query)     if not result then        exception:raise(&quot;mysql.queryFailed&quot;, &#123;            query = query,            message = errmsg,            code = errno,            state = sqlstate        &#125;)    end     return resultend return MySQL\n\n使用 set_keepalive(max_idle_timeout, pool_size) 替代 close() 将启用连接池特性。set_keepalive 的意思可以理解为，保持连接，并将连接归还到连接池内。这样在下次连接时，会首先会尝试从连接池获取连接，获取不成功才会创建新的连接。在高并发下，连接池能大大的减少连接 MySQL 和 Redis 的次数，明显的提升性能。\n使用模块缓存静态数据利用 lua_code_cache 开启时模块会被缓存的特性，我们可以使用模块来缓存静态数据，其效率接近于将数据缓存在内存中。\n存储方法：\n123456789101112131415local exception = require(&quot;core.exception&quot;)local mysql = require(&quot;core.driver.mysql&quot;) --- 实现示例，可以根据项目情况，完善后封装在数据查询层local function makeCityCache()    local citys = mysql:query(&quot;SELECT * FROM `data_city` WHERE 1&quot;)    local cityData = &#123;&#125;     for _, city in ipairs(citys) do        cityData[city.id] = city    end     package.loaded[&quot;cache.city&quot;] = cityDataend\n读取方法：\n12345678910--- 实现示例，可以根据项目情况，完善后封装在数据查询层local function getCityCache(id)    local ok, cacheData = pcall(require, &quot;cache.city&quot;)     if ok then        return cacheData[id]    end     return nilend\n清理方法：\n1234--- 实现示例，可以根据项目情况，完善后封装在数据查询层local function clearCityCache()    package.loaded[&quot;cache.city&quot;] = nilend\n数据存储_G\n请求级 table 变量，生命周期为本次请求，可存储请求级任意 Lua 数据。\nNGX.CTX\n请求级 table 变量，生命周期为本次请求，可存储请求级任意 Lua 数据。\nNGX.SHARED.DICT\n全局级 key-value 字典，使用共享内存实现，实现了读写锁，所有请求均可安全读写。value 只能为布尔值、数字和字符串。Reload Nginx 时不会受影响，只有当 Nginx 被关闭时才会丢失。\n模块属性和模块级局部变量\nworker 级变量，同一 worker 的所有请求共享，没有读写锁，多个请求同时写入时不安全。\n多谢原作者的分享：http://zivn.me/?p=157\n","slug":"old_topic/2016-09-17-135","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"ceeda26fcc5b2c890a2ed530be0ef341","title":"OPENRESTY 中的简易HTTP加密","content":"需求速度快；可逆；容易实现，不存在语言障碍；思考将一个任意内容的字符串作为密钥，从明文中取等长字符串，逐字节将明文和密钥进行异或计算，得到密文。循环处理整个明文，得到完整密文。对密文进行同样的运算即可解密。\n算法\n123456789101112131415161718192021222324local bit = require(&quot;bit&quot;) --- 使用密钥对字符串进行加密(解密)---- @param string str 原始字符串(加密后的密文)-- @param string key 密钥-- @return string 加密后的密文(原始字符串)local function encrypt(str, key)    local strBytes = &#123; str:byte(1, #str) &#125;    local keyBytes = &#123; key:byte(1, #key) &#125;    local n, keyLen = 1, #keyBytes     for i = 1, #strBytes do        strBytes[i] = bit.bxor(strBytes[i], keyBytes[n])         n = n + 1         if n &gt; keyLen then            n = n - keyLen        end    end     return string.char(unpack(strBytes))end\n测试\n123456789101112131415-- 加密密钥local ENCRYPT_KEY = &quot;EFH@^&amp;%#^&amp;*@#G@&amp;()*!&amp;*@)(#$!@$GJHGHJ$G#HJ!$G&quot; -- 原始字符串local originalStr = &quot;Hello, world! Hello, world! Hello, world! Hello, world! Hello, world! Hello, world!&quot; -- 加密字符串local encryptStr = encrypt(originalStr, ENCRYPT_KEY) -- 打印密文print(&quot;encryptStr:&quot; .. encryptStr) -- 打印原文print(&quot;originalStr:&quot; .. encrypt(encryptStr, ENCRYPT_KEY))\n\n\n处理加密 POST 数据客户端将通讯数据组成 URI 模式字符串，并用本地语言实现加密算法，将加密后的密文通过 POST 方式提交，服务端使用加密算法将 POST 数据还原成明文并解析成参数表。\n12345678910-- 准备body数据ngx.req.read_body() -- 解密body数据，并解析成table格式local postData = &#123;&#125;local encryptData = ngx.req.get_body_data() if encryptData then    postData = ngx.decode_args(encrypt(encryptData, ENCRYPT_KEY))end\n\n感谢原作者分享：http://zivn.me/?p=183\n","slug":"old_topic/2016-09-17-136","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"e77113c5554b3f904d7fab1c518f6770","title":"NGINX配置初始化过程","content":"nginx解析配置文件，将解析出来得配置存放在ngx_cycle_s的conf_ctx中，conf_ctx是个四级指针，因为保存这些配置需要context，而这些context是有层级关系，最终的配置结构如图：\n图片：27767798_1370416906jegE.png \n http模块的配置有些复杂，由于server的配置还可以出现在http模块中，同时location的配置可以出现在http模块或者server模块中，所以对于http来说也就是最上面的那个ngx_http_ctx_conf_t有srv_conf和loc_conf是十分有必要的，这两个指针后面的结构体数组保存了在http中的那些server的和location的配置。同样对于每个server来说，不需要单独的main配置了，直接引用main的就可以。每个server必须有自己单独的ngx_http_core_srv_conf_t，来保存当前server块内的配置，这个配置最后会和http的里面的ngx_http_core_srv_conf_t做merge，这个merge是把父server的配置merge到子server配置上面。对于location的配置，在http和server中都可以配置，那么merge的操作需要首先把http的location配置merge到每个server配置中，然后每个server的location配置再和每个location模块中的配置进行merge，这里location配置需要merge两次。举例ngx_http_core_module模块merge的过程：\n图片：27767798_1370417515HdmN.png\n merge过程是按照module一个一个module的merge，第一步从main配置里面的servers，遍历每个server，把main里面的server配置merge到每个server的配置中，然后把main里面的location配置merge到每个server的location的配置中。第二步再次遍历每个server的locations，把这个server的location的配置merge到具体的每个location中。代码：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static char *ngx_http_merge_servers(ngx_conf_t *cf, ngx_http_core_main_conf_t *cmcf,    ngx_http_module_t *module, ngx_uint_t ctx_index) //cmcf代表http的main配置&#123;     char *rv;     ngx_uint_t s;     ngx_http_conf_ctx_t *ctx, saved;    ngx_http_core_loc_conf_t *clcf;    ngx_http_core_srv_conf_t **cscfp;    cscfp = cmcf-&gt;servers.elts;             //得到servers数组，cmcf是main层的配置    ctx = (ngx_http_conf_ctx_t *) cf-&gt;ctx; //ctx是main的 ngx_http_conf_ctx_t    saved = *ctx;    rv = NGX_CONF_OK;    for (s = 0; s &lt; cmcf-&gt;servers.nelts; s++) &#123; //遍历每个server，把main的配置merge到每个server中        /* merge the server&#123;&#125;s&#x27; srv_conf&#x27;s */        ctx-&gt;srv_conf = cscfp[s]-&gt;ctx-&gt;srv_conf;         if (module-&gt;merge_srv_conf) &#123;           //调用模块的merge server操作            rv = module-&gt;merge_srv_conf(cf, saved.srv_conf[ctx_index],                                        cscfp[s]-&gt;ctx-&gt;srv_conf[ctx_index]); //save.srv_conf是父server配置，cscf-&gt;ctx-&gt;srv_conf是当前server的配置，相当于图中的第一步            if (rv != NGX_CONF_OK) &#123;                goto failed;            &#125;         &#125;         if (module-&gt;merge_loc_conf) &#123; //调用模块的merge location操作，把父location配置merge到每个server的location配置相当于图中的第一步            /* merge the server&#123;&#125;&#x27;s loc_conf */            ctx-&gt;loc_conf = cscfp[s]-&gt;ctx-&gt;loc_conf;            rv = module-&gt;merge_loc_conf(cf, saved.loc_conf[ctx_index],                                        cscfp[s]-&gt;ctx-&gt;loc_conf[ctx_index]);            if (rv != NGX_CONF_OK) &#123;                goto failed;            &#125;             /* merge the locations&#123;&#125;&#x27; loc_conf&#x27;s */            clcf = cscfp[s]-&gt;ctx-&gt;loc_conf[ngx_http_core_module.ctx_index];            rv = ngx_http_merge_locations(cf, clcf-&gt;locations,                                          cscfp[s]-&gt;ctx-&gt;loc_conf,                                          module, ctx_index); //该merge每个server的location配置到每个location的配置中了，相当于图中的第二步            if (rv != NGX_CONF_OK) &#123;                goto failed;            &#125;        &#125;    &#125;\n\nserver中location和location的merge过程\n1234567891011121314151617181920212223242526272829303132333435363738static char *ngx_http_merge_locations(ngx_conf_t *cf, ngx_queue_t *locations,    void **loc_conf, ngx_http_module_t *module, ngx_uint_t ctx_index)&#123;    char *rv;    ngx_queue_t *q;    ngx_http_conf_ctx_t *ctx, saved;    ngx_http_core_loc_conf_t *clcf;    ngx_http_location_queue_t *lq;    if (locations == NULL) &#123;        return NGX_CONF_OK;    &#125;    ctx = (ngx_http_conf_ctx_t *) cf-&gt;ctx;    saved = *ctx;    for (q = ngx_queue_head(locations);      //遍历server中的locations队列         q != ngx_queue_sentinel(locations);         q = ngx_queue_next(q))    &#123;        lq = (ngx_http_location_queue_t *) q;        clcf = lq-&gt;exact ? lq-&gt;exact : lq-&gt;inclusive;         ctx-&gt;loc_conf = clcf-&gt;loc_conf;        rv = module-&gt;merge_loc_conf(cf, loc_conf[ctx_index],                                    clcf-&gt;loc_conf[ctx_index]); //loc_conf代表server下location配置，clcf-&gt;loc_conf代表每个location的配置        if (rv != NGX_CONF_OK) &#123;            return rv;        &#125;        rv = ngx_http_merge_locations(cf, clcf-&gt;locations, clcf-&gt;loc_conf,                                      module, ctx_index);        //递归嵌套location        if (rv != NGX_CONF_OK) &#123;            return rv;        &#125;    &#125;\n\n\n感谢作者分享，原文地址：http://blog.chinaunix.net/uid-27767798-id-3757684.html\n","slug":"old_topic/2016-09-17-134","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"1c16f4ddd5c0935af18ce72063de0291","title":"如何在SAE上架设RPC服务与Openresty的Lua服务通信","content":"作者：糖果\n有时候我们写的服务可能会部署到很同种不同类型的服务器上，有一些数据，可能不便于存在本地，需要一个数据中心，保存这些数据。\n我们要求是这样的：\n1．客户端服务要周期性的去服务器上拉取数据。（存在SAE MySQL中）。\n2．不使用长连接的方式通信，使用基于HTTP的协议。\n3．客户端与数据库交互不依赖服务器端采用什么数据库，抽象出一层数据访问层。\n基于以上三点：\n服务器端：我们将服务器服务架设到SAE的云端，使用SAE支持的Python语言，WEB框架使用的Django,通过RPC协议，为客户端提供服务。服务端的数据存储在SAE的MySQL数据库中，为使服务器端可以对外开发RPC服务接口，使用开源的RPC服务端解决方案RPC4Django。\n客户端：这里的客户端其是架设在另一台服务器的Openresty服务，使用Lua语言进行扩展，加入了定时拉取访问数据的流程演示模块，至于如何接定RPC接口，传输什么数据，看具体的实际业务，这里只是通过程序演示这个机制如何在SAE上完成变互的过程。\n客户访问端使用持术是用Openresty做服务器，用Lua Lapis框架写成应用。在客户访问端需要做以下几件事情：\n1.安装Openresty服务器，按装Lua Lapis框架。\n2.使用Lua  Lapis创建一个Openresty的项目。\n3.配置Openresty，创建一个定时作任务。\n这时我们先跳出Lua阶段，进行SAE端Python的RPC服务的,部署和编码，然后回来完成，客户端的剩下的两个动作。\n4.用Lua RPC Client访问SAE上的RPC服务。\n5.将取得的数据，存储到客户端的Openresty服务器的ShareDiction中，供本地其它业务使用些数据。\n下面开始：\n第1步：Openresty服务器安装和Lapis框架部署（此处只介绍Lapis的安装），更详细的信息请参考如下文章。\na). 安装luarocks。\n1sudo apt-get install luarocks\n\n\nb). 通过luarocks安装lapis框架。\n1sudo luarocks install lapis\n\n\n第2步：用Lapis 创建Openresty工程.\n1lapis new\n\n命令执行后，会生成下面所示的目录结构。\n3.在Openresty中创建一个定时任务。\n定时器的实现思想如下：\n让Openresty去加载一个lua脚本，脚本通过启动一个timer设定，调用一个函数，在被调用的函数内部，循环递归的进行time设定，调用这个被周函数本身，利用这种周期性的调用事件，我们定时递归的函数体中，执行一个函数过程CallRPC（）去通过RPC协议访问SAE云上的数据。\nRPC接口定义与实现，在下面接下来的Django部分会详细说明，下面就是提到的函数。此函数的主要的目的是6秒钟的时间间隔，通过RPC协议，拉取SAE上Mysql数据库里的数据，至于传输什么数据是和你的业务直接相关的，我们此处就使用一个简单的数据结构来说明问题。\n12345678910111213141516171819202122232425262728293031local handlerfunction handler(premature, params)     --CallRPC就是Lua通过JSON.RPC访问SAE的RPC服务器。     CallRPC()     --递归的timer，重复调用handler函数。     local ok, err = ngx.timer.at(6, handler, &quot;params-data&quot;)     ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok, &quot; err:&quot;, err)end--第一次设定timer，调用hander函数。local ok, err = ngx.timer.at(6, handler,&quot;params-data&quot;)ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok,&quot; err:&quot;, err)--判断第一次调用是否成功，如查不成功，把问题原因打印出来。if not ok then       ngx.log(ngx.ERR, &quot;err:&quot;, err)end\n\n创建SAE上的RPC服务：\n完成创建工作需要五步：\n\n创建一个Django工程 。\n\n安装RPC4Django。\n\n.创建立数据库表。\n\n实现RPC服务接口。\n\n启动RPC服务。\n\n\n我们先暂停Openresty的部分，先介绍如何在SAE构建RPC服务器。\n之前已经提过，构SAE上的RPC服务使用的是SAE的PYTHON服务，使用的也是SAE天然支持的Django框架。下面介绍的是创建一个Django工程，SAE天然支持 Django, Tornado, Flask框加。如果需要更多信息，请参考如下文章。\nhttp://www.epubit.com.cn/article/143\n服务器端\n第一步：创建一个Django工程 。\na).  创建工程。\n1django-admin.pystartproject testrpc\n\n\nb).  在工程内创建APP。\n1pythonmanage.py startapp myrpc\n\n\n\n两格指令执行后，系统上建立如下的目录结构。\n这表明Djago已经成功能完成创建工程和APP。\n第二步：安装RPC4Django。\nRPC服务主要靠的就是用RPC4Django来实现，rpc4django是一个开源项目，项目的地址如下：https://github.com/davidfischer/rpc4django\nrpc4django也是一个Django的App，使用的话，只要在setting.py配置文件中引用即可。\n修改testrpc文件夹中的setting.py文件,如下图：\n把rpc4django加入到工程安装的APP的列表里，这样就可以像引用普APP一样使用rpc4django了。\n第三步.创建立数据库表。\nDjango是MVC模式的Python框加，并且支持ORM，只要定一义一个Python的Model类，就可以同步生成数据库表。\n我们在myrpc文件夹下的models.py里面加入表定义类，如下图：\n创建完Model模块类后，需要同步一下DB，将Django根据类的定义生成对应的DB表格。\n1pythonmanage.py syncdb\n如果之前安装了SAE的本地运行环境的话，可能使用cloudsql.py 直接访问远端的SAE数据库命令行。\n执行后同步后，我们查看一下MyRPC数据库表的定义。\n上图所示，表生成成功。\n第四步.实现RPC服务接口。\n因为使用rpc4django，生成一个RPC接口，就变的简单很多。\n之前在新建的每一个Django App的时候，对应每个APP文件夹都有一个__init__.py文 ，我们在此文件中声明函数，并且使用rpcmethod装饰器，就会对应产生一个RPC服务接口，可以提供给客户端访问使用。这里我们就创建了一个叫做testrpc.MyRPC的RPC服务接口，返回的数据类型是一个数驵元素。这个数组的取得，就是通过Django的ORM模型，访问了我们之前所定义的MySQL数据表MyRPC。\n第五步：启动RPC服务。\n经过以上四步，一个最简单的SAE上的RPC服务就架设完了，让我们启到一个这个应用，然后RPC服务才可用。\n1Python manager.py runserver 127.0.0.1:8080\n\n回到之前的Lua介绍，还剩下的步骤:\n1.Lua调用 SAE上的RPC服务接口。\n2.将返回的数据写入Openresty的ShareDiction中。\n3.使用Lapis模板系统，将返回结果显示到网页上。\n（此部分略，可参考此连接内容：http://www.epubit.com.cn/article/158）\n第一步：如何使用Lua RPC客户端访问RPC。\nLua访问RPC使用的库是JSON库的RPC机能，原来还是通过HTTP向服务器发送一定格式的\nJSON数据，并将服务器返回的数据，从JSON数据专成函数可以直接使用数据。\n12345678910111213json=require&quot;json&quot;require&quot;json.rpc&quot;function CallRPC()list, error =json.rpc.call(&quot;http://XXX.sinaapp.com/RPC&quot;,&quot;testrpc.MyRPC&quot;)for _key, _val in pairs(list) do    print  _val    print &quot;\\n&quot;end\n运行后会把SAE上数据库表里的数据返回，并打印出来，如下图：\n第二步：将返回的数据写入Openresty的ShareDiction中。\n我们已经通过Lua RPC客户端，访问RPC服务，将数据返回了，我们还需要将读取的数据存储到Openresty的ShareDiction里，提供给Openresty的Lua系统内部其它模块使用。\n使用ShareDiction首先要修改.conf配置文件，需要在文件加入如下内容：\n1234567http &#123;  include mime.types;  lua_shared_dict g_dict 10m;  ...\n\n创建了一个名字为g_dict的10m的共享字典，我们需要的就是将取后的数据，存入到共享字典中，封闭一个简单的函数来存储返回值。\n123456789101112function set_key(_key,_value)    if _key then    local g_dict = ngx.shared.g_dict        g_dict:set(_key, _value)      endend\n\n第三步：使用Lapis模板系统，将返回结果显示到网页上。\n（此部分略，可参考此连接内容：http://www.epubit.com.cn/article/158）\n接下来，还会介绍，如何利用Django的用户验证系统，进行RPC的限制性访问。\n（通过JS调用SAE上的RPC服务。）\n如何在SAE上，使用BeautifulSoup在线分析指定网站内容的文章。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-123","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"cbbd7e228645caa3cfb0dd345f9fe075","title":"最简单的LUA随机数生成","content":"[code]math.randomseed(os.time())for i=1, 5 do print(math.random())end\n[/code]\n","slug":"old_topic/2016-09-17-139","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"62ab39d0bc32c5ce1245ceed42efb629","title":"Python的List和C++的Vector的对比","content":"作者：糖果\n简单的对比了一下Python的List和C++的Vector操作，用Python代替C++的注释。\n另外推荐一个在线的编译器，codepad.org。\n1.定义数据\nPython\n\n1candyList = [&quot;Red Candy&quot;, &quot;Green Candy&quot;, &quot;Blue Candy&quot;, &quot;Yello Candy&quot;]\n\n\n\nC++\n1vector&lt;string&gt; candyList;\n\n2.增加元素\nPython\n1234candyList.append(&quot;Append Candy&quot;)candyList.insert(1, &quot;Insert Candy&quot;)candyList.extend([&quot;Extend Candy Front&quot;, &quot;Extend Candy Background&quot;])candyList = candyList + [&quot;Add Candy Front&quot;, &quot;Add Candy Background&quot;]\n\nC++\n1234candyList.push_back(&quot;Red Candy&quot;);candyList.push_back(&quot;Green Candy&quot;);candyList.push_back(&quot;Blue Candy&quot;);candyList.push_back(&quot;Yellow Candy&quot;);\n\n\n3.删除元素\nPython\n\n12candyList.pop()candyList.remove(&quot;Insert Candy&quot;)\n\nC++\n\n12candyList.pop_back();candyList.erase(candyList.begin(), candyList.begin()+1);\n\n4.查找\nPython \n123candy = candyList[3]candy = candyList[-1]candy = candyList[-3]\n\nC++ \n\n12candyList.at(0);vector&lt;string&gt;::iterator it = candyList.begin() + 1;\n\n字典 \n\n5.定义\n123456candyMap = &#123;&quot;Red&quot;:&quot;R&quot;, &quot;Green&quot;:&quot;G&quot;, &quot;Blue&quot;:&quot;B&quot;&#125;map = [&quot;%s=%s&quot; % (k,v) for k,v in candyMap.items()]color = candyMap[&quot;Red&quot;]candyMap.keys()candyMap.values()candyMap.items()\n\n6.连接分割\n123str = &quot;;&quot;.join([&quot;%s=%s&quot; % (k,v) for k,v in candyMap.items()])candyList = str.split(&quot;;&quot;)\n\n\n7.过滤器count()是查找元素在list中的位置下标值。\n1[elem for elem in candyList if candyList.count(elem) == 1]\n\n\n8.遍历\nPython \n\n1234567len(candyList)list = [elem for elem in candyList]list = [elem for elem in candyList if len(elem) &gt; 9]candyList = [&quot;red&quot;, &quot;green&quot;, &quot;blue&quot;]for elem in range(len(candyList)):        print candyList[elem]\n\nC++ \n1234567for (int i=0; i &lt; candyList.size(); i++) &#123;     cout &lt;&lt; candyList.at(i) &lt;&lt; endl;&#125;for (vector&lt;string&gt;::iterator it = candyList.begin(); it != candyList.end(); ++it) &#123;     cout &lt;&lt; *it &lt;&lt; endl;&#125;\n\n123456789101112131415161718192021#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int main(int argc, char** argv) &#123;        vector&lt;string&gt; candyList;        candyList.push_back(&quot;Green Candy&quot;);        candyList.push_back(&quot;Blue Candy&quot;);        candyList.push_back(&quot;Yellow Candy&quot;);        for (int i=0; i &lt; candyList.size(); i++) &#123;                cout &lt;&lt; candyList.at(i) &lt;&lt; endl;        &#125;        vector&lt;string&gt;::iterator it;        candyList.erase(candyList.begin(), candyList.begin()+1);        candyList.pop_back();           cout &lt;&lt; &quot;###SPLIT###&quot; &lt;&lt; endl;        for (vector&lt;string&gt;::iterator it = candyList.begin(); it != candyList.end(); ++it) &#123;                cout &lt;&lt; *it &lt;&lt; endl;        &#125;&#125;\n\n\n[后记]Python里的join和split很好用，一般的算法原型，完全可以先用python写出来，然后再改成C++，为什么这么干？\n注释：个人劳动成果，转载使用请注明本文作者及出处链接，谢谢合作！\n","slug":"old_topic/2016-09-17-14","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"d52502bd5958725397262906a370cd45","title":"Openresty的ngx_http_lua_balancer代码下载","content":"Openresty代码下载，已经替换过了ngx_http_lua_balancer模块：\n点击链接下载：\n","slug":"old_topic/2016-09-17-140","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"a7f454cd8b8cc1ba699e660a76d25326","title":"LUA FAQ","content":"LUA FAQ \n\n\nLua判断空表的正确姿势\nLua中ipair和pair关键字的区别是什么？ \nLua的转义符号“%” \nNginx用户权限(文件读写时候应该注意到的问题) \n关于 OPENRESTY 的两三事 \nNGINX配置初始化过程\nOPENRESTY 中的简易HTTP加密\n","slug":"old_topic/2016-09-17-133","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"1c4e1c2d58b108caf66093510a587e9f","title":"Windows版本的Openresty文件下载","content":"openresty for windows32位 \nopenresty for windows64位\n","slug":"old_topic/2016-09-17-141","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f92daeec6e530de0b09511ed8dbb5099","title":"Nginx用户权限(文件读写时候应该注意到的问题)","content":"Nginx用户权限\nNginx用户权限\n有时候当Nginx读取本地目录时会收到403错误，权限问题。先来了解一下Nginx的用户管理，Nginx在以Linux service脚本启动时，通过start-stop-domain启动，会以root权限运行daemon进程。\n然后daemon进程读取/etc/nginx/nginx.conf文件中的user配置选项，默认这里的user=nginx也就是用nginx用户启动worker process。403错误就是因为nginx用户没有权限访问我当前开发用的用户目录，/home/dean/work/resources。\n解决方法是将user=nginx替换成root，然后重新启动nginx，可以了。其他方法也试过，比如给/home/dean/work/resources目录设置777权限，比如将nginx用户加入root组，都不行。\n所以当开发的时候，就用user=root配置吧。至于产品环境下，resouces目录完全可以放到nginx用户目录下，所以问题不大。\n感谢作者分享：http://www.2cto.com/os/201306/218538.html\n","slug":"old_topic/2016-09-17-142","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a727f439282961c5a114ce0175689f60","title":"Python FAQ","content":"Python FAQ\nFlask 教程，第二部分：模板\n\n\n\n\nPython多分隔符号拆分字符串\n","slug":"old_topic/2016-09-17-146","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"7f033721bb83cf2964dc352671260885","title":"Windows下LUA配置环境变量(LDT)","content":"下面举个例子，在LDT下，如保设定环境变量，让IDE知道Lua安装的位置。\n1LUA_CPATH=/usr/lib64/lua/5.1/?.so;?.so;/home/merge/1209/Core/lua_client/?.so;?.so;/usr/local/lib/lua/5.1/?.so;?.so\n\n\n\n1LUA_PATH=/usr/share/lua/5.1/?.lua;?.lua;/home/merge/1209/Core/lua_client/?.lua;*.lua;/usr/local/share/lua/5.1/?.lua;*.lua;","slug":"old_topic/2016-09-17-149","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"70c113f1b89df0b719f9ae169720a491","title":"Lua功能模块之“加密”","content":"作者：糖果\n在Lua开发的世界中，有很多开源的模块，分布在一些网站（比如开普勒项目），github上，有的都已经配置好了，可以向python的pip工具一样，只不过在lua世界中使用luarocks安装工具快速的安装。\n我们在开发的工作中，难免要对一些数据进行加密处理，而加密模块的使用有是就必不可少。\n在lua官方的WIKI列表中就列出了，很多lua程序写的加密库，这写加密库有的是用纯lua写的，也有用lua调用C的程序实现加密。不过有些时候甄选这些库还是需要花一些时间精力，只是需要测试一下这是加密算是否是好用的\n这是lua组织列出的一览列表。\n1http://lua-users.org/wiki/CryptographyStuff\n\n\n说一下为什么要加密，我们面临的任务是什么！我们现在面临的任务是，要对一段字符串进行sha256算法加密。\n我们从列表中选出了几个支持sha256加密的包，并说明一下这几个工具包。\n1.SecureHashAlgorithm和SecureHashAlgorithmBW \n这个工具包是支持sha256加密的，而且是纯lua方法的实现，问题是，这两个包分别依赖lua5.2和lua5.3。\n\n而我们系统的运行环境是lua5.1，因为大部分的生产环境都是lua5.1，因为历史原因暂时没法改变。如果要把5.2的程序移植到5.1下运行，还需要移植一个lua5.2才独有的包，这是lua5.2升级之后才有的部件：bit32,而在lua5.3中又将这个部件去掉了,移植的动力不大，暂时不使用这个包。\n2.Lcrypt \n\n这个包不是纯lua的实现，底层加密用的是C语言，而且额外还有依赖另外另个工具包 libTomCrypt和libTomMath，这两个包的官网已经被和谐了，github上有源码，所以要想让这个包正常运行需要手动make安装3个源码工程，还是算了，有时间的时候再装好测试一下，先暂时不用。\n网站：\n1http://www.eder.us/projects/lcrypt/\n\n3.LuaCrypto \n\n这个包的安装用的是luarocks，就比较简单了 luarocks install luacrypto ，我们选用这个包进行加密处理。\nLuaCrypto其实是openssl库的前端lua调用，依赖openssl，openssl库显然会支持sha256加密，相对也比一般的第三方实现更可靠。\n写一个简单的加密程序：\n12345678local crypto = require(&quot;crypto&quot;)local hmac = require(&quot;crypto.hmac&quot;)local ret = hmac.digest(&quot;sha256&quot;, &quot;abcdefg&quot;, &quot;hmackey&quot;)print(ret)\n\nret的返回结果是，如下这个字符串。\n1704d25d116a700656bfa5a6a7b0f462efdc7df828cdbafa6fbf8b39a12e83f24\n\n我们需要改造一下代码，在调用digest的时候指定输出的形式是raw二进制数据形式，然后在编码成base64的数据形式。\n123local ret = hmac.digest(&quot;sha256&quot;, &quot;abcdefg&quot;, &quot;hmackey&quot;,rawequal)print(ret)\n\n这时候的输出结果是：\n1cE0l0RanAGVr+lpqew9GLv3H34KM26+m+/izmhLoPyQ=\n\n\n\n\nlua-base64使用的是下面的库，lua库就是这样，有很多功能程序有很多的实现，并且很多非官方的第三方实现。\n1https://github.com/toastdriven/lua-base64\n\n\n=============================================================\n同样的我们再写一个php的测试程序：\n1234567&lt;?php$ret = hash_hmac(&#x27;sha256&#x27;, &#x27;abcdefg&#x27;, &#x27;hmackey&#x27;, false);print($ret)?&gt;\nret的返回结果是，如下这个字符串。\n704d25d116a700656bfa5a6a7b0f462efdc7df828cdbafa6fbf8b39a12e83f24\n没有确认php的hash_hamc是否底层调用的也是openssl的加密算法，至少从目前的测试结果来看，两种语言加密返回的结果是一致的。\n我们同样需要改造一下php代码的调用加密的方式：\n1234567&lt;?php$ret = hash_hmac(&#x27;sha256&#x27;, &#x27;abcdefg&#x27;, &#x27;hmackey&#x27;, true);print($ret)?&gt;\n函数调用的最后一个参数，true表示用raw二进制形式输出，false是以16进制字符串的形式输出。\n最后的结果是：\n1cE0l0RanAGVr+lpqew9GLv3H34KM26+m+/izmhLoPyQ=\n\n\n=============================================================\n我们测试一下python的sha256加密：\n12345678910import hmacimport base64import hashlibret = base64.b64encode(hmac.new(&#x27;hmackey&#x27;, &#x27;abcdefg&#x27;, hashlib.sha256).digest())print(ret)\n最后的输出结果是：\n1cE0l0RanAGVr+lpqew9GLv3H34KM26+m+/izmhLoPyQ=\n\n\n\n\n通过这次测试我们会发现，lua的库很多都是第三方程序员实现的，并且有很多的实现版本，而php和python的库，相对更统一。\n如果你真的花了时间去了解lua，能驾驭lua，可以有精力去解决前期遇到的问题，排除库的匹配查找的问题，lua处理的效率会慢慢的展现出来，在之后我们会举出例子来说明lua的好处和不足。\nPS:转载到其它平台请注明作者姓名及原文链接。\nhttp://www.lua.ren\n","slug":"old_topic/2016-09-17-147","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3988d823db5f3d6aedfba2bc8caffd2b","title":"Python多分隔符号拆分字符串","content":"如下代码，实现python多个分隔符拆分字符串。\n1234567891011121314def tsplit(string, delimiters):    &quot;&quot;&quot;Behaves str.split but supports multiple delimiters.&quot;&quot;&quot;    delimiters = tuple(delimiters)    stack = [string,]    for delimiter in delimiters:        for i, substring in enumerate(stack):            substack = substring.split(delimiter)            stack.pop(i)            for j, _substring in enumerate(substack):                stack.insert(i+j, _substring)    return stack\n很多时候我们需要用多个分隔符拆分字符串，例如拆分标签时，既要用中文的分号，也要用到英文的分号。\n如下是使用方法：\n123&gt;&gt;&gt; s = &#x27;thing1,thing2/thing3-thing4&#x27;&gt;&gt;&gt; tsplit(s, (&#x27;,&#x27;, &#x27;/&#x27;, &#x27;-&#x27;))[&#x27;thing1&#x27;, &#x27;thing2&#x27;, &#x27;thing3&#x27;, &#x27;thing4&#x27;]\n\n\n感谢作者分享：http://outofmemory.cn/code-snippet/814/python-use-duoge-separator-chaifen-string\n程序员听说需求改了\n","slug":"old_topic/2016-09-17-148","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"087f4f77da99a0fec1375818d3495ed6","title":"LUA的WEB开发框架Vanilla","content":"作者：糖果\n图片：vanilla_logo.jpg \n这次我们介绍的框架和以往有些不同，最大的不同是，这是介绍的是一个国产Openresty Lua WEB框架，名字叫做Vanilia我们先简单的安装，和创建一个建工的工程，然后分析一下项目的源码。\n我们假定用户用系统是centos。\n1.安装luarocks和lua-dev开发部件。\n12yum install lua-devel yum install luarocks\n\n\n2.安装vanilla。\n1luarocks install vanilla \n\n\n3.使用vanila的命令工具，自动生成工程代码。\n3.1创建工程\n12vanilla new app_name(工程名称)cd app_name\n\n3.2启动工程vanilla的起动模式分要两种模式，一种是开发模式[ development ]\n1vanilla start [--trace]\n\n另一种是，产品模式。（production）\n1VA_ENV=production vanilla start [--trace]\n\n我们采用的是产品模式启动，可以看一下vanilla启动后的效果。\n点击如下连接，查看运行效果：\nhttp://www.openresty.com.cn:8080/\n","slug":"old_topic/2016-09-17-153","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9aeff2cf84352e0facabfc6256b648d7","title":"LUA与STOMP协议","content":"作者：糖果\nSTOMP协议是一种简单的消息文本协议。协义本身简单明了，用消息头定义和消息体数据传输。\nRabbitMQ做为一种队列中间件，提供了STOMP协议的支持，我们可以通过STOMP协议向队列发送消息。下面的例子中，我们将使用LUA程序向RabbitMQ发送消息， 通过Python程序读取消息。\nsend.lua文件\n12345678local client = require &quot;stomp&quot;local mq, err = client:new()local ok, err = mq:connect(&quot;127.0.0.1&quot;, 61613)local msg = &quot;say hi!&quot;local headers = &#123;&#125;headers[&quot;destination&quot;] = &quot;/queue/test&quot;headers[&quot;app-id&quot;] = &quot;APP&quot;local ok, err = mq:send(info_json, headers)\n对上面的代码说明一下：\n连接时候RabbitMQ的IP是本机的127.0.0.1， STOMP协议的服务的端口是默认的61613。\n在headers的头定义部分，指明了我们发送信息的目的地“/queue/test“名字为Test的队列。\n其实可以深入到STOMP的LUA的实现内部，仔细研究一下是如何实现，如何直接通过sock，发送数据帧到服务器，可以作为独立的章节。\n与LUA不同，Python对STOMP协议支持的比较好，不需要甄别第三库，然后再选择使用。用pythonstomp就好。\nreceive.py文件\n1234567891011121314151617181920212223242526import stompimport timeimport sysimport randomimport jsonclass MyListener(stomp.ConnectionListener):    def on_error(self, headers, message):        print(&#x27;received an error %s&#x27; % message)    def on_message(self, headers, message):        for k,v in headers.iteritems():            print(&#x27;header: key %s , value %s&#x27; %(k,v))        print(&#x27;received message\\n %s&#x27;% message)conn=stomp.Connection([(&#x27;127.0.0.1&#x27;,61613)])conn.set_listener(&#x27;somename&#x27;,MyListener())conn.start()conn.connect(wait=True)message=&#x27;say hi!&#x27;dest = &#x27;/queue/test&#x27;headers=&#123;&#x27;seltype&#x27;:&#x27;mandi-age-to-man&#x27;,&#x27;type&#x27;:&#x27;textMessage&#x27;,&#x27;MessageNumber&#x27;:random.randint(0,65535)&#125;metadata = [] info_json = json.dumps(metadata)conn.send(body=info_json, destination=&#x27;/queue/test&#x27;)conn.disconnect()\n\n接受程序和发送程序的主要流程区别是：要在接受端注册监听回调程序。\n上面的\n12conn.set_listener(&#x27;somename&#x27;,MyListener())conn.start()\n\n\n这两行代码就是注册监听类，在队列上有消息的时候，就会调用监听回调。\non_message。发生错误的时候调用。on_error函数。\n具体的实现不完全列出来，针对一般的STOMP连接过程，列出”连接“和\n发送的”消息包”的数据结构，结构采用的是LUA语法，table类型定义的。\n共计二帧的数据：\n123456789101112131415161718connect_frame = &#123;  &quot;CONNECT\\n&quot;,  &quot;accept-version:1.2\\n&quot;,  &quot;login:guest\\n&quot;,  &quot;passcode:guest\\n&quot;,  &quot;host:/\\n&quot;,  &quot;\\n\\n&quot;,  &quot;\\0&quot;&#125;send_frame = &#123;  &quot;SEND\\n&quot;,  &quot;destination:/queue/test\\n&quot;,  &quot;app-id:APP\\n&quot;,  &quot;\\n&quot;,  &quot;say hi!\\n&quot;,  &quot;\\0&quot;&#125;\n\n包体的第一个字段“CONNECT,SEND”都是协议的命令，剩下的是说明字段。\n文字不能把所有的问题和协议都描述清楚，可参考以下网站：\nhttp://stomp.github.io/stomp-specification-1.1.html\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n点击查看Lua FAQ\n","slug":"old_topic/2016-09-17-152","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"40c3b450ff372f1daa99baee2e917fc2","title":"Lua的转义符号“%”","content":"作者：糖果\nLua有些符号在用户字符替换的时候，可能会发生转义。今天群里的一位小伙伴，就需要到类似的问题，比如说要将字符串中的’（’变成’[‘。\n解答问题的伙伴给出如下代码：\n123a = &#x27;123.(456)&#x27;c = string.gsub(a, &#x27;%(&#x27;, &#x27;[&#x27;)print(c)\n\n输出的结果是：\n1123.[456)\n\n\n\nngx.re.gsub是如何使用转义的，下面给一个实际的正则的例子：\n1sleep\\((\\s*)(\\d*)(\\s*)\\)\n\n主要是”%”符号，起到了告诉系统转义的用途。\n","slug":"old_topic/2016-09-17-150","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9898726b61c279db4684cd03b2a439c0","title":"Lua中ipair和pair关键字的区别是什么？","content":"ipair是从key=1，开始累加，遇到val是nil就结束循环。pair输出的结果和table定义的顺序是一致的(非数组不保证与声明的顺序一致)。\npairs()可以遍历整个table，即包括数组及非数组部分。ipairs()函数用于遍历table中的数组部分。\ni= integer ,integer key\n1:使用ipair循环 \n\n1234567891011local tt =  &#123;      [1] = &quot;test3&quot;,      [4] = &quot;test4&quot;,      [5] = &quot;test5&quot;  &#125;  for i,v in ipairs(tt) do        print( tt[i] )  end \n\n运行结果：\n1test3\n\n\n\n2:使用pair循环 \n\n1234567891011local tt =  &#123;      [1] = &quot;test3&quot;,      [4] = &quot;test4&quot;,      [5] = &quot;test5&quot;  &#125;  for i,v in pairs(tt) do        print( tt[i] )  end \n\n运行结果：\n123test3test4test5\n\n\n\n怎么解决，数组里，某个元素是nil后面就不遍历的问题：\n@ms2008老师的方案如下：\n1234567891011local t = &#123;10, nil, 30&#125;for k,v in ipairs(t) do    print(&quot;in&quot;, k,v)endprint(&quot;=============&quot;)for i=1, select(&#x27;#&#x27;, unpack(t)) do    local param = select(i, unpack(t))        print(param)end\n\n\n在讨论ipair和pair的过程中，触发了另外一个问题，就是对lua的map型table按照Map的value，而不是key进行排序，对key的排序lua有sort方法提供支持，而对value的排序是没有的，下面提供了一个对value进行排序的演示算法，是用MoonScript实现的排序算法，应用在反描模块中，对指定用户port访问量的大小进行排序：\n1234567891011121314151617181920212223242526272829303132class GUtils   @mapsort: (board) =&gt;    b_len = 0     for k,v in pairs(board)      b_len = b_len + 1     a1 = &#123;&#125;    a2 = &#123;&#125;    i = 0     for k,v in pairs(board)      i = i + 1       a1[i] = k       a2[i] = v     for i = 1, b_len       max = a2[i]       for j = i + 1, b_len          if a2[j] &gt; max            tmp = a2[j]           a2[j] = max            a2[i] = tmp            max = tmp            tmp1 = a1[j]           a1[j]  = a1[i]           a1[i] = tmp1    ret = &#123;&#125;    for k,v in ipairs(a1)       ret[k] = &#123;a1[k], a2[k]&#125;    return ret \n\n\n下面是纯lua实现，而不是用moonc编译的上面的.moon文件：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253local board = &#123;   [&#x27;0.0.0.1&#x27;] = 1,  [&#x27;0.0.0.5&#x27;] = 5,  [&#x27;0.0.0.3&#x27;] = 3,  [&#x27;0.0.0.2&#x27;] = 2,  [&#x27;0.0.0.9&#x27;] = 9,  [&#x27;0.0.0.3&#x27;] = 3,  [&#x27;0.0.0.6&#x27;] = 6 &#125;local mapsortmapsort = function(board)  local b_len = 0   for k, v in pairs(board) do    b_len = b_len + 1   end   local a1 = &#123; &#125;   local a2 = &#123; &#125;   local i = 0   for k, v in pairs(board) do    i = i + 1     a1[i] = k     a2[i] = v   end   for i = 1, b_len do    local max = a2[i]    for j = i + 1, b_len do      if a2[j] &gt; max then        local tmp = a2[j]        a2[j] = max         a2[i] = tmp        max = tmp        local tmp1 = a1[j]        a1[j] = a1[i]        a1[i] = tmp1      end    end  end  local ret = &#123; &#125;  for k, v in ipairs(a1) do    ret[k] = &#123;      a1[k],      a2[k]    &#125;  end  return retendprint(&quot;########&quot;)local ret = mapsort(board)for k, v in ipairs(ret) do  print(ret[k][1], ret[k][2])end","slug":"old_topic/2016-09-17-151","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"85399f84f55b8c1291e5685cda57f473","title":"Lua Curl的一般应用","content":"作者：糖果\nCurl是一个WEB开发常用的工具，直接用官网的翻译\ncurl是一个开源的命令行工具，也是一个库，用于传输URL语法的工具，支持DICT, FILE, FTP, FTPS, Gopher, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMTP, SMTPS, Telnet and TFTP等。\n在lua中，curl就是以库的形式存在的，安装过程比较简单：\n1sudo luarocks install luacurl\n\n另外，curl还是支持代理的方式访问主机，这个很有用，之后会用一个模拟DDOS攻击程序说明他的用处。\n这一次，我们用一个和SAE云平台相关的机能，说明pycurl的使用。\n简单的说明一下，SAE云平台是国内较早的云开开放平台之一，经过多年的积累，有广大的用户基础，提供便利的开发平台，最近开放了一个实时LOG查询功能。用户可以通过其对外开放的REST API，查询自己运行在云平台上的APP产出的LOG。\n文档说明：\n接入流程概述：\n1.计算取得安全签名 。\n2.向指定URL发送HTTP的GET请求，请求之前要根据官网的文档要求，填充HTTP header信息，如果没有准备的填充信息，会被视为无效请求。\n3.取得返回的LOG信息，如果需要还可以对，返回LOG进行显示格式化。\n技术栈：\n依赖关联，此模块使用了几个常用的LUA库：\ncrypto：加密包，用于sha256运算。\nbase64:base64格式的转换处理。\ncrypto,base64在之前的章节有过介绍。\nluacurl：HTTP工具包，此处用于向服务器发送HTTP请求。\nsocket：luasocket是调用socket api的，但此程序只是用于取得系统时间，用作当时间戳。\n另外，国内的云风老师，因为觉得luasocket过于大了，不是很喜欢（QQ群里他自己说的…），他又写了一个lsocket，可以在github中找到，lsocket有一个sample,是使用lsocket实现了一个Http Server。\n多说一句，Lua的库不像python或是php等语言，Lua的很多库都是第三方个人实现的，需要一个寻找和甄别的过程，使用之前，确认一下也很必要。\n下面是具体的代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465local crypto = require(&quot;crypto&quot;)local hmac = require(&quot;crypto.hmac&quot;)local curl = require(&quot;luacurl&quot;)local socket = require(&quot;socket&quot;)require(&#x27;base64&#x27;)ALOG = &#123;&#125;TIME_STAMP = nilLOG_PATH = nilSAE_LOG_HOST = &#x27;g.sae.sina.com.cn&#x27;SAE_ACCESSKEY = &#x27;XXXXXXXX&#x27;SAE_SECRETKEY = &#x27;XXXXXXXXXXXXXXXXXXXXXXXXX&#x27;function ALOG.request()    local auth_info = ALOG.get_sec_token()    local header_info = &#123;         &#x27;Host: &#x27;..SAE_LOG_HOST,         &#x27;Accept: text/plain&#x27;,         &#x27;x-sae-accesskey: &#x27;..SAE_ACCESSKEY,         &#x27;x-sae-timestamp: &#x27;..TIME_STAMP,         &#x27;Authorization: &#x27;..auth_info     &#125;    local url = &#x27;http://&#x27;..SAE_LOG_HOST..LOG_PATH    local c = curl.new()    c:setopt(curl.OPT_URL, url)    c:setopt(curl.OPT_HEADER, false)    c:setopt(curl.OPT_HTTPHEADER,     table.concat(header_info,&quot;\\n&quot;))    local t = &#123;&#125;    c:setopt(curl.OPT_WRITEFUNCTION, function(param, buf)    table.insert(t, buf)    return #buf    end)    assert(c:perform())    return table.concat(t)endfunction ALOG.get_sec_token()    local header = &#123;     &#x27;GET&#x27;,        LOG_PATH,     &#x27;x-sae-accesskey:&#x27;..SAE_ACCESSKEY,     &#x27;x-sae-timestamp:&#x27;..TIME_STAMP,    &#125;    data_str = table.concat(header, &#x27;\\n&#x27;)    local ret = &#x27;SAEV1_HMAC_SHA256 &#x27;..to_base64(hmac.digest(&quot;sha256&quot;, data_str,SAE_SECRETKEY,rawequal))    return retendfunction ALOG.get_log_info(service, date, ident, fop, format)    LOG_PATH = &#x27;/log/&#x27;..service..&#x27;/&#x27;..date..&#x27;/&#x27;..ident..&#x27;.log&#x27;..&#x27;?&#x27;..fop    TIME_STAMP = math.ceil(socket.gettime())    local log_info = ALOG.request()    return log_infoendlocal service = &#x27;http&#x27;local date = &#x27;2015-07-31&#x27;local ident=&#x27;1-access&#x27;local meta = ALOG.get_log_info(service, date, ident, &#x27;head/0/1&#x27;, true)print(meta)return meta\n\n在云平台上可以运行，python,php,python的脚本。目前是不支持lua的，以后是否支持不得而知。\n因为将一个系统，分解成不同的子系统，一部分的功能是用lua实现，一部分的功能是用python实现，而系统之间的通信使用RPC通信，由lua端向python发送RPC，服务器端再接收RPC接收，必然会产生LOG。我们就在log端将实时的log取出，分析执行过程，这就是这段代码的意义。\n关于Pycurl使用代理的案例，之后单起一篇说明，另外会将C实现代码的关键截取出来说明上层LUA与底层代码的功能。\n1234567POST /auth HTTP/1.1\\r\\nContent-Type: application/x-www-form-urlencoded\\r\\nContent-Length: 29\\r\\nHost: localhost:9000\\r\\nConnection: close\\r\\n\\r\\nuserName=Ganesh&amp;password=pass\n\n\n\nPS:转载到其它平台请注明作者姓名及原文链接。\n点击查看Lua FAQ\n","slug":"old_topic/2016-09-17-154","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"41a2ce410f87ba443188f31dccca5c41","title":"LUA调用C语言实现的SO库","content":"作者：糖果\n这篇文章归纳lua5.1的C语言模库so的“标准”写法，代码都是编译通过的，可直接参考使用！\ntangguo.h\n123456789101112131415161718#ifndef __tangguo_h__#define __tangguo_h__#include &quot;lauxlib.h&quot;#include &quot;lua.h&quot;#include &quot;lualib.h&quot;#include &quot;lauxlib.h&quot;extern int add(lua_State* L);extern int sub(lua_State* L);extern int luaopen_libtangguo(lua_State* L);static luaL_Reg libtangguo[] = &#123;        &#123;&quot;add&quot;, add&#125;,        &#123;&quot;sub&quot;, sub&#125;,        &#123;NULL, NULL&#125;&#125;;#endif\n\ntangguo.c\n1234567891011121314151617181920212223242526#include &quot;tangguo.h&quot;int sub(lua_State* L) &#123;    double op1 = luaL_checknumber(L, 1);    double op2 = luaL_checknumber(L, 2);    lua_pushnumber(L, op1 - op2);    return 1;&#125;int add(lua_State* L) &#123;    double op1 = luaL_checknumber(L, 1);    double op2 = luaL_checknumber(L, 2);    lua_pushnumber(L, op1 + op2);    return 1;&#125;int luaopen_libtangguo(lua_State* L)&#123;    luaL_openlibs(L);    const char* libName = &quot;libtangguo&quot;;    luaL_register(L, libName, libtangguo);    return 0;&#125;\n\n\nMakefile\n123456789101112131415161718192021#LUALIB=-I/usr/include/lua5.1 -L/usr/local/lib -llua -ldl -lmLUALIB=-I/usr/include/lua5.1 -L/usr/local/lib -ldl -lm.PHONY: all win linuxall:        @echo Please do \\&#x27;make PLATFORM\\&#x27; where PLATFORM is one of these:        @echo win linuxwin:linux: libtangguo.solibtangguo.so : tangguo.c        #gcc --shared -Wall -fPIC -O2 $^ -o$@        gcc --shared -Wall -fPIC -O2 $^ -o$@clean:        rm -f libtangguo.so\n\n2016.6.7日的时候，重新看了一下这篇文章，发现gcc的一个有开关没加，lib库又多加了一个。追加了$(LUALIB), 去掉了 -llua 编译选项。\n12345678910111213141516171819202122232425262728293031323334353637383940/*** Try to find a load function for module &#x27;modname&#x27; at file &#x27;filename&#x27;.** First, change &#x27;.&#x27; to &#x27;_&#x27; in &#x27;modname&#x27;; then, if &#x27;modname&#x27; has** the form X-Y (that is, it has an &quot;ignore mark&quot;), build a function** name &quot;luaopen_X&quot; and look for it. (For compatibility, if that** fails, it also tries &quot;luaopen_Y&quot;.) If there is no ignore mark,** look for a function named &quot;luaopen_modname&quot;.*/static int loadfunc (lua_State *L, const char *filename, const char *modname) &#123;  const char *openfunc;  const char *mark;  modname = luaL_gsub(L, modname, &quot;.&quot;, LUA_OFSEP);  mark = strchr(modname, *LUA_IGMARK);  if (mark) &#123;    int stat;    openfunc = lua_pushlstring(L, modname, mark - modname);    openfunc = lua_pushfstring(L, LUA_POF&quot;%s&quot;, openfunc);    stat = lookforfunc(L, filename, openfunc);    if (stat != ERRFUNC) return stat;    modname = mark + 1;  /* else go ahead and try old-style name */  &#125;  openfunc = lua_pushfstring(L, LUA_POF&quot;%s&quot;, modname);  return lookforfunc(L, filename, openfunc);&#125;static int ll_loadlib (lua_State *L) &#123;  const char *path = luaL_checkstring(L, 1);  const char *init = luaL_checkstring(L, 2);  int stat = lookforfunc(L, path, init);  if (stat == 0)  /* no errors? */    return 1;  /* return the loaded function */  else &#123;  /* error; error message is on stack top */    lua_pushnil(L);    lua_insert(L, -2);    lua_pushstring(L, (stat == ERRLIB) ?  LIB_FAIL : &quot;init&quot;);    return 3;  /* return nil, error message, and where */  &#125;&#125;\n\nhttps://github.com/lua/lua/blob/e354c6355e7f48e087678ec49e340ca0696725b1/loadlib.c\n作者：糖果PS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n点击查看Lua FAQ\n","slug":"old_topic/2016-09-17-156","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"2caace3339612aabd4a60ee7889dcc5d","title":"CSRF攻击预防的Token生成原理","content":"作者：糖果\n以往我们讲到CSRF，谈及都是CSRF的攻击原理，这次讲一下预防CSRF，生成Token背后的加密原理和具体实现例示。\n1.Token构成。\n从需求功能上来讲，为了防止CSRF工具，token需要具有不重复，另外，还含有特定的功能信息，比如过期时间戳。\n下面的图描述了一个token的数据构成：\nToken的数据结构。\n123456-----------------------------------------------------------------------------|             msg                  |        separator       |           signature                    |-----------------------------------------------------------------------------|     key     |   timestamp  |              .               |    Base64(sha256(msg))        |-----------------------------------------------------------------------------\ntoken由三部分组成：a).msg b). separator c).signature。\na). msg部分：而msg本身也有两部分组成：一部分，随机字符的主体，另一部分是过期时间戳。\nb). 分隔符号：用符号分隔msg部分，和加密后生成的signature签名部分，这里用的是”.“\nc). 签名signature。signature签名，是对上面提到的msg，按照msg中提到的msg的信息部分，按照特定的秘锁进行加密。\n1token = base64(msg)格式化..base64(sha256(&quot;秘锁&quot;, msg))\n\n2.Token的加密。首先，是按照合适得加密方法对数据进行加密。这里我们通用的就使用了sha256散列算法，然后进行BASE64的格式转换。然后，我们需要在token串中隐含过期时间的设定，从需求上讲，每条与服务器交互的token有是有过期时间的，超过这个时间范围，就无效了，需要重新从服务器中取得。\n3.Token的验证。\n当用户从客户端，得到了token,再次提交给服务器的时候，服务器需要判断token的有效性，否则不加判断直接处理数据，token的生成就无意义了。\n验证的过程是:\na). token解包。\n先把接受到的token，进行分解。“.”为分隔符，分为msg部分+signature签名部分。\nb). 比对签名。\n对msg部分进行base64解码, decode_base64(msg)然后在对解码后的msg明文，进行同样的encode_base64(sha256(msg))加密。秘锁相同，然后，判断加密后的数据和客户端传过来的token.signature的部分是否一致。如果一致，说明这个token是有效的。\nc). 判断时间过期。如果是有效的,取出msg.timestamp，和当前系统时间进行比较，如果过期时间小于当前时间，那这个token是过期的，需要重新的取得token。\n原理都通用，此处使用lua对上处理过程进行描述。\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556local gen_token = function(key, expires)    --做成一个过期时间戳。    if expires == nil then     expires = os.time() + 60 + 60 * 8    end       --对msg部分进行base64编码。    local msg = encode_base64(     json.encode(&#123;         key = key,         expires = expires     &#125;))        --进行sha256哈希。    local signature = encode_base64(hmac_sha256(&#x27;testkey&#x27;, msg))        --拼接成一条token。    return msg .. &quot;.&quot; ..signatureendlocal  val_token = function(key,token)    --对输入数据的判空操作    if not (token) then     return nil, &#x27;mssing csrf token&#x27;    end        --对token的msg部分，signature签名部分进行拆分。    local msg, sig = token:match(&quot;^(.*)%.(.*)$&quot;)    if not (msg) then         return nil, &quot;malformed csrf token&quot;    end    sig = encoding.decode_base64(sig)    --对解包后msg，按照相同的加密key:&quot;testkey&quot;，重新进行sha256哈希，比对signature，    --如果不一致，说明这个token中的数据有问题，无效的token。    if not (sig == hmac_sha256(&#x27;testkey&#x27;, msg)) then         return nil, &quot;invalid csrf token(bad sig)&quot;    end    --对msg进行base64解码，判断其中的key和传入的key是否一致。    --如果不一致说明token也是无效的。    msg =json.decode(decode_base64(msg))    if not (msg.key == key) then     return nil, &quot;invalid csrf token (bad key)&quot;        end        --取出msg部分的时间戳，判断是否大于当前时间，如果大于，说明token过期无效了。    if not (not msg.expires or msg.expires &gt; os.time()) then         return nil, &quot;csrf token expired&quot;    endend\n下面是关于Lua语言加密库，lua语言有别于其他语言，没有同意的官方指定加密库，为了便于读者，看后实践，下面对lua的加密库进行了补充描述。lua语言是一种弱类型的语言，简单明了，对于描述某些课题，便于表述，类似于伪语言，操作起来也很轻便，便于实践推敲算法。即使之后不适用lua，也可以很方面的迁移到其他语言。\n我们在开发的工作中，难免要对一些数据进行加密处理，而加密模块的使用有是就必不可少。在lua官方的WIKI列表中就列出了，很多lua程序写的加密库，这写加密库有的是用纯lua写的，也有用lua调用C的程序实现加密。不过有些时候甄选这些库还是需要花一些时间精力，只是需要测试一下这是加密算是否是好用的。这是lua组织列出的一览列表。\n1http://lua-users.org/wiki/CryptographyStuff\n说一下为什么要加密，我们面临的任务是什么！我们现在面临的任务是，要对一段字符串进行sha256算法加密。我们从列表中选出了几个支持sha256加密的包，并说明一下这几个工具包。\n1.SecureHashAlgorithm和SecureHashAlgorithmBW \n这个工具包是支持sha256加密的，而且是纯lua方法的实现，问题是，这两个包分别依赖lua5.2和lua5.3。\n而我们系统的运行环境是lua5.1，因为大部分的生产环境都是lua5.1，因为历史原因暂时没法改变。如果要把5.2的程序移植到5.1下运行，还需要移植一个lua5.2才独有的包，这是lua5.2升级之后才有的部件：bit32,而在lua5.3中又将这个部件去掉了,移植的动力不大，暂时不使用这个包。\n\n2.Lcrypt \n这个包不是纯lua的实现，底层加密用的是C语言，而且额外还有依赖另外另个工具包 libTomCrypt和libTomMath，这两个包的官网已经被和谐了，github上有源码，所以要想让这个包正常运行需要手动make安装3个源码工程，还是算了，有时间的时候再装好测试一下，先暂时不用。\n\n网站：\n1http://www.eder.us/projects/lcrypt/\n3.LuaCrypto \n这个包的安装用的是luarocks，就比较简单了 \n1luarocks install luacrypto \n\n我们选用这个包进行加密处理。LuaCrypto其实是openssl库的前端lua调用，依赖openssl，openssl库显然会支持sha256加密，相对也比一般的第三方实现更可靠。写一个简单的加密程序：\n1234local crypto = require(&quot;crypto&quot;)local hmac = require(&quot;crypto.hmac&quot;)local ret = hmac.digest(&quot;sha256&quot;, &quot;abcdefg&quot;, &quot;hmackey&quot;)print(ret)\nret的返回结果是，如下这个字符串。\n1704d25d116a700656bfa5a6a7b0f462efdc7df828cdbafa6fbf8b39a12e83f24\n我们需要改造一下代码，在调用digest的时候指定输出的形式是raw二进制数据形式，然后在编码成base64的数据形式。\n12local ret = hmac.digest(&quot;sha256&quot;, &quot;abcdefg&quot;, &quot;hmackey&quot;,rawequal)print(ret)\n\n这时候的输出结果是：\n12cE0l0RanAGVr+lpqew9GLv3H34KM26+m+/izmhLoPyQ=lua-base64\n使用的是下面的库，lua库就是这样，有很多功能程序有很多的实现，并且很多非官方的第三方实现。\n1https://github.com/toastdriven/lua-base64\n作者：糖果PS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n点击查看Lua FAQ\n","slug":"old_topic/2016-09-17-155","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a4dc51fe6b804bd703cc11ff53f294af","title":"LUA书","content":"var jd_union_pid=\"936552349\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936550394\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936535377\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936553329\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936538385\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936561407\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936538386\";var jd_union_euid=\"\";\n\n\nvar jd_union_pid=\"936532392\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936530400\";var jd_union_euid=\"\";\n\nvar jd_union_pid=\"936530401\";var jd_union_euid=\"\";\n\n\n\n\nLua快速入门\nsky9,关于balancer!\nLUA WAF—VeryNginx\nkafka for openresty \nAn Introduction To OpenResty (nginx + lua) - Part 1 \nOpenResty的大时代已经来临 \nAn Introduction to OpenResty \nbalancer_by_lua_block \nLua 在 Nginx 中的应用 \nVideo\n\nOpenresty大会的视频合集 \n浅谈OpenResty未来的发展 by 章亦春 \n第一次 Openresty大会的视频分享 \n春哥与OpenResty的视频 \n如何对nginx Lua module添加新api \nnginx-lua的API中文文档翻译\nTools\n\nYandex英文版\nYandex俄文版\nGithub\ndrizzle MySQL的分支数据库","slug":"old_topic/2016-09-17-157","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f3e99e9ea7d7d80df722bfdd4f318e9e","title":"Lua快速入门书","content":"这是一本lua的入门书籍。\n","slug":"old_topic/2016-09-17-163","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9eeeb777591d00c19e4d4fed3011ba33","title":"Lua动态加载脚本( loadstring )","content":"作者：糖果\n下面是代码：\n123456789local lua_script = [[     local var = 1     print(var)]]local  script = lua_script local tb=assert(loadstring(script))()print(tb[0].text)\n\n\n\n123456789101112131415const char* testfunc = &quot;print (add(1.0, 2.0)) print(sub(20.1, 19))&quot;;int main()&#123;        lua_State* L = luaL_newstate();        luaL_openlibs(L);        lua_register(L, &quot;add&quot;, add);        lua_register(L, &quot;sub&quot;, sub);        if (luaL_dostring(L, testfunc))                printf(&quot;Failed to invoke.\\n&quot;);        lua_close(L);        return 0;&#125;\n\n糖果实验室www.lua.ren/topic/158\n","slug":"old_topic/2016-09-17-158","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"6fb84e2c72aba63aea886444da3d9874","title":"Openresty 火焰图","content":"这是群里的小伙伴分享，感谢这位小伙伴，mc!信春哥，看文档。\n\n\n\n\nOpenresty最佳实践—讲火焰图\n1https://github.com/moonbingbing/nginx-systemtap-toolkit/blob/master/README-CN.markdown#sample-bt   \n\n\nLUA火焰图\n1https://github.com/openresty/stapxx#lj-lua-bt\n具体的，可以参考以下文章： http://openresty.com.cn/pra_flame_install.html\n","slug":"old_topic/2016-09-17-167","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e9cffae5d10e90dbf9fa8da995c5d84e","title":"Nginx共享内存","content":"本文由李航老师创建，李航老师的微博账号是：http://weibo.com/lidaohang\n","slug":"old_topic/2016-09-17-166","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a746a11133e39b0cf464a04ba5004aa9","title":"LUA FAQ提问区","content":"如果您希望Lua FAQ出现一些您感兴趣的课题，请在评论下留言!:)\n","slug":"old_topic/2016-09-17-169","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"5b530fb1728124affce356d72e211113","title":"Lua相关资源的下载","content":"一个WEB框架https://github.com/appwilldev/moochine\n压力测试工具loadrunner淘宝使用的压测工具tsung\n压测工具tcpcopy\ncosbench分布式压力测度工具http://reins.se.sjtu.edu.cn/cosbench/https://github.com/intel-cloud/cosbench/releases\nluarocks install –server=http://gin.io/repo ginhttp://keplerproject.github.io/luarocks/releases/ftp://ftp.gnu.org/gnu/readline/http://ftp.gnu.org/pub/gnu/ncurses/\nlua 5.1源码下载 \napt-get install libncurses5-dev \nlua51.dll(lua5.1.dll)文件下载\nngx_http_lua_balancer版Openresty下载\n","slug":"old_topic/2016-09-17-168","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f81311e15bc564f4e3d4ae96d3d0048c","title":"为何巴西人能做出 Lua 这种出彩的东西？","content":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。作者：冯东链接：http://www.zhihu.com/question/24596411/answer/36516759来源：知乎\n再推荐一次这本书：Coding Places: Software Practice in a South American City (Acting with Technology): Yuri Takhteyev: 9780262018074: Amazon.com: Books本答案大部分观点都来自于上面这本书。如果想看短一点，可以看：From Brazil to Wikipedia\n首先要说，Lua 在巴西受到的重视是非常低的。因为巴西没有 Blizzard 这样的公司，没有 Adobe 这样的公司，也没有人有热情维护一个独立的 web server 模块。Lua 初期的资金支持确实来自巴西本土的石油公司，但是从一开始 Lua 就肩负着另一项任务：出 paper。\n当然，出 paper 这个动力会导致什么样的投入，就要看巴西国内的学术氛围。巴西国内的大学分为三个层次，从低到高是公立、私立、和 Catholic 大学。不知道大家看出什么了吗？巴西不是一个发达国家。腐败在巴西也很严重。社会并不高效。但是，就和民国时代的教育一样，巴西的学术体系分成几个和社会其它部分逐渐隔离的圈子。其中不乏宗教力量的影响。我想这应该是巴西会产生 Lua 的最重要的原因（之一）。\n在不发达地区进行效仿发达地区的活动（比如软件开发）的人面临一个困境：是利用物理距离的优势争取本地生态环境的支持，还是集中力量建立和发达地区的联系。如果是选择前者，就只能产生出软件本地化、本地企业的网站、或者本地社区网站这样的产品。Lua 的设计者选择了后者。一开始是考虑学术研究，直接和美国大学的学术圈建立联系。然后凭借一些幸运，以及本身研究成果确实不错，被美国的公司采用。这时候 Lua 团队直接说出了，Lua had to succeed abroad to gain acceptance at home. 巴西作为一个葡萄牙语国家，Lua 在相当长的时间里却只有英文文档，《Programming in Lua》这本书只在美国有售。甚至当巴西政府里有人希望出面支持 Lua 在国内的采用时，受到了 Lua 团队的消极回应。因为巴西本地公司只相信 Java，Unix 这样的美国技术。作为一个纯粹的技术，如果 Lua 想要成功，必须在硅谷成功。如果成为「巴西国产自主知识产权技术」，只会列入类似的行列遭到嘲笑。\n另一方面，美国纽带很强的 Lua 团队还能坚持留在巴西，很大部分是上面说到的 Catholic 大学背景来支持的。否则的话，对美国纽带如此重视的团队，一定会郑重考虑迁移到美国去。同为发达国家的芬兰，不是也没能留住 Linus 吗？\nhttps://github.com/middlefeng/LuaVMRead\n","slug":"old_topic/2016-09-17-170","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a2becc30bdee919f8734dc94a8f8ee13","title":"Lua代码风格指南（代码规范参考）","content":"写代码也有风格？ \n\n当然，写代码就跟写文章一样，每个人或多或少都有自己的风格。不同的语言也就像不同的文体一样，也有自己的独特的风格。Lua是一门脚本语言，写起来轻松惬意，但不代表它没有属于自己的风格指南。\n好的代码风格基于可读性和一致性。代码更多的时间是给人看的，如果思考好了结构和逻辑，写代码的过程其实很快。风格的一致性也很重要，这样可以减少复杂度和理解成本。养成一种良好的代码风格会形成一种良好写代码习惯，这种习惯会使编码事半功倍。\n下文将从命名，作用域，模块，注释和惯用法（精巧用法）等方面来说明Lua的代码风格，文章的最后会附上一些参考资料的链接以供读者拓展阅读。\n命名 \n\n最好的代码是自说明代码，这种代码不需要多余的注释，其本身便具备了描述作者意图的信息。一种好的命名风格是自说明代码的基础。\n命名法 \n\n驼峰命名法 \n\n小驼峰式命名法：第一个单字以小写字母开始；第二个单字的首字母大写，例如：firstName、lastName。大驼峰式命名法：每一个单字的首字母都采用大写字母，例如：FirstName、LastName、CamelCase，也被称为Pascal命名法。\n下划线命名法 \n\n小下划线命名法：所有字母均为小写，例如登录按钮：login_btn。大下划线命名法：所有字母均为大写，常见于常量，例如：最小间隔时间MIN_GAP_TIME。采用驼峰法或者下划线法都不太重要，重要的是你采用了自己喜欢的一种命名法，然后一直保持下去。\n变量名长度 \n\n通常作用域范围更大的变量名要比作用域范围更小的变量名具有更多的描述信息。例如：i经常用于循环中充当计数变量，而将其作为全局变量使用容易导致诸多问题。\n变量命名 \n\n对于变量（包括函数），小驼峰式命名法或小下划线命名法是一个好选择。比如：curSpeed表示当前速度，canDrop表示是否能掉落等等。\n对于布尔值型的变量，通常前缀加上is可以方便理解，比如isRemoved比Removed更加能表示这是一个布尔值变量。\nLua中有一种特殊的变量名：_，常用来表示可以被忽略的、不会使用到的变量，常使用在循环中。\n12-- `_`表示表的键可以被忽略，只在循环内使用表中的值`v`for _,v in ipairs(t) do print(v) end\n在表的循环中和函数参数列表中，i常表示ipairs下的数组下标，k常表示pairs下的键，v常表示对应的值，t则表示表。\n123for k,v in pairs(t) do ... endfor i,v in ipairs(t) do ... endmt.__newindex = function(t, k, v) ... end\n常数命名 \n\nLua里没有严格的常数定义标识符，所以对于常数的命名格外重要。\n常数一般采用大下划线命名法。这样每个字母都大写，十分醒目，且各个单词都用下划线分割，便于阅读。\n比如：MAX_SPEED表示最大速度，IS_SHOW_DEBUG_ERROR_MSG表示是否显示报错消息等等。\n类名 \n\n为了不与变量名和常数名混淆，类名通常使用大驼峰式命名法，即首字母大写。比如：TouchManager表示触摸管理器类。\n包和模块名 \n\n包名和模块名通常很短，并且全部小写，单词间并没有下划线区分。比如：文件读取库名为lfs，表示Lua File System；XML解析库名为lxp，表示Lua XML Parser等等。\n文件名 \n\n通常为了不与类名混淆，对于文件名，经常使用小驼峰式命名法或小下划线命名法。\n作用域 \n\nLua的作用域以关键字end进行标识。\n对于变量，有一条原则：在一切能使用local修饰的情况下，使用local进行修饰。\n因为不用local修饰的变量会自动变成全局变量。全局变量十分危险，很容易被篡改而不知道在哪里被篡改了，这很容易导致顽固的bug出现。并且全局变量的处理速度也比局部变量的速度要慢很多。\n所以，尽可能的用local来修饰变量。\n有时候，用do .. end可以用来明确限定局部变量的作用域。\n12345678910111213local vdo  local x = u2*v3-u3*v2  local y = u3*v1-u1*v3  local z = u1*v2-u2*v1  v = &#123;x,y,z&#125;end -- x,y,z的作用域结束，被系统清理 local countdo  local x = 0  count = function() x = x + 1; return x endend -- x的作用域结束，被系统清理\n模块 \n\nLua中有一个叫module的公有函数，此函数的作用是将一组变量和函数打包在一个模块名下，便于其他文件require。但是这个函数受到了诸多的指责，原因是其会创建一个公共变量，并且这个公共变量中的所有细节都会暴露出来。这其实十分不符合面向对象的规范。\n以下有一种办法可以避免这个问题，即不采用module函数进行打包。\n123456789-- hello/mytest.lua local M = &#123;&#125; -- 私有变量 local function test() print(123) endfunction M.test1() test() endfunction M.test2() M.test1(); M.test1() end return M -- 关键\n以下是导入此模块的方法。\n12local MT = require &quot;hello.mytest&quot;MT.test2()\nLua内没有类这个变量类型，但是通过Lua的metatable可以轻松实现类的继承，多态等等特性。关于Lua中类的实现原理，请参考我之前写的这篇博客：Lua中实现类的原理。\n注释 \n\n通常在–前加上一个空格。\n12return nil  -- not found    (建议)return nil  --not found     (不建议)\n注释通常用在函数接口，或者复杂，精巧的逻辑上。\n对于接口的注释，可以按照javadoc类似的来写。\n1234567-- Deletes a session.-- @param id Session identification.-------------------------------------function delete (id)    assert (check_id (id))    remove (filename (id))end\n惯用法（精巧用法） \n\n尽可能使用local修饰变量（重要的事情要说三遍！）\n原因： \n\n使用local的变量会在作用域结束时释放其内存使用local的变量会比全局变量的存取更快全局变量会污染全局的命名空间，可能会导致诡异的bug出现直接判断真假值\n123456789-- 不推荐if obj ~= nil and willBreak == false then    -- ...end -- 推荐if obj and not willBreak then    -- ...end\n原因： Lua在逻辑判断时将所有非false和nil的逻辑判断视为真，反之视为假，不需要再与布尔值和nil进行比对。\n\n但是，在需要对false和nil进行区分时，需要写明==：obj == nil和obj == false。\n默认参数的实现 \n\n范式：param = param or defaultValue\n1234function setName(name)    name = name or &#x27;noName&#x27;    -- ...end\n原因：or会在第一次为true的时候断路，返回其判断的最后一个值。所以当name为空时，name or ‘noName’返回为’noName’，这会将name的值自动设置为noName。\n一行代码实现表的拷贝 \n\n1u = &#123;unpack(t)&#125;\n需要注意的是此法在表内条目大于2000时会失效。\n一行代码判断表是否为空\n用#t == 0并不能判断表是否为空，因为#预算符会忽略所有不连续的数字下标和非数字下标。\n正确做法是： \n\n1234if next(t) == nil then     -- 表为空    -- ...end\n因为表的键可能为false，所以必须与nil比较，而不直接使用~next(t)来判断表是否空。\n更快的插入代码\n12345-- 更慢，不推荐table.insert(t, value)  -- 更快，推荐t[#t+1] = value \n原因：[]和#避免了高层的函数调用开销。\n参考资料 \n\n这篇文章是基于Lua Style Guide而来。\n语言的风格大致是通用的，在Python里，有一种叫pythonic的代码风格，详见：让你的python代码更加pythonic。\n对于任何程序员，我都力荐《代码大全》这本书。在里面，你可以找到十分完备的从设计，架构到具体编码，注释，到团队协作等等相关的引导。\n还有几本书：《程序员修炼之道》，《高效程序员的45个习惯》，《重构》。它们可以作为《代码大全》的补集存在。\n关于《高效程序员的45个习惯》这本书，我进行了总结和提炼，阅读之前不妨看看这篇读书笔记。\n编辑：糖果\n作者：Tim’s Blog\n","slug":"old_topic/2016-09-17-172","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ae4d85e0c91441200158f7ee6ba4f723","title":"项目","content":"Java版本的ＨＴＴＰ访问客户端(curl) \nNginx NP Dashboard \n\n\nOpenresty Windows版\n\n\n e/gbc-core\" target=\"_blank\">gbc-core","slug":"old_topic/2016-09-17-173","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"92d99ee2d13a8d36703ac725a2bba93f","title":"快讯","content":"2015/11/26\n人民邮电出版社-异步社区-两本免费电子书 \n\n众妙之门——国际顶级Web设计师成功法则 \n众妙之门——移动Web设计精髓 \n过期Openresty 2015大会现场直播请点击进入观看：\n","slug":"old_topic/2016-09-17-171","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"5dd63397e730372ad714df83ebd3c1b7","title":"WebSockets with OpenResty","content":"WebSockets with OpenResty \nLua WebSocket Implementation Installation \n\nThis blog post is updated for OpenResty 1.4.2.9. \n\n本文适用于OpenResty 1.4.2.9\nI have been following OpenResty development closely for a while now, but I did never got an inspiration to really try it out, until now. Yichun Zhang (@agentzh) of OpenResty-fame announced that he just released a preliminary WebSockets support for Lua Nginx module (lua-nginx-module). I have been waiting for this to happen.\nI managed to install, and test this on my Mac. Here is how I did it:\n12345678910$ brew install pcre$ wget http://openresty.org/download/ngx_openresty-1.4.2.9.tar.gz$ tar zxf ngx_openresty-1.4.2.9.tar.gz$ cd ngx_openresty-1.4.2.9$ ./configure \\    --with-luajit \\    --with-cc-opt=&quot;-I/usr/local/Cellar/pcre/8.33/include&quot; \\    --with-ld-opt=&quot;-L/usr/local/Cellar/pcre/8.33/lib&quot;$ make$ make install\n\nNow we should have OpenResty installed with Lua module that supports WebSockets at /usr/local/openresty.Next we need to write the WebSockets server code (right now just a stupid echoing server). Again, edit nginx.conf, and add a new location after “location / { … }”:\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546location /s &#123;  lua_socket_log_errors off;  lua_check_client_abort on;  content_by_lua &#x27;    local server = require &quot;resty.websocket.server&quot;    local wb, err = server:new&#123;      timeout = 5000,      max_payload_len = 65535    &#125;    if not wb then      ngx.log(ngx.ERR, &quot;failed to new websocket: &quot;, err)      return ngx.exit(444)    end    while true do      local data, typ, err = wb:recv_frame()      if wb.fatal then        ngx.log(ngx.ERR, &quot;failed to receive frame: &quot;, err)        return ngx.exit(444)      end      if not data then        local bytes, err = wb:send_ping()        if not bytes then          ngx.log(ngx.ERR, &quot;failed to send ping: &quot;, err)          return ngx.exit(444)        end      elseif typ == &quot;close&quot; then break      elseif typ == &quot;ping&quot; then        local bytes, err = wb:send_pong()        if not bytes then          ngx.log(ngx.ERR, &quot;failed to send pong: &quot;, err)          return ngx.exit(444)        end      elseif typ == &quot;pong&quot; then        ngx.log(ngx.INFO, &quot;client ponged&quot;)      elseif typ == &quot;text&quot; then        local bytes, err = wb:send_text(data)        if not bytes then          ngx.log(ngx.ERR, &quot;failed to send text: &quot;, err)          return ngx.exit(444)        end      end    end    wb:send_close()  &#x27;;&#125;\n\nLooks great. Now add websockets.html to /usr/local/openresty/nginx/html directory:\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;html&gt;&lt;head&gt;&lt;script&gt;var ws = null;function connect() &#123;  if (ws !== null) return log(&#x27;already connected&#x27;);  ws = new WebSocket(&#x27;ws://127.0.0.1/s/&#x27;);  ws.onopen = function () &#123;    log(&#x27;connected&#x27;);  &#125;;  ws.onerror = function (error) &#123;    log(error);  &#125;;  ws.onmessage = function (e) &#123;    log(&#x27;recv: &#x27; + e.data);  &#125;;  ws.onclose = function () &#123;    log(&#x27;disconnected&#x27;);    ws = null;  &#125;;  return false;&#125;function disconnect() &#123;  if (ws === null) return log(&#x27;already disconnected&#x27;);  ws.close();  return false;&#125;function send() &#123;  if (ws === null) return log(&#x27;please connect first&#x27;);  var text = document.getElementById(&#x27;text&#x27;).value;  document.getElementById(&#x27;text&#x27;).value = &quot;&quot;;  log(&#x27;send: &#x27; + text);  ws.send(text);  return false;&#125;function log(text) &#123;  var li = document.createElement(&#x27;li&#x27;);  li.appendChild(document.createTextNode(text));  document.getElementById(&#x27;log&#x27;).appendChild(li);  return false;&#125;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;  &lt;form onsubmit=&quot;return send();&quot;&gt;    &lt;button type=&quot;button&quot; onclick=&quot;return connect();&quot;&gt;      Connect    &lt;/button&gt;    &lt;button type=&quot;button&quot; onclick=&quot;return disconnect();&quot;&gt;      Disconnect    &lt;/button&gt;    &lt;input id=&quot;text&quot; type=&quot;text&quot;&gt;    &lt;button type=&quot;submit&quot;&gt;Send&lt;/button&gt;  &lt;/form&gt;  &lt;ol id=&quot;log&quot;&gt;&lt;/ol&gt;&lt;/body&gt;&lt;/html&gt;\n\nAnd now start the nginx with:\n1sudo /usr/local/openresty/nginx/sbin/nginx\n\nThen open a browser that has WebSocket support enabled, and open following url:http://127.0.0.1/websockets.html\nLua Web Sockets in ActionTo guard against half-open TCP connections, it is a good idea to enable TCP keepalive in your Nginx listen configuration directive:\nso_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];\nfor example:\nlisten 80 so_keepalive=2s:2s:8;(nginx documentation about so_keepalive)You could also do this on system level, if you wish:\n1$ sysctl net.inet.tcp.always_keepalive\n\nnet.inet.tcp.always_keepalive: 0\n1$ sudo sysctl -w net.inet.tcp.always_keepalive=1\n\nnet.inet.tcp.always_keepalive: 0 -&gt; 1(for Linux, see: Using TCP keepalive under Linux)\n编辑：糖果作者：Aapo Talvensaari\n","slug":"old_topic/2016-09-17-175","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"1d32e6a3ca5529481390baf7789466f8","title":"Vanilla框架静态的路由使用","content":"作者：糖果\n这次我们来看一下，如何在Vanilla下，追加新的路由。\n在Vanilla中追加一个新的路由，需要添加两个文件即可完成。\n我们进入工程根目录下的application目录，分别在controllers文件夹、views文件夹下肯创建两个文件。\n1.创建controllers文件。\nwaf.lua\n12345678910111213local WafController = &#123;&#125;function WafController:waf()    local view = self:getView()    local p = &#123;&#125;    p[&#x27;vanilla&#x27;] = &#x27;WAF&#x27;    p[&#x27;zhoujing&#x27;] = &#x27;Power by Openresty&#x27;    view:assign(p)    return view:display()endreturn WafController\n2.创建views文件。\nwaf.html\n1234567 &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;  &lt;img src=&quot;http://m1.sinaimg.cn/maxwidth.300/m1.sinaimg.cn/120d7329960e19cf073f264751e8d959_2043_2241.png&quot;&gt;  &lt;h1&gt;&lt;a href = &#x27;https://github.com/idevz/vanilla&#x27;&gt;&#123;&#123;vanilla&#125;&#125;&lt;/a&gt;&lt;/h1&gt;&lt;h5&gt;&#123;&#123;zhoujing&#125;&#125;&lt;/h5&gt;&lt;/body&gt;&lt;/html&gt;\n\n3.创建后的目录结构 。\n12345678910111213../controllers./controllers/index.lua./controllers/error.lua./controllers/waf.lua./views./views/error./views/error/error.html./views/waf./views/waf/waf.html./views/index./views/index/index.html\n最后我们在浏览器中输入路由到新网页的地址：\nhttp://www.vanilla.ren:7200/waf/waf\n下一篇介绍，如何配置vanilla中的WAF。\n1http://vanilla.ren:7200/waf.php?key=../\n\n\n\n\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-176","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3d42be7f67c57899442ba0d89e7757b9","title":"闲置域名出售","content":"手上有一些闲置的域名，有需要的同学可以卖走。\nwww.openresty.win \nopenresty.win 8元出售\nwww.vanilla.ren \nwww.errcode.xyz \n2元出售\nwww.errorcode.xyz \n1元出售\nwww.108086.xyz5元出售\nwww.108088.xyz5元出售\nwww.jianguo.win \nwww.waf.site \n联系QQ: 49263457\n","slug":"old_topic/2016-09-17-174","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4a16c2a8faba18731e43fdbaee33025b","title":"LUA的#操作符,getn,maxn操作table的区别","content":"作者：糖果\n#操作符与getn 作用是一样的，是取得table，连续数组元素的长度。\n12arr = &#123;1, 2, 3, [5]=789&#125;print(#arr)\n\n结果：3\n1print(table.getn(arr))\n结果：3\n#arr和getn在遇到第一个nil元素时，就停止了常数的记数。\n1print(table.maxn(arr))\n结果：5\n maxn是取复table中Hash值最大的一个数。\n","slug":"old_topic/2016-09-17-177","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"834bce8a4e8450443d18797324bd3ee0","title":"nil、null与ngx.null","content":"问题概述 \n\n今天第一次在nginx+lua架构下，写了个需要操作Redis的后台接口，该接口的功能主要是接受客户端的json格式的post请求，实现对保存在redis中的任务插入、删除、查询等。虽然nginx，lua等都是刚接触，但这几个接口还是顺风顺水的坐下来了，不能忘了感谢春哥章亦春。\n在Redis中记录的任务其实很简单，每插入一个任务，就在redis中增加一个HASH结构，每次查询返回该SET的各个Field和对应的Value值，例如md5，filesize等。由于任务类型的不同，有的Field可能在该任务中不存在，此时在以json格式将查询结果返回时不应显示该Field。\n以md5域为例，在对当前任务以md5域执行hget后，应该对返回结果做一个判断，如果该HASH结构并没有设置md5这个域，则跳过，继续执行后面的逻辑，如果设置了md5域，则把该域的Value取出来，插入到结果table中，后续再作为json格式返回结果的一部分，返回给后台。\n测试时，却发现在某些域未设置时，查询结果中却仍然会把该域返回给查询调用者，但其Value部分是null。例如,执行下面的测试用例：\n1curl -d &quot;&#123;\\&quot;queryfile\\&quot;:[&#123;\\&quot;url\\&quot;:\\&quot;/www.baidu.com/img/bdlogo.gif\\&quot; &#125;]&#125;&quot; &quot;127.0.0.1/cjson&quot;\n尽管对该任务而言，在插入时并没有设置md5域，但返回结果包含了md5域：\n1&#123;&quot;result&quot;:[&#123;&quot;url&quot;:&quot;\\/www.baidu.com\\/img\\/bdlogo.gif&quot;,&quot;result&quot;:0,&quot;md5&quot;:null,&quot;putflag&quot;:&quot;remote&quot;&#125;]&#125;\n问题分析 \n\n看到这个现象，首先想到的当然是lua脚本中对执行hget md5操作的返回值判断失效了，我第一次是这么写的：\n1234local md5,err=red:hget(tasklist,&quot;md5&quot;)if md5 and  md5 ~= &quot;&quot;  then    tb.md5=md5end\n从后面的结果看，当md5值为空时，该判断条件并没有将其过滤掉，依然执行了tb.md5=md5。由于redis模块也是调用春哥的lua-resty-redis，因此猜测是否春哥把redis查询结果中的空值用“null”字符串返回了，于是将上面的几行代码改为：\n1234local md5,err=red:hget(tasklist,&quot;md5&quot;)if md5 and  md5 ~= “null”  then    tb.md5=md5end\n仍然过滤失败，忽然眼前一亮，发现查询结果中显示的是”md5”:null,而非”md5”:”null”，上面这种猜测不攻自破。\n1red:hget(tasklist,&quot;md5&quot;)\n\n肯定是返回了一个跟null相关的结果，但这个结果既不是nil，又不是空字符串，也不是”null”。再次猜测，该值类型可能不是string,虽然这个猜测看上去很奇怪，因为在设置了md5的情况下，其类型的确是string。于是在判断语句前面加了一句打印信息：\n1ngx.say(&quot;type of null is &quot;..type(md5))\n\n果然，这个”空值“并不是string类型，而是userdata类型，userdata类型当然跟字符串类型不会相等，所以上面的过滤条件不管设置成什么样子，都不会生效，永远会执行tb.md5=md5。\n这样是找到原因了，但还未最终解决。既然当hget操作返回一个空值时，lua-resty-redis将其设置为一个userdata类型，那我们在代码里该如何过滤这种情况呢?本质问题就是，red:hget当查询resdis结果为空时，到底返回了什么？（不为空时，是string)\n这时候开源的好处就体现出来了，在https://github.com/agentzh/lua-resty-redis里扫了下redis.lua文件，发现返回的是ngx.null。\n恩，问题到这就解决了，将上面的过滤代码改为：\n1234local md5,err=red:hget(tasklist,&quot;md5&quot;)if md5 and md5 ~= null and md5 ~= ngx.null  then    tb.md5=md5end\n就能保证返回结果里不会包含值为null的域了。\n眼高手低 \n\n回头看了一下lua-resty-redis的文档，发现关于上面的内容，在Readme里已经写的清清楚楚了，在https://github.com/agentzh/lua-resty-redis/blob/master/README.markdown中，有这么一句：\nA non-nil Redis \"bulk reply\" results in a Lua string as the return value. A nil bulk reply results in a ngx.null return value. \n\n\n首先不应该是自责，而是再次赞一下agentzh的态度，业界标杆。\nngx.null是什么？ \n\n那么ngx.null到底是什么东西呢？ 在http://wiki.nginx.org/HttpLuaModule有如下说明：\nThe ngx.null constant is a NULL light userdata usually used to represent nil values in Lua tables etc and is similar to the lua-cjson library's cjson.null constant. This constant was first introduced in the v0.5.0rc5 release. \n\nngx.null在print、ngx.print、ngx.log、ngx.say等函数中，有如下特点：\nLua nil arguments are accepted and result in literal \"nil\" strings while Lua booleans result in literal \"true\" or \"false\" strings. And the ngx.null constant will yield the \"null\" string output. \n\n为什么要这么设计？ \n\nlua-resty-redis中，为什么要把redis查询为空的情况返回一个userdata类型的ngx.null？直接返回nil不行吗？\n答案是不行，因为nil在lua中有其特殊意义，如果一个变量被设置为nil，就等于说该变量未定义，与无穷无尽的其他未定义的变量一样。那么，如果把redis查询为空的结果设置为nil，就无法把”查询为空”和“未定义”区分开来了，例如在一个table中，一个key对应一个value，如果将该value设置为nil，则相当让key凭空消失，这显然是不合理的。所以必须用一个userdata类型的独特的值来表示这种查询为空，但又不等同于未定义的变量，例如ngx.null。同样的情况想必在sql的lua模块中也会出现，用来处理记录中键值查询为空的情况。\n幽灵般的nil \n\n这就要说道lua中神奇的nil了。nil是一种类型，该类型只有一个值，这个值也叫nil。改值的作用只有一个，表示一个变量不存在。跟C\\C++等常规语言不同，”不存在“跟空、0完全是两个概念。在C语言中，一个字符串如果为空，那么它就只有一个为0的\\nul结束符，如果对齐进行逻辑判断，则是假。但lua中，只要一个变量不是nil类型或者是boolean类型中的false,则对它进行逻辑判断，结果是真，即使该值是一个数字0，或者是一个空字符串。\n编辑：糖果\n作者：strider原文链接：http://www.pureage.info/2013/09/02/125.html\n","slug":"old_topic/2016-09-17-178","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"85a31f98ce1faec97b54316baed59b3d","title":"LUA模拟面向对象：类与对象","content":"首先还是向大家介绍一下国产LUA框架Vanilla。这次我们来看看Vanilla中如何用Lua 模拟面向对象编程。实现主要是使用lua的setemetatable特性来实现的。下面程序大体的处理流程是：\n类和对象创建流程：1.创建一个Controller在类模板程序。2.在Controller:new方法里，创建返回一个实例对象instance(lua table)，对象使用Controller的函数接口，做为对象实例产生的“类”模板。3.使用new方法的形参，传递新建立对象的属性数据，成员变量。\n[code]local Controller = {}\nfunction Controller:new(app_config, tst_val)        local instance = {                app_config = app_config,                tst_val = tst_val        }        setmetatable(instance, {__index = self})        return instanceend\nfunction Controller:display(view_tpl, values)end\nfunction Controller:getTestField()        return self.tst_valend\nreturn Controller[/code]\n测试类文件的流程：1.用require引入contorller类定义文件。2.创建对象初始化要使用的数据结构：config, val。3.调用Controller类模板的new方法，创建新的对象实例，传入需要形参。4.使用新创建的对象实例的getTestFiled()接口方法，返回我们在第三步传入的测试字符串：“test value”5.输出返回值，确认是否与传入的数据一致。\n[code]Controller = require “controller”\nlocal config = { ip=”127.0.0.1”, port=”8080” }local val = “test value”\nlocal obj_instance = Controller:new(config, val)local ret = obj_instance:getTestField()print(ret)\n[/code]\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\nhttps://github.com/idevz/vanilla\n","slug":"old_topic/2016-09-17-180","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4f367eaf18737796ed26e3985923aa72","title":"如何用Lua取得ASCII表中的字符","content":"比如我们要显示ASCII表中的”a”，我们可以使用如下代码：\n1print(string.char(97))","slug":"old_topic/2016-09-17-181","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"1b3a4d7f131dd65bcee1a16042fe9553","title":"Lrexlib安装(Lua PCRE)","content":"作者：糖果\nLrexlib是PCRE的Lua调用库。在此说一下 Lrexlib的安装过程。\nUbuntu下安装：\n1.首先是安装依赖。\n12apt-get install libpcre3apt-get install libpcre3-dev\n\n2.建立连接。Ubuntu安装的是pcre3，安装完之后系统内才能有libpcre.so的库。apt-get安装的库文件没有在/usr/lib文件夹下，需要建立连接。\n1ln -s /lib/x86_64-linux-gnu/libpcre.so.3 /usr/lib/libpcre.so\n\n3.使用luarocks安装PCRE。\n1sudo luarocks install lrexlib-PCRE PCRE_LIBDIR=/usr/lib/\n\n4.测试库。\n1lua -e &quot;require &#x27;rex_pcre&#x27;&quot;\n\n\nCentos下安装PCRE：\n1.首先是安装依赖。\n12yum install pcreyum install pcre-devel\n\n2.建立连接。\n1ln -s  /usr/lib64/libpcre.so /usr/lib\n\n3.使用luarocks安装PCRE。\n需要特别说明的地方是，在centos上安装2.8是编译不过的，需要指定2.7.2版本的安装。\n1luarocks install lrexlib-pcre 2.7.2-1 PCRE_LIBDIR=/usr/lib64/\n\n4.测试库。\n1lua -e &quot;require &#x27;rex_pcre&#x27;&quot;\n\n\nhttps://luarocks.org/modules/luarocks/lrexlib-pcre\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-182","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a63cff28e964bdf4acd74377beb1b3f4","title":"Lua源码赏析","content":"Lua源码赏析\n","slug":"old_topic/2016-09-17-179","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"cc7492c9c593b6abb05073ddf9060cb2","title":"Moonscript的常用WEB特性","content":"下面是一个简单的moonscript脚本，值得注意的地方有几点。1.Moonscript如何表示List列比数据结构。2.Moonscript的路由样式。3.Moonscript如何取得请求URL中的参数变量值。4.Moonscript如何遍历List数据结构。（pairs）5.Moonscript如何显示HTML。6.Moonscript判空语句。\n  1.Moonscript如何表示List列比数据结构。 \n  \n  Lua种的Table在Moonscript种，便成了如下的格式。\n– Moonscript[code]list_items =  {  “item1”:”test item1”  “item2”:”test item2”  “item3”:”test item3”}[/code]\n–Lua[code]local list_items = {  [“item1”] = “test item1”,  [“item2”] = “test item2”,  [“item3”] = “test item3”}\n[/code]\n值得注意的地方就是，每个表元素之间没有了”,”逗号分割。\n如何直接翻译成Lua后，代码形式如下：\n2.Moonscript的路由样式。 \n\n[code]  item: “/item/:name”:=&gt;[/code]Moonscript是用这种形式表示路由的“item”， “/item/:name”表示URL后面可以跟的参数表量。\n3.Moonscript如何取得请求URL中的参数变量值。 \n[code]\n    item_description =  list_items[@params.name]\n[/code]    \n@params.name中，params表示输入参数的集合数据结构，\".name\"就是URL种的变量名。\n\n4.Moonscript如何遍历List数据结构。（pairs）[code]        for item in pairs list_items          li -&gt;            a href: @url_for(“item”, name:item), item [/code] Moonscript遍历Table，for关键字后面不用加do end结构。另外，可以使用pairs关键字，而没有ipairs关键字。\n 5.Moonscript如何显示HTML。 \n 逻辑和模板放到一起写，“业务”和“表示”放到一起写不便于解耦，但是对于懒人来说，这个特性就比较方便了。\n \n [code]     @html -&gt;      h1 @params.name      h2 “Result list items”      p item_description      div  “abc” [/code]    \n @html -&gt;下面就可以直接用短关键字，快捷的生成HTML语句。\n6.Moonscript判空语句。 \n [code]    \n    item_description =  list_items[@params.name]\n    unless item_description\n [/code]    \n \n \nunless关键字用于判空，更接近自然语言。感觉用起来像Cobol的感觉，关键字好长。   \n后记：其实Moonscript也有语法缩进的，如果缩进不对在编译的时候会报错，这和Python，Cobol很像。\n另外，如下:[code] @html -&gt;[/code]\n“@html”和”-&gt;”之间有一个空格。\nMoonscript懒人的福音。\n代码列表：[code]lapis = require “lapis”\nlist_items =  {  “item1”:”test item1”  “item2”:”test item2”  “item3”:”test item3”}\nlist_div = {  “div1”:”div1”  “div2”:”div2”  “div3”:”div3”}\nclass extends lapis.Application  [index: “/“]:=&gt;    @html -&gt;      h1 “test page”      a href: @url_for(“list_items”), “Check out my list items”\n@html -&gt;\n  ul -&gt;\n    for item in pairs list_items\n      li -&gt;\n        a href: @url_for(&quot;item&quot;, name:item), item\n        \n\nitem_description =  list_items[@params.name]\nunless item_description\n  return &quot;Not found&quot;, status:404\n\n@html -&gt;\n  h1 @params.name \n  h2 &quot;Result list items&quot;\n  p item_description\n  div  &quot;abc&quot;\n  \n\n@html -&gt;\n  for item in pairs list_div\n    h1 item\n    h1 &quot;test&quot;\n\n[/code]\n","slug":"old_topic/2016-09-17-184","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"92825ad55c31699146a13eff573616d1","title":"Moonscript的WEB工程配置文件","content":"作者：糖果http://www.lua.ren\nLapis框架默认是没有配置文件，lapis new 创建出来的工程没有对监听的端口和数据库的相关设置，需要在工程目录下创建一个config.moon或是moon.lua配置文件，进行相关的设定。\n首先，看一下如何通过Moonscript设置工程Openresty监听的端口号和数据库配置信息。\n12345678config = require(&quot;lapis.config&quot;)config &quot;development&quot;, -&gt;  port 8080  mysql -&gt;    host &quot;127.0.0.1&quot;    user &quot;moonscript&quot;    password &quot;moonscript&quot;    database &quot;moonscript&quot;\n\n我们来看一下config.moon，被翻译成Lua之后的形态。\n12345678910local config = require(&quot;lapis.config&quot;)return config(&quot;development&quot;, function()  port(8080)  return mysql(function()    host(&quot;127.0.0.1&quot;)    user(&quot;moonscript&quot;)    password(&quot;moonscript&quot;)    return database(&quot;moonscript&quot;)  end)end)\n\n这需要需要的特别注意的就是 ，需要特别注意的是， 无论是Moonscript，还是Lua都需要引用lapis .config\n1config = require(&quot;lapis.config&quot;)\n\n以上的配置是Moonscript和自动翻译成的Lua,我们看看直接用Lua写，config.lua是什么样的。\n1234567891011local config = require(&quot;lapis.config&quot;)config(&quot;development&quot;, &#123;port = 8080,mysql = &#123;host = &quot;127.0.0.1&quot;,user = &quot;moonscript&quot;,password = &quot;moonscript&quot;,database = &quot;moonscript&quot;&#125;&#125;)\n其实，还是纯Lua的写法，最简洁明。Lapis默认的骨架工程使用的不是Mysql数据库，我们在配置文件种指定了Mysql为工程的数据库，这块的实现，可以直接看Lapis的DB相关的源码。\n原文来至糖果实验室\n","slug":"old_topic/2016-09-17-185","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"72fc9906b7ade28d0ec3b847f7af3a98","title":"Tup与Moonscript自动编译","content":"tup可以监控文件变动的，再执行相应有执行动作。可以设定tupfile规则，当监控目录中的文件发生变化的时候，实时执行编译脚本，只要文件有改动，然后openresty服务会reload文件，刷新一下url就可以看到新的变动结果（LUA）。\n安装TUP首先要在Linux上安装FUSE。\n第一步：安装FUSE。\n1yum install fuse\n只安装fuse是不够的，还需要安装fuse-devel，在之后的编译需要.h和库文件。\n123yum list fuse*yum install fuse-devel\n\n如果是在ubuntu下：\n1sudo apt-get install libfuse-dev\n\n第二步：下载tup。\n12345git clone https://github.com/gittup/tup.git./build.sh linuxsudo ./bootstrap.sh\n\n第三步：运行tup。\n12345678ln tup /usr/bintup initsudo tupsudo tup monitor -a\n\n特别说明：\nA.创建软链接。\n1ln -s tup /usr/bin\n-s创建软连接，可跨文件系统。\nB.监控变化。\n第二次输入就是重起就是monitor\n1sudo tup monitor -a\n\n\nC.监控规则tup在文件发生变动的时候，根据什么规则去什么动作。\n在创建lapis工程的时候，我们不是简单的输入：\n1lapis new\n\n而是要输入：\n1lapis new --git --tup\n\n这样会在当前目录，生成规则文件Tuprules.tup\n1: foreach *.moon |&gt; moonc %f |&gt; %B.lua  \n所有.moon文件，用moonc编译成同名的lua程序。\nTup的效果就是，只要编辑工程目录中的.moon文件，就会自动触发moonc把.moon编译成.lua文件。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\nhttp://www.lua.ren\n","slug":"old_topic/2016-09-17-183","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"b8a0477ffed33bd6d0efdb938e9ec4db","title":"Moonscript的循环结构","content":"除了使用迭代器，某些应用场合，我们还需要使用固定次数的循环结构，Moonscript提供While风格的固定循环控制。\nMoonscript\n1234567class extends lapis.Application  [loop: &quot;/loop&quot;]:=&gt;    @html -&gt;      i =  10      while i &gt; 0        div text &quot;Moonscript&quot;        i -= 1\n\n我们把纯循环的代码，从Moonscript Lapis框架代码独立出来：\nMoonscript\n12345678910i = 100my_func = -&gt;  i = 10  while i &gt; 0    print i    i -= 1my_func!print i\n\nLua\n1234567891011local i = 100local my_funcmy_func = function()  i = 10  while i &gt; 0 do    print(i)    i = i - 1  endendmy_func()return print(i)\n\n\n为什么这个？用这种循环样式在Moonscript直接控制HTML标签应该能比较便捷一些。\n把静态文档的目录用些控制，配合sitegen生成静态网页很好。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-187","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e5306b1f99d6e83b5a21496ff6f51752","title":"老衲，这代码不能要！","content":"Christ people. This is just sh*t.\nThe conflict I get is due to stupid new gcc header file crap. But whatmakes me upset is that the crap is for completely bogus reasons.\nThis is the old code in net/ipv6/ip6_output.c:\nmtu -= hlen + sizeof(struct frag_hdr);\nand this is the new “improved” code that uses fancy stuff that wantsmagical built-in compiler support and has silly wrapper functions forwhen it doesn’t exist:[code]if (overflow_usub(mtu, hlen + sizeof(struct frag_hdr), &amp;mtu) ||mtu &lt;= 7)goto fail_toobig;[/code]and anybody who thinks that the above is\n(a) legible(b) efficient (even with the magical compiler support)(c) particularly safe\nis just incompetent and out to lunch.\nThe above code is sh*t, and it generates shit code. It looks bad, andthere’s no reason for it.\nThe code could easily have been done with just a single andunderstandable conditional, and the compiler would actually havegenerated better code, and the code would look better and moreunderstandable. Why is this not\n[code]if (mtu &lt; hlen + sizeof(struct frag_hdr) + 8)goto fail_toobig;mtu -= hlen + sizeof(struct frag_hdr);[/code]which is the same number of lines, doesn’t use crazy helper functionsthat nobody knows what they do, and is much more obvious what itactually does.\nI guarantee that the second more obvious version is easier to read andunderstand. Does anybody really want to dispute this?\nReally. Give me one reason why it was written in that idiotic waywith two different conditionals, and a shiny new nonstandard functionthat wants particular compiler support to generate even half-way sanecode, and even then generates worse code? A shiny function that wehave never ever needed anywhere else, and that is justcompiler-masturbation.\nAnd yes, you still could have overflow issues if the whole “hlen +xyz” expression overflows, but quite frankly, the “overflow_usub()”code had that too. So if you worry about that, then you damn welldidn’t do the right thing to begin with.\nSo I really see no reason for this kind of complete idiotic crap.\nTell me why. Because I’m not pulling this kind of completely insanestuff that generates conflicts at rc7 time, and that seems to haveabsolutely no reason for being anm idiotic unreadable mess.\nThe code seems designed to use that new “overflow_usub()” code. Itseems to be an excuse to use that function.\nAnd it’s a f*cking bad excuse for that braindamage.\nI’m sorry, but we don’t add idiotic new interfaces like this foridiotic new code like that.\nYes, yes, if this had stayed inside the network layer I would neverhave noticed. But since I did notice, I really don’t want to pullthis. In fact, I want to make it clear to everybody that code likethis is completely unacceptable. Anybody who thinks that code likethis is “safe” and “secure” because it uses fancy overflow detectionfunctions is so far out to lunch that it’s not even funny. All thiskind of crap does is to make the code a unreadable mess with code thatno sane person will ever really understand what it actually does.\nGet rid of it. And I don’t ever want to see that shit again.\nLinus\nhttp://lkml.iu.edu/hypermail/linux/kernel/1510.3/02866.html\n","slug":"old_topic/2016-09-17-186","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"43450fb948daac9a77b252ddeba99506","title":"Moonscript的Busted单体测试","content":"作者：糖果\nBusted是Lua的单体测试工具。去官网Github看一下，也支持Moonscript的单体测试。\nmoonunit.moon\n123456describe &#x27;moonscript tests&#x27;, -&gt;  it &#x27;works&#x27;, -&gt;    assert.are.equal true, true    return  returnreturn\n\nDescribe关键字：描述了一组单元测试。It关键字： 是对一个Case的描述。\n把Moonscript脚本，翻译成Lua脚本。moonc  moonunit.moon\n12345describe(&#x27;moonscript tests&#x27;, function()  it(&#x27;works&#x27;, function()    assert.are.equal(true, true)  end)end)\n\n其实，不用有这个翻译过程，因为busted直接可以解析.moon脚本。\n因为这个脚本只有一个Case，所有显示结果如下：\n123 busted moonunit.moon ●1 success / 0 failures / 0 errors / 0 pending : 0.000782 seconds\n\n下面我们估计，把Case的表达结果，改成NG。\n123456describe &#x27;moonscript tests&#x27;, -&gt;  it &#x27;works&#x27;, -&gt;    assert.are.equal true, false    return                  returnreturn\n\n1234567891011busted moonunit.moon ◼0 successes / 1 failure / 0 errors / 0 pending : 0.000996 secondsFailure → moonunit.moon @ 2moonscript tests worksmoonunit.moon:3: Expected objects to be equal.Passed in:(boolean) falseExpected:(boolean) true\n如预期一样，出现了NG报告。\n在另一篇中，我们用Vanilla框架的Simple Route做例子，写单体测试CASE。\n","slug":"old_topic/2016-09-17-189","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"2ae7e20708abb11b61241dea5050fc63","title":"给Vanilla框架的路由模块加入单体测试","content":"作者：糖果\n下面是单体测试的代码：\n123456789101112131415161718192021222324252627282930313233343536373839-- perflocal error = errorlocal sgmatch = string.gmatch-- init Simple and set routeslocal Simple = &#123;&#125;function Simple:new(request)    local instance = &#123;        route_name = &#x27;vanilla.v.routes.simple&#x27;,    \trequest = request    &#125;    setmetatable(instance, &#123;        __index = self,        __tostring = function(self) return self.route_name end        &#125;)    return instanceendfunction Simple:match()    local uri = self.request.uri    local match = &#123;&#125;    local tmp = 1    if uri == &#x27;/&#x27; then        return &#x27;index&#x27;, &#x27;index&#x27;    end    for v in sgmatch(uri , &#x27;/([A-Za-z0-9_]+)&#x27;) do        match[tmp] = v        tmp = tmp +1    end    if #match == 1 then        return match[1], &#x27;index&#x27;    else        return table.concat(match, &#x27;.&#x27;, 1, #match - 1), match[#match]    endendreturn Simple","slug":"old_topic/2016-09-17-188","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"bc3b37831d103f6bddad2d9961281834","title":"Openresty工程如何处理mime定义问题","content":"Lapis处理mime问题，一共使用了两个文件。\nmime.types\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293types &#123;    text/html                             html htm shtml;    text/css                              css;    text/xml                              xml;    image/gif                             gif;    image/jpeg                            jpeg jpg;    application/x-javascript              js;    application/atom+xml                  atom;    application/rss+xml                   rss;    text/mathml                           mml;    text/plain                            txt;    text/vnd.sun.j2me.app-descriptor      jad;    text/vnd.wap.wml                      wml;    text/x-component                      htc;    image/png                             png;    image/tiff                            tif tiff;    image/vnd.wap.wbmp                    wbmp;    image/x-icon                          ico;    image/x-jng                           jng;    image/x-ms-bmp                        bmp;    image/svg+xml                         svg svgz;    image/webp                            webp;    application/java-archive              jar war ear;    application/mac-binhex40              hqx;    application/msword                    doc;    application/pdf                       pdf;    application/postscript                ps eps ai;    application/rtf                       rtf;    application/vnd.ms-excel              xls;    application/vnd.ms-powerpoint         ppt;    application/vnd.wap.wmlc              wmlc;    application/vnd.google-earth.kml+xml  kml;    application/vnd.google-earth.kmz      kmz;    application/x-7z-compressed           7z;    application/x-cocoa                   cco;    application/x-java-archive-diff       jardiff;    application/x-java-jnlp-file          jnlp;    application/x-makeself                run;    application/x-perl                    pl pm;    application/x-pilot                   prc pdb;    application/x-rar-compressed          rar;    application/x-redhat-package-manager  rpm;    application/x-sea                     sea;    application/x-shockwave-flash         swf;    application/x-stuffit                 sit;    application/x-tcl                     tcl tk;    application/x-x509-ca-cert            der pem crt;    application/x-xpinstall               xpi;    application/xhtml+xml                 xhtml;    application/zip                       zip;&#125;[/code][code]nginx.confworker_processes $&#123;&#123;NUM_WORKERS&#125;&#125;;error_log stderr notice;daemon off;pid logs/nginx.pid;events &#123;  worker_connections 1024;&#125;http &#123;  include mime.types;  server &#123;    listen $&#123;&#123;PORT&#125;&#125;;    lua_code_cache $&#123;&#123;CODE_CACHE&#125;&#125;;    location / &#123;      default_type text/html;      content_by_lua &#x27;        require(&quot;lapis&quot;).serve(&quot;app&quot;)      &#x27;;    &#125;    location /static/ &#123;      alias static/;    &#125;    location /favicon.ico &#123;      alias static/favicon.ico;    &#125;  &#125;&#125;","slug":"old_topic/2016-09-17-191","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"2f345e8c1c99108bbbdc1391c900b270","title":"LUACURL使用笔记","content":"CURL是 URL命令行工具， 即 command URL， 可以通过命令行模拟各种应用协议的发包， 包括FTP HTTP HTTPS，\n官方网站 \n1http://curl.haxx.se/\n\n\nluacurllua curl是基于curl的库libcurl\n1http://curl.haxx.se/libcurl/\n\n针对libcurl开放的API\n1http://curl.haxx.se/libcurl/c/\n, 定义lua API对curl基本功能进行封装。\nluauser中列出来3中绑定libcurl的lua封装库\n1http://lua-users.org/wiki/LuaCurl\n\n其中freepops-luacurl\n1http://www.freepops.org/en/\n\n实现了libcurl所有的easy 接口 \n1http://curl.haxx.se/libcurl/c/libcurl-easy.html\n\n\n luaforge上提供一个 windows 上可运行luacurl的压缩包\n1http://files.luaforge.net/releases/luacurl/freepops-luacurl/0.3.0\n\n1freepops-lua-curl-binary-win32-openssl\n\n本文示例就采用这个windows可运行包。\n解压后， cmd命令行cd到解压目录，使用 luaxx.exe yy.lua 接口运行示例脚本。\n 示例 例子，实现https方式，登录网站，访问某个网页，修改其中参数的功能。其中xx应用时候需要修改。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384require(&quot;curl&quot;)local ipList = &#123;    &quot;192.168.1.1&quot;,　　&quot;192.168.1.1&quot;,&#125;--登陆function loginWeb(ip) 　　c = curl.easy_init() 　　c:setopt(curl.OPT_SSL_VERIFYHOST, 0); 　　c:setopt(curl.OPT_SSL_VERIFYPEER, 0); 　　c:setopt(curl.OPT_URL, &quot;https://&quot;..ip..&quot;/&quot;)    c:setopt(curl.OPT_POSTFIELDS, &quot;Username=admin&amp;Password=admin&amp;Frm_Logintoken=&amp;action=login&quot;)　　c:setopt(curl.OPT_WRITEFUNCTION, function(buffer)　　　　--print(buffer) 　 　　--print(&quot;\\r\\n---------------------------\\r\\n&quot;);　　　　return #buffer　　end)   c:perform()end--访问页面function accessPage(ip) 　　c = curl.easy_init() 　　c:setopt(curl.OPT_SSL_VERIFYHOST, 0); 　　c:setopt(curl.OPT_SSL_VERIFYPEER, 0); 　　c:setopt(curl.OPT_URL, &quot;https://&quot;..ip..&quot;/xxpage.html&quot;)　　c:setopt(curl.OPT_WRITEFUNCTION, function(buffer)　　　　--print(buffer) 　 　　--print(&quot;\\r\\n---------------------------\\r\\n&quot;);　　　　return #buffer　　end)   c:perform()end--设置参数function setParameter(ip, file) 　　c = curl.easy_init() 　　c:setopt(curl.OPT_SSL_VERIFYHOST, 0); 　　c:setopt(curl.OPT_SSL_VERIFYPEER, 0); 　　c:setopt(curl.OPT_URL, &quot;https://&quot;..ip..&quot;/xx.php&quot;) 　　c:setopt(curl.OPT_POSTFIELDS, &quot;DaylightSavingsUsed=1&amp;Dscp=-1&quot;)　　local htmlTable = &#123;&#125;　　c:setopt(curl.OPT_WRITEFUNCTION, function(buffer)　　　　--print(buffer) 　 　　--print(&quot;\\r\\n---------------------------\\r\\n&quot;);　　　　table.insert(htmlTable, buffer)　　　　return #buffer　　end)   c:perform()　　local htmlStr = table.concat(htmlTable);　　local resultBuff = &quot;&quot;;　　if string.match(htmlStr, &quot;&lt;result&gt;SUCC&lt;/result&gt;&quot;) ~= nil then　　　　resultBuff = ip..&quot; config OK\\r\\n&quot;;　　　　print(resultBuff)　　　　file:write(resultBuff);　　else　　　　resultBuff = ip..&quot; config NOK\\r\\n&quot;;　　　　print(resultBuff)　　　file:write(resultBuff);　endendlocal file = io.open(&quot;.\\\\result.txt&quot;, &quot;w+&quot;);for key,ip in ipairs(ipList) do 　　loginWeb(ip); 　　accessPage(ip); 　　openLightSave(ip, file); endfile:close();print(&quot;Done&quot;)\n\n作者：LightSong出处：http://www.cnblogs.com/lightsong/本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利\n","slug":"old_topic/2016-09-17-192","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"56f67290590d9d72dc1ccb87fe155f52","title":"Vanilla工程如何设置静态文件夹static","content":"修改/config/nginx.conf\n加入路由设置[code]        location /static/ {            alias static/;        }[/code]\n完整的配置文件，如下：[code]pid tmp/-nginx.pid;\nThis number should be at maxium the number of CPU on the serverworker_processes 4;\nevents {    # Number of connections per worker    worker_connections 4096;}\nhttp {    # use sendfile    sendfile on;\n# Va initialization\n&#123;&#123;LUA_PACKAGE_PATH&#125;&#125;\n&#123;&#123;LUA_PACKAGE_CPATH&#125;&#125;\n&#123;&#123;LUA_CODE_CACHE&#125;&#125;\n&#123;&#123;LUA_SHARED_DICT&#125;&#125;\n&#123;&#123;INIT_BY_LUA&#125;&#125;\n&#123;&#123;INIT_BY_LUA_FILE&#125;&#125;\n&#123;&#123;VANILLA_WAF&#125;&#125;\n&#123;&#123;ACCESS_BY_LUA&#125;&#125;\n&#123;&#123;ACCESS_BY_LUA_FILE&#125;&#125;\n\nserver &#123;\n    # List port\n    listen &#123;&#123;PORT&#125;&#125;;\n    set $template_root &#39;&#39;;\n\n    # Access log with buffer, or disable it completetely if unneeded\n    access_log logs/&#123;&#123;VA_ENV&#125;&#125;-access.log combined buffer=16k;\n    # access_log off;\n\n    # Error log\n    error_log logs/&#123;&#123;VA_ENV&#125;&#125;-error.log;\n\n\n    # Va runtime\n    &#123;&#123;CONTENT_BY_LUA_FILE&#125;&#125;\n\n    // 在此处加入静态链接的设置\n    location /static/ &#123;\n        alias static/;\n    &#125;\n&#125;\n\n}[/code]\n","slug":"old_topic/2016-09-17-190","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d9f46b0969f93bdf774649548bb0ec97","title":"《MacTalk 跨越边界》","content":"对于池老师的关注是从他到锤子科技之后开始的。关于IT类的散文随笔也看过一些，比如《黑客与画家》，这次看池老师的文章也有类似的读阅体会。\n池老师的文章，将IT技术与对其思考的理念杂揉到一起，形散而又主题突出。看到这本书，让人想起了编剧史航对王朔的评价，大概的意思是， 他是一个走在我们前面的人，而同时他又有能力，把自己所见所思，换成理念和文字 传达给后面的人，后面的人可以看到他的勇敢、智慧，胆识。\n\n看到这本书的中写的内容，比如：35的岁程序员，加班这些主题，对那些刚上路的朋友们来说，就像摸黑走夜路的时候，边上有个人给你打了一只手电筒给你一道光，照出你前行的路。\n\n   如果你是一个文艺青年的话！什么叫文艺青年？印象里用老罗的观点，是那些天生敏感，而又有表达欲望的人，都可以别归为文艺青年。这书适合你，不是也没关系, 只要你是从事IT行业的。\n   这本书是“文艺青年”写的， 要是更准确的说，是文艺壮年程序员写的，看着书就能感到一种画面感，作者透着一种手持搬砖的力道之美，用逻辑武装的坚不可摧， 他经历祖国IT行业的潮起潮落，他的脑海中有很多的故事,他的手中有着漂亮的“贝壳”， 他把“贝壳”藏在了这个本书中，你会发现有“贝壳”会是你喜欢的，打开贝壳，你会看到智慧。\n","slug":"old_topic/2016-09-17-193","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"210155a39a8b6625ee1b84d14c0c7978","title":"如何在Lapis中给前端JS传送JSON数据对象","content":"在Lua编写WEB程序的过程中， 有一种应用场景，是从KVDB,或是DB中取出JSON数据，或是直接定义JSON数据传给前端，用于显示展示，或是其它之用。\n为了减化说明，我们直接用一个不是从DB取得，而是自定义一个JSON数据， 返回给前端的模板。\nLapis lua代码：\n12345678app:get(&quot;/return_json&quot;, function(self)        --自定义一个最简单的JSON结构        tmp_json= &#123;test=&quot;abc&quot;&#125;        --对JSON进行编码        self.tmp_json = json.encode(tmp_json)        --渲染模板        return &#123; render = &quot;json_template&quot; &#125;end)\n\n\nJavascript代码：\n1234567891011121314151617181920212223&lt;script type=&quot;text/javascript&quot;&gt;    //这个函数是对文本中含有的特殊符号进行转换处理    function htmlspecialchars_decode(text) &#123;        var replacements = Array(&quot;&amp;&quot;, &quot;&lt;&quot;, &quot;&gt;&quot;, &#x27;&quot;&#x27;, &quot;&#x27;&quot;);        var chars = Array(&quot;&amp;&quot;, &quot;&lt;&quot;, &quot;&gt;&quot;, &quot;&quot;&quot;, &quot;&#x27;&quot;);        for (var i = 0; i &lt; chars.length; i++) &#123;            var re = new RegExp(chars[i], &quot;gi&quot;);            if (re.test(text)) &#123;                text = text.replace(re, replacements[i]);            &#125;        &#125;        return text;    &#125;    // 从etlua模板中，取出lapis传递的值。    var tmp_json = &quot;&lt;%= tmp_json %&gt;&quot;    // 转换特殊符号    var html_tmp_json = htmlspecialchars_decode(tmp_json)    //  这是将一个普通的字符串，转换成Javascript的JSON对象    var js_json = eval(html_tmp_json);&lt;/script&gt;\n\n\n整个JSON从Lua到JS对象过程是：\n1lua table-&gt; lua json-&gt; js string-&gt;js object\n中间特殊符号的处理，只是改变了内容，而没改变数据型态。\n这个例子是返回JSON数据，同时我们也可以传JSON数据给Lapis， 之后我们可能会简单介绍一下Lapis如何解释JSON参数。\n","slug":"old_topic/2016-09-17-199","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"8b705c23d4a474e218260c1eafaf275e","title":"来至英国朋友的消息","content":"[Alert] Importance message for British nationals in Beijing \n\nThe British Embassy Beijing has received information of possible threats against Westerners in the Sanlitun area of Beijing, on or around Christmas Day. British citizens are urged to exercise heightened vigilance. The UK Embassy has issued the same guidance to British Government Staff.\nIf you’re a British national in China and you urgently need help, call +86 (10) 5192 4000.If you’re in the UK and concerned about a British national in China, call 020 7008 1500.\nFor other general consular services, please click ‘Read more’ at the left bottom.\n","slug":"old_topic/2016-09-17-197","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f7046ce417542dc934d2749b052430d6","title":"Python的PIP应用Fetch不到下载文件","content":"如果出现，以下的消息，或者是在Python源码里，直接抛出异常，类似Connect Error的信息，可以肯定的是链接pypi的安装数据源出现问题了．\n1Cannot fetch index base URL https://pypi.python.org/simple/\n\n列一下可用的安装源：天朝外https://pypi.python.org/simple/\n天朝pypi.douban.com/simple/\nhttp://ypi.v2ex.com/simple\n当被墙，或是网络不好的时候，需要配置一下，当前用户目录下的.pip文件夹中的pip.conf\n配置如下：\n12345[global]index-url=http://pypi.douban.com/simplev2ex:http://ypi.v2ex.com/simple\n\n\n创建了这个配置文件，在使用pip安装文件就基本OK了．\n测试过同样是因为网络问题，windows下的pip用非国内有也不好用。在windwos下pip安装部件也需要配置conf文件。\n在unix和macos，配置文件为：$HOME/.pip/pip.conf在windows上，配置文件为：%HOME%\\pip\\pip.ini  \n配置文件的内容是一样的，在Windows在pip安装时还需要，添加一个参数。\n–trusted-hostpip install django==1.55 –trusted-host pypi.douban.com\n","slug":"old_topic/2016-09-17-200","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"047b86aef4992c639f275b13c69e96b7","title":"如何定制Nginx的Log输出格式","content":"123456set $currentDate &#x27;day&#x27;;              access_by_lua &#x27;                  ngx.var.currentDate = os.date(&quot;%Y-%m-%d&quot;)              &#x27;;              access_log /logs/app.access.$currentDate.log app_log;\n\n\n图片：yuanzhang.png\n一个很棒的库https://github.com/cloudflare/lua-resty-logger-socket\n下载链接：一个独立的LOG输出模块\n","slug":"old_topic/2016-09-17-194","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"340b5f6f2b7fa198ce66c515bcec1223","title":"LUA中实现面向对象","content":"我们引用云风大哥的代码：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546local _class=&#123;&#125; function class(super)\tlocal class_type=&#123;&#125;\tclass_type.ctor=false\tclass_type.super=super\tclass_type.new=function(...) \t\t\tlocal obj=&#123;&#125;\t\t\tdo\t\t\t\tlocal create\t\t\t\tcreate = function(c,...)\t\t\t\t\tif c.super then\t\t\t\t\t\tcreate(c.super,...)\t\t\t\t\tend\t\t\t\t\tif c.ctor then\t\t\t\t\t\tc.ctor(obj,...)\t\t\t\t\tend\t\t\t\tend \t\t\t\tcreate(class_type,...)\t\t\tend\t\t\tsetmetatable(obj,&#123; __index=_class[class_type] &#125;)\t\t\treturn obj\t\tend\tlocal vtbl=&#123;&#125;\t_class[class_type]=vtbl \tsetmetatable(class_type,&#123;__newindex=\t\tfunction(t,k,v)\t\t\tvtbl[k]=v\t\tend\t&#125;) \tif super then\t\tsetmetatable(vtbl,&#123;__index=\t\t\tfunction(t,k)\t\t\t\tlocal ret=_class[super][k]\t\t\t\tvtbl[k]=ret\t\t\t\treturn ret\t\t\tend\t\t&#125;)\tend \treturn class_typeend\n\n调用\n1234567891011121314base_type=class()\t\t-- 定义一个基类 base_type function base_type:ctor(x)\t-- 定义 base_type 的构造函数\tprint(&quot;base_type ctor&quot;)\tself.x=xend function base_type:print_x()\t-- 定义一个成员函数 base_type:print_x\tprint(self.x)end function base_type:hello()\t-- 定义另一个成员函数 base_type:hello\tprint(&quot;hello base_type&quot;)end\n\n类继承\n123456789test=class(base_type)\t-- 定义一个类 test 继承于 base_type function test:ctor()\t-- 定义 test 的构造函数\tprint(&quot;test ctor&quot;)end function test:hello()\t-- 重载 base_type:hello 为 test:hello\tprint(&quot;hello test&quot;)end\n\n\n再次调用\n123a=test.new(1)\t-- 输出两行，base_type ctor 和 test ctor 。这个对象被正确的构造了。a:print_x()\t-- 输出 1 ，这个是基类 base_type 中的成员函数。a:hello()\t-- 输出 hello test ，这个函数被重载了。 \n\nhttp://blog.codingnow.com/cloud/LuaOO\n","slug":"old_topic/2016-09-17-196","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"1f4f3b0cdc7ac1495b8bbbf5b8327672","title":"Lapis读取中文Mysql数据的问题","content":"作者：糖果\n在阿里云的VPS上，准备用lapis克隆一版blog程序，就是现在这个发文章的Blog。\nMysql移植的过程中发现的了问题，Lapis读取mysql数据库数据出现乱码。\n查看结果集合\n1SHOW VARIABLES LIKE &#x27;character%&#x27;;\n\n12345678910111213141516mysql&gt; SET character_set_client = utf8 ;  mysql&gt; SET character_set_connection = utf8 ;   mysql&gt; SET character_set_database = utf8 ;   mysql&gt; SET character_set_results = utf8 ;    mysql&gt; SET character_set_server = utf8 ;    mysql&gt; SET collation_connection = utf8 ;  mysql&gt; SET collation_database = utf8 ;   mysql&gt; SET collation_server = utf8 ; SET NAMES &#x27;utf8&#x27;;  SET character_set_client = utf8;  SET character_set_results = utf8;   SET character_set_connection = utf8; \n\n\n上面这些在运行修改参数的方式，phpmyadmin修改有限的字符的方式都失灵。\n注意，下面才是好用的方法：  \n\n1mysqld --character-set-server=utf8\n\n1234567891011121314mysql&gt; SHOW VARIABLES LIKE &#x27;character%&#x27;;+--------------------------+----------------------------+| Variable_name            | Value                      |+--------------------------+----------------------------+| character_set_client     | utf8                       || character_set_connection | utf8                       || character_set_database   | utf8                       || character_set_filesystem | binary                     || character_set_results    | utf8                       || character_set_server     | utf8                       || character_set_system     | utf8                       || character_sets_dir       | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec)\n\n12mysqld --character-set-server=latin1 \\           --collation-server=latin1_swedish_ci\n\n另外，collation-server可以在phpmyadmin和mysql-workbench修改，就是GUI有些罗嗦。\n12./configure --with-charset=latin1 \\           --with-collation=latin1_german1_ci\n\n这种编译时指定，个人很少用，没试过。\nLapis目前最大的问题是Moonscript翻译过来的lua代码，人类不易看懂。\n这个问题是不是，lapis以来resty mysql引起呢，因为resty mysql connect数据库的时候，不能指定字符集，不能很肯定，没看源码。\n下面这个连接是春哥对这个问的回答，供参考：\n","slug":"old_topic/2016-09-17-203","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9e3528aaa8fffc1f32ba95ca160d9152","title":"误删Unity导致Ubuntu桌面左边栏消失","content":"昨天安装老的版本的Django,删除Python，误删除了Unity．结果发现桌面的左边栏和Terminal的标题栏都没了．\n恢复安装一下就好了．\n12sudo apt-get install unitysudo apt-get install gnome-terminal\n这样重启系统就恢复了．\n","slug":"old_topic/2016-09-17-201","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9973dbca8e7d2bdfff8377e05eaa65ee","title":"Vanilla的Control返回必须是String类型","content":"这是今天社区里的一位朋友遇到的问题， Control最后return回去的数据是一个table类型，而不是一个字符串，这时候Vanilla报错了。\n社区里朋友的代码，如下：\n12345678910111213141516function ResController:fetchData()    local hc = http:new()    local resp, err = hc:request_uri(&quot;http://xxx.xxx.x.xx&quot;, &#123;            metod = &quot;GET&quot;        path = &quot;/sec/res/find?pid=&quot;..id,        headers = &#123;            [&quot;User-Agent&quot;] = &quot;Mozilla/5.0...&quot;        &#125;        &#125;)    if not resp then        return &quot;request error :&quot;..err    end     return resp.bodyend\n\n在看一下Vanilla的代码是如何处理这个逻辑的：\nvanilla的代码：\n12345function Response:response()    local body = &#123;[1]=self.append_body, [2]=self.body, [3]=self.prepend_body&#125;    ngx.print(table.concat( body, &quot;&quot;))    return trueend","slug":"old_topic/2016-09-17-195","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"88294b3320ee535773bca2da0894980a","title":"SAE到VPS的移植","content":"SAE到VPS的移植\n主要移植的内容是python的django, tornado程序。\n除了代码不能全放到blog上，把环境移植的东西简单的记录一下。\nVPS上比较要有的Python部件。apt-get install pippip install django==1.5.5apt-get install pyhton-mysqldbpip install sae-python-dev\n================上面的内容是去年写的， 今年SAE有调整， 有必要把SAE上的所有应用，移植到VPS上，比如当前这个www.lua.ren的博客系统，这个博客已经已经成功的移植到了VPS上。\n因为SAE上的Python运行python都是WSGI形式的， 在移到VPS上的时候，自然就想到了gunicorn,用gunicorn启动python服务，经过在VPS上的测试，要比SAE速度快，在过去在SAE上的主要框架用的是Python的django和tornado， 通过gunicorn把这两个框架放到VPS，是通过的。而确实对这个环境的安装，也没多少兴趣相写了， 不过特别提的是另外一个软件 meinheld\n另外MoPaas也是一个灵活配置的云平台，并且MoPaas是允许访问外部数据的的，所有在MoPaas上跑Django应用是一个不错的选择。\n","slug":"old_topic/2016-09-17-204","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f901c944f1965d8d412a5f9878199225","title":"smbclient，ubuntu访问windows共享文件夹","content":"因为有些需求要让Linux通过samba协议访问windows的共享目录，所以做了一下连接的实验。\n一.Samba安装 \n[code]\nsudo apt-get install samba\nsudo apt-get install samba-client\nsudo apt-get install cifs-utils\n[/code]\n\n二.Samba的客户端连接 \n[code]\nsmbclient //shilihe/lala -U shilihe\n[/code]\n\n三.Mount Windows共享文件夹 \n[code]\nmkdir /mnt/win\nsudo mount -t cifs -o username=xxx,password=yyyy //xxx.xxx.xxx.xxx/lala  /mnt/win\nsudo umount /mnt/win\n[/code]\n\n四.安装VSFTP \n为了方便其间，直接开一个vsftpd的服务最最省时间的。\n\n[code]sudo apt-get install vsftpd\nvim /etc/vsftpd.conf\nsudo service vsftpd statussudo service vsftpd stopsudo service vsftpd start[/code]\n/etc/init.d/vsftpd start\nyum install vsfptd…\n","slug":"old_topic/2016-09-17-205","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"cb65b6a08ddc1a4fe7638bb1bb5bebfa","title":"Simple HTTP","content":"下面是代码：\n1234567891011121314151617181920212223242526local http = require(&quot;lapis.nginx.http&quot;)local app = lapis.Application()app:get(&quot;/&quot;, function(self)  -- a simple GET request  local body, status_code, headers = http.simple(&quot;http://leafo.net&quot;)  -- a post request, data table is form encoded and content-type is set to  -- application/x-www-form-urlencoded  http.simple(&quot;http://leafo.net/&quot;, &#123;    name = &quot;leafo&quot;  &#125;)  -- manual invocation of the above request  http.simple(&#123;    url = &quot;http://leafo.net&quot;,    method = &quot;POST&quot;,    headers = &#123;      [&quot;content-type&quot;] = &quot;application/x-www-form-urlencoded&quot;    &#125;,    body = &#123;      name = &quot;leafo&quot;    &#125;  &#125;)end)","slug":"old_topic/2016-09-17-202","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"b5599f0c4982724e820f3ee1c077e29a","title":"Lapis的layout模板","content":"作者：糖果\n在Lapis框架的源码当中的views文件夹有一个layout.lua文件。\n1234567html = require &quot;lapis.html&quot;class Default extends html.Widget  content: =&gt;    html_5 -&gt;      head -&gt; title @title or &quot;Lapis Page&quot;      body -&gt; @content_for &quot;inner&quot;\n\nmoonscript的代码很简单。提起这个事是因为， 如果不注意这段代码， 在用lapis的render渲染模板时，这个模板生成的”Lapis Page”的Hmtl title标签会覆盖你的etlua中的title标签。 {render = “index”} \n这段程序会自动生成下面下的代码\n1&lt;!DOCTYPE HTML&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;title&gt;Lapis Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\n\n\n下面是moonscript翻译后的lua代码\n1234567891011content = function(self)  return html_5(function()    head(function()      return title(self.title or &quot;Lapis Page&quot;)      --return &quot;&quot;     end)    return body(function()      return self:content_for(&quot;inner&quot;)    end)  end)end\n\n\n需要在你的APP里设置self.title=”XXXXXXXX”\n123456app:get(&quot;/&quot;,function(self)    self.title=&quot;smartisan.black&quot;    return &#123; render = &quot;index&quot; &#125;end)\n\n\n这样title会被设置成samrtisan.black,但是上面自动生成代码其实还是多余的，最暴力的方法是把layout.lua代码改了。\n1234head(function()  --return title(self.title or &quot;Lapis Page&quot;)  eturn &quot;&quot; end)\n\n直接return “”空回去, 这样etlua中的title暂时不会被覆盖了。\n","slug":"old_topic/2016-09-17-206","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"c3417f1fb400de72f3ba30cadd868e18","title":"Linux内存管理","content":"","slug":"old_topic/2016-09-17-207","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"0091fba8ffac5443fa18d009f43bac53","title":"2015年国产LUA WEB框架一览","content":"2015年国产LUA WEB框架一览\n国内框架 \nVanilla \nLOR \nSingeLUA \n\n\n国外框架： \nLapis \nGin \n\n\n\n\n\n\n\n概况 \n现在是2016年的开始， 这次想说说LUA国内外的WEB框架，国内开发者的开发框架。据平时的观察，国内做LUA的WEB框架的目前知道的有3到4个，有3个已经开源，有一个至少在一个月后可能开源。\n\n先说已经开源的3个框架： Vanilla、LOR、SingleLUA。国内框Vanilla、LOR、SingleLUA至少这三框架代码在Github上都要以找到。从框架完成度上来看， 三者完成应最高的是Vanilla，LOR有些是借Vanilla的风格，例如目录结构。\n简单说一下，3个框架的渊源。（Gin,Vanilla,LOR）Vanilla是一款向国外的框架致敬的作品， 从代码和设计上借鉴了国外的Gin框架， 而LOR借鉴了Vanilla，作者本身也在Vanilla的社区里。从基因的延续的关系来看，三者之间的关系是：爷爷(Gin)-&gt;父亲(Vanilla)-&gt;孙子（LOR）的关系。\nSingleLUA,没太看出和以上说的三个框架有什么太大的联系，但是他们有一个共同点，框架的目录结构类似，延续了PHP框架目录结构特点。Vanilla，SingleLUA框架的作者本身就是PHP程序员。\n国外框架Lapis \n平时本人用的比较多的LUA WEB框架是国外的Lapis,Lapis框架本身的和以上所说的框架有着明显的区别，在写这篇文章的同时， Lapis的作者已经更新Lapis的路由式样，有了新的路由网格。Lapis框架的使用体验上，更接近于Python、Ruby风格，而不同于PHP的风格，Lapis的路由很像Python的Flask。有意思的是，Lapis的作者，也写PHP，做出的框架风格，没有像国产框架那样，延续PHP框架网格的特点。\n\n有人反应Lapis的框架的Lua代很乱，其是也确实挺乱的，为什么呢？Lapis的作者本身也MoonScript的作者，MoonScript语言与CoffeScript有着类似的思想，CoffeScript用来翻译成JavaScript, Moonscript会翻译成LUA，MoonScript写的代码更短，更简洁。Lapis框架不是直接用LUA写的，而是用MoonScript编写，然后翻译成LUA后，被Openresty使用的，所有翻译后的LUA代码看着很乱，如果直接在Github上看Moonscript代码其实不太乱。\nOpenresty \n性能？本文说的所有的框架都是基于春哥的Openresty，所有说性能的基础都是基于Openresty之上的。从WEB框架的考量，基本的就是三个方面：路由、模板，ORM。\n\n其它的因素有：文档完善、REST API、WEB安全性CRSF、加密、SESSSION、Cookie等。\n资源 \n1.Vanilla  \n2.LOR  \n3.SingleLUA  \n4.Lapis  \n5.Gin\n\n\n\n\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-208","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ab8b42f29fb5ba730495ad9d0a7a7b32","title":"Lapis框架如何“接受”和“返回”JSON数据","content":"by 糖果\nLapis可以定义Json格式的路由，Lapis本身，提供了JSON的解析机制，可以用json_params动作装饰器，想请求发过来的json数据，传self.parms变量中，代码如下：\n1234local json_params = require(&quot;lapis.application&quot;).json_paramsapp:match(&quot;/json&quot;, json_params(function(self)  return self.params.ipend))\n\n用Curl模拟请求：\n1234$ curl \\  -H &quot;Content-type: application/json&quot; \\  -d &#x27;&#123;&quot;ip&quot;: &quot;127.0.0.1&quot;&#125;&#x27; \\  &#x27;https://localhost:8080/json&#x27;\n\n返回的JSON数据解析：\n1&lt;!DOCTYPE HTML&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;title&gt;Lapis Page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;127.0.0.1&lt;/body&gt;&lt;/html&gt;\n\n\n\nLapis返回json数据一目了然，直接指定json关键字，然后赋予一个lua table的数据结构就好，如下：\n12345678910111213local lapis = require(&quot;lapis&quot;)local app = lapis.Application()app:get(&quot;/&quot;, function()  return &quot;Welcome to Lapis &quot; .. require(&quot;lapis.version&quot;)end)app:get(&quot;/world&quot;, function()  return &#123; json = &#123; success = true， ip=&quot;127.0.0.1&quot; &#125; &#125;end)return app","slug":"old_topic/2016-09-17-209","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"cec276ee8af804b9a2147b603fad4daa","title":"setmetatable和__call","content":"作者：糖果\n网上找来一个很能说明__call用法的例子：\n12345678910111213141516171819function f(tb, x, y)    for k,v in pairs(tb) do        print(k,v)    end    return x+y+tb.nendb = &#123;&#125;b.__call = fa = &#123;&#125;function a:test()enda.n = 100a.m = 200setmetatable(a,b)print(a(1,2))\n\nb作为a的元表的时候，table b={}的表函数,使用__call提定的话，在执行a(惨数列表)， 参数列表和b的f函数的参数列表一致， 被指定函数的第一个参数，是一个table，里面存放的是a的成员变量和函数。\n如果这种效果要有C来实现的话，要指向来指向去的指针实现。\n","slug":"old_topic/2016-09-17-210","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4565b99fae7d71a23c039a81b59544a8","title":"Select 网络API","content":"【问题】select,poll,epoll的区别是什么？\nselect的并发处理是源于BSD系统的支持，poll是商业公司的unix版本SystemV 提供支持。epoll是在Linux 2.5+开始支持的。就像message queue都有BSD和SystemV版本的API。select是处理网络并发处理，与poll的区别是有文件句柄上线限制。poll不会因为打开文件的增多而降低效率。\n\n【select功能概述】\n一切复杂的问题都是简单问题叠加组合，引用一下英文文档原文。“This module provides access to the select() and poll() functions available in most operating systems, epoll() available on Linux 2.5+ and kqueue() available on most BSD. Note that on Windows, it only works for sockets; on other operating systems, it also works for other file types (in particular, on Unix, it works on pipes). It cannot be used on regular files to determine whether a file has grown since it was last read.”\nserver.py\n[code]\nimport socket, select;\nimport time;\nimport os;\n\nhost = “127.0.0.1”port = 1688\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)#通过指定第三个参数“IPPROTO_TCP/IPPROTO_UDP”， 指定使用”TCP/UDP”协议进行传输！s.bind((host, port))s.listen(5)\nwhile True:        inputfds, outputfds, errorfds = select.select([s,],[],[],5)        if len(inputfds) !=0:                clientsock, clientaddr = s.accept()                buf = clientsock.recv(8024)                if len(buf) != 0:                        print (buf)                        clientsock.close() \n[/code]\nclient.py\n[code]\nimport socket, select\nhost = \"127.0.0.1\"\nport = 1688\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ns.connect((host, port))\ns.send(\"the Candy Web server on SAE of sina!\")\ns.close()\n[/code]\n\n【API说明】 \nselect的作用是“Waiting for I/O completion.”一般会和socket的API结合处理网络异步并发，但是也可以不和socket联系在一起应用。核心的API函数是select，结合几个关键的宏使用。FD_ZERO, FD_SET, FD_CLR，FD_ISSET。通过一套的函数和宏管理用户的文件描述符集合。（SETS）\n\n英文文档总是能直戳这些宏的本质。“ Four  macros  are provided to manipulate the sets.  FD_ZERO() clears a set.  FD_SET() and FD_CLR() respectively add and remove a given file descriptor from a set.  FD_ISSET() tests to see if a file descriptor is part of the set; this is useful after select() returns.“\n【宏定义】\nFD_ZERO():清空文件集。\nFD_SET():添加句柄到集合。\nFD_CLR():从集合中清除句柄。\nFD_ISSET():判断句柄是否在集合中。\n\n\n【Select接口说明】\n1.int n\n2.fd_set * readfds\n3.fd_set * writefds\n4.fd_set * exceptfds\n5.struct timeval * timeout\ntimeout == NULL: 一直等待直到事件发生。\ntimeout > 0: 按设定的大于0的时间值进行等待。\ntimeout = 0: 没有时间等待，直接返回。\n\n\n【选读】\n\n\"select（I/O多工机制）\n定义函数 int select(int n,fd_set * readfds,fd_set * writefds,fd_set * exceptfds,struct timeval * timeout);\n函数说明 select()用来等待文件描述词状态的改变。参数n代表最大的文件描述词加1，参数readfds、writefds 和exceptfds 称为描述词组，是用来回传该描述词的读，写或例外的状况。底下的宏提供了处理这三种描述词组的方式:\nFD_CLR(inr fd,fd_set* set)；用来清除描述词组set中相关fd 的位\nFD_ISSET(int fd,fd_set *set)；用来测试描述词组set中相关fd 的位是否为真\nFD_SET（int fd,fd_set*set）；用来设置描述词组set中相关fd的位\nFD_ZERO（fd_set *set）；用来清除描述词组set的全部位\"\n \n看到，“多工机制”和类似\"是用来回传该描述词的读，写或例外的状况。\"这种文字，直接就被干倒了，难道原文英语就这么晦涩不堪吗？残酷的阅读体验。\n\n\n\n【例子A：读取键盘输入的数据】\n\n在Linux系统中，键盘设备也被标识为文件，找来一个例子，很简短的/dev/tty键盘设备和select的联合使用。这么做的目的，就是很单纯的演示select本身相关函数和使用。\nkeyboard.c[code]#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;assert.h&gt;#include&lt;fcntl.h&gt;#include&lt;sys/select.h&gt;\nint main(int argc, char **argv){        int keyboard; //键盘的文件句柄        int ret,i;        char c;        fd_set readfd; //读操作的集合的定义        struct timeval timeout; // 提供给select函数使用的，延时时间结构体，告知需要等待的时间长度        keyboard = open(“/dev/tty”, O_RDONLY | O_NONBLOCK);//读取键盘缓冲区里的数据        assert(keyboard&gt;0);        while(1) //主循环        {                timeout.tv_sec = 1;  // 等待的时间设定                timeout.tv_usec = 0;                FD_ZERO(&amp;readfd); // 初始化读操作集合。                FD_SET(keyboard, &amp;readfd); //把键盘文件句柄填入读文件集                ret = select(keyboard+1, &amp;readfd, NULL, NULL, &amp;timeout); // 取得外部IO的状态数据                if (FD_ISSET(keyboard, &amp;readfd)) //判断读集合中的keyboard句柄是否准备好了，可以工作。                {                        i = read(keyboard, &amp;c, 1); //读取键盘文件                        if (‘\\n’ == c)                                continue;                        printf(“input is %c\\n”, c);                        if (‘q’ == c)                                break;\n            &#125;\n    &#125;\n\n}[/code]\nserver.cppclient.cpp\n【结尾】\n也许我应该长期的维护这个文档，回头看看对细节表述曾经放下的错误，对说的不是人话的地方，进行修改，并且围绕主题加入更高级的应用内容。\n\n\n作者：小盛注释：个人劳动成果，转载使用请注明本文作者及出处链接，谢谢合作！Python与C++ select API的对比 \n参考文献：Python官方文档\n","slug":"old_topic/2016-09-17-21","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"e465db6ba9cb253a17d5f94de4f683b9","title":"LUA WEB架框LOR基础简介","content":"作者：糖果\nLOR是最近国内的LUA WEB开发框架，目前已经发布到了0.3版，昨天晚上作者分享了他的初始设计图， 在QQ群里发的。\n最开始的时候，lor是借鉴vanilla的，之后作者转向设计，开始向expressjs靠拢。\n目前来看的，lor非常引人关注的是lor的路由设计。\n主要的几人文件。\n1234567lor.index -&gt; lor.lib.lor-&gt;lor.lib.application-&gt;lor.lib.router.router-&gt;lor.lib.router.layer-&gt;lor.lib.router.router-&gt;lor.lib.utils.path_to_regexp\n\n\nLOR的Application里的函数除了Http常用方法(get、post、put、delete)是通过循环定义的，共它的函数都是显示声明的。\nApplicaton里有InitMethod方法循环定义的。\n下面是选出一些代码片段，来简述这个实现。\n定义一个有支持子函数的列表：\n12345678local supported_http_methods = &#123;get = true, -- work wellput = true, -- no testpatch = true, -- no testdelete = true, -- no testtrace = true, -- no testall = true -- todo:&#125;\n\n\n循环定义函数：\n1234567891011function app:initMethod()    for http_method, _ in pairs(supported_http_methods) do        self[http_method] = function(self, path, fn)            debug(&quot;\\napp:&quot; .. http_method, &quot;start init&quot;)            local route = self.router:route(path)            route[http_method](route, fn)            debug(&quot;app:&quot; .. http_method, &quot;end init\\n&quot;)            return self        end    endend\n\n这个关键的声明关键字是：self[函数数] = function(函数参数) end\n我们用最小化的一个lua对象来描述这个过程。\napp应属于框架的代码。\n1234567891011121314151617181920212223242526272829303132333435363738local app = &#123;&#125;function app:new()    local instance = &#123;&#125;    instance.m = 100    instance.n = 500    setmetatable(instance, &#123;        __index = self,        __call = self.handle    &#125;)    instance:initMethod()    return instanceendfunction app:handle(req, res, callback)    print(req)    print(res)    print(callback)endfunction app:output(path, fn)    print(&quot;##################&quot;)    print(path)    print(fn)    print(&quot;###################&quot;)endfunction app:initMethod()    self[&quot;get&quot;] = function()        print(&quot;app:get&quot;)    endendreturn app\n\n下面是对象的调用：\n这个对象调用，就是平时写的web代码，不属于框架，是普通的应用框架写的web程序。\n123456789101112131415161718app = require&quot;app&quot;local obj = app:new()obj:output(&quot;/test&quot;,function(req, res)      print(&quot;abc&quot;)      print(req, res)end)obj:handle(&quot;abc&quot;,&quot;efg&quot;,&quot;hij&quot;)--每个get的函数的调用，都触发一次路由的判断--后面的时序，是lor核心 app:get-&gt;router-&gt;layer-&gt;route--注意一下,request数据，函数形参req的填充时机obj:get(&quot;/index&quot;,function(req, res)end)\n\n一般每次用户的url请求，都会触发以下时序app:new  -&gt;app:initMethod-&gt;app:get-&gt;route[http_method]\nrouter-&gt;layer-&gt;route的时序，接下来放几张，饭总的原始设计图：\n图片：reqres.jpg\n还有几张设计图，在后续的文章中加入。\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-211","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"bb30e03d07b81113ffb361e7f94598db","title":"Openresty的非典型安装","content":"作者：糖果\nOpenresty也安装了很多遍整理一下安装过程。\n上来先更新一下系统\n1sudo yum update\n\n安装Openresty安装需要的依赖：\n1sudo yum install -y gcc gcc-c++ readline-devel pcre-devel openssl-devel tcl perl\n\n下载一个安装包：\n1wget https://openresty.org/download/ngx_openresty-1.7.10.1.tar.gz\n\nhttps访问不灵，就用http\n12wget http://openresty.org/download/ngx_openresty-1.7.10.1.tar.gztar -xvf ngx_openresty-1.7.10.1.tar.gz\n安装\n123./confiuregmakesudo gmake install\n\n配置一下环境变量\n12export PATH=/usr/local/openresty/nginx/sbin:$PATHnginx -v\n\n\n写了一部分，就被各种运维工作，打断…\n","slug":"old_topic/2016-09-17-212","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"8f06b9deb34ffdfee8f8030a216bc228","title":"ConcurrentLua","content":"介绍 \n\nConcurrentLua 是一个无共享异步消息传递模型的实现.该模型来自Erlang语言.她改编了Erlang的并发元素并整合进Lua里.\nConcurrentLua的一个核心元素是 process(进程).一个进程是一个轻量级虚拟机 \n线程,扮演和操作系统的进程同样的角色;他们不共享内存而是使用某这进程间通讯机制.这些进程能够根据需要被创建和销毁,并通过一个简单的环罗宾(轮训)算法来调度他们.\n每一个进程关联到一个邮箱(临时存储消息的队列),通过邮箱来接受别的进程发来的消息.进程可以在任何时候检查自己的邮箱有没有新消息抵达,如果有,进程可以按照抵达的顺序依次读取.\n每个进程都有一个唯一的数字作为进程标识,叫 PID(process identifier).也可以给进程取一个名字,并用名字来指代进程.进程名和进程的对应关系被保存到一个中心储藏室–registry(注册表).进程可以编辑注册表,添加或者删除表项.\n错误捕捉机制也被实现成 monitors 和 links .通过 monitors 进程能够监视其他进程,并在被监视进程异常终止的时候获得通知.通过 linker 进程绑定进程到一起,当一个进程异常终止的时候,其他进程也被通知并终止.\n本系统还支持分布式编程和所有相关的组件.分布式的进程通过和本地进程一样的方式来通讯.\n分布是基于 node(节点) 组件的.一个节点代表一个运行着很多进程的运行时环境.节点们可以相互连接和通讯,于是建立了一个虚拟网络.分布的进程使用这个网络来顺序交换信息.\n每个节点有个名字.其他的节点可以通过这个名字来连接.一个端口映射器精灵进程(译注:就是服务进程,类似Erlang提供的名字服务)提供了名字解析服务.端口映射器知晓虚拟网络中所有的节点的信息.\n正如进程可以在本地创建,进程已可以在远端节点被创建.一个远程进程能够被视同为一个本地进程来操作.\n如果虚拟网络中的节点是全互联的(每一个节点双向连接其他的节点),那么可以使用全局进程名.节点们相互交流和保养虚拟全局注册表并保持自己本地的注册表时时更新.\nmonitors 和 links 以同样的语义支持分布进程和本地进程.节点可以透明的处理分布进程的错误.另外,进程可以像监视整个节点.\n节点可以在通讯前进行鉴权.一个已鉴权的节点才可以成为虚拟网络的一部分.这些策略通过一个简单安全机制来保证.\n实现 \n\nConcurrentLua的实现是基于Lua组件系统实现的.这个系统负责组织和管理Lua的模块和子模块.主模块有两个,分别提供了并发功能和分布式编程功能.并发模块可以单独加载,每个模块都可以选择性加载需要使用的子模块.独立的端口映射器精灵进程也是实现的一部分.系统中的进程是通过Lua的协程机制来实现的.一个进程其实就是一个Lua协程,通过 yield 来挂起一个进程,通过 resume 来继续执行一个进程.\n进程的调度机制仍然是基于Lua使用的 协作式多线程模型. 进程自愿挂起自己,从而让其它的进程获得运行的机会.然而,挂起和恢复进程被部分隐藏于高层机制之下;当一个进程去等待消息抵达的时候挂起,而在消息抵达进程邮箱后准备恢复.一个简单的环罗宾(轮训)调度器用来恢复进程的执行.\n任何类型的Lua数据,除了内存引用外,都可以通过消息来发送.消息可以是布尔值,数字,字符串,表或者函数,或者他们的混合.数据自动在发送时被序列化,并在接受时反序列化,所以的数据都是值传递.\n节点间的分布式进程间通讯机制是基于异步socket的.映射到网络层是非阻塞socket和定时轮训.这是如今大部分Lua模块采用的方法,非阻塞语义也应该被用在例如文件和管道的IO操作上.\n用法 \n\n一些例子提供了系统不要组件的用法,例如,创建进程,分布式进程的消息传递和错误捕获.创建进程\nspawn()函数可以创建进程.spawn()函数接受至少一个参数,该参数标志进程的入口函数.其它附加参数则被直接转交给入口函数.下面的例子示范创建一个进程.该进程输出指定次数的消息:\n1234567require &#x27;concurrent&#x27;function hello_world(times)    for i = 1, times do print(&#x27;hello world&#x27;) end    print(&#x27;done&#x27;)endconcurrent.spawn(hello_world, 3)concurrent.loop()\n\n输出应该是: \n\n\n1234hello worldhello worldhello worlddone\n\n\n首先加载系统: \n\n\n1require &#x27;concurrent&#x27;\n\n进程入口函数: \n\n\n1234function hello_world(times)    for i = 1, times do print(&#x27;hello world&#x27;) end    print(&#x27;done&#x27;)end\n\n\n创建一个新进程: \n\n\n1concurrent.spawn(hello_world, 3)\n\n\n\n最后调用系统无限循环: \n\nconcurrent.loop()消息交互进程通过 send() 和 receive() 函数来交换消息.同样,self()函数也被用来获取本进程ID.下面的程序实现了两个进程交换消息然后终止:\n1234567891011121314151617181920212223242526272829303132333435require &#x27;concurrent&#x27;function pong()    while true do        local msg = concurrent.receive()        if msg.body == &#x27;finished&#x27; then            break        elseif msg.body == &#x27;ping&#x27; then            print(&#x27;pong received ping&#x27;)            concurrent.send(msg.from, &#123; body = &#x27;pong&#x27; &#125;)        end    end    print(&#x27;pong finished&#x27;)endfunction ping(n, pid)    for i = 1, n do        concurrent.send(pid, &#123;            from = concurrent.self(),            body = &#x27;ping&#x27;        &#125;)        local msg = concurrent.receive()        if msg.body == &#x27;pong&#x27; then            print(&#x27;ping received pong&#x27;)        end    end    concurrent.send(pid, &#123;        from = concurrent.self(),        body = &#x27;finished&#x27;    &#125;)    print(&#x27;ping finished&#x27;)endpid = concurrent.spawn(pong)concurrent.spawn(ping, 3, pid)concurrent.loop()\n\n\n输出应该是: \n\n\n12345678pong received pingping received pongpong received pingping received pongpong received pingping received pongpong finishedping finished\n\n\n在 pong 进程被创建后, ping 进程获得了 pong 进程的 PID: \n\n12pid = concurrent.spawn(pong)concurrent.spawn(ping, 3, pid)\n\nping 进程发送一个消息: \n\n1234concurrent.send(pid, &#123;    from = concurrent.self(),    body = &#x27;ping&#x27;&#125;)\n\n\n\npong 进程等待消息抵达,然后把接收到的消息保存到一个变量中: \n\n\n1local msg = concurrent.receive()\n\npong 进程回复: \n\n\n1concurrent.send(msg.from, &#123; body = &#x27;pong&#x27; &#125;)\n\n\n\npong 进程在接收到 ping 进程发来的一个提示后终结.注册进程名可以用进程名替代PID来指定消息接收方. register() 函数可以用来在注册表(译注:指系统的名字对应表,而不是Windows的注册表,顺便鄙视一下Windows. :) )\n创建一个进程的名字: \n\n\n123456789101112131415161718192021222324252627282930313233343536require &#x27;concurrent&#x27;function pong()    while true do        local msg = concurrent.receive()        if msg.body == &#x27;finished&#x27; then            break        elseif msg.body == &#x27;ping&#x27; then            print(&#x27;pong received ping&#x27;)            concurrent.send(msg.from, &#123; body = &#x27;pong&#x27; &#125;)        end    end    print(&#x27;pong finished&#x27;)endfunction ping(n)    for i = 1, n do        concurrent.send(&#x27;pong&#x27;, &#123;            from = concurrent.self(),            body = &#x27;ping&#x27;        &#125;)        local msg = concurrent.receive()        if msg.body == &#x27;pong&#x27; then            print(&#x27;ping received pong&#x27;)        end    end    concurrent.send(&#x27;pong&#x27;, &#123;        from = concurrent.self(),        body = &#x27;finished&#x27;    &#125;)    print(&#x27;ping finished&#x27;)endpid = concurrent.spawn(pong)concurrent.register(&#x27;pong&#x27;, pid)concurrent.spawn(ping, 3)concurrent.loop()\n\n相对前一个版本的改变就是 ping 进程发送消息的地方: \n\n\n\n1234concurrent.send(&#x27;pong&#x27;, &#123;    from = concurrent.self(),    body = &#x27;ping&#x27;&#125;)\n\n\n\n和: \n\n\n1234concurrent.send(&#x27;pong&#x27;, &#123;    from = concurrent.self(),    body = &#x27;finished&#x27;&#125;)\n\n\n\n以及现在 pong 进程注册了它的名字: \n\n\n1concurrent.register(&#x27;pong&#x27;, pid)\n\n\n\n因此 ping 进程不需要知道 pong 进程的 PID 了.分布式消息传递不同节点上的进程仍然可以使用同样的消息传递机制.远程进程通过 PID或进程名 加上节点名来指定.先前的例子可以改造成两个程序,分别是一个独立进程.\npong 进程的代码如下: \n\n123456789101112131415161718require &#x27;concurrent&#x27;function pong()    while true do        local msg = concurrent.receive()        if msg.body == &#x27;finished&#x27; then            break        elseif msg.body == &#x27;ping&#x27; then            print(&#x27;pong received ping&#x27;)            concurrent.send(msg.from, &#123; body = &#x27;pong&#x27; &#125;)        end    end    print(&#x27;pong finished&#x27;)endconcurrent.init(&#x27;pong@gaia&#x27;)pid = concurrent.spawn(pong)concurrent.register(&#x27;pong&#x27;, pid)concurrent.loop()concurrent.shutdown()\n\nping 进程的代码如下: \n\n12345678910111213141516171819202122require &#x27;concurrent&#x27;function ping(n)    for i = 1, n do        concurrent.send(&#123; &#x27;pong&#x27;, &#x27;pong@gaia&#x27; &#125;, &#123;            from = &#123; concurrent.self(), concurrent.node() &#125;,            body = &#x27;ping&#x27;        &#125;)        local msg = concurrent.receive()        if msg.body == &#x27;pong&#x27; then            print(&#x27;ping received pong&#x27;)        end    end    concurrent.send(&#123; &#x27;pong&#x27;, &#x27;pong@gaia&#x27; &#125;, &#123;        from = &#123; concurrent.self(), concurrent.node() &#125;,        body = &#x27;finished&#x27;    &#125;)    print(&#x27;ping finished&#x27;)endconcurrent.spawn(ping, 3)concurrent.init(&#x27;ping@selene&#x27;)concurrent.loop()concurrent.shutdown()\n\n(译注: 如果你想自己跑这个例子需要修改上面的节点名后半部分的机器名部分,使之和你的网络环境相匹配.)pong 进程的输出应该是:\n1234pong received pingpong received pingpong received pingpong finished\n\n\nping 进程的输出应该是: \n\n\n1234ping received pongping received pongping received pongping finished\n\n\n在这个例子里,运行时系统运行在分布式模式.为了看到结果,端口映射器必须先运行: \n\n\n\n$ clpmd\n初始化 pong 进程所在节点的代码: \n\n\n1concurrent.init(&#x27;pong@gaia&#x27;)\n\n\n\n初始化 ping 进程所在节点的代码: \n\n\n1concurrent.init(&#x27;ping@selene&#x27;)\n\n\n上面两句代码注册节点到端口映射器.去注册是通过: \n\n\n1concurrent.shutdown()\n\n\n\n这个例子的唯一改动是消息发送的目的地.node()函数会返回调用进程坐在节点的名字: \n\n\n1234concurrent.send(&#123; &#x27;pong&#x27;, &#x27;pong@gaia&#x27; &#125;, &#123;    from = &#123; concurrent.self(), concurrent.node() &#125;,    body = &#x27;ping&#x27;&#125;)\n\n\n接下来: \n\n\n1234concurrent.send(&#123; &#x27;pong&#x27;, &#x27;pong@gaia&#x27; &#125;, &#123;    from = &#123; concurrent.self(), concurrent.node() &#125;,    body = &#x27;finished&#x27;&#125;)\n\n\n\n错误处理一个捕获进程间错误的方法是连接进程.两个进程被绑定到一起,一个异常终止的后另一个也会终止.link()函数用来绑定进程: \n\n123456789101112131415161718192021222324252627282930require &#x27;concurrent&#x27;function ping(n, pid)    concurrent.link(pid)    for i = 1, n do        concurrent.send(pid, &#123;            from = concurrent.self(),            body = &#x27;ping&#x27;        &#125;)        local msg = concurrent.receive()        if msg.body == &#x27;pong&#x27; then            print(&#x27;ping received pong&#x27;)        end    end    print(&#x27;ping finished&#x27;)    concurrent.exit(&#x27;finished&#x27;)endfunction pong()    while true do        local msg = concurrent.receive()        if msg.body == &#x27;ping&#x27; then            print(&#x27;pong received ping&#x27;)            concurrent.send(msg.from, &#123; body = &#x27;pong&#x27; &#125;)        end    end    print(&#x27;pong finished&#x27;)endpid = concurrent.spawn(pong)concurrent.spawn(ping, 3, pid)concurrent.loop()\n\n输出应该是: \n\n\n1234567pong received pingping received pongpong received pingping received pongpong received pingping received pongpong finished \n\n\n– 译注:这里应该是: ping fininshedpong 进程永远不会运行到最后一行,因为他在接收到 ping 进程退出信号的时候会终止.\n连接进程的代码如下: \n\n\n1concurrent.link(pid)\n\n\n也可以捕获进程终止导致的exit信号.被捕获的exit信号会转换成一个特殊的消息: \n\n1234567891011121314151617181920212223242526272829303132333435require &#x27;concurrent&#x27;concurrent.setoption(&#x27;trapexit&#x27;, true)function pong()    while true do        local msg = concurrent.receive()        if msg.signal == &#x27;EXIT&#x27; then            break        elseif msg.body == &#x27;ping&#x27; then            print(&#x27;pong received ping&#x27;)            concurrent.send(msg.from, &#123; body = &#x27;pong&#x27; &#125;)        end    end    print(&#x27;pong finished&#x27;)endfunction ping(n, pid)    concurrent.link(pid)    for i = 1, n do        concurrent.send(pid, &#123;            from = concurrent.self(),            body = &#x27;ping&#x27;        &#125;)        local msg = concurrent.receive()        if msg.body == &#x27;pong&#x27; then            print(&#x27;ping received pong&#x27;)        end    end    print(&#x27;ping finished&#x27;)    concurrent.exit(&#x27;finished&#x27;)endpid = concurrent.spawn(pong)concurrent.spawn(ping, 3, pid)concurrent.loop()\n\n输出应该是: \n\n\n1234567pong received pingping received pongpong received pingping received pongpong received pingping received pongpong finished\n\n\nping finished可以通过 setoption() 函数来设置进程链接的选项,这里是 trapexit 选项: \n\n\n1concurrent.setoption(&#x27;trapexit&#x27;, true)\n\n\npong 进程会接收到一个退出消息: \n\n\n12if msg.signal == &#x27;EXIT&#x27; then    break\n\n\n基于提示消息的monitor, 也可以用来处理错误.\n原文连接：http://floss.qiniucdn.com/data/20110831112702/index.html\n","slug":"old_topic/2016-09-17-213","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a8389061bbd1e9023a83242f7e76acdb","title":"使用Pages服务创建静态博客(上)","content":"作者：糖果\nCoding.net同样提供了类似github的pages的功能， 这样就可以使用pages服务创建静态博客。\n创建步骤： \n\n\n配置本地git环境。\n本地创建目录结构和静态文件。\n初始化本地目录为git工程，创建本地分支，并上传文件。\n启动配置coding上的pages，绑定域名。\n域名服务解析。\n确认解析。\n\n下面是对具体细节的说明。\n1.配置本地基本的git环境。 \n1.1.生成公钥。 \n用你登陆coding.net的邮箱账号生成一个公钥。\n1ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;\n\n在导航上选择:设置-&gt;部署公钥-&gt;点击这里：\n1.2.复制pub.key到coding.net的设置面板上。 \n12cd ~/.sshvim id_rsa.pub\n将id_rsa.pub的内容复到coding.net的公钥控制面板里。\n图片：jjkkkkjjjjjjj\n \n\n重新连接一下。\n1234github用这个测试ssh -T git@githb.comcoding用下面的测试ssh -T git@git.coding.net\n\n1.3.设置一下用户名和邮箱。 \n12git config --user.name XXXgit config --user.email XXX\n\n2.本地创建目录结构和静态文件。 \n 我们在本地创建一个目录。\n12mkdir moonscriptvim index.html\n将下面的内容贴到文件里：\n123456789&lt;html&gt;   &lt;head&gt;     &lt;title&gt;Moonscript&lt;/title&gt;   &lt;/head&gt;   &lt;body&gt;      &lt;h1&gt;Moonscript&lt;/h1&gt;   &lt;/body&gt;&lt;/html&gt;\n\n3.初始化本地目录为git工程，创建本地分支，并上传文件。 \n3.1 初始化本地git工程。 \n\n12345git initgit add index.htmlgit commit -m&#x27;init&#x27;git remote add origin git@git.coding.net:&#123;user_name&#125;/&#123;project_name&#125;\n\n{user_name}/{project_name}为你的coding.net账户名对应在coding.net上的git工程。\n3.2.创建分支 \n我们在此处创建一个分支，在之后开启pages服务时，指定从这个分支下取代码进行部署。\n1git checkout -b coding-pages\n\n3.3.上传代码。 \n1git push origin coding-pages\n\n4.启动配置coding上的pages，绑定域名。 \n\n图片：b.png \n在导航上选择:代码-&gt;Page服务-&gt;绑定一个自定义的域名:绑定了四个域名。\n1234http://moonscript.cnhttp://moonscript.xyzhttp://www.moonscript.cnhttp://www.moonscript.xyz\n5.域名服务解析。 \n\n\n 在域名服务商那里，将域名CNAME解析到，coding的pages服务的二级域名。图片：c.png \n6.确认解析。 \n我们确认一下域名，是否被正常解析了，在浏览器中输入域名地址：\n1234http://moonscript.cnhttp://moonscript.xyzhttp://www.moonscript.cnhttp://www.moonscript.xyz\n\n图片：d.png \n作者：糖果PS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。LUA.RENhttp://www.lua.ren\n官方文档：https://coding.net/help/doc/pages/index.html\n","slug":"old_topic/2016-09-17-215","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9430d64b8d40e629bac43d0184c0f2ac","title":"NGINX执行阶段概念","content":"图片：1079283195.png \n原文连接：http://leandre.cn/web/79.html\n","slug":"old_topic/2016-09-17-214","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ad959d61ae3ba0f4919be1ad782c86c1","title":"LOR框架设计草图","content":"下面图是LOR的框架的设计草图，是作者饭总当时为实现LOR画的，提供给大家参考：\n想把route,router,layer那部分的設計畫清楚一些，饭總提供了一下現這個在線畫圖的工具：\nhttps://www.processon.com/\n图片：1.jpg \n图片：2.jpg \n图片：3.jpg \n图片：4.png \n图片：stack.lor.jpg\n","slug":"old_topic/2016-09-17-216","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"708c3ab643b3760bed43ade6e846877c","title":"使用Pages服务创建静态博客(下)---部署Jekyll静态站","content":"作者：糖果\n上一篇我们在Coding.net上部署了Pages服务，但是展示的页面比较单一，这次我们使用Jekyll工程生成一个相对完整的静态网站。\n概要步骤如下： \n\n1.安装较新的Ruby开发环境。\n\n\n2.安装Jekyll。\n\n\n3.创建工程。\n\n\n4.上传代码。\n\n\n5.确认站点。\n\n\n\n\n\n\n\n1.安装较新的Ruby开发环境。 \n因为Jekyll是依赖Ruby开发环境的，所以首先要装的是Ruby开发环境。\n\n\n\n\n1.1 本地安装Ruby。 \n在Ubuntu15上，简单的两部就可以安装完成。\n1sudo apt-get install ruby\n\n这样默认装的是Ruby2.2\n1ruby -v\n安装ruby2.2-dev,有了这个包可见ruby.h等后继需要的文件。\n1sudo apt-get install ruby2.2-dev\n\n1.2 VPS上安装。 \n在阿里这种VPS上安装Ruby，推荐使用RVM安装方式。\n\n1.2.1 安装curl，下载RVM。 \n123sudo apt-get curlcurl -L https://get.rvm.io | bash -s stablesource ~/.rvm/scripts/rvm\n\n1.2.2 安装RVM依赖 \n1rvm requirements\n\n1.2.3 安装Ruby \n12rvm install rubyrvm use ruby --default\n\n2.安装Jekyll。 \n安装Jekyll之前，记得要把gem的安装源换成淘宝的，你懂。\n\n2.1更新gem源。 \n123gem sources --remove http://rubygems.org/gem sources --add https://ruby.taobao.org/gem sources -l\n\n\n2.2安装Jekyll \n1gem install jekyll\n\n3.创建工程。 \n创建一个Jekyll的静态站，自动生成。\n1jekyll new moonscript\n\n4.上传代码。 \n把新生成的所有代码文件和文件夹，全部移动到Pages服务部署文件所在有分支文件夹。\n\n123git add *git commit -m&quot;将自动生成的文件全部上传到coding-pages分支上&quot;git push origin coding-pages\n\n\n\n5.确认站点。 \n\nmoonscript.cn \n图片：moonscript.png\n在更新coding.net的jekyll文章时，有一个关键的文件要更新，就是feed.xml这个文件。\n原文来至糖果实验室\n作者：糖果PS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。LUA.RENhttp://www.lua.ren\n","slug":"old_topic/2016-09-17-217","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"b420dcba79befee8d1737be19f072a96","title":"Luabit的位运算简介","content":"作者：糖果\nLuabit的位运算 \n\nLua提供了bit库，可以对变量数据进行位运算，在某些应有场景，我们得确需要在lua中对数据进行位移，或是进行“与，或，非”，进制转换等操作。\n例如有这么一种较典型的情况，我们用一个32位的整数表示RGB颜色,32位整数，被分为4个部分，每个部分8bit, 8bit可表示的10进制数的范围是0~255。\n我们现在有一组RGB的颜色值: Alpha通道=8, R=4, G=2, B=1\n1234567891011121314下面是,二进制表示：Alpha    Red      Green    Blue00001000 00000100 00000010 00000001第四组    第三组    第二组    第一组下面是,十六进制表示：Alpha   Red    Green   Blue0x08    0x04   0x02    0x01第四组   第三组  第二组  第一组下面是,十进制表示：134480385\n\n我们现在要作的是把整数”134480385”的“4组”“8bit”数据截取出来。思路和C语言二进制运算是一样，首先是“4组“每”8bit“的数据，都移动到”第一组的“位置，每一组不需要移位，然后是，第次移位后和0x000000FF这个数进行”AND”运算，清空前24位数据，保留最后的8位bit数据。\n需要分解的原始数据： \n\n\n\n\n\n\n\n\n\n12local num = bit.tobit(0x08040201)print(num) \n\n\n\n第一组Blue数据的取得： \n12348        4        2        1Alpha    Red      Green    Blue00001000 00000100 00000010 00000001第四组    第三组    第二组    第一组\n\n第一组的数据，不需要移位操作，直接将数据与”0x000000FF”进行”与“运算。\n123456788        4        2        1Alpha    Red      Green    Blue00001000 00000100 00000010 00000001And（与运算）00000000 00000000 00000000 11111111结果（1）00000000 00000000 00000000 00000001第四组    第三组    第二组    第一组\n\n\n\n\n\n\n\n\n\n\n123local t_num = numlocal blue = bit.band(t_num, 0x000000ff)print(&quot;blue:&quot;..blue) \n\n第二组Green数据的取得：第二组Green数据，需要先右移8位，然后，才能与”0x000000FF”进行”与“运算。\n123456789108        4        2        1Alpha    Red      Green    Blue00001000 00000100 00000010 00000001RShift(右移8位，左边空位补零)00000000 00001000 00000100 00000010 And（与运算）00000000 00000000 00000000 11111111结果（2）00000000 00000000 00000000 00000010第四组    第三组    第二组    第一组\n\n\n\n\n\n\n\n\n\n\n123local t_num = bit.rshift(num, 8)local green = bit.band(t_num, 0x000000ff)print(&quot;green:&quot;..green)\n\n第三组Red数据的取得：第三组Red数据，需要先右移16位，然后，才能与”0x000000FF”进行”与“运算。\n123456789108        4        2        1Alpha    Red      Green    Blue00001000 00000100 00000010 00000001RShift(右移16位，左边空位补零)00000000 00000000 00001000 00000100 And（与运算）00000000 00000000 00000000 11111111结果（4）00000000 00000000 00000000 00000100第四组    第三组    第二组    第一组\n\n\n第四组Alpha数据的取得：第四组Alpha数据，需要先右移24位，然后，才能与”0x000000FF”进行”与“运算。\n123456789108        4        2        1Alpha    Red      Green    Blue00001000 00000100 00000010 00000001RShift(右移24位，左边空位补零)00000000 00000000 00000000 00001000 And（与运算）00000000 00000000 00000000 11111111结果（8）00000000 00000000 00000000 00001000第四组    第三组    第二组    第一组\n\n最后，取得四组数据的值：  Alpha通道=8, R=4, G=2, B=1\n下面是Lua代码： \n\n1234567891011121314151617181920212223local bit = require &quot;bit&quot;local num = bit.tobit(0x08040201)print(num)--第一组Blue数据的取得：local t_num = numlocal blue = bit.band(t_num, 0x000000ff)print(&quot;blue:&quot;..blue)--第二组Green数据的取得：local t_num = bit.rshift(num, 8)local green = bit.band(t_num, 0x000000ff)print(&quot;green:&quot;..green)--第三组Red数据的取得：local t_num = bit.rshift(num, 16)local red = bit.band(t_num, 0x000000ff)print(&quot;red:&quot;..red)--第四组Alpha数据的取得：local t_num = bit.rshift(num, 24)local alpha = bit.band(t_num, 0x000000ff)print(&quot;alpha:&quot;..alpha)\n\n\n下面是Luabit常用函数：\n1234567891011121314&#123;    [&quot;band&quot;] = function: 0055B430,    [&quot;rshift&quot;] = function: 0055B530,    [&quot;bor&quot;] = function: 0055B470,    [&quot;bnot&quot;] = function: 0055B3F0,    [&quot;bswap&quot;] = function: 0055B3B0,    [&quot;bxor&quot;] = function: 0055B4B0,    [&quot;tobit&quot;] = function: 0055B390,    [&quot;ror&quot;] = function: 00559C98,    [&quot;lshift&quot;] = function: 0055B4F0,    [&quot;tohex&quot;] = function: 0055B610,    [&quot;rol&quot;] = function: 0055B5B0,    [&quot;arshift&quot;] = function: 0055B570,&#125;\n\n\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。LUA.RENhttp://www.lua.ren\n","slug":"old_topic/2016-09-17-218","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"196dea8989620545d3f5d9c787f58f7a","title":"OpenResty中文社区ORChina上线","content":"最新LOR社区，小范围上线社区站， http://www.orchina.org ， 还有一个另外的域名是 http://orc.black \n这是饭总用LOR框架写的，如果你用过ruby-china， 会发现这网站的前端和rubychina的很像, 大家可以注册个账号，上去测试一下。\n点击如下连接进入：\nwww.orchina.org \norc.black\nsmartisan.black\n=================================================经过一段时间的运行，OR现在一般性的应用是可以的，接下来就新添加功能，已经有一个朋友提交过一些代码。\n","slug":"old_topic/2016-09-17-220","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"270916a1da291606f4da9f2bca1552a5","title":"Sublime的LUA和Openresty插件。","content":"作者：糖果\n下面是两个补全插件，在Sublime中可以很好的补全LUA代码和OpenResty的API。\nLua插件\ninstallation\nOpenresty的补全\n","slug":"old_topic/2016-09-17-219","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"24ab8e9d901f65823a76249d9d5b0489","title":"OpenResty China简报","content":"OpenRestyChina简报—20160401 \n1.(文章) ：开源经济和OpenResty \nOpenResty北京面基大会后，池老师发表了一篇文章，很有料。\n\n2.(问答)：error loading module 'cjson' from file \n因为conf的文件设置不正确， 造成了OpenResty将.so文件，做为.lua为文件进行 了require读取。\n\n3.(问答)：resty 的md5和string的问题 \npart_end 导致的计算错误。\n\n4.（图书）：高可用架构·硅谷篇（第4期） \n人邮异步社区，出版新的免费电子书，高可用架构·硅谷篇（第4期）\n\n5.（软件）：Orange - 基于OpenResty的API Gateway \n饭总发布了他的， API Gateway， 可以说是Kong的mini版本吗？","slug":"old_topic/2016-09-17-221","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4a3d58a7b2640de2406b2e1d53c042d1","title":"Lapis的数据库查询分页功能","content":"作者：leafo\n翻译：糖果\nPagination分页 \n\nUsing the paginated method on models we can easily paginate through a query that might otherwise return many results. The arguments are the same as the select method but instead of the result it returns a specialPaginator object. \n\n使用paginated方法，我们可以很轻松的实现多检索结果的分页效果。select方法的参数都是一样的，但是返回的查询结果是特定的Paginator对象。\nFor example, say we have the following table and model: (See Database Schemas for more information on creating tables.) \n\n例如,下面的数据表定义：（Database Schemas那章有更多关于表创建的细节内容。）\n12345678910create_table(&quot;users&quot;, &#123;  &#123; &quot;id&quot;, types.serial &#125;,  &#123; &quot;name&quot;, types.varchar &#125;,  &#123; &quot;group_id&quot;, types.foreign_key &#125;,  &quot;PRIMARY KEY(id)&quot;&#125;)local Users = Model:extend(&quot;users&quot;)\n\nWe can create a paginator like so: \n\n我们可以创建一个分页器：\n1local paginated = Users:paginated(&quot;where group_id = ? order by name asc&quot;, 123)\n\nA paginator can be configured by passing a table as the last argument. The following options are supported: per_page: sets the number of items per page \n\n可以在最后一个参数传个lua table定义来配置分页器，下面的这个设置：per_page:设置每页显示项目的条数。\n1local paginated2 = Users:paginated(&quot;where group_id = ?&quot;, 4, &#123; per_page = 100 &#125;)\n\nprepare_results: a function that is passed the results of get_page and get_all for processing before they are returned. This is useful for bundling preloading information into the paginator. The prepare function takes 1 argument, the results, and it must return the results after they have been processed: \n\nprepare_results:此函数在把结果传给get_page和get_all处理之前就返回了。这个为分页器提前绑定信息很有用。预处理函数有一个参数，结果， 在返回结果之后就已对处理完了。\n1234567local preloaded = Posts:paginated(&quot;where category = ?&quot;, &quot;cats&quot;, &#123;  per_page = 10,  prepare_results = function(posts)    Users:include_in(posts, &quot;user_id&quot;)    return posts  end&#125;)\n\n\nAny additional options sent to paginated are passed directly to the underlying select method call when a page is loaded. For example you can provide a fields option in order to limit the fields returned by a page. \n\n在页面被加载后，任何附加参数被传给分页器都直接被select底层方法调用， 例如你可提供一个fields 选项，来限制每页返回的字段数。\nWhenever possible you should specify an ORDER clause in your paginated query, as the database might returned unexpected results for each page. The paginator has the following methods: \n\n可能你在查询中指定了一个ORDER语句， 数据库的分页数据可能返回了非预期的结果，分页器有下面的这些方法。\nget_all() \n\nGets all the items that the query can return, is the same as calling the select method directly. Returns an array table of model instances. \n\n返回所有的查询项目，效果和直接调用select一样，Model返回的是lua的数组table。\n123local users = paginated:get_all()SELECT * from &quot;users&quot; where group_id = 123 order by name ascget_page(page_num)\n\nGets page_numth page, where pages are 1 indexed. The number of items per page is controlled by theper_page option, and defaults to 10. Returns an array table of model instances. \n\n取得提定的page_num页， 页数从1索引 ，每页多少项是通过per_page这个参数来控制的，默认是10， Model返回的是lua的数组table。\n1234local page1 = paginated:get_page(1)local page6 = paginated:get_page(6)SELECT * from &quot;users&quot; where group_id = 123 order by name asc limit 10 offset 0SELECT * from &quot;users&quot; where group_id = 123 order by name asc limit 10 offset 50\n\n\nnum_pages() \n\nReturns the total number of pages. \n\n返回总页数。\ntotal_items() \n\nGets the total number of items that can be returned. The paginator will parse the query and remove all clauses except for the WHERE when issuing a COUNT. \n\n返回总项目数，分页器会分析查询，当查询是COUNT就移去WHERE之句。\n12local users = paginated:total_items()SELECT COUNT(*) as c from &quot;users&quot; where group_id = 123\n\nReturns an iterator function that can be used to iterate through each page of the results. Useful for processing a large query without having the entire result set loaded in memory at once. \n\n返回一个迭代函数，被用于遍历每页的结果。在有大型查询处理，内存一次放不下时，很有用。\n123for page_results, page_num in paginated:each_page() do  print(page_results, page_num)end\n\nBe careful modifying rows when iterating over each page, as your modifications might change the pagination order and you may process rows multiple times or none at all. \n\n遍历每页中行要小心，你的编辑可能会改变分页的顺序，还有你可能会对行结果处理多次，或一次也没有。\nhas_items() \n\nChecks to see if the paginator returns at least 1 item. Returns a boolean. This is more efficient than counting the items and checking for a number greater than 0 because the query generated by this function doesn’t do any counting. \n\n检查处理，判断分页器至少返回一条数据。返回的是boolean值，这个比判断返回结果&gt;0更高效，因为用这函数生成不会产生任何的计数查询。\n1234if pager:has_items() then  -- ...endSELECT 1 FROM &quot;users&quot; where group_id = 123 limit 1","slug":"old_topic/2016-09-17-224","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"27034822c77be4d440dd0177169f41b5","title":"vim 可视化模式（visual模式）","content":"为了便于选取文本，VIM 引入了可视(Visual)模式。 要选取一段文本，首先将光标移到段首，在普通模式下按 v 进入可视模式，然后把光标移到段末。 需要注意，光标所在字符是包含在选区中的 。\nv    进入字符可视化模式V    进入行可视化模式Ctrl+v    进入块可视化模式块选择 Ctrl+v   \n在表格中删除指定列非常有用\n用 v 命令进入的字符可视化模式（Characterwise visual mode)。文本选择是以字符为单位的。用 V 命令进入的行可视化模式（Linewise visual mode)。文本选择是以行为单位的。用 ctrl-V 进入的块可视化模式（Blockwise visual mode）。可以选择一个矩形内的文本。选择：\n选中{}中间的内容,不包括{}\nva{ 选中{}中间内容，包括{}\n选中()中间内容\nvi&lt; 选中&lt;&gt;中间内容\nvi[ 选中[]中间内容\nvit 选中中间的内容\nvi” 选中””中间内容\nvi’ 选中”中间的内容、\nvis 选中一个句子\nvib 选中一个block\nviw 选中一个单词\nvip 选中一个段落G        从光标所在处选择到结尾\n操作：\n这时可以对所选的文本进行一些操作，\n常用的(可视模式)命令有：\nx或d     剪切(即删除，同时所选的文本进入剪贴板) \ny           复制 \nr字符     所有字符替换为新字符 \nu U ~     分别是所有字母变小写、变大写、反转大小写 \n\n\n\n\n\n\n\n\n\n 和 &lt;  将选中字符右移或左移 shiftwidth位置\n当输入了命令以后，VIM 将回到普通模式，这时可以按 p 或 P 进行粘贴。普通模式下有关复制和粘贴的命令：\np或P    在当前位置粘贴剪贴板的内容，p 粘在光标所在字符后面，P 粘在前面。\nd   与 D 的区别\nd只删除选中的字符，而D删除选中字符所在行的所有字符， c 和 C ， y 和 Y 同理\n我们还可以利用可视化模式，来合并多行文本。 J 命令可以将高亮显示的文本内容合并为一行，同时以空格来分隔各行。如果不希望在行间插入空格，那么可以使用 gJ 命令。\n使用 g? 命令，可以使用rot 13算法来加密高亮显示的文本。针对同一个文本再次执行加密命令，就可以进行文本解密。\n在可视化模式下，按下 : 键就可以对选定范围进行操作。例如：我们先在可视化模式下选中文本，然后执行 :write block.txt 命令，就可以将文本块写入另一文件中。选择多行，然后执行 :sort 命令，则可以对选中的文本进行排序。\n查看Visual Mode下的命令  \n:help v_， 例如使用 :help v_d 命令，可以得到关于在可视模式下进行删除操作的帮助信息。\n","slug":"old_topic/2016-09-17-222","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"c71d78db21b611560e342ecd25e79bf6","title":"Openresty的Lua各阶段模块执行的顺序","content":"by 糖果收集\n","slug":"old_topic/2016-09-17-228","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"7fb84a036597ed4f4715be63b9185cf1","title":"动态修改OpenResty的Conf配置文件（nginx-upsync-module）","content":"翻译：糖果\nnginx-upsync-module - Nginx C module, sync upstreams from consul or others, dynamiclly modify backend-servers attribute(weight, max_fails,...), needn't reload nginx. \n\nnginx-upsync-module Nginx C模块，通过consul组件对upstream进行同步，动态的修改后端服务器的属性。（权重，最大失败数，…）并且不需要reload重新加载nginx.\nIt may not always be convenient to modify configuration files and restart NGINX. For example, if you are experiencing large amounts of traffic and high load, restarting NGINX and reloading the configuration at that point further increases load on the system and can temporarily degrade performance. \n\n不能总是方便的修改配置文件重起Nginx。比如，大流量业务，配置重起NGINX， 会暂时性降低加载性能。\nThe module can be more smoothly expansion and constriction, and will not influence the performance. \n\n这模块可对其进行，平滑的扩展和收束，而不影响性能。\nAnother module, nginx-stream-upsync-module supports nginx stream module(TCP protocol), please be noticed. \n\n别一模块，nginx-stream-upsync-module 支持nginx流（TCP协议），敬请关注！\n动态修改OpenResty的Conf配置文件（nginx-upsync-module）\nwww.lua.ren\n","slug":"old_topic/2016-09-17-226","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ff49a8763d0bd255c289aba24f00a480","title":"深入探究MoonScript的类实现","content":" （An in-depth look into the MoonScript class implementation） \nPosted July 05, 2015 by leafo (@moonscript) · Tags: lua, moonscriptTweet\nMoonScript’s class system is great balance of functionality and brevity. It’s simple to get started with, doesn’t impose many restrictions, and is incredibly flexible when you need to do advanced things or bend the rules. \n\nMoonScript的类系统功能设计的简洁明了，容易上手，无过多的牵绊， 是一款可以方便灵活使用的高级货。\nEven if you have no intention of using MoonScript, understanding the class system implementation is a good exercise for understanding some of the more complicated parts of Lua. \n\n即使你对MoonScript不感冒，理解类系统的实现，也是一次对lua高端用法深入理解的契机。\n例子（A simple example）\n\n类对象（The class object）\n基类（The base object）\n\n \n类与继承（Classes with inheritance）\n类使用的提示与技巧（Class tips and tricks）\n\n添加__tostring和其它的meta方法。（Adding __tostring and other metamethods）\n添加类声明的new方法。（Adding a new method to a class after declaration）\n转换一个已经存在表结构为一个实例。（Converting an existing table to an instance）\n给一个实例添加__index的meta属性。（Adding __index metafield to an instance）\n\n \n特性增强（Future improvements） \n尾声（Closing） \n\n简单例子（A simple example） \nLets start with a typical class in MoonScript: \n\n我们来创建一个典型的MoonScript类。\n12345class Player  new: (@x, @y) =&gt;  say_hello: =&gt;    print &quot;Greetings! I&#x27;m at #&#123;@x&#125;, #&#123;@y&#125;&quot;\n\n\nAnd take a look at the generated Lua: (Warning: there’s a lot going on, scroll past for analysis of each component) \n\n看由MoonScript翻译生成的Lua代码（提示：内容比较多，注意看每个部分。）\n12345678910111213141516171819202122232425local Playerdo  local _base_0 = &#123;    say_hello = function(self)      return print(&quot;Greetings! I&#x27;m at &quot; .. tostring(self.x) .. &quot;, &quot; .. tostring(self.y))    end  &#125;  _base_0.__index = _base_0  local _class_0 = setmetatable(&#123;    __init = function(self, x, y)      self.x, self.y = x, y    end,    __base = _base_0,    __name = &quot;Player&quot;  &#125;, &#123;    __index = _base_0,    __call = function(cls, ...)      local _self_0 = setmetatable(&#123;&#125;, _base_0)      cls.__init(_self_0, ...)      return _self_0    end  &#125;)  _base_0.__class = _class_0  Player = _class_0end\n\nLets go from the outside in. The result of the class expression is a new local variable called Player. Nothing else is made available on the calling scope. \n\n彻底看一下，类表达式产生了一个叫Palyer的局部变量， 超出作用域的调用不了。\nThe class’s internal objects are created inside of a Lua do end block, this ensures that they are scoped to just the class in question. The two internal objects are _class_0 and _base_0. \n\n\n类的内部对象，是在do和end 声明块之间定义的，确保子对象的作用域只在类里，两个内部对象，_class_0和_base_0。\nThe resulting local, Player is assigned _class_0. \n\n结果也是局部的，Player最终的是用_class_0赋予的。\nThe numbers at the end of these variables are not fixed, they come from MoonScript’s local name generator. They will increment if you nest classes. You should never write code that depends on their names. \n\n这些变量结尾的数字是不能改的， 是由MoonScript的本地名称生成的。如果你有新类，他会自增长，你写的代码不要和这名字产生直接的依赖。\n类对象（The class object） \n\nThe class object, aka _class_0 in the generated code, is a Lua table that represents the class. To create a new instance we call the class object as if it were a function. We can see here that it’s not actually a function. \n\n类对象， aka _class_0 是一个生成的代码，是lua的table结构来表示类，创建一个新的实例，我们调用调用类对象就像他是函数一样，但实际上它又不是一个函数。\nIn order to make a Lua table callable it must implement the __call metamethod. \n\n为了让一个lua table可调用，就必须实现一个__call的meta方法。\nHere’s the extracted class object’s creation: \n\n这里展开了类对象的创建\n1234567891011121314local _class_0 = setmetatable(&#123;  __init = function(self, x, y)    self.x, self.y = x, y  end,  __base = _base_0,  __name = &quot;Player&quot;&#125;, &#123;  __index = _base_0,  __call = function(cls, ...)    local _self_0 = setmetatable(&#123;&#125;, _base_0)    cls.__init(_self_0, ...)    return _self_0  end&#125;)\n\nThe Lua function setmetatable sets the metatable of the first argument to the second argument. It then returns the first argument. This means the value of _class_0 is the modified version of the first table. \n\nlua的setmetatables函数设置，第一个参数到第二个参数的meta表结构(metatable)。返回的是第一个参数。意味_class_0的值第一个talbe的版本是可被编辑的。\nThe table _class_0 is very basic. It has the constructor we created (with new) stored in __init, the base object stored in __base and the name of the class stored in __name. \n\n表 _class_0非常的基础。它是我们创建并存储在__init中的一个构造器， 基类对象是存在 __base中，并且类的名存在__name中。\nUnlike the generated names, these names are unchanging and safe to use in your code. Because they are stored directly on the class object we can access them with dot syntax:\n不像自动生成的那些名字，这个名字不能改变，可以安全的在你的代码中使用。因为它是直接存在类对象中的，我们可以直接用”.”进行访问。\n\n\n\n\n\n\n\n\n\nprint(Player.__name) --> prints \"Player\" \n\n\nTwo metafields are provided on the class objects metatable: __index and __call.\nmeta字段(metafiels)被提供在class对象的meta表中(metatable)。\nThe __call function is what is called when we create a new instance: Player() It’s responsible for creating a new table to be the instance, providing it with a metatable, then calling the constructor.\n__call函数会在我们创建一个新实例时被调用：Player()的职责是把一个新表给成一个实例，提供一个meta表（metatable）, 当我们调用构造函数时。\nYou can can see how the _base_0 is used directly as the metatable of the object.\n你可看到_base_0是如何被用作对象的meta表的。(metatable)\nAdditionally, the class object has an __index metafield set to the base. This has a lot of implications. The most important is you can access any fields from base directly on the class object, assuming they haven’t been shadowed by any fields directly on the class object.\nThe base object\nlocal _base_0 = {  say_hello = function(self)    return print(“Greetings! I’m at “ .. tostring(self.x) .. “, “ .. tostring(self.y))  end}_base_0.__index = _base_0_base_0.__class = _class_0\n```\nThe base object, __base_0 is a regular Lua table. It holds all the instance methods of the class. Our example from above implemented a say_hello method which is compiled directly into the base.\nThe base object has a circular reference to itself in the __index field.\nThis lets us use the base object directly as the metatable of instances. The __index property is where instance methods are fetched from. Since it points to itself, the instance methods can be pulled directly from the metatable without any indirection.\nLikewise, this also lets us implement other metamethods directly as instance methods of the class. I’ll have an example below.\nIt’s a very cool concept, and definitely worth taking a moment to understand.\nLastly, a reference to the class placed on the base object with the name __class. This is how the @@ operator accesses the class object.\nClasses with inheritance\nSuper invocation has changed a bit in MoonScript 0.4.0Classes that inherit from other classes in MoonScript introduce a few more ideas. The extends keyword is used for inheritance:\nclass SizedPlayer extends Player  new: (@size, …) =&gt;    super …\n  say_hello: =&gt;    super!    print “I’m #{@size} tall”\nHere’s the resulting Lua:\nlocal SizedPlayerdo  local _parent_0 = Player  local _base_0 = {    say_hello = function(self)      _parent_0.say_hello(self)      return print(“I’m “ .. tostring(self.size) .. “ tall”)    end  }  _base_0.__index = _base_0  setmetatable(_base_0, _parent_0.__base)  local _class_0 = setmetatable({    __init = function(self, size, …)      self.size = size      return _parent_0.__init(self, …)    end,    __base = _base_0,    __name = “SizedPlayer”,    __parent = _parent_0  }, {    __index = function(cls, name)      local val = rawget(_base_0, name)      if val == nil then        return _parent_0[name]      else        return val      end    end,    __call = function(cls, …)      local _self_0 = setmetatable({}, _base_0)      cls.__init(_self_0, …)      return _self_0    end  })  _base_0.__class = _class_0  if _parent_0.__inherited then    _parent_0.__inherited(_parent_0, _class_0)  end  SizedPlayer = _class_0end\nThe majority of the generated code is the same as a regular class. Here are the differences:\nlocal _parent_0 = PlayerThere’s a new local variable inside the do end block called _parent_0 that holds a reference to the parent class.\nlocal _base_0 = {  – …}_base_0.__index = _base_0setmetatable(_base_0, _parent_0.__base)\nThe metatable of the base is set to the base of the parent class. This establishes the inheritance chain for instances. If a method can’t be found on the class’s base, then the parent class’s base is automatically searched due to how __index works.\nThere’s a slight disadvantage to this. Metamethods are fetched with rawget, so metamethod inheritance does not work by default. We can work around this with the __inherited callback discussed below.\nlocal _class_0 = setmetatable({  – …  __parent = _parent_0}, {  – …}\nThe parent class is stored on the class object in a field called __parent. This gives you an easy way to reference the parent class object.\n{  __index = function(cls, name)    local val = rawget(_base_0, name)    if val == nil then      return _parent_0[name]    else      return val    end  end,  – …}\nThe __index metafield on the class object is now a function, instead of a reference to the base (which is a table). rawget is used control the precedence of the properties. If the field can’t be found directly on the base then the parent class is searched.\nRemember that class objects also pull fields from their bases, so this has the effect of searching both the parent class object and the parent class’s base. Even though we’ve used rawget on the base, we can still get access to the parent class’s base.\nif _parent_0.__inherited then  _parent_0.__inherited(_parent_0, _class_0)end\nLastly, we now have a class callback. When a subclass is created and the parent class has a method __inherited then it is called with the class object that has just been created.\nThe __inherited method works directly with class objects, no instances are involved.\nlocal _base_0 = {  say_hello = function(self)    _parent_0.say_hello(self)    return print(“I’m “ .. tostring(self.size) .. “ tall”)  end}\nIn the example I included a method that calls super. All MoonScript does is provide sugar for calling the method of the same name on the parent class.\nClass tips and tricks\nNow that you have an understanding of how a class in MoonScript is implemented, it’s easy to see how we can work with the internals to accomplish new things.\nAdding __tostring and other metamethods\nIf you want your instances to have a string representation you can implement a __tostring method in the metatable.\nAs we saw above, the metatable has an __index field set to itself, we just need to implement metamethods as instance methods:\nclass Player  new: (@x, @y) =&gt;\n  __tostring: =&gt;    “Player(#{@x}, #{@y})”\nprint Player(2, 8) –&gt; “Player(2, 8)”\nAll of Lua’s metamethods work (except __index, see below). Here’s an example of a vector class with overloaded operators:\nclass Vector  new: (@x, @y) =&gt;\n  __tostring: =&gt;    “Vector(#{@x}, #{@y})”\n  __add: (other) =&gt;    Vector @x + other.x, @y + other.y\n  __sub: (other) =&gt;    Vector @x - other.x, @y - other.y\n  __mul: (other) =&gt;    if type(other) == “number”      – scale      Vector @x * other, @y * other    else      – dot product      Vector @x * other.x + @y * other.y\nprint Vector(1,2) * 5 + Vector(3,3) –&gt; Vector(8, 13)\nI mentioned above that metamethod inheritance does not work:\nclass Thing  __tostring: =&gt; “Thing”\nclass BetterThing extends Thing\nprint BetterThing! –&gt; table: 0x1057290We can work around this by using the __inherited callback:\nclass Thing  __tostring: =&gt; “Thing”  __inherited: (cls) =&gt;    cls.__base.__tostring = @__tostring\nclass BetterThing extends Thing\nprint BetterThing! –&gt; Thing\nAdding a new method to a class after declaration\nNow that we know about __base it’s easy to add new methods to classes that don’t have them.\nclass Player  new: (@name) =&gt;\n– add the new methodPlayer.__base.jump = =&gt;  print “#{@name} is jumping!”\nPlayer(“Adam”)\\jump! –&gt; Adam is jumping!\nWe can extend this concept even further to dynamically generate methods:\nclass Player  new: (@name) =&gt;\n  for dir in *{“north”, “west”, “east”, “south”}    @_base[“go#{dir}”]: =&gt;      print “#{@name} is going #{dir}”\nPlayer(“Lee”)\\go_east! –&gt; Lee is going east\nConverting an existing table to an instance\nSometimes you might already have a table that you’d like to convert to an instance of a class without having to copy it. Now that we know how the __init method works we can use setmetatable to accomplish a similar result:\nclass Rect  area: =&gt; @w * @h\nsome_obj = { w: 15, h: 3 }\n– apply the metatablesetmetatable(some_obj, Rect.__base)\nprint some_obj\\area! –&gt; 45\nThis same method can be used to convert on object from type to another.\nAdding __index metafield to an instance\nMoonScript uses the __index metafield on class instances in order to allow instance properties to be looked up. If we just replace __inde with another implementation without any consideration we would break the instance. We’ll have to chain our custom __index with the old one.\nHere’s how we might implement getter methods:\nclass Thing  getters: {    age: =&gt;      os.time! - @created_at  }\n  new: =&gt;    @created_at = os.time!\nmt = getmetatable @\nold_index = mt.__index\n\nmt.__index = (name) =&gt;\n  if getter = old_index.getters[name]\n    getter @\n  else\n    if type(old_index) == &quot;function&quot;\n      old_index @, name\n    else\n      old_index[name]\n\nt = Thing!print t.age\nIts’s important that you don’t try to access self (without rawget) within the __index metamethod, otherwise you’ll cause an infinite loop.Writing that massive implementation in the constructor isn’t ideal. Here’s a base class that automatically upgrades anyone who inherits with getter functionality:\nclass HasGetters  getters: {}  __inherited: (cls) =&gt;    old_init = cls.__init    cls.__init = (…) =&gt;      old_init @, …\n  mt = getmetatable @\n  old_index = mt.__index\n\n  mt.__index = (name) =&gt;\n    if getter = old_index.getters[name]\n      getter @\n    else\n      if type(old_index) == &quot;function&quot;\n        old_index @, name\n      else\n        old_index[name]\n\nclass BetterThing extends HasGetters  getters: {    age: =&gt;      os.time! - @created_at  }\n  new: =&gt;    @created_at = os.time!\nt = BetterThing!print t.age\nThe clever part here is replacing the __init method on the base class with a custom one that automatically injects support for getters.\n特性增强（Future improvements） \n\nThe class system is far from perfect. Here are some future improvements that I’d like to add:\nThere’s no way to determine which order methods are added to a class. If you’re going to be triggering side effects from method creation then your options are limited.The MoonScript class meta-properties use double underscore just like Lua. If Lua ever decides to use any of the same names then there will be conflicts.Closing\nNot all of the functionality of MoonScript classes was covered in this guide. You can learn more on the Object Oriented Programming section of the MoonScript documentation. \n\n不是所有的MoonScript的类功能都在这篇中会讲到。学习更多关于OOP的部分，可以看MoonScript的文档。\n","slug":"old_topic/2016-09-17-227","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"65da3e09abf807b11cd52abb8b1dad7d","title":"Lapis如何读写HTTP的Header数据","content":"by 糖果这不是翻译的文章，其中直接用了我的理解，进行功能的描述。\nHow do I read a HTTP header? \n\n如何读取HTTP的Header数据\nThe req field of the self passed to actions has a headers fields with all the request headers. They are normalized so you don’t have to be concerned about capitalization. \n\n在Lapis中headers数据，直接存于self.req.headers数据结构中，可以像访问map一样，用key取得对应的字段值，代码如下：\n123456local lapis = require(&quot;lapis&quot;)local app = lapis.Application()app:match(&quot;/&quot;, function(self)  return self.req.headers[&quot;referrer&quot;]end)\n\nHow do I write a HTTP header? \n如何向HTTP的header中写入数据。\n\nThere are two ways to write headers. In these examples we set the Access-Control-Allow-Origin header to * \n\n基本上有两种方式，可以进行写操作，下面代码中的例子是把Access-Control-Allow-Origin这个字段设成”*”\nYou can return a headers field (or pass it to write) from an action: \n\n我们可以一个路由的return响应动作中返回一个Header。\n1234567891011local lapis = require(&quot;lapis&quot;)local app = lapis.Application()app:match(&quot;/&quot;, function(self)  return &#123;    &quot;OK&quot;,    headers = &#123;      [&quot;Access-Control-Allow-Origin&quot;] = &quot;*&quot;    &#125;  &#125;end)\n\nAlternatively, the res field of the self has a headers field that lets you set headers. \n\n或者，你也可以通过改变self.res.header这个数据结构中的字段值，来改变headers的设定。\n1234567local lapis = require(&quot;lapis&quot;)local app = lapis.Application()app:match(&quot;/&quot;, function(self)  self.res.headers[&quot;Access-Control-Allow-Origin&quot;] = &quot;*&quot;  return &quot;ok&quot;end)\n\nIf you need to change the content type see below.\n\n如何你想改变，返回数据的类型，看下面的说明。\nHow do I set the content type? \n\n如何设定返回内容的类型。\nEither manually set the header as described above, or use the content_type option of the write method, or action return value: \n\n我们使用content_type选项方法， 改变返回数据的类型。\n123456local lapis = require(&quot;lapis&quot;)local app = lapis.Application()app:match(&quot;/&quot;, function(self)  return &#123; content_type = &quot;text/rss&quot;, [[&lt;rss version=&quot;2.0&quot;&gt;&lt;/rss&gt;]] &#125;end)","slug":"old_topic/2016-09-17-229","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"2707eecc13e3136ac3d2044a4e3fff26","title":"在Heroku云上部署Lua应用","content":"在Heroku云上部署Lua应用\nRunning Lua on Heroku\nPosted February 05, 2012 by leafo (@moonscript) \nSince the release of Heroku’s Cedar platform they've opened up the opportunity for users to run web applications on any stack. Using something called a buildpack we can describe a template for deploying any kind of application. I saw this as a great opportunity to try using Lua on a cloud hosting platform (for free). \n\n因为Heroku发布的Cedar平台，开放了为用户运行任意web应用的栈技术支持，buildpack使我们可以用模板来描述任意类型的应用部署，关键的是这东西,在云上运行lua还免费。\nI put together heroku-buildpack-lua, a buildpack containing Lua 5.1 andLuaRocks (a Lua package manager) enable you to quickly deploy Lua along with any required dependencies that can be found on theLuaRocks server. \n\n我做了一个heroku-buidlparck-lua的构建包，包里有lua 5.1和luarocks（LUA包管理器），充许你快速的部署一个lua程序，并且任何相关的依赖，都可以在LuaRocsks服务器上找到。\nHere’s a tutorial on getting a very simple app running: \n下面的是运行一个简单app的教程。\n\nFeb 12 2012 — I’ve updated the buildpack and this post to simplify the process.\n \n1.Creating An App\n2.Describing Dependencies\n3.Creating A Web Server\n4.Deploying The Web Server\n5.What’s Next?\n \n\n1.创建APP2.描述依赖3.创建一个WEB服务器4.部署WEB服务器5.后续\n1.创建APP \nCreating An App\n\n\n\nAssuming you've installed heroku we start by creating a new app: \n\n假设你已经安装了heroku,我们就开始创建一个应用。\n12$ heroku create --stack cedar --buildpack http://github.com/leafo/heroku-buildpack-lua.git\n\nClone the repository it created and we're ready to begin. (stark-dust-4830 was the randomly generated name of my app, replace it with yours.) \n\n克隆分支，创建后我们开始读取。(stark-dust-4830是一个随机生成app名称)\n12$ git clone git@heroku.com:stark-dusk-4830.git$cd stark-dust-4830\n\n\n2.描述依赖 \nDescribing Dependencies\n\n\nHeroku manages a collection of app servers for us, called web dynos in their terminology. Each application server must expose itself to the outside world. This is done by running a web server on the dyno.  \n\nHeroku为我们管理服务器上的应用集合， 术语叫做web dynos，每个应用服务必须对外界暴露自己，这是运行在dyno上的WEB服务。\nThe Xavante project is simple web server written in Lua with a couple dependencies. \nXavate project是一个简单的用lua弄的web服务，两依赖。\n\n\nUsing LuaRocks bundled in the Lua buildpack, we can easily install Xavante and all its dependencies. We describe the dependencies of our Lua project by creating a rockspec for it. \n\nLuaRocks被绑定在lua级的buidlpack中， 我们可以很容易的安装Xavante和所有她的依赖， 我们创建一个rockkspec的文件来描述我们lua工程的依赖。\nA rockspec is a special Lua file ending in .rockspec that describes meta-data about a Lua module. This meta-data includes things like the project name, the maintainer. It also holds any dependencies and how to build the module. \n\nrockspeck是一个特殊的扩名是.rockspec的lua文件，描述关于lua模块的头信息，这个头信息包括了像项目名、维护者，甚至任何的关于如何创建模块的所需的依赖信息。\nThe Lua buildpack understands the rockspec format, but only looks at the dependencies. Thus, for simplicity we'll only define the dependencies.\nGo ahead and create app.rockspec and place inside of it: \n\nLua的构建包知道rockspec的格式，但是只能是依赖，我们的只能定义依赖，以下是之前创建的app.rockspec的内容。\n1234-- app.rockspecdependencies = &#123;  &quot;xavante&quot;&#125;\n\nXavante will be our only dependency. We're going to keep this tutorial short and leave out the web frameworks. Xavante’s API is flexible enough that it functions as a makeshift framework. \n\nXavante 是我们唯一的依赖，我们这教程不使用lua web框架。Xavante的API很灵活，是够应付一般函数的简易框架。\nIf you commit and push, you'll see the buildpack fetch and build all the dependencies. There will be a lot of output, don’t be be concerned. \n\n如果你提交了代码，会看到build会取得重建所有的依赖，会有很多的输出，可无视。\n12$ git add app.rockspec$ git commit -m &quot;init&quot;$ git push origin master\n\n…\n—–&gt; Heroku receiving push—–&gt; Fetching custom buildpack… done—–&gt; Lua app detected—–&gt; Copying lua to bin—–&gt; Installing packagesInstalling http://www.luarocks.org/repositories/rocks/xavante-2.2.1-1.all.rock…\n… output truncated …\n—–&gt; Discovering process types       Procfile declares types -&gt; (none)—–&gt; Compiled slug size is 292K—–&gt; Launching… done, v5       http://stark-dusk-4830.herokuapp.com deployed to \nHeroku \nOur dependencies work, but we still haven’t set up a web server. This we'll do by writing some Lua. \n\n依赖配置好了，但还需要配置web服务器，那我们就用lua写点啥。\n3.创建WEB服务 \nCreating A Web Server\n\n\n\nWe'll use Xavante’s programmatic API to create and run our server through a simple Lua script\n\nCreate a file, web.lua, and place in it: \n \n\n我们用Xavnate的可编程API来创建和运行我们的简单的lua脚本。创建一个web.lua文件。\n123456789101112131415161718192021222324252627-- web.luarequire&quot;xavante&quot;require&quot;xavante.filehandler&quot;port =...xavante.HTTP &#123;  server = &#123; host =&quot;*&quot;, port =tonumber(port) &#125;,  defaultHost = &#123;    rules = &#123;      &#123;        match =&quot;/$&quot;,        with =function(req, res)          res.headers[&quot;Content-type&quot;] =&quot;text/html&quot;          res.content =&quot;hello world, the time is: &quot;..os.date()          return res        end      &#125;, &#123;        match =&quot;.&quot;,        with = xavante.filehandler,        params = &#123; baseDir =&quot;static/&quot; &#125;      &#125;    &#125;  &#125;&#125;xavante.start()\n\nIn this file we create a web server with two simple rules. If you go to the path / then we say hello and show the time. Otherwise, we default to trying to serve files from the static/ directory in our app. \n\n在这个文件，我们创建一个web服务和两个简单的规则。当你访问路径’/‘时，会显示 ‘say hello’的字样，并且显示时间信息，另外静态文件是放在当前app的static目录 。\nGo ahead and create the static/ directory now, and put something inside of it like a favicon or a html file. \n\n继续，创建的 static目录 ，现在就可以把放一些图标和html文件放到里面。\nIf you have Xavante installed locally, we can test the app. (where 5000 is a port to bind to) \n\n如果Xavante被安装在本地，我们测下APP。（绑定的端口是5000）\n12$ lua web.lua 5000Xavante started on port(s) 5000\n\nIf not, go on to the next step. \n如果不是，进入下一步。\n\n4.部署 Web Server \nDeploying The Web Server\n\n\nNow that all the required code is written, the only thing left to do is to tell Heroku how to start it. \n\n现在所有的代码都写了，接下来唯一要做的是告诉Heroku如何开始。\nHeroku uses something called a Procfile to list the commands needed to start things like web severs and workers. We only need a single web server. \nHeroku使用了一个叫Procfile的文件，列出了web server要执行的命令任务，我们只需要一个单独的web 服务。\n\nCreate a file called Procfile and place inside of it: \n创建一个procfile文件。\n\n1web: lua web.lua $PORT\n\nNow we're ready to deploy. Commit and push once again. \n开始部署，再一次上传代码。\n\n1$ git commit -a -m &quot;...&quot;$ git push origin master\n\nWe can check and see if our app is running by typing into the console: \n使用命令行检查我们正在运行的app。\n\n1$ heroku ps\n\nYou'll probably see nothing running! It’s because we deployed before without a Procfile. Tell Heroku to start up our web server: \n\n你也看到了，什么都没运行！ 因为之前的部署没有Procfile文件，来告诉Heroku是如何启动web服务的。\n1234567$ heroku scale web=1Scaling web processes... done, now running 1$ heroku psProcess  State       Command                -------  ----------  ---------------------  web.1    up for 16s  bin/lua web.lua $PORT\n\n\nIf you still see nothing running you'll have to debug. Run heroku logs to see if anything failed. \n如果你还是看到什么也没运行，执行一下heroku logs，看一下有什么错误发生。\n\nNow our web server is running, navigate to the url of the app to see it live.\nDon’t forget to try out some of the static files you included. \n\n此刻我们的Web服务在运行了，跳到的Url 证明app在运行中，别忘了测试一下static目录下的文件。\n5.后续 \nWhat’s Next?\n\nWhat we've created here is fairly primitive. There are a lot of opportunities for expanding: \n\n这篇比较糙，后续还有很多可以展开的题目 。\n\n\n\n\n\n\n\n\n\nUse a Lua web framework like Orbit\nTalk to a SQL database with LuaSQL\nTalk to Redis with redis-lua\nTalk to CouchDB with luachia\nMake a website in MoonScript \n\n使用Orbit 这种Lua WEB框架。探讨SQL数据库和LuaSQL探讨Redis和redis-lua探讨CouchDB和luachia使用Moonscript创建站点。\nIt’s also worth reading the the Lua buildpack’s README because it explains how and where Lua and it’s packages are installed. \n\n更多有价值的信息可以看buildpack里面的README文件， 里面解释了lua和对应包是如何被安装的。\nleafo.net 2015 · Generated Fri Apr 8 14:00:07 2016 by Sitegen\n翻译：糖果\nLua On Heroku\n","slug":"old_topic/2016-09-17-223","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"27a76f8b85be215ce4dc3b40107bebc6","title":"Writing a DSL in Lua","content":"作者：leafo\nDSLs, or domain specific languages, are programming languages that are designed to implement a set of features specific to a particular problem or field. An example could be Make, the build tool, which is a specially designed language for combining commands and files while managing dependencies. \n\nDSLs,“领域特定语言”：是为了特定领域的问题，设计实现了某些功能的编程语言。\n* Dropping the parenthesis\n* Chaining\n* Using function environments\n* Implementing the HTML builder\n* Closing\n\nA lot of modern programming languages have so much flexibility in their syntax that it’s possible to build libraries that expose their own mini-languages within the host language. The definition of DSL has broadened to include these kinds of libraries. \n\n很多现代编程语言，语法非常的灵活，用库的形式，在宿主语言中构他们自己的迷你语言。 用DSL扩展自己的库。\nIn this guide we'll build a DSL for generating HTML. It looks like this: \n这篇我们会用DSL语言生成HTML标记语言，如下：\n\n[code]html {  body {    h1 “Welcome to my Lua site”,    a {      href = “http://leafo.net&quot;,      “Go home”    }  }}[/code]\nBefore jumping in, here are some DSL building techniques: \n\n至此，有一些DSL的构建技术：\nDropping the parenthesis One of the cases for Lua as described in its initial public release(1996) is that it makes a good configuration language. That’s still true to this day, and Lua is friendly to building DSLs.\n \n1996年的lua发行版的描述中就去掉了括号，使他成为一个出色配置语言，延续至今，LUA是友好的DSLs构建语言。\nA unique part about Lua’s syntax is parenthesis are optional in some scenarios when calling functions. Terseness is important when building a DSL, and removing superfluous characters is a good way to do that. \n\n唯一lua语法用到括号的场合是函数调用。构建DSL的关键点就是简洁，剔除多余字符也是很好的途径。\nWhen calling a function that has a single argument of either a table literal or a string literal, the parenthesis are optional. \n\n函数调用时的参数是单参数的表字符串或是字符串。括号是可选。\n[code]print “hello” –&gt; print(“hello”)my_function { 1,2,3 } –&gt; my_function({1,2,3})\n– whitespace isn’t needed, these also work:\n空白符非必须，一样管用。\nprint”hello” –&gt; print(“hello”)my_function{ 1,2,3 } –&gt; my_function({1,2,3})[/code]\nThis syntax has very high precedence, the same as if you were using parenthesis: \n\n这是个高优先级的语法， 类似于用括号。\n[code]tonumber “1234” + 5 – &gt; tonumber(“1234”) + 5[/code]\nChainingParenthesis-less invocation can be chained as long as each expression from the left evaluates to a function (or a callable table). Here’s some example syntax for a hypothetical web routing framework: \n\n–&gt;()运操符调用， 链是从一个左值表达式函数（或是一个可调用的表）。这有一个假设的web路由框架的语法的例子。\n[code]match “/post-comment” {  GET = function ()    – render the form  end,\n  POST = function ()    – save to database  end}\n[/code]\nIf it’s not immediately obvious what’s going on, writing the parenthesis in will clear things up. The precedence of the parenthesis-less invocation goes from left to right, so the above is equivalent to: \n如果还是不能立马说明问题，写一个括号就一目了然了。\n-->符的调用优先级是从左到右的，与上面的效果一样。\n\n\n\n[code]match(“/post-comment”)({ … })[/code]\nThe pattern we would use to implement this syntax would look something like this: \n\n这种模式可以实现这个语法，类似于下面这种：\n[code]local function match(path)  print(“match:”, path)\n  return function(params)    print(“params:”, params)    – both path and params are now availble for use here  endend\n[/code]\nUsing a recursive function constructor it’s possible to make chaining work for any length. \n\n使用递归函数构造,可以是让链变为任意长度。\nUsing function environments When interacting with a Lua module you regularly have to bring any functions or values into scope using require. When working with a DSL, it’s nice to have all the functionality available without having to manually load anything. \n\n使用函数环境，与lua模块进行交互，你可以require任意一个变量或是函数到作用域。\nOne option would be to make all the functions and values global variables, but it’s not recommended as it might interfere with other libraries. \n\n可以让全局变量让所有函数都可见，但不推荐这样，可能会影响其它的库。\nA function environment can be used to change how a function resolves global variable references within its scope. This can be used to automatically expose a DSL’s functionality without polluting the regular global scope. \n\n函数环境可以用来改变，解决函数作用域范围内的全局变量的引用。\nFor the sake of this guide I'll assume that setfenv exists in the version of Lua we're using. If you're using 5.2 or above you'll need to provide you own implementation:  \n\n这篇我会假设，setfenv已经存在的lua版本中使用。如果你使用的是5.2或是更高版本，你需要自己动手。\nImplementing setfenv in Lua 5.2, 5.3, and above Here’s a function run_with_env that runs another function with a particular environment. \n\n[code]local function run_with_env(env, fn, …)  setfenv(fn, env)  fn(…)end[/code]\nThe environment passed will represent the DSL: \n环境传递的就是DSL。\n\n[code]local dsl_env = {  move = function(x,y)    print(“I moved to”, x, y)  end,\n  speak = function(message)    print(“I said”, message)  end}\nrun_with_env(dsl_env, function()  move(10, 10)  speak(“I am hungry!”)end)\n[/code]\nIn this trivial example the benefits might not be obvious, but typically your DSL would be implemented in another module, and each place you invoke it is not necessary to bring each function into scope manually, but rather activate the whole sscope with run_with_env. \n在这平时的例子显示的益处不明显，一般你的DSL可以在其它模块实现，不必要每个地方都调用，让每个函数到作用域里，但是激活整个作用域用run_with_env。\n\nFunction environments also let you dynamically generate methods on the fly. Using the __index metamethod implemented as a function, any value can be programmatically created. This is how the HTML builder DSL will be created. \n\n函数环境也让你飞速动态的生成方法。使用__index元方法实现一个函数，任何的变量都可以自动化创建。这是HMTL创建器DSL如何被创建。\nImplementing the HTML builder Our goal is to make the following syntax work: \n\n\n实现HTML构建器，我们的目地就是让下面的语法工作。\n[code]\nhtml {  body {    h1 “Welcome to my Lua site”,    a {      href = “http://leafo.net&quot;,      “Go home”    }  }}\n[/code]\nEach HTML tag is represented by a Lua function that will return the HTML string representing that tag with the correct attribute and content if necessary. \n\n每个HTML标签被用一个lua函数表示， 将会返回HTML字符串表示标签正确的属性和正文，如果必要。\nAlthough it would be possible to write code to generate all the HTML tag builder functions ahead of time, a function __index metamethod will be used to generate them on the fly. \n\n虽然它可能提前写代码来生成所有的HTML标签生成器函数， __index函数方法用于快速的生成它。\nIn order to run code in the context of our DSL, it must be packaged into a function. The render_html function will take that function and convert it to a HTML string: \n\n为了运行我们的DSL正文中代码，它必须打包到函数中。 render_html函数将会把这个函数转换成HTML字符串。\n[code]render_html(function()  return div {    img { src = “http://leafo.net/hi&quot; }  }end) – &gt; [/code]\nThe img tag is self-closing, it has no separate close tag. HTML calls these “void elements”. These will be treated differently in the implementation. \n\nimg标签是自动关闭，它没分割符关闭标签。HTML叫这个”空标签”。这个处理会有不现的实现。\nrender_html might be implemented like this: \n\nrender_html实现类似于下面：\n[code]local function render_html(fn)  setfenv(fn, setmetatable({}, {    __index = function(self, tag_name)      return function(opts)        return build_tag(tag_name, opts)      end    end  }))\n  return fn()end[/code]\nThe build_tag function is where all actual work is done. It takes the name of the tag, and the attributes and content as a single table. \n\nbuild_tag函数是在所有实际工作完成时。它取得标签的名字，属性和正文是一个单个的table。\nThis function could be optimized by caching the generated functions in the environment table. \n\n这函数是缓冲区优化的，生成的函数在环境table里。\nThe void elements, as mentioned above, are defined as a simple set: \n\n空元素， 如上所述，定义一个简单的设置：\n[code]local void_tags = {  img = true,  – etc…}[/code]\nThe most efficient way to concatenate strings in regular Lua is to accumulate them into a table then call table.concat. Many calls to table.insert could be used to append to this buffer table, but I prefer the following function to allow multiple values to be appended at once: \n\n大多数有效的方式连接字符串在常规的lua中是堆积到table中，当调用table.concat方法时。许多调用talbe.insert可被用于添加到这个缓冲表，但我更喜欢下面的函数，可以允许一次插入多个值。\n[code]local function append_all(buffer, …)  for i=1,select(“#”, …) do    table.insert(buffer, (select(i, …)))  endend[/code]\n– example:–[code]local buffer = {}–append_all(buffer, “a”, “b”, c)–buffer now is {“a”, “b”, “c”}[/code]\nappend_all uses Lua’s built in function select to avoid any extra allocations by querying the var args object instead of creating a new table. \n\nappend_all 使用lua的构建于函数选择避免任何额外分配，用查询的变理参数对象代替创建新表。\nNow the implementation of build_tag: \n\n现在是build_tag的实现。\n[code]local function build_tag(tag_name, opts)  local buffer = {“&lt;”, tag_name}  if type(opts) == “table” then    for k,v in pairs(opts) do      if type(k) ~= “number” then        append_all(buffer, “ “, k, ‘=”‘, v, ‘“‘)      end    end  end\n  if void_tags[tag_name] then    append_all(buffer, “ /&gt;”)  else    append_all(buffer, “&gt;”)    if type(opts) == “table” then      append_all(buffer, unpack(opts))    else      append_all(buffer, opts)    end    append_all(buffer, “&lt;/“, tag_name, “&gt;”)  end\n  return table.concat(buffer)end[/code]\nThere are a couple interesting things here: \n\n有两个很有趣的事。\nThe opts argument can either be a string literal or a table. When it’s a table it takes advantage of the fact that Lua tables are both hash tables and arrays at the same time. The hash table portion holds the attributes of the HTML element, and the array portion holds the contents of the element. \n\n选项参数可以是字符串或是table，当时table时，他高级的事实，lua和table同时是哈希表和数组。哈希表的部分何存HTML元素的属性。\n\n\n\n\n\n\n\n\n\nChecking if the key in a pairs iteration is numeric is a quick way to approximate isolating array like elements. It’s not perfect, but will work for this case. \n检查如果KEY在一对迭代是数字是一种快速的方式近似隔离数组像元素。并不完美，但是此种情况可适用。\n\n\n[code]for k,v in pairs(opts) do  if type(k) ~= “number” then    – access hash table key and values  endend[/code]\n\n\n\n\n\n\n\n\n\nWhen the content of the tag is inserted into the buffer for the table based opts, the following line is used: \n\n当标签的内容插入到缓冲区为有表的基础选择，以下：\n[code]append_all(buffer, unpack(opts))[/code]\n\nLua’s built in function unpack converts the array values in a table to var args. This fits perfectly into the append_all function defined above. \n\nlua的内建函数unpack转换数组的值到表变量参数。这完美适应上面的append_all函数所定义的。\n\n\n\n\n\n\n\n\n\nunpack is table.unpack in Lua 5.2 and above. Closing This simple implementation of an HTML builder that should give you a good introduction to building your own DSLs in Lua. \n\nunpack函数在lua5.2中有，结束这个简单的HTML构建器的实现，应该会给你一个好的介绍在lua中构建你自己的DSL。\n\nThe HTML builder provided performs no HTML escaping. It’s not suitable for rendering untrusted input. If you're looking for a way to enhance the builder then try adding html escaping. For example: \n\nHTML生成器提供的是没HTML脱字符,不太适合用于渲染非信认的输入，如果你想通过新方式增强生成器，尝试添加html脱字符，例如：\n[code]local unsafe_text = [[alert('hacked!')]]\nrender_html(function()  return div(unsafe_text)end)\n– should not return a functional script tag:– \n\nalert('hacked!')\n\n[/code]\n","slug":"old_topic/2016-09-17-225","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"7c6c0bd644fe170c87ec457e7a5178a5","title":"Lua的HTTP库","content":"其实除lua curl，还有另外一个库，也用以用HTTP请求。就是lua socket的http请求。\n可以用这种方式进行http请求和简单的数据爬取，然后用正则，对返回的数据进行分析。\n123http = require(&quot;socket.http&quot;)body, ret = http.request(&quot;http://wwww.baidu.com&quot;)print(body)","slug":"old_topic/2016-09-17-235","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e623d764e660785c48cbd0cf5044deb0","title":"ES（Elasticsearch）常用操作与Python客户端","content":"ES常用操作\n之前老板本的ES使用的创建索引的指令已经失效了。\n123456curl -X PUT &#x27;http://127.0.0.1:9200/testcase/&#x27; -d &#x27;        index:            number_of_shards:3            number_of_replicas:2&#x27;\n\n索性就不创建索引，直接插入数据， ES不用像关系型数据库那样，需要在插插入数据前，先定义数据库表结构，没有create table的过程。\n1curl -X POST http://127.0.0.1:9200/testcase/case/1 -d  &#x27;&#123;&quot;phone&quot;:&quot;15811111111&quot; ,&quot;identity&quot;:&quot;xxx&quot;, &quot;credit&quot;:&quot;xxx&quot;&#125;&#x27;\n\n\n输出结果：\n{“_index”:”testcase”,”_type”:”case”,”_id”:”1”,”_version”:4,”_shards”:{“total”:2,”successful”:1,”failed”:0},”created”:false}\n读出的方式没有变化：\n1curl -X GET http://localhost:9200/testcase/case/1\n\n输出结果：{“_index”:”testcase”,”_type”:”case”,”_id”:”1”,”_version”:2,”found”:true,”_source”:{“phone”:”15811111111” ,”identity”:”xxx”, “credit”:”xxx”}}\nES的Python操作库：\n123456789101112131415161718192021222324252627282930313233from elasticsearch import Elasticsearch#与ES建立连接es = Elasticsearch(&#x27;127.0.0.1:9200&#x27;)#创建索引es.indices.create(index=&#x27;testcase&#x27;, ignore=400)#向索引中插入一条数据es.index(index=&quot;testcase&quot;, doc_type=&quot;test-type&quot;, id=1, body=&#123;&quot;phone&quot;:&quot;15812345678&quot; ,&quot;identity&quot;:&quot;789&quot;, &quot;credit&quot;:&quot;efg&quot;&#125;)#取得一条数据，按ID号es.get(index=&quot;testcase&quot;, doc_type=&quot;test-type&quot;, id=1)[&#x27;source&#x27;]#刷新数据es.indices.refresh(index=&quot;testcase&quot;)#按条件检索记录res = es.search(index=&#x27;testcase&#x27;)res = es.search( index=&#x27;testcase&#x27;, doctype=&#x27;test-type&#x27;, body=&#123; &#x27;query&#x27;: &#123; &#x27;match&#x27;: &#123; &#x27;credit&#x27;: &#x27;abc&#x27; &#125; &#125;&#125;)#检索所有数据res = es.search(index=&quot;testcase&quot;, body=&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125;) #按条件检索res = es.search( index=&#x27;testcase&#x27;, body=&#123; &#x27;query&#x27;: &#123; &#x27;match&#x27;: &#123; &#x27;phone&#x27;: &#x27;10086&#x27; &#125; &#125;&#125;)#统计记录个数res[&#x27;hits&#x27;][&#x27;total&#x27;]\n\n\n另外，通过PYES库，也可以操作数据。\n123456789101112from pyes.connection import connectfrom pyes import *from pyes.query import *from pyes.es import ResultSetfrom pyes.connection import connectc = connect(servers=[&#x27;127.0.0.1:9200&#x27;])myFilter = TermFilter(&#x27;phone&#x27;, &#x27;123&#x27;)q = FilteredQuery(MatchAllQuery(), myFilter).search()mymodel = lambda x,y:y","slug":"old_topic/2016-09-17-232","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4da29ce129daf83f615c694be3984fda","title":"Lua web framework Lapis(日文版)","content":"Lua web framework Lapis\n前记： \n这篇的原文，原文是一篇很老的文章，一直以来也没有翻译。原文其实是有配置的，下面只是其中的一小段。\n正文： \nLua web framework Lapis\nLuaのWeb Frameworkの需要はほとんどないと思いますが、LapisというFrameworkを見かけたので触ってみました。\nLuaのWeb Frameworkといえば、OrbitやTirがありますが、いずれも開発は止まっていて寂しい限りでした。そこへ最近になって現れたのがLapisです。\nLapisのホームページの頭には、MoonScriptとOpenRestyのWeb Frameworkと書かれています。\nMoonScriptはCoffeeScriptにインスパイアされて作られた言語で、CoffeeScriptがJavaScriptに変換されるように、Luaに変換することができます。\nまた、OpenRestyはNginxに拡張モジュールを入れたもので、コアはNginxそのものです。\nインストール moonscriptとlapisはluarocksでインストールできます。\n12$ sudo luarocks install moonscript $ sudo luarocks install lapis\n\nopenrestyはtarballをダウントードしてmakeします。\n1234$ tar xzvf ngx_openresty-1.2.8.6.tar.gz $ cd ngx_openresty-1.2.8.6 $ ./configure –with-luajit $ make $ sudo make install\n\nLapisプロジェクト\nLapisプロジェクトを作成します。空のディレクトリで以下のコマンドを実行します。生成されるファイルは2つのみです。\n1$ lapis new lapis new -&gt; wrote nginx.conf -&gt; wrote mime.types\n\nサーバーを起動\n","slug":"old_topic/2016-09-17-231","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"cb434518329140d52cda782e9eb061d5","title":"Paloalto的Log数据推送思路与Syslog-NG服务使用与配置","content":"前言： \n\n对于Log数据集中收集管理来说，Syslog服务的重要性不言而喻。比如在平时，Openresty就吐出很多log数据，对这些数据进行集中，可以对积累的数据进行分析，从中找到很多有价值的信息。\n像paloalto这种设备，可以根据定制化的策略规则产生的数据，对应不同机器的不同的syslog服务， 如果性能和负荷都够的话，也可以把一台paloalto设备上的安全策略，对应同一台syslog-ng服务的不同端口。\n把高，中，低，交通数据，吐到192.168.0.1的 810,811,812,813端口上的syslog服务上。 然后，分别对不同级别信报进行分类处理。\n也可以把，指定一个网段的所有交通数据都集中吐到一个端口服务上。然后，通过ELK进行这个网站数据流量的分析，对记录字段进行分词统计。\n正文： \n\n拿阿里VPS来说，如果是Ubuntu系统，安装Syslog-NG很方便，使用apt-get的方式：\n1sudo apt-get install syslog-ng\n\n\n安装之后，可以看一下运行的状态：\n1/etc/init.d/syslog-ng status\n\nsyslog-ng启动，关闭，重启的参数用法也很简明。\n1Usage: /etc/init.d/syslog-ng &#123;start|stop|restart|reload|force-reload|status&#125;\n\nsyslog-ng的新开端口接收数据写入。\n自动安装的syslog-ng的配置文件的位置在/etc/syslog-ng下， 叫syslog-ng.conf， 配置动作需要三步。\n一共需要定义三个部分：Sources, Destinations, Log  paths。\nSources:  是用来定义， syslog服务要绑定的本机IP和对应的Port，还有定义用于网络传送数据使用的协议（TCP/UDP）。\nDestinations: 用于定义Log文件存储的位置，定义log文件名定义的样式，比如，使用年，月，日，时间等组成部分来给log文件命名。\nLog paths： 用于定义Sources和Destinations的关联关系，就是指定那个监听的端口接收的Log数据，存储到本地的那个目录文件下。\n这三部分，在配置文件中对应有注释块,下面就是要追加端口服务的配置定义：\n123456789101112131415161718192021222324######################### Sources#########################我们定义810端口，为syslog对外服务端口。source s_src &#123;       udp(ip(0.0.0.0) port(810));&#125;;######################### Destinations#########################定义log文件存储的位置和log文件名的规则,前缀使用Openresty,后缀依年，月，日变量参于文件名命名。destination d_portscan &#123; file(&quot;/data0/syslog/Openresty_$&#123;YEAR&#125;_$&#123;MONTH&#125;_$&#123;DAY&#125;.log&quot;); &#125;;######################### Log paths#########################将定义的source和destination进行关联。log &#123; source(s_src); destination(d_portscan); &#125;;\n\n\n\n修改配置文件后，我们重新起动一下syslog-ng\n1/etc/init.d/syslog-ng restart\n\n\n后记： \n\n很多服务都提供syslog吐出的功能，我们可以建立一个log数据集中的服务器，定义不同的端口来收集不同服务的数据，数据可能来自Openresty的访问log，也可以来至paloalto的威胁情服，还可以是邮件服务器的用户登陆情报log，通过这些数据的关联性，挖掘我们想要的数据，得出参考结论，可以ELK这种工具，也可用脚本语言实现数据分析。\n","slug":"old_topic/2016-09-17-234","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"2bf41dddbaf54ce129f68a67d1688ceb","title":"如何在Lapis中响应POST,GET方法","content":"by 糖果\nHow do I respond to GET, POST, DELETE or other HTTP verbs? \n如何响应GET,, POST, DELETE等动作。\n\nThe respond_to action decorator function gives a basic framework for running different code depending on the HTTP method. \n\n在同一个路由中响应类似get,post这种用户请求，关键是要使用respond_to这个装饰器。\ntry_to_login is a hypothetical functions, and not regularly globally available \n\ntry_to_login,只是一个假的，用说明可能会调用的驱动函数。\n1234567891011121314151617181920212223local lapis = require(&quot;lapis&quot;)local app = lapis.Application()local respond_to = require(&quot;lapis.application&quot;).respond_toapp:match(&quot;/&quot;, respond_to(&#123;  -- do common setup  before = function(self)    if self.session.current_user then      self:write(&#123; redirect_to = &quot;/&quot; &#125;)    end  end,  -- render the view  GET = function(self)    return &#123; render = true &#125;  end,  -- handle the form submission  POST = function(self)    self.session.current_user =      try_to_login(self.params.username, self.params.password)    return &#123; redirect_to = &quot;/&quot; &#125;  end&#125;))\n\n在一个函数里声明了三个闭包函数，before、GET、POST，其中的GET,POST函数就是用来响应不同的类型请求。\n","slug":"old_topic/2016-09-17-230","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"1e50e730134daba789397d1d6a4f834b","title":"LVS负载均衡下的Openresty间的主从Redis同步","content":"LVS负载均衡下的Openresty间的主从redis同步\n正文： \n像一般在多台提供相同服务的Openresty服务前端会挂F5或是Ha,做为负载均衡，因为逻辑关系有时会用共享使用一份Redis，如果这时，使用Redis的主从模式，就可以很好共享一份Redis服务的数据，但从时间上讲，还是存在数据同步的延时的问题。\n\n简单说一下Redis的主从设置：\n在redis安装的目录，或是etc下会找到redis的配置文件， redis.conf。只要在配置文件追加两句话，就可以配置主从模式。\n12slaveof 192.168.0.0.1 6379masterauth password\n\nslaveof ：子句后指定主服务器的地址和端口号。masterauth ： 后跟主服务器的登陆密码。\n设置后重起一下Redis：\n1redis-server /etc/redis.conf\n\n分别登陆一下两台机器，简单的可以看一下数据是否同步。\n12redis-cli&gt;keys *\n\n\n后记： \n\n在某种情况下，同一上HA后的两个Openresty服务，很可能不在一个大楼的网络里，这种互备的情况，当一台服务器出现问题时，另一台可以作备机，因为平时网络和其它原因，redis主从同步也是有延迟的，这样可以把服务都只向一台Redis机器，另外一台只做数据备份,需要时和实际业务进行挂载。\n","slug":"old_topic/2016-09-17-238","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a808962806fc68aa9d5c82e6e01d4f97","title":"Openresty使用Log_by_lua推送数据到Syslog服务器","content":"LOG_BY_LUA推送数据到Syslog服务器\n正文： \n\nOpenresy的resty_logger组件，提供了一种可能，就是在Openresty的Log阶段，推送数据到syslog-ng服务器上，Openresty的执行阶段，其实是一种虚拟化的逻辑业务划分，如果从TCP数据包的角度来看，是分不出什么init, content，log等阶段，而log阶段应该是所有的Openresty执行阶段的最后一个阶段，关于执行阶段的顺序，可以参照下面的这个图：\n \n\n\n对于resty-logger的执行处理，如果要划分几大处理的话，可以分成， syslog服务器信息定义，初始化连接，写入log数据。可以在代码中，比较清晰的看出来，官方的例子如下，一些参数进行了调整：\n1234567891011121314151617181920212223242526log_by_lua &#x27;           local logger = require &quot;resty.logger.socket&quot;           ngx.log(ngx.ERR, &quot;Test Syslog: &quot;, &quot;call&quot;)           if not logger.initted() then               local ok, err = logger.init &#123;                   host=&quot;127.0.0.1&quot;,                   port=810,                   sock_type=&quot;udp&quot;,                   flush_limit = 1,                   --drop_limit = 5678               &#125;               if not ok then                   ngx.log(ngx.ERR, &quot;failed to initialize the logger: &quot;, err)                   return               end           end           -- construct the custom access log message in           -- the Lua variable &quot;msg&quot;           local bytes, err = logger.log(&quot;test&quot;)           if err then               ngx.log(ngx.ERR, &quot;failed to log message: &quot;, err)               return           end       &#x27;;\n\n上面的代码，需要注意的是 flush_limit  这个参数，在实际的联动Openresty和Syslog-ng服务的过程中，可能更希望看到实时写入效果，比如说， 用tail -f 监控syslog-ng端的日志服务，然后在浏览器中，请求Openresty的WEB服务，访问一次,syslog文件就写入一条，如果是这样话，需要把flush_limit，设置等于1，不然会，等待log数据积攒到一定的数据（我们自己指定，&gt;1）才向syslog服务器的服务端口推送一次。\n此阶段有那些数据可输出？ \n\n做一个小实验，以下的API，都可以在这个阶段调用。\n12345678910111213-- construct the custom access log message in-- the Lua variable &quot;msg&quot;local url = ngx.var.urilocal method = ngx.req.get_method()local headers = ngx.req.raw_header(true)-- tbllocal params_var = ngx.req.get_uri_args()local client_ip = ngx.var.remote_addr-- tbllocal body_var = ngx.req.get_post_args()local user_agent = ngx.req.get_headers()[&quot;User-Agent&quot;]local referer = ngx.req.get_headers()[&quot;Referer&quot;]local cookies = ngx.req.get_headers()[&quot;Cookie&quot;]\n\n这样就可以把这些数据，通过“分隔符”推送到syslog-ng服务器上，然后用logstash安照正则，分词解开，将对应的字段，以JSON形式存到ES里。\n1local bytes, err = logger.log(client_ip..&quot; &quot;..table.concat(params_var)..&quot; &quot;..table.concat(body_var)..&quot; &quot;..user_agent..&quot; &quot;..referer..&quot; &quot;..cookies..&quot; &quot;..url..&quot; &quot;..method)\n\n后记： \n上面的table.concat的数据其实连在一起时，会对解析产生困扰，最好不用，此处只是为了简单的实验用。\n最后，没有给出完整的代码，直接把logger.log手动的替换一下，就可以完成这个实验，剩下就是自定义和整合问题。\n如果是用Logstash向ES导入数据，也可不使用这种方式，直接使用远程代理的方式向远端口的ES导入数据。而使用这种，会涉及到修改Openresty的Conf中的代理代码，好处是可以更细致的定制log输出的格式。\n","slug":"old_topic/2016-09-17-237","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"20597ab06842fbc260e3af6d26f03675","title":"用Lapis工程创建Openresty正向代理服务","content":"作者：糖果\n正文： \n利用Openresty服务创建一个正向代理服务器，最开始是想在Lapis创建的工程下直接创建，基本的配置如下面的代吗：\n创建一个Lapis工程：\n1lapis new\n\n然后在配置文件里加入，正向代理的配置。\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546worker_processes $&#123;&#123;NUM_WORKERS&#125;&#125;;error_log stderr notice;daemon off;pid logs/nginx.pid;events &#123;  worker_connections 1024;&#125;http &#123;  include mime.types;  default_type  application/octet-stream;  log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;  access_log  logs/access.log  main;  server &#123;    resolver 114.114.114.114;    resolver_timeout 15s;    listen $&#123;&#123;PORT&#125;&#125;;    lua_code_cache $&#123;&#123;CODE_CACHE&#125;&#125;;    location / &#123;        default_type text/html;        proxy_pass $scheme://$host$request_uri;        #proxy_pass http://$host$request_uri;        proxy_set_header Host $http_host;        proxy_buffers 256 8k;        proxy_max_temp_file_size 0;        proxy_connect_timeout 30;        proxy_cache_valid 200 302 10m;        proxy_cache_valid 301 1h;        proxy_cache_valid any 1m;      content_by_lua &#x27;        --require(&quot;lapis&quot;).serve(&quot;app&quot;)      &#x27;;    &#125;  &#125;\n\n启动Lapis代理，配置FF的代理选项。打开浏览器后发现，可以载入网站的图标，但是正文无法显示出来，返回结果被Lapis拦截了。\n然后，我向群里的朋友 ，求了一份，nginx的正向代理的配置，然后用纯nginx的方式，启动正向代理，代码如下：\n1234567891011121314151617181920212223242526272829303132333435363738worker_processes 1;error_log stderr notice;daemon off;pid logs/nginx.pid;events &#123;  worker_connections 1024;&#125;http &#123;  include mime.types;  default_type  application/octet-stream;  log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;                      &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;                      &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;  access_log  logs/access.log  main;  server &#123;    resolver 114.114.114.114;    resolver_timeout 15s;    listen 0.0.0.0:8080;    location / &#123;        default_type text/html;        proxy_pass $scheme://$host$request_uri;        #proxy_pass http://$host$request_uri;        proxy_set_header Host $http_host;        proxy_buffers 256 8k;        proxy_max_temp_file_size 0;        proxy_connect_timeout 30;        proxy_cache_valid 200 302 10m;        proxy_cache_valid 301 1h;        proxy_cache_valid any 1m;    &#125;  &#125;&#125;\n\n\n然后用传统的方式运行nginx\n1nginx -p `pwd` conf/nginx.conf\n\n\n重新刷新浏览器，OK，结果出现。\n后记： \n其实，浏览器无返回结果的根原因，不是因为用了lapis起动工程，而是在lapis创建的nginx.conf中，定义了content_by_lua，却没有做任何的返回处理，造成的返回了空白网页。\n如果还想用lapis server的方式启动正向代理，就把下面的代码注释掉。\n123#content_by_lua &#x27;#  --require(&quot;lapis&quot;).serve(&quot;app&quot;)#&#x27;;","slug":"old_topic/2016-09-17-239","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"53a0bde2072be76e8f3cf834995df5a3","title":"在VIM中把tab定义成四个空格","content":"编辑.vimrc文件，加入下面两行。\n12set shiftwidth=4set softtabstop=4\n\n再次打开vim后， tab就定义成了四个空格。\n","slug":"old_topic/2016-09-17-240","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e1c15d24208ab78866f391c375d36922","title":"Linux开发者全家福","content":"","slug":"old_topic/2016-09-17-24","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"b59c6092a311db06ed0d5532848d26fa","title":"VIM创建新行与跳到下一个字符","content":"在当前行所在行的任意列的位置”o”可以在下一行创建新的一行，并且光标跳到了下一行。\n“a”快捷键是跳到一下这符，如果已经是取后一个字符，光标也会跳到最后一个字符的一个光标位置。\n","slug":"old_topic/2016-09-17-241","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"81ed100fdd2c30055bc0890be02c4788","title":"SCSS的PHP编译程序SCSSPHP","content":"作者：糖果\nSCSS是用于生成CSS的，leafo老哥，实现了一个php版本的项目叫：SCSSPHP\n这个项目在他的leafo.net的项目中有使用，配合sitegen使用，生成静态网站。下面是直接引用了他的项目的 Readme\nhttp://leafo.github.io/scssphp\nBuild License\nscssphp is a compiler for SCSS written in PHP.\nCheckout the homepage, http://leafo.github.io/scssphp, for directions on how to use.\nRunning Tests\nscssphp uses PHPUnit for testing.\nRun the following command from the root directory to run every test:\n1vendor/bin/phpunit tests\n\nThere are several tests in the tests/ directory:\nApiTest.php contains various unit tests that test the PHP interface.\nExceptionTest.php contains unit tests that test for exceptions thrown by the parser and compiler.\nFailingTest.php contains tests reported in Github issues that demonstrate compatibility bugs.\nInputTest.php compiles every .scss file in the tests/inputs directory then compares to the respective .css file in the tests/outputs directory.\nScssTest.php extracts (ruby) scss tests from the tests/scss_test.rb file.\nServerTest.php contains functional tests for the Server class.\nWhen changing any of the tests in tests/inputs, the tests will most likely fail because the output has changed. Once you verify that the output is correct you can run the following command to rebuild all the tests:\n1BUILD=1 vendor/bin/phpunit tests\n\nThis will compile all the tests, and save results into tests/outputs.\nTo enable the scss compatibility tests:\n1TEST_SCSS_COMPAT=1 vendor/bin/phpunit tests\n\nCoding Standard\nscssphp source conforms to PSR2.\nRun the following command from the root directory to check the code for “sniffs”.\n1vendor/bin/phpcs --standard=PSR2 bin src tests\n\nscssphp的使用方法其实很简单，pscss 源文件。\n","slug":"old_topic/2016-09-17-242","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"87ad0835fe7e01f9e6199a2d7f96fa18","title":"SAE上用Git部署Laravel5","content":"作者：糖果\n有好心人做了Laravel在SAE的移植工作。我 fork了一下， 本向导入到coding.net里，因为原作者的主分支在github，所有就在github上fork一个分支。\nLaravel on SAE \nSAE很久以前也开起了git部署功能，所以现在在SAE部署一个github上的php项目相对就很方便。\n1.在SAE控制台创建一个php的空项目。\n2.克隆Laravel on sae的代码。\n1git clone https://github.com/shengnoah/laravel5-on-sae.git\n\n3.Push代码到SAE上。\n在你应用的git代码目录里，添加一个新的git远程仓库 sae\n1$ git remote add sae https://git.sinacloud.com/moonscript\n\n编辑代码并将代码部署到 sae 的版本1。\n123$ git add .$ git commit -am &quot;Laravel on SAE&quot;$ git push sae master:1\n\n注意这里的原本的origin变成了sae, master后面的:1，对应之前SVN的10个版本号。\n其实，Coding.net现在已经开如支持svn了，可以把代码部署到coding.net上，然后在让SAE的应用去Checkout coding.net上的代码通过svn或是github的方式，用php的github第三方中间件的方式，是比较好的选择， 这样可以直接在coding.net的web ide,或是WEB页面直接操作SAE的源码资源。\n4.进入浏览器check效果。http://moonscript.applinzi.com/\n","slug":"old_topic/2016-09-17-243","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"35ed74a52ffa4508c72ebfa9a93f778d","title":"一条AWK命令统计出Ningx访问LOG中的状态数据","content":"作者：糖果\n下面是脚本代码：\n1cat access_log.log | awk &#x27;&#123;print $7&#125;&#x27; | sort | uniq -c","slug":"old_topic/2016-09-17-248","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"2f003d0017b1d37a480d2ac6c15521d5","title":"Dynamic scoping in Lua","content":"作者：leafo\n原文连接： \n准备翻译这篇文章。\nWhat is dyanmic scopingAn exampleImplementing dynamic scopingWhen to use dynamic scoping\nWhat is dyanmic scoping\nDynamic scoping is a programming language paradigm that you don’t typically see. The scoping that most programmers are used to is called lexical scoping. It’s found in Lua and many other languages. Lexical scoping is the dominant choice for a reason: it’s easy to reason about and understand just by looking at the code. We can see what variables are in scope just by looking at the structure of the text in our editor. Scoping controls how a variable’s value is resolved.\nDynamic scoping does not care how the code is written, but instead how it executes. Each time a new function is executed, a new scope is pushed onto the stack. This scope is typically stored with the function’s call stack. When a variable is referenced in the function, the scope in each call stack is checked to see if it provides the value.\nAn example\nUsing the syntax dynamic(var) to represent a dynamic scope variable lookup:\n1234567891011121314151617local function make_printer()  local a = 100  return function()    print(&quot;Lexical scoping:&quot;, a)    print(&quot;Dynamic scoping:&quot;, dynamic(a))  endendlocal function run_func(fn)  local a = 200  fn()endlocal print_a = make_printer()run_func(print_a)\n\n– prints:– Lexical scoping: 100– Dynamic scoping: 200In this example we’re priting a variable named a with each of the scoping styles. With lexical scoping it’s very easy to see that we’ve created a closure on the variable a. That variable is bound to the scope of print_a because the way the code blocks have been written nest the scopes.\nWith dynamic scoping things are a bit different. Each entry in the callstack represents a different scope to check for the variable a. Because there is no a defined in the function referencing it, we traverse up the call stack to find a declared variable. It’s found in the body of run_func, where the value is 200.\nThe usefulness of this scoping may not be immediately clear. It may seem very error prone because the value of the variable we’re requesting can come from any caller’s stack, even code that we haven’t event written.\nThe power of dynamic scoping is that we can inspect the calling context to control the behavior of our functions.\nImplementing dynamic scoping\nWe can implement dynamic scoping fairly easily in Lua through the debug library. We’ll mimic the example above with a function called dynamic that takes the name of a variable, as a string, to look up dynamically.\nIn Implementing setfenv in Lua 5.2, 5.3, and above we discovered how we could use debug.getupvalue to implement setfenv. For dynamic scoping we’ll rely on the debug.getlocal function.\nThe signature of getlocal is debug.getlocal ([thread,] level, local). In this example we’re not concerned with the thread so we’ll focus on level and local.\nlevel is an integer that represents how many levels up the call stack we want to look for the variable we’re searching for.local is the index of that local variable we want to resolve, starting at 1.The return value of this function is either nil if nothing was found, or the name and value of the variable.\nTo find a local variable in an higher up scope, we just need to keep incrementing level and querying each local variable by its numeric index until we find the matching name. Here’s the implementation:\n1234567891011121314151617function dynamic(name)  local level = 2  -- iterate over   while true do    local i = 1    -- iterate over each local by index    while true do      local found_name, found_val = debug.getlocal(level, i)      if not found_name then break end      if found_name == name then        return found_val      end      i = i + 1    end    level = level + 1  endend\n\n\nNow we can rewrite the example from the top of the post to use this function:\n123456789101112131415161718local function make_printer()  local a = 100  return function()    print(&quot;Lexical scoping:&quot;, a)    -- notice we pass in &quot;a&quot; here    print(&quot;Dynamic scoping:&quot;, dynamic(&quot;a&quot;))  endendlocal function run_func(fn)  local a = 200  fn()endlocal print_a = make_printer()run_func(print_a)\n\nWhen to use dynamic scoping\nIn the general case, it’s probably best to avoid dynamic scoping since it makes code harder to understand at a glance. In any case, there are some situations where dynamic scoping is useful.\nDSLs, where terseness is important, can benefit from dynamic scoping by using the implicit context of function calls to make arguments available that haven’t been explicitly passed. A basic example would be removing the need to pass self as an argument if it can be fetched from the containing scope.\n","slug":"old_topic/2016-09-17-244","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"5385226c4dd69806de6132d1a0edacdd","title":"在Coding.net上使用SVN部署代码","content":"在Coding.net上使用SVN部署代码\ncoding.net上新建的工程是支持svn部署的。\n我们需要在coding上新建一个普通git工程然后开起svn功能。\n例如我新建了一个工程叫svntest， 是一个公开的地址：\n1https://coding.net/u/shengyang/p/svntest/git\n\n然后，开起svn功能后，访问的svn地址是：\n1svn+ssh://svn@svn.coding.net/shengyang/svntest\n官方的说明如下：\n\n\n\n\n\n\n\n\n\n注意：git 仓库的分支和标签按照如下规则映射到 svn 路径：\n\nmaster -&gt; /trunk，即：svn checkout &lt;仓库地址&gt;/trunk 可以检出 master 分支\n分支 -&gt; /branches/分支，例如：svn checkout &lt;仓库地址&gt;/branches/test 可以检出 test 分支\n标签 -&gt; /tags/标签，例如：svn checkout &lt;仓库地址&gt;/tags/v1.0 可以检出 v1.0 标签\n暂不支持分支标签的创建删除和合并，git submodule 检出为空目录 \n\n这里已经明确说了，master对应就是trunk。\n所以，checkout的地址是:\n1svn co svn+ssh://svn@svn.coding.net/shengyang/svntest/trunk\n\n然后建立一个README文件。\n123echo README &gt; READMEgit add  READMEsvn ci -m&quot;测试coding.svn功能&quot;\n\n提示用户名密码，文件就上传了。\nhttps://coding.net/u/shengyang/p/svntest/git/blob/master/README\n","slug":"old_topic/2016-09-17-245","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"b3a6fb6eb4424ca7a4f65fdb6f39a8d3","title":"用Django构建REST网页服务","content":"作者:糖果\nDjango的高版本自身提供了很好REST服务组件和方便的库,Djano REST Framework提供了一个现成的方案，可以将对外的REST服务，与类似Mysql的数据存储建立有机关联，直接与ORM一起使用就更便利。\nJSONRenderer和JSONParser提供了方便的JSON解析和响应服务。不过用这些库意味着要按装的新包，对版本和环境可能也有要求，所以，要想在更低的Django版本下支持JSON数据接收和响应，就不要使用这些高级的库，而是直接使用老的API。\n如果用Lua来解析和响应JSON，也是同样方便的，关于这些json数据的存储也有很多的选择， mysql,ES,mongo都可以，甚至在SAE上，用kvdb也没有问题。\n下面是Django 1.5.x支持的实现。\n123456789101112@csrf_exemptdef testcase(request):    try:        if request.method == &#x27;POST&#x27;:            receive_data = json.loads(request.body)            phone = receive_data[&#x27;phone&#x27;]            return HttpResponse(json.dumps(receive_data), content_type=&quot;application/json&quot;)    except:         import sys         info = &quot;%s || %s&quot; % (sys.exc_info()[0], sys.exc_info()[1])        return HttpResponse(&quot;Parse JSON data error!&quot;)    return HttpResponse(&quot;Building  JSON REST Web Service!&quot;)\n\n\n因为django使用的了中间件django.middleware.csrf.CsrfViewMiddleware，对要测试的函数需要加上@csrf_exempt装饰器，不然会报警。\n需要引用下面的包：\n1from django.views.decorators.csrf import csrf_exempt\n\n\n\n对于”testcase“这个方法说，主要用做的处理就两件事，一是接收用户传过的JSON数据，另一个处理，就是直接再把这个数据，依JSON数据形式传回给用户，中途并没有对JSON做过任何的操作。\n12import jsonreceive_data = json.loads(request.body)\n\n如果是POST类型的请求，JSON数据，主要取得的API是request.body,在1.5.x较高的版本中，用的是这个，也可以用另外一个等价的API是raw_post_data，这是一个旧的接口，虽然可以执行，但会给出警告信息。\n净raw数据解析成json，主要靠的函数是json.loads(request.body).\n12receive_data = json.loads(request.body)phone = receive_data[&#x27;phone&#x27;]\n\n\n接口返回json数据时要指明一下mime类型。\n1return HttpResponse(json.dumps(receive_data), content_type=&quot;application/json&quot;)\n\n\n 就是这个比较简单的就可以实现json数据的接收和返回。\n可以简单的用curl测试一下，这个接口：\n1curl -b &quot;key=value&quot; http://127.0.0.1/json/ -d&#x27;&#123;&quot;phone&quot;:&quot;15811111111&quot; ,&quot;identity&quot;:&quot;xxx&quot;, &quot;credit&quot;:&quot;xxx&quot;&#125;&#x27;\n\n这接口的圈复杂度其实不高，主要要测试的就三个分支，基本都有Message输出。\n源码地址:\n","slug":"old_topic/2016-09-17-247","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f47eb985f6ae8a0bdc7e70fa6ba8170e","title":"Octopress评论方本框的样式问题","content":"作者：糖果\n前几天改octopress的样式，发现评论框的样式没了，变成了普通的表单。然后，想用vimdiff在vps上比较一下，发现新版的css就行一行，没有经过格式化，再小伙伴们的支持下，用chrome把css格式化了，然后在老版的css找到了评论文本框的样式，添加到新的css文件中。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#respond input, #respond textarea &#123;    background-color: #fff;    border: 5px solid rgba(128, 128, 160, 0.15);    padding: 10px;    font-family: &quot;PT Serif&quot;, &quot;Georgia&quot;, &quot;Helvetica Neue&quot;, Arial, sans-serif;    color: #4b4b4b;    font-size: 24px;    -webkit-border-radius: 5px;    margin-bottom: 15px;    margin-top: -10px;&#125;#respond input:focus, #respond textarea:focus &#123;    border: 5px solid #efefef;    background-color: rgba(255, 255, 255, 1);&#125;#respond .submit &#123;    border: none;    cursor: pointer;    color: #666;    font-size: 24px;    background-color: #7ac000;    padding: 5px 36px 8px 36px;    -webkit-border-radius: 10px;    -moz-border-radius: 10px;    -webkit-box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.4);    -moz-box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.6);    border-bottom: 1px solid rgba(0, 0, 0, 0.4);    border-top: 1px solid rgba(255, 255, 255, 0.6);    background: -webkit-gradient(    linear,    left bottom,    left top,    color-stop(0.23, #999),    color-stop(0.62, #ccc)    );    background: -moz-linear-gradient(    center bottom,    #999 23%,    #ccc 62%    );&#125;#respond .submit:hover &#123;    color: #fff;    border-bottom: 1px solid rgba(0, 0, 0, 0.4);    background-color: #666;    background: -webkit-gradient(    linear,    left bottom,    left top,    color-stop(0.23, #666),    color-stop(0.62, #999)    );    background: -moz-linear-gradient(    center bottom,    #666 23%,    #999 62%    );&#125;#respond .submit:active &#123;    position: relative;    top: 1px;&#125;\n\n\n后记：这个博客主题的样式网格使用的是Octopress,外管部分，内容部分使用的是Markdown样式的。\n","slug":"old_topic/2016-09-17-252","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f9f6eed6d27827bc96782faa045f082a","title":"C模拟多态","content":"【问题】多态的虚函数调用，含虚函数对象大小计算，字节对齐，函数覆盖，构造与析函数的执行顺序,This指针。\n【简介】首先，需要介绍一下用C语言实现C++的单根继承，然后分析一下构造函数和析构函数的执行顺序。看看C++都在背后做了什么，这也是C++的基本内容，不涉及哲学和C++软件的复用性讨论，立足于，C++是对C的扩展，Class是对结构体的扩展，用struct和变量的讨论，代替class和属性。\n【概念】\n1.继承：子类继承父类，就是被叫做子类的结构体内，含有称为父类类型的结构体变量。例：drived结构体内含有base结构类型的变量。\n2.多态：在具有包含关系的结构体间的强类型转换，通过修改结构体内，指向虚表的，指针变量的内容，使其指向不同的虚表（虚表：指针函数结构体），来实现虚函数调用的功能。\n【代码】[code]#include&lt;stdlib.h&gt;#include&lt;stdio.h&gt;\ntypedef void(*F_BASE_A)(void *obj);typedef void(*F_BASE_B)(void *obj);typedef void(*F_DRIVED_B)(void *obj);\nvoid f_base_a(void *obj) {        printf(“base class function a is called!\\n”);}\nvoid f_base_b(void *obj) {        printf(“base class function b is called!\\n”);}\nvoid f_drived_b(void *obj) {        printf(“drived class function b is called!\\n”);}\ntypedef struct base_vt {        unsigned int    rtti;        F_BASE_A        base_a;        F_BASE_B        base_b;}base_vt;\ntypedef struct drived_vt {        unsigned int    rtti;        F_DRIVED_B      drived_b;}drived_vt;\ntypedef struct Base {        void *vtr;        int b_data;}Base;\ntypedef struct Drived {        Base b;        int s_data;}Drived;\nbase_vt g_base_vt;drived_vt g_drived_vt;\nvoid complier_init() {        g_base_vt.rtti = 6;        g_base_vt.base_a = f_base_a;        g_base_vt.base_b = f_base_b;\n    g_drived_vt.rtti = 8;\n    g_drived_vt.drived_b = f_drived_b;\n\n}void t_base_call() {        printf(“### test base begin ###.\\n”);        Base b;        b.vtr = &amp;g_base_vt;\n    //call stlye 1\n    F_BASE_A function =  (F_BASE_A)(g_base_vt.base_a);\n    function(&amp;b);\n\n    function = (F_BASE_B)(g_base_vt.base_b);\n    function(&amp;b);\n\n    //call style 2\n    F_BASE_A fun_a = (F_BASE_A)(( (base_vt*)b.vtr )-&gt;base_a);\n    fun_a(&amp;b);\n\n    F_BASE_B fun_b = (F_BASE_B)(( (base_vt*)b.vtr )-&gt;base_b);\n    fun_b(&amp;b);\n\n    //call style 3\n    unsigned int *ptr = (unsigned int*)(&amp;b);\n    printf(&quot;%d\\n&quot;, *ptr);\n\n    ptr = (unsigned int*)(*ptr);\n    printf(&quot;%d\\n&quot;, *ptr);\n\n    F_BASE_A fun = (F_BASE_A)(*(ptr+1));\n    fun(&amp;b);\n\n    fun = (F_BASE_B)(*(ptr+2));\n    fun(&amp;b);\n    printf(&quot;### test base end ###.\\n&quot;);\n\n}\nvoid t_drived_call() {        printf(“### test drived begin. ###\\n”);        Drived d;        d.b.vtr = &amp;g_drived_vt;\n    unsigned int *ptr = (unsigned int*)(&amp;d);\n    ptr = (unsigned int*)(*ptr);\n    F_BASE_A function = (F_BASE_A)(*(ptr+1));\n    function(&amp;d);\n\n    function=(F_DRIVED_B)(*(ptr+2));\n    function(&amp;d);\n    printf(&quot;### test drived end. ###\\n&quot;);\n\n}\nvoid t_poly(){        printf(“### test poly begin. ###\\n”);\n    Drived d;\n    d.b.vtr = &amp;g_drived_vt;\n\n    Base* base = (Base*)&amp;d;\n    unsigned int *ptr = (unsigned int*)(base);\n    ptr = (unsigned int*)(*ptr);\n    F_BASE_A function = (F_BASE_A)(*(ptr+1));\n\n    function(base);\n\n    function = (F_DRIVED_B)(*(ptr+2));\n    function(base);\n    printf(&quot;### test poly end. ###\\n&quot;);\n\n}\nint main(int argc, char** argv){\n    complier_init();\n    t_base_call();\n    return 0;\n\n}\n[/code]\n【多态】如果说class是struct的加强版本的话，class相比struct有了虚表的管理和对成员变量权限管理(public, protected, private).对于stuct来说，struct没有成员变量的权限管理，默认所有的struct成员变量都默认为是public属性，可以被其他函数访问。这篇主要是描述，C如何模拟C++对class虚表的模拟。\n模拟虚表管理采用的方式是，用两个struct模拟class,一个struct用于存储class的数据,一个struct用于存储class中接口函数的函数指针（函数指针集合。）【模拟类的定义】[code]//附属结构体（虚表）:用于存储，指向函数（接口）的函数指针。typedef struct base_vt {        unsigned int    rtti;// 是一个存储继承信息的变量。        F_BASE_A        base_a;//函数指针        F_BASE_B        base_b;//函数指针}base_vt;\n//主结构体（数据）：用于存储数据。typedef struct Base {        void *vtr; //1.vtr指针用于指向base_vt结构体。2.vtr一定要是struct的第一个成员变量，这是之后实现多态的关键。        int b_data;}Base;[/code]\n并且这两个struct之间通过一个”void* vtr“的空类型指针进行联系。vtr是主stuct的一个指针类型的成员变量，用于指向附属类所在的内存空间。\n在定义函数指针的时候，使用了自定义的宏。[code]typedef void(*F_BASE_A)(void *obj);typedef void(*F_BASE_B)(void *obj);typedef void(*F_DRIVED_B)(void *obj);[/code]\n【this指针】在C++中，非静态的成员函数的形参列表中，有一个被隐藏的参数,就是”this“[code]class Sample {public:     void foo(int i);}[/code]\n实际上foo的参数列表会被编译器翻译成，foo(Sample* this, int i);这也是为什么，在成员函数中，可以访问Sample类的数据。 \n[code]class Sample {public:     void foo(Sample* this, int i);}[/code]而我们在使用函数指针宏的时候，typedef void(*F_BASE_A)(void *obj)，指定了void *obj，相当于this指针，让用宏定义的这些成员函数，都可以访问主结构体的成员数据。\n[code]typedef void(*F_BASE_A)(void *this) //obj和this作用类似[/code]【static方法】C++类，有一种叫做static的成员函数，类的static函数，可以在类不被实例化前，允许调用，但是类的static方法不能访问类的成员变量，类没有对象实例化，在内存中就类成员的空间，也无从访问其数据。但是，如果类成员变量也是static类型的话，static函数就可以，因为static变量被分别在常量存储区。\n[code]typedef void(*F_BASE_A)(void *obj);[/code]如果把上面的函数定义的参数”void *obj“删除，那么用F_BASE_A定义的函数，就类似于static方法，因为没有obj指针，对于函数来说，是不能访问主struct的数据的。\n[code]typedef void(*F_BASE_A)();[/code]\n【字节对齐】\n【对象的size】\n【选读】市面上往往出现过很多的大部头书，大部头书更多的时候被当做工具书进行查阅，但是如果书的组织形式不好，就很难高效的找到自己主要想看的内容，更多的视野被重复的内容的占据，做重复的阅读工作。\n参考文档：http://blog.chinaunix.net/uid-20940095-id-66146.htmlhttp://club.topsage.com/thread-2263309-1-1.html\n","slug":"old_topic/2016-09-17-25","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"d97242e82975d5be79f8c9c982dae804","title":"Octopress的Figcaption的CSS样式差异","content":"作者、编辑：糖果\n新版的Octopress与旧版的的Figcaption的CSS样式差异，以下的CSS是被格式化之后的：\n旧版的\n12345678910111213141516171819202122232425262728293031.code-title,html .gist .gist-file .gist-meta a[href*=&#x27;#file&#x27;],h3.filename,figure[role=code] figcaption &#123;    text-align: center;    font-size: 13px;    line-height: 2em;    text-shadow: #cbcccc 0 1px 0;    color: #474747;    font-weight: normal;    margin-bottom: 0;    -moz-border-radius-topleft: 5px;    -webkit-border-top-left-radius: 5px;    -o-border-top-left-radius: 5px;    -ms-border-top-left-radius: 5px;    -khtml-border-top-left-radius: 5px;    border-top-left-radius: 5px;    -moz-border-radius-topright: 5px;    -webkit-border-top-right-radius: 5px;    -o-border-top-right-radius: 5px;    -ms-border-top-right-radius: 5px;    -khtml-border-top-right-radius: 5px;    border-top-right-radius: 5px;    font-family: &quot;Helvetica Neue&quot;, Arial, &quot;Lucida Grande&quot;, &quot;Lucida Sans Unicode&quot;, Lucida, sans-serif;    background: #aaa url(&#x27;../images/code_bg.png&#x27;) top repeat-x;&lt;del&gt;&lt;/del&gt;     border: 1px solid #565656;    border-top-color: #cbcbcb;    border-left-color: #a5a5a5;    border-right-color: #a5a5a5;    border-bottom: 0&#125;\n\n新版的\n12345678910111213141516171819202122.code-title,html .gist .gist-file .gist-meta a[href*=&#x27;#file&#x27;],h3.filename,figure.code figcaption &#123;    text-align: center;    font-size: 13px;    line-height: 2em;    text-shadow: #cbcccc 0 1px 0;    color: #474747;    font-weight: normal;    margin-bottom: 0;    -moz-border-radius-topleft: 5px;    -webkit-border-top-left-radius: 5px;    border-top-left-radius: 5px;    -moz-border-radius-topright: 5px;    -webkit-border-top-right-radius: 5px;    border-top-right-radius: 5px;    font-family: &quot;Helvetica Neue&quot;, Arial, &quot;Lucida Grande&quot;, &quot;Lucida Sans Unicode&quot;, Lucida, sans-serif;    background: #aaa url(&#x27;images/code_bg.png&#x27;) top repeat-x;    border: 1px solid #565656;    border-top-color: #cbcbcb;    border-left-color: #a5a5a5;    border-right-color: #a5a5a5;    border-bottom: 0&#125;\n\n@mind-or的解答时：\n旧的：表示figure 这个标签 下面属性 role=’code’ 节点下面的 pre标签\n123&lt;figure role=&#x27;code&#x27;&gt;  &lt;pre&gt;&lt;/pre&gt;&lt;/figure&gt;\n新的：\n表示figure 这个标签 下面属性class=“code”节点下面的 pre标签\n123&lt;figure class=&#x27;code&#x27;&gt;  &lt;pre&gt;&lt;/pre&gt;&lt;/figure&gt;\n\n\n\n\n\n\n\n\n\n\n就是一个 根据 属性值  来选择。一个根据class 来选择\n123选择器                例子                例子描述                                   CSS.class                .intro              选择 class=&quot;intro&quot; 的所有元素。\t     1[attribute|=value]    [lang|=en]          选择 lang 属性值以 &quot;en&quot; 开头的所有元素。   2\n\n参考：CSS选择器\nPS：请用于非商业用途。\n","slug":"old_topic/2016-09-17-254","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"63f91faf649dc18cb1abcbe76e9b1360","title":"程序员如何选择机械键盘","content":"作者： 糖果\n“一，最好不要机械键盘，我没有听噪声的癖好，但如果有声音不是很大的，求推荐。二，键程不用很大，有反馈的感觉就好，像笔记本键盘一样。三，按键稳定，你不能手指放上面晃一晃按键就跟着你跑(夸张说法。。)四，能素一点就素一点，这个是次要的，比如某些游戏键盘那样，灯光四射，我hold 不住。。。五，这个不是需求。。纯感谢～感谢推荐～”\n看了题主的需求后，觉得最优先应该考虑的问题是：“长时间敲击键盘，保持手不累与手腕不痛。”\n首先这个累不累的问题是与键盘的敲击量相关的。如果每天按键敲击量不大，无论什么键盘，只要质量不是太差，都可应付。如果键盘敲击点大的话，在一天的范围内，键盘的使用量也是有限的，可以通过软件跟踪，个人每天的击键数在26000-40000下这个范围左右，这是普通一天的敲击量，如果用普通键盘，基本一天下来会感觉到手累和手腕痛。\n在这个量化条件下(26000-40000敲击量左右)，需要选购一个键盘来，来缓解在一天范围内，因键盘敲击对手的伤害的问题。\n1.第一个要解决的问题：手腕痛的问题。 \n有很多人说用人体工学的键盘可以解决这个问题。\n那什么是人体工学键盘，像微软那种流线型设计的是人体工程学键盘，像cherry那种机械键盘，只有键帽设计考虑到人体工学的，也算人体工学键盘。\n微软的人体工学键盘\n微软的人体工学键盘用过的体验是，的确可以解决手腕子痛的问题，那种垫高的仿皮手托的确很舒服，一天下来缓解了不少，输入量适中的话（注意不是大量），一天用下来手没问题，但后来还是放弃了使用这种键盘，原因有几点：\n\n这种键盘一般采用的是ABS键帽，时间长了就会被打油，看着不舒服，用着也不舒服，不定期护理就比较粘手，键帽上的字很容易被磨掉。\n\n这种键盘大多也是薄膜键盘，有人说带些机械键盘的手感， 用过，没感觉有什么机械键盘的手感，没有机械键盘那种明显的反馈力。\n\n键盘适合手比较大的人用，欧美用户的手明显比亚洲人的手大一些，亚洲大手的人使用可能更合适，这可能是一个个别问题，但也是个问题。\n\n如果你有不只一台电脑，也就不是一台键盘，除非你全用人体工学的，不然，在非人体工学键盘和人体键盘之间切换也是个问题，如果有人觉的切换自如，那也无所谓了。\n\n\n结论：无论是什么键盘，配有一个手托，对腕子痛对有很大的缓解作用。如果输入量适中，人体工学键盘是不错的选择。人体工学，不代表你可以敲击省力。\n2.第二个要解决的问题：手不累的问题。 \n普通的机械键盘\n我们先来分析一下，让手不累的问题，如果想让手不累。\n\n尽量不敲。（不敲不行啊，不出字啊。）\n\n尽量少敲，还能多出字。（那和键盘没关系，使用快捷键或高效的输入法，比如五笔字型，但是有训练时间成本）\n\n敲，但不需太用力的敲。（小时候玩过那种助力车吧，加了助力装置的小车，向前一推，比没有加这个装置的小车，同样的用力，可以跑相对更远的距离，跑同样的距离（输入量），就可以少用力。）\n\n\n经过分析，第三种是我们需要，敲键盘不用太使劲，还能把字都输入了，最省力的，同样的输入量，还能减少疲劳。\n机械键盘里，那种比较适应这种情况？常见的机械键盘除了外型的不同，主要的区别在于按键下的轴体设计的不同，比较常见的轴体，有黑轴，青轴，茶轴，红轴。\n红轴：压力是相对较轻的，并且按下去时没有被阻段的感觉(段落感)， 按下去后的反馈力良好(键按下去，轴机械装置的设计的一种自动反弹力。) 键程无论高低（键帽高矮），都是点到即生效，不用触底。\n黑轴：是红轴的加重版，需要更大的力量，长期积累，手会累。\n青轴:是段落感最明显的轴体，产量也最大，是最有机械手感的轴体，问题还是长时间，使用手会累，声音过大。这不符合我们初忠，我们初忠不是光敲着爽，而是一天积累下来手不会累，这个不行。\n茶轴：是青轴的轻量级，有一点段落感，资料上说，设计出段落感是早期为了模拟传统打字机的特点，缓解过打字人员都新键盘的一些不适应。茶的设计，各方面是比较中庸的，那种使用场景差不多能适用，所有也被称为万能轴。\n现在自己日常使用的比较多的红轴，茶轴的。\n结论：长期使用敲击，红轴是最省力的，比红再重一点的就是茶轴。红的敲击速度快，因人而不同，误码率也相对高一些（敲快了容易出错，想不出错慢点敲）。茶轴因为有段落感回馈确认的原因，误输率也相对低一些（代价是手还是会累一些）。\n3.第三个要解决的问题：键盘噪音的问题。 \n薄膜键盘的声音一定就比机械键盘小吗？\n其实不一定的，那种用过的微软的人体工学键盘，敲击起来的声音真的也不比红轴车厘子的声音小到那去，另外相比红轴的车厘子键盘，声音更闷一些（觉得比经较难听）。\n是什么原因，造成机械键盘的声音大？ \n声音一部产生于按键轴体本身，一部分产生于机械键盘里的钢板。\n像青轴这种轴体，单个轴按下去，本身就会产生类似于按圆珠笔帽一样的咔哒声音，外加按键触底到钢板的撞击声，噪音就更大！同时按104根圆珠笔帽，撞击钢板的声音。用过的青轴，实在是受不了这种声音，而且因为青轴的结构复杂，一般还容易出现问题，还有就是带背光的键盘问题率也相对高一些。\n而相反，如果使用没有段落感的轴体，另外也不使用有钢板的设计，在降噪方面就很好，像红轴这种键盘的设计，按键不用触底都可以输入的键盘，不需用大量都可以完成输入动作，声音就更小了。\n结论：要想声音做到最小，就用红轴，并且是无钢板设计的机械键盘，声音比有些薄膜还要小。\n4.第四个要解决的问题：工业设计和素不素的问题。 \n设计素不素这种问题其实也不难，不要买带背光的键盘。另外300元以下的机械键盘是没什么设计的，那种87,104什么的键盘，本身都是南方那些厂子生产的，模具几乎都一样，那还来的设计，有的都是一个代工厂生产的，就是贴了不同的牌子，区别除了做工和用料，主要是轴体区别，轴本有内地产的，有台湾产的，还有德国产的。不是说国产的就不好，其实，他就是没有台产和德产的好，所以，如果预算够的话，要德产车厘子的轴，一分钱一分货。\n300以下基本没有设计的，模具都一样。那怕是车厘子初门歀的键盘，其实都是有设计的。基本的红轴在500元上下，键盘与手托一体的工业设计，可以解决一天输入不累，手碗不痛的问题。\n键盘帽的最省心的方案，就是买一套原产的，没有什么别的原因，这东西没什么性价比，品质差距明显，一分钱一分货。\n结论：要素买经典款，经典款本身就素，有时是太素了。\n5.第五个要解决的问题：关于价格和做工。 \n机械键盘的主要部件，基本就是车厘子的轴了，大家都一样， 说到做工，其实日产的键盘的做工比原产车厘子要好，包括台产和国内的有些厂商都比原产做工好（价格会高一些），同是用的原产的轴体。就像耳机一样，到后来差别，一般人很难分辨了，500元用的也是车厘子红轴，1200用的也是车厘子红轴，多花的钱都在其它部件工艺上，反正你买单，不差价就买。100元键盘和500键盘，差别明显,500元和800，1000的区别，已经不在轴体本身了。\n有人说HHKB一步到位，对于这个想说的是，如果你有钱，完全可以买超跑，买回来做运营的活， 如果你是码字大户，对自己好一些没问题。 但也见过，买HHBK回来，对键盘布局很不适应的。实用的话，就买个87,或是108标准键盘，带一体手托工业设计，是一些小布局键盘的超集，数字键盘可盲打，不累，手腕不痛，省心。\n6.第六个要解决的问题：购买与渠道的问题。 \n从国内的渠道来看，最现实的购买人体工学方案的键盘就是微软的，别的几乎没有，如果你去美亚上看，有很多其它高端人体工学的牌子，还有那种，同时是机械键盘，又是人体工学键盘，但是国内没有卖的，可以走转运，如是你不是高烧用户， 费力不讨好，本身那些在国内就是小众品，微软的人体工学键盘国内可以买到，和转运回来的价格比相对便宜，但设计上都是多少年前的设计。\nCherry历史上好像只出过一款人全工学的键盘，很多年前的事，还是和微软合作的貌似。\nHHBK之前京东上还没有卖的时候，可以走淘宝，代购售后没保证，有人经历过。\n上文没有提到其它具体的品牌，提到了微软的键盘，是因为在国内，微软的人体工学键盘，几乎就是人体工学键盘的代名词。cherry是机械的代名词，几乎所有有的品质的机械键盘，什么牌子的都算上，用的大多数都是她的轴体。\n想想为什么微软后来就没有新品的人体工学键盘上市了，为什么车厘子这么多年，也没出过多少款的人体工学键盘。键盘本身的核心在于轴体和整体的工业设计。\n所以，如果想买个打字不累，手腕不痛的键盘，不一定非要买人体工学的键盘，买一个原产红轴，不带钢板设计，配一个手托，无论什么牌子的机械键盘都可以满足基本需求。\n个人浅见，仅供参考！\n","slug":"old_topic/2016-09-17-246","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ea8283997977848c6827a1a83f28911d","title":"Moonscript与HTML模板","content":"作者：糖果\nMoonscript与HTML模板\nLapis框架可以用Moonscript直接编程，Moonscript可以将需要模板系统对于的网页输出，一揽子的都在Moonscript中用代码实现，可以看leaof.net/lapis下最典型的官方例子，其实DB的相关操作也可以在moonscript中都完成了，对于某种类型的操作来看，这是很酷的。\n我们先来看一下模板的例子：\n12345678910111213import Widget from require &quot;lapis.html&quot;class Index extends Widget  content: =&gt;    h1 class: &quot;header&quot;, &quot;Hello&quot;    @user_panel!    div class: &quot;body&quot;, -&gt;      text &quot;Welcome to my site!&quot;  user_panel: =&gt;    return unless @current_user    div class: &quot;user_panel&quot;, &quot;Welcome back &quot; .. @current_user.name\n\n\n这段mooncript代码会被翻译成下面的HTML\n1234567891011&lt;h1 class=&quot;header&quot;&gt;&lt;%= &quot;Hello&quot; %&gt;&lt;/h1&gt;&lt;% if current_user then %&gt;  &lt;div class=&quot;user_panel&quot;&gt;    Welcome back &lt;%= current_user.name %&gt;  &lt;/div&gt;&lt;% end %&gt;&lt;div class=&quot;body&quot;&gt;  Welcome to my site&lt;/div&gt;\n\n\n在实际leafo之前的应用代码中，利用的最明显的是下面这段：\n12345678910111213import Widget from require &quot;lapis.html&quot;class PostLayout extends Widget  content: =&gt;    @page.template_stack\\push &quot;web&quot;    div class: &quot;post&quot;, -&gt;      div class: &quot;sidebar&quot;, -&gt;        text @root      div class: &quot;main_column&quot;, -&gt;        raw @body\n\n下面这句话出现了问题：\n12div class: &quot;sidebar&quot;, -&gt;  text @root\n@root在某些情况下晃是一个”..“, 这个会造成左边栏的导航栏消失了。\n这里核心的库就是这个lapis.html\n1import Widget from require &quot;lapis.html&quot;\n\n代码太长，就贴个连接过来lapis.html.moon,Moonscript如果用来做个人项目还是挺酷的。如何用Moonscript生成Html看下面的连接：HTML Generation,Moonscript生成大量的前端可以维护起来可能有些难度，但做为生成模板描述，还是方便快速有优势。\n上面的模板定义代中，使用了一个助手函数raw：\n1raw @body\n\n还使用了另外的一个助手函数：\n1text @root\n\n\nraw(str)\n\n\n\n\n\n\n\n\n引用文本： — outputs the argument, a string, directly to the buffer without escaping.\nraw是直接将字符串写入到buffer，并且不经过转意。\ntext(args)\n\n\n\n\n\n\n\n\n引用文本： — outputs the argument to the buffer, escaping it if it’s a string. If it’s a function, it executes the function in HTML builder environment. If it’s a table, it writes each item in the table\n这个函数区别于raws，如果是字符串就转义。是函数就执行。如果是表，把每个元素都写入表。\n上面提到的@root是sitegen的内建变量。\n\n\n\n\n\n\n\n\n\n引用文本： $root — a relative path prefix that points back to the top level directory of your site. For example, if the current page is wwww/hello/world.html, the $root would be ../. This make it easy to built URLs to other pages without being concerned about where your page is being rendered to.\n一般的情况下,@root值就取”.”、”..” 比较常见。不过，此处这种输出会导致左导航栏消失。sitgen, jekyll,还有这个saepy-log，这三个系统，前二者是静态转换Markdown,saepy-log是从Mysql里，读取Markdown（最开始不是，改成了直接支持Markdown。）三个工具分别用三种语言实现。moonscript(lua), ruby, python(tornado)，设计风格也不一样。对SEO支持比较好的是SAEPY_LOG，最酷的还是sitegen。\n","slug":"old_topic/2016-09-17-253","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"27f5dd10d15b97af4bd3b63c97316dd6","title":"Sitegen的模板问题","content":"作者：糖果\nSitegen的模板是用MoonScript定义， 但是leafo老版的代码，貌似和VPS的环境结合的不是很好，是不是纯环境原因造成的不深究了，直接把模板代码改成需要的样式。\n1234div class: &quot;post&quot;, -&gt;  div class: &quot;sidebar&quot;, -&gt;    raw &quot;&lt;a href=&#x27;.&#x27; title=&#x27;leafo.net&#x27;&gt;&lt;img class=&#x27;logo&#x27; src=&#x27;../img/leafo.svg&#x27; alt=&#x27;leafo.net&#x27; /&gt;&lt;/a&gt;&quot;","slug":"old_topic/2016-09-17-256","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9aa4800266f7113f51164edc798c6fc2","title":"Nginx命令行自动生成工具","content":"Nginx命令行自动生成工具\n这篇其实想说的内容是，Vanilla和LOR都共通使用的scaffold\n","slug":"old_topic/2016-09-17-251","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d0886af109289466091152072b994710","title":"安装zsh及其常用插件","content":"zsh可以被视为是对Bourne shell的一种扩展，完全兼容bash。它强大的自动补全功能对我还是非常有吸引力的。\n总体来说，zsh的功能主要包括：\n\n开箱即用、可编程的命令行补全功能可以帮助用户输入各种参数以及选项。\n在用户启动的所有shell中共享命令历史。\n通过扩展的文件通配符，可以不利用外部命令达到find命令一般展开文件名。\n改进的变量与数组处理。\n在缓冲区中编辑多行命令。\n多种兼容模式，例如使用/bin/sh运行时可以伪装成Bourne shell。\n可以定制呈现形式的提示符；包括在屏幕右端显示信息，并在键入长命令时自动隐藏。\n可加载的模块，提供其他各种支持：完整的TCP与Unix域套接字控制，FTP. 客户端与扩充过的数学函数。\n完全可定制化。\n\n安装zsh\n在Linux中，我们可以：\n# 如果你用的是yum包管理器，将下面的apt-get替换成yum即可。\nsudo apt-get install zsh\n# 安装完成后，我们要讲默认的shell替换成zsh\nchsh -s /bin/zsh\n\n在cygwin中，我们可以用cygwin安装器来安装zsh： install zsh\n安装完成后，我们只需在~/.bash_profile文件的末尾添加一行exec zsh。然后重启终端即可。\n安装oh-my-zshoh-my-zsh的源码是托管于github上的。所以，我们要先克隆该版本库中的代码：\ngit clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh\n\n然后，为谨慎起见，我们在安装之前应该先备份一下现有的zsh配置：\ncp ~/.zshrc ~/.zshrc.orig\n\n现在，我们创建一个新的zsh配置文件：\ncp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc\n\n如果你看到如下界面，说明安装完成。 cygwin_oh_my_zsh\n安装zsh-syntax-highlighting插件同样地，我们要先下载它的源码，但在这里，我们可以利用一下oh-my-zsh的插件管理功能：\ncd ~/.oh-my-zsh/custom/plugins\ngit clone git://github.com/zsh-users/zsh-syntax-highlighting.git\n\n然后，我们打开~/.zshrc文件，找到以下段落；\n# Which plugins would you like to load? (plugins can be found in ~/.oh-my-zsh/plugins/*)\n# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/\n# Example format: plugins=(rails git textmate ruby lighthouse)\n# Add wisely, as too many plugins slow down shell startup.\nplugins=(git)\n\n按照注释中的提示改成plugins=(git zsh-syntax-highlighting)即可。\n安装autojump插件。同样地，我们需要先下载源码：\ngit clone git://github.com/joelthelion/autojump.git\n\n然后安装该程序：\ncd autojump\n./install.py\n\n最后，我们只需在~/.zshrc文件中加入以下代码即可。\n# install autojump\n[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; . ~/.autojump/etc/profile.d/autojump.sh\n\n安装Powerline-Shell插件其过程与autojump的安装基本相同，先下载源码：\ngit clone https://github.com/milkbikis/powerline-shell\n\n再安装：\ncd powerline-shell\n./install.py\nln -s &lt;path/to/powerline-shell.py&gt; ~/powerline-shell.py\n\n最后再配置~/.zshrc文件，在其末尾加入如下代码：\n1234567891011121314# install powerline-shellfunction powerline_precmd() &#123;  export PS1=&quot;$(~/powerline-shell.py  --cwd-max-depth 1 --cwd-only $? --shell zsh 2&gt; /dev/null )&quot;&#125;function install_powerline_precmd() &#123;  for s in &quot;$&#123;precmd_functions[@]&#125;&quot;; do    if [ &quot;$s&quot; = &quot;powerline_precmd&quot; ]; then      return    fi  done  precmd_functions+=(powerline_precmd)&#125;install_powerline_precmd\n然后在cygwin中，我们就看到如下最终效果： my_zsh\n作者：凌杰\n原文连接:\n","slug":"old_topic/2016-09-17-255","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a118688c77f2ae8c55789318279921c8","title":"Logstash基础配置","content":"编辑：糖果\nLogstash的启动脚本中有比较多的命令行参数：\n###-f ：用于指定配置文件\n使用文件，目录，或者通配符加载配置信息，如果指定为目录或者通配符，按字母顺序加载。\n###-e:  用于指定字符串输入\n默认输入为，\n1stdin &#123; type =&gt; stdin &#125;\n\n\n默认输出为：\n1stdout &#123; codec =&gt; rubydebug &#125;&#125;\n\n-w: 指FilterWorkers的数量，默认为1-l：指定输出文件的路径，默认为控制台输出–verbose:设置较少的日志–debug:设置更消息的日志–watchdog-timeout TIMEOUT 设置watchdog超时时间，默认为10秒。启动案例：\n1bin/logstash -f logstash-simple.conf  -w 2 \n\n\nlogstash-simple.conf内容为：\n1234567input &#123; stdin &#123; &#125; &#125; #输入filter&#123;&#125;            #过滤器output &#123;            #输出  elasticsearch &#123; host =&gt; localhost &#125;  stdout &#123; codec =&gt; rubydebug &#125;&#125;\n\n插件安装：\nLS提供了一个plugin脚本用于安装输入输出插件。\n1$LS_HOME/bin/plugin\n如：安装KafKa插件\n1bin/plugin install logstash-output-kafka\n\n卸载KafKa插件\n1bin/plugin uninstall logstash-output-kafka\n\n更新所有的插件\n1bin/plugin update\n\n更新单个插件\n1bin/plugin update logstash-output-kafka\n\n查看插件列表\n123bin/plugin listbin/plugin list ko  列出包含ko字符的插件bin/plugin list --group output 列出指定组的插件。\n\n\n\n原文\n","slug":"old_topic/2016-09-17-258","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3654658d46c7379d31d55d1693594cbc","title":"Markdown语法说明","content":"编辑：糖果\n11# Guide\n这是一篇讲解如何正确使用OpenResty China 的 Markdown 的排版示例，学会这个很有必要，能让你的文章有更佳清晰的排版。\n\n\n\n\n\n\n\n\n\n引用文本：Markdown is a text formatting syntax inspired\n语法指导普通内容这段内容展示了在内容里面一些小的格式，比如：\n\n加粗 - **加粗**\n倾斜 - *倾斜*\n删除线 - ~~删除线~~\nCode 标记 - Code 标记\n超级链接 - [超级链接](http://github.com)\nsumory.wu@gmail.com - [sumory.wu@gmail.com](mailto:sumory.wu@gmail.com)\n\n评论文章时提及用户@sumory  … 通过 @ 可以在评论里面提及用户，信息提交以后，被提及的用户将会收到系统通知。以便让他来关注这个帖子或回帖。\n表情符号 EmojiOpenResty China 支持表情符号，你可以用系统默认的 Emoji 符号。也可以用图片的表情，输入 : 将会出现智能提示。\n一些表情例子:smile: :laughing: :dizzy_face: :sob: :cold_sweat: :sweat_smile:  :cry: :triumph: :heart_eyes:  :satisfied: :relaxed: :sunglasses: :weary:\n:+1: :-1: :100: :clap: :bell: :gift: :question: :bomb: :heart: :coffee: :cyclone: :bow: :kiss: :pray: :shit: :sweat_drops: :exclamation: :anger:\n对应字符串表示如下：\n12:smile: :laughing: :dizzy_face: :sob: :cold_sweat: :sweat_smile:  :cry: :triumph: :heart_eyes:  :satisfied: :relaxed: :sunglasses: :weary::+1: :-1: :100: :clap: :bell: :gift: :question: :bomb: :heart: :coffee: :cyclone: :bow: :kiss: :pray: :shit: :sweat_drops: :exclamation: :anger:\n\n更多表情请访问：http://www.emoji-cheat-sheet.com\n大标题 - Heading 3你可以选择使用 H2 至 H6，使用 ##(N) 打头，H1 不能使用，会自动转换成 H2。\n\n\n\n\n\n\n\n\n\nNOTE: 别忘了 # 后面需要有空格！\nHeading 4Heading 5Heading 6代码块普通123*emphasize*    **strong**_emphasize_    __strong__@a = 1\n\n语法高亮支持如果在 ``` 后面更随语言名称，可以有语法高亮的效果哦，比如:\n演示 Lua 代码高亮12345678local lor = require(&quot;lor.index&quot;)local app = lor()app:get(&quot;/&quot;, function(req, res, next)    res:send(&quot;hello world!&quot;)end)app:run()\n\n演示 Javascript 高亮12345678910111213141516171819202122(function (L) &#123;    var _this = null;    L.Common = L.Common || &#123;&#125;;    _this = L.Common = &#123;        data: &#123;&#125;,         init: function () &#123;            console.log(&quot;init function&quot;);        &#125;,        formatDate: function (now) &#123;            var year = now.getFullYear();            var month = now.getMonth() + 1;            var date = now.getDate();            var hour = now.getHours();            var minute = now.getMinutes();            var second = now.getSeconds();            if (second &lt; 10) second = &quot;0&quot; + second;            return year + &quot;-&quot; + month + &quot;-&quot; + date + &quot; &quot; + hour + &quot;:&quot; + minute + &quot;:&quot; + second;        &#125;    &#125;;&#125;(APP));\n\n演示 YAML 文件123zh-CN:  name: 姓名  age: 年龄\n\n\n\n\n\n\n\n\n\n\nTip: 语言名称支持下面这些: ruby, python, js, html, erb, css, coffee, bash, json, yml, xml …\n有序、无序列表无序列表\nRuby\nRails\nActiveRecord\n\n\n\n\nGo\nGofmt\nRevel\n\n\nNode.js\nKoa\nExpress\n\n\n\n有序列表\nNode.js\nExpress\nKoa\nSails\nRuby\nRails\nSinatra\nGo\n\n表格如果需要展示数据什么的，可以选择使用表格哦\n\n\n\nheader 1\nheader 3\n\n\n\ncell 1\ncell 2\n\n\ncell 3\ncell 4\n\n\ncell 5\ncell 6\n\n\n段落留空白的换行，将会被自动转换成一个段落，会有一定的段落间距，便于阅读。\n请注意后面 Markdown 源代码的换行留空情况。\n原文\n","slug":"old_topic/2016-09-17-249","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f173cba451a203ccad448cb458769230","title":"用Logstash解析OpenResty的Resty.Logger推送的Syslog数据","content":"作者：糖果\n【前记】用Resty.Logger给SyslogNG推送了几个测试的数据字段，如下：\n1192.168.0.1 68.180.228.95 GET /feed Jun 28 16:12:19\n\n中间用空格区分，下面是grok的测试，经测式这些模式的测试数据都能正常解析。\n【正文】\n1ruby grokdebug.rb -m &#x27;192.168.0.1 68.180.228.95 GET /feed Jun 28 16:12:19&#x27; -p &#x27;%&#123;IP:server_ip&#125; %&#123;IP:client_ip&#125; %&#123;WORD:http_verb&#125; %&#123;PATH:baseurl&#125; %&#123;MONTH:month&#125; %&#123;MONTHDAY:day&#125; %&#123;TIME:time&#125;&#x27;\n\n被正常分析出来的JSON，如下：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123;  &quot;server_ip&quot;: [    &quot;139.129.93.234&quot;  ],  &quot;IPV6&quot;: [    null,    null  ],  &quot;IPV4&quot;: [    &quot;139.129.93.234&quot;,    &quot;68.180.228.95&quot;  ],  &quot;client_ip&quot;: [    &quot;68.180.228.95&quot;  ],  &quot;http_verb&quot;: [    &quot;GET&quot;  ],  &quot;baseurl&quot;: [    &quot;/feed&quot;  ],  &quot;UNIXPATH&quot;: [    &quot;/feed&quot;  ],  &quot;WINPATH&quot;: [    null  ],  &quot;month&quot;: [    &quot;Jun&quot;  ],  &quot;day&quot;: [    &quot;28&quot;  ],  &quot;time&quot;: [    &quot;16:12:19&quot;  ],  &quot;HOUR&quot;: [    &quot;16&quot;  ],  &quot;MINUTE&quot;: [    &quot;12&quot;  ],  &quot;SECOND&quot;: [    &quot;19&quot;  ]&#125;\n\n\n【后记】放到ES里，就可以直接用Django REST创建接口了，给外部使用。原理和使用的过程都是一样的，接口怎么实现，看具体业务复杂情况。\n搭建grok的debugger环境，参考这篇:\n更多的问题，直接参考StackOverflow上的问题:\n","slug":"old_topic/2016-09-17-260","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"64be2f7f885d3e6489a053f52dc644fa","title":"Nginx与OpenResty的用户权限管理","content":"作者：足至迹留\n编辑：糖果\n原文引用:\n【原文】\nNginx用户权限 \n在nginx.conf文件的第一行一般是设置用户的地方（编译安装nginx时的参数–user=也是指定用户的地方），如 user www www; \n如不指定默认是nobody. 这里用户的设置又有什么意义呢？主要是指定执行nginx的worker process的用户，linux里所有程序都是文件，都具有权限问题，这个指定的用户对特定的文件有没有权限访问或执行，就是这个用户的意义。 \n一、本人遇到问题 \n1.1 问题描述 \n不想让请求直接访问到具体页面，只是列出目录内的文件列表。于是把proxy_pass参数去掉，配置autoindex on，然后指定root目录。可访问后返回403,没有权限。 \n1.2 问题解决 \n猜测是用户原因，因为是默认的nobody，没有访问目录权限，然后指定有权限的用户，ok了。 \n二、网上类似问题 \n例一：403错误，没有权限 \n参考文章A：参考文章B：\n有时候当Nginx读取本地目录时会收到403错误，权限问题。 \n先来了解一下Nginx的用户管理： \n（1）Nginx在以Linux service脚本启动时，通过start-stop-domain启动，会以root权限运行daemon进程。 \n（2）然后daemon进程读取/etc/nginx/nginx.conf文件中的user配置选项，默认这里的user=nginx，也就是用nginx用户启动worker process。403错误就是因为nginx用户没有权限访问我当前开发用的用户目录，/home/dean/work/resources。 \n解决方法是将user=nginx替换成root，然后重新启动nginx，可以了。其他方法也试过，比如给/home/dean/work/resources目录设置777权限，比如将nginx用户加入root组，都不行。所以当开发的时候，就用user=root配置吧。至于产品环境下，resouces目录完全可以放到nginx用户目录下，所以问题不大。 \n举例2：访问速度慢 \n参考文章：\n在说问题前，先扫下盲，关于linux下的nobody用户：nobody是系统用户,是一个不能登陆的帐号，一个特殊用途的用户 ID ,一些服务进程如apache，aquid等都采用一些特殊的帐号来运行，比如nobody,news,games等等。一般来说 uid &lt; 500 的都是系统 ID 。 \nLinux 系统为了安全，很多操作和服务的运行都不是运行在 root 用户下面的，而是一个专用的 ID ，这个 ID 一般就是 nobody ，这样就可以把每个服务运行的情况隔离出来。保证不会因为服务器程序的问题而让服务器程序成了黑客的直接操作源（黑客拿下了服务器程序，也仅仅是 nobody 用户而不是 root 用户）。同时也不会影响其他用户的数据。服务器程序提权有专用的办法来防止恶意使用的。 \n除了 nobody ，常见的还有 ftp 、ssh 什么的。有的不是用来跑服务，而是用来占坑，主要是用用户组的权限管理进行权限设置，这个时候会有一个占坑用的同名 ID 加入到用户组。这种情况好像主要是为了兼容。 \n问题描述：上午业务人员反映，系统响应很慢，界面要刷新很久才出得来。查后台也没有报什么错，我们系统是用nginx做负载均衡。惯性地不走负载均衡而直接访 问单节点应用，发现响应很快，很正常。初步定位问题出在nginx上，然后查nginx日志，发现有很多错误，错误中有“13: Permission denied”这个信息，明显是权限问题，很奇怪，之前运行都很正常啊。后来一问才知道，维护人员做了操作。 \n系统上nginx安装时使用的是root用户，也是用root用户启动的，所以要修改配置的时候需要使用root用户，管理上不方便，所以维护人员 心血来潮修改了nginx的权限（后来知道他是使用这个命令修改的权限chown -R user:group $nginxdir）。就是将nginx的用户和组都换掉了，但是这样为什么会造成“响应慢”呢？ \n问题原因及解决：前面提到在linux上有些应用程序的一些进程会默认使用nobody这个用户来启动，以保安全。nginx有两种进程，除主进程之外的工作进程都 是用nobody这个用户启动的（nginx工作进程的数量使用worker_processes这个参数来设定）。而工作进程要访问nginx下这两个 目录client_body_temp和proxy_temp（这两个目录按我的理解是缓存一些静态文件，比如图片或者css文件什么的，以提高 nginx访问速度），权限变更后，造成工作进程访问不了这两个目录下的内容，造成某些图片和连接打不开，就像响应很慢一样。将权限变更一下就OK了。\n【糖果后记】\n一般权限的问题集中在，文件的上传读写，和静态目录就是必要常用就用场景，比如静态目录的文件读取。还有一种最常见的应用场景就是上传图片文件。\n如果在conf中不指定user,默认起动的静态文件夹被归为了Nobody，用root用户启动的话，某些没有进行权限指定的文件还是不能读取，如果指定了用户，正确设定静态目录的所属用户和读写权限，才可以读和正常的写（上传文件），过程中必然要使用chown,chmod这种常用的权限操作。\n感谢原文作者的分享！\n","slug":"old_topic/2016-09-17-257","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"79e330aa651aa9f646dd55d111ec9437","title":"Logstash Grok Debugger环境构建","content":"编辑：糖果\n【前记】\n这个环境的搭建，主要为了用于分离lua_logger推送到syslog中的数据，解析后放到ES里，再对外提供RESTY接口。基本的工具就是这么使用，至于是具全的业务如何设计实现，根据实际情况来。比如，有的WAF系统不提供开发的API把block的数据暴露出来，可能就需要自己实现一套。\n【正文】\n1. 安装 RVM2. 安装 Ruby 和 Gems3. 安装 Rails4. 安装 jls-grok5. Ruby grok 解析6. 调试 grok注意：不要用 root 执行以下操作。用 logstash 收集 IIS、tomcat 日志，或是其他时，你需要调试 grok 表达式，每次都需要重新加载文件，然后再把 sincedb 文件全部删除，否则 logstash 不会重复处理文件，很麻烦。\n本文主要介绍如何安装 GrokDebuger 环境，再在命令行调试 Grok 表达式。Logstash 是用 Ruby 编写的，而 Ruby 有专门的处理 grok 表达式的 gem。\n下面过程有先后顺序。\n安装 RVMrvm（Ruby Version Manager），是一个非常好用的ruby版本管理以及安装工具。\n1curl -sSL https://get.rvm.io | sudo bash -s stable\n\n\n参见A：\n参见B：\n这步可能要多试几次，不是你的问题，是它们的网络问题。\n若不能 sudo ，就自己设置下你用户的权限。\nRVM 安装位置自己 FIND 一下。\n安装 rvm 后，需要用 rvm 把你当前用户添加到 rvm 组。rvm 会自己创建 rvm 组。\n12rvm group add rvm &quot;$USER&quot; rvm fix-permissions“$USER”\n\n表示你当前用户，然后重新登录。\n在 RVM 下安装 Ruby。\n安装 Ruby 和 Gems\n123rvm install rubyruby -vgem –v\n\n这步很简单如果能看到版本信息，就说明成功了\n安装 Rails\n1gem install rails\n\n若不能访问，则添加淘宝镜像 https://ruby.taobao.org/。\n安装 jls-grok\n1gem install jls-grok\n\n这步也很简单基本不会出问题\nRuby grok 解析编写一个 Ruby 脚本，用来调试 Grok 表达式。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748require &#x27;rubygems&#x27;gem &#x27;jls-grok&#x27;, &#x27;=0.11.2&#x27;require &#x27;grok-pure&#x27;require &#x27;optparse&#x27;require &#x27;json&#x27;options = &#123;&#125;ARGV.push(&#x27;-h&#x27;) if ARGV.size === 0OptionParser.new do |opts|  opts.banner = &#x27;Run grokdebug at your terminal.&#x27;  options[:dirs] = %w(patterns)  options[:named] = false  opts.on(&#x27;-d DIR1,DIR2&#x27;, &#x27;--dirs DIR1,DIR2&#x27;, Array, &#x27;Set grok patterns directories. Default: &quot;./patterns&quot;&#x27;) do |value|    options[:dirs] = value  end   opts.on(&#x27;-m MESSAGE&#x27;, &#x27;--msg MESSAGE&#x27;, &#x27;Your raw message to be matched&#x27;) do |value|    options[:message] = value  end  opts.on(&#x27;-p PATTERN&#x27;, &#x27;--pattern PATTERN&#x27;, &#x27;Your grok pattern to be compiled&#x27;) do |value|     options[:pattern] = value  end   opts.on(&#x27;-n&#x27;, &#x27;--named&#x27;, &#x27;Named captures only&#x27;) do  end end.parse!grok = Grok.newoptions[:dirs].each do |dir|   if File.directory?(dir)     dir = File.join(dir, &quot;*&quot;)   end   Dir.glob(dir).each do |file|     grok.add_patterns_from_file(file)   end end grok.compile(options[:pattern], options[:named]) puts JSON.pretty_generate(grok.match(options[:message]).captures())\n调试 grok\n12345678910111213141516171819202122232425262728293031323334353637[ln@vcyber myruby]$ ruby grokdebug.rb -m &#x27;10.1.1.1&#x27; -p &#x27;%&#123;IP:client&#125;&#x27; &#123;   &quot;client&quot;: [     &quot;10.1.1.1&quot;   ],   &quot;IPV6&quot;: [     null   ],   &quot;IPV4&quot;: [     &quot;10.1.1.1&quot;   ] &#125; [ln@vcyber myruby]$ ruby  grokdebug.rb -m &#x27;10.1.8.166:8000&#x27; -p &#x27;%&#123;HOSTPORT:test&#125;&#x27; &#123;   &quot;test&quot;: [     &quot;10.1.8.166:8000&quot;   ],   &quot;IPORHOST&quot;: [     &quot;10.1.8.166&quot;   ],   &quot;IP&quot;: [     &quot;10.1.8.166&quot;   ],   &quot;IPV6&quot;: [     null   ],   &quot;IPV4&quot;: [     &quot;10.1.8.166&quot;   ],   &quot;HOSTNAME&quot;: [     null   ],   &quot;POSINT&quot;: [     &quot;8000&quot;   ] &#125; \n\n若提示找不到“pattern”，你可以将 logstash 目录底下的复制过来拿来用\n【后记】经群里的好朋友提醒，这个目录的位置，如下：\n1logstash-2.3.2/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.5\n\n\n\n\n\n\n原文转载\n","slug":"old_topic/2016-09-17-259","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"b47efc97ee4123d2f7e53bb4b25277cf","title":"Logstash Filter解析Openrety的Log数据的简单配置","content":"作者：糖果\nLogstash的配置文件位置:/etc/logstash, 而logstash本身的程序，可以放到别的定制的位置。\n一般性的Logstash配置有三个节:\n12345678910111213141516171819202122input &#123;file &#123;        path =&gt; &quot;/test/log/567/*.log&quot;        type =&gt; &quot;nginx&quot; # a type to identify those logs (will need this later)&#125;&#125;filter &#123;if [type] == &quot;nginx&quot; &#123; # this is where we use the type from the input section        grok &#123;                match =&gt; [ &quot;message&quot;, &quot;COMBINEDNGINXLOG&quot; ]        &#125;&#125;&#125;output &#123;        elasticsearch &#123;                hosts =&gt; [&quot;127.0.0.1:9200&quot;]                index =&gt; &quot;testdata&quot;&#125;&#125;\n\n第一个节：input用于指定log文件的位置和类型。\n123456input &#123;file &#123;        path =&gt; &quot;/test/log/567/*.log&quot;        type =&gt; &quot;nginx&quot; # a type to identify those logs (will need this later)&#125;&#125;\n\n\n第二节：filter指定log文件指段配置的Pattern，关键分词就靠这个。\n1234567filter &#123;if [type] == &quot;nginx&quot; &#123; # this is where we use the type from the input section        grok &#123;                match =&gt; [ &quot;message&quot;, &quot;COMBINEDNGINXLOG&quot; ]        &#125;&#125;&#125;\n\n第三节：output指定log转换后的数据存储和位置，下面的设置是典型的输出到ES中。\n1234567output &#123;        elasticsearch &#123;                hosts =&gt; [&quot;127.0.0.1:9200&quot;]                index =&gt; &quot;testdata&quot;&#125;&#125;\n\n\ngrok filter的官吏法可以参考这篇: 参考文\nCOMBINEDNGINXLOG实际是没有这个pattern的，只有占位用的。\n","slug":"old_topic/2016-09-17-261","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"7a3c5a1d23bfd5b9726de20fd52ae700","title":"PIL与Pylibmc","content":"作者：糖果\n要用一个小系统，需要装PIL和Pylibmc。\nPIL就不用pip装了，直接用apt-get装：\n1sudo apt-get install python-imaging\n\nPylibmc需要安装下面的依赖库：\nUbuntu\n123sudo apt-get install memcachedsudo apt-get install libmemcached-devsudo apt-get install libmemcached-tools \n\nCenOS\n12sudo yum install libmemcached10sudo yum install libmemcached10-devel\n\n最后安装\n1pip install pylibmc","slug":"old_topic/2016-09-17-262","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"916d00d5ac3386eee42a586e5f38ef7d","title":"爬虫小工具BeautifulSoup","content":"BeautifulSoup是一种用于分析网页HTML内容元素的工具，还有类似的Request也可完成相关工作。\n下面是一小段程序，翻出来：\n123456789101112131415161718192021from urllib2 import urlopen, URLErrorfrom bs4 import BeautifulSoupdef fetch():        baseUrl = &#x27;http://house.focus.cn/msglist/7906/&#x27;        hd = urlopen(baseUrl, timeout = 6)        content = hd.read()        content = content.decode(&#x27;gb2312&#x27;, &#x27;ignore&#x27;)        soup = BeautifulSoup(content)        p = soup.findAll(&#x27;a&#x27;)        for item in p:                val = str(item)                if (val.find(&#x27;title&#x27;) &gt; 0) and (val.find(&#x27;href&#x27;) &gt; 0) and (val.find(&#x27;font&#x27;) &gt; 0):                        print item.text                        tmpurl =  &#x27;http://house.focus.cn&#x27; + str(item[&#x27;href&#x27;])                        print tmpurlfetch()\n\n\nBeautiful最本质完成一个作内容，是把HTML的元素标签”对像:化，item化。如果不喜欢那种，直接通过正则表达式在HTML内容中匹配数据，或是不是所有的都用正则，Beautiful是一个不错的选择。\nscrapy生成爬虫生成，更工程化，至少会自动生成一个目录构成，自动生成脚本脚架代码。没有非常大的爬取量，这些python工具可以完成任务的。\n","slug":"old_topic/2016-09-17-264","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e7519b56d8be6d962f5762cfa924baa8","title":"Lapis快速分页查询","content":"作者：糖果\nLapis分页查询和一般的Django分页查询有明显的分别：\nlapis分页器对象的创建和查询条件的指定是同时的。\n1234567891011121314151617181920local lapis = require &quot;lapis&quot;local app = lapis.Application()local config = require(&quot;lapis.config&quot;)local db = require(&quot;lapis.db&quot;)local Model = require(&quot;lapis.db.model&quot;).Modellocal schema = require (&quot;lapis.db.schema&quot;)app:get(&quot;/&quot;,function(self)       local Cmt = Model:extend(&quot;user&quot;)    local paginated = Cmt:paginated(&quot;where id &lt;= ?&quot; , 100, &#123; per_page = 10,        prepare_results = function(posts)        return posts    end    local page1 = paginated:get_page(1)end)\n\n\n不像Django，Lapis不需要定义表的结构类，一句就可以解决这个问题：\n1local Cmt = Model:extend(&quot;user&quot;)\n\n\n接下来就是定义分页模式, 查询条件是id&lt;=100, 10行分一页：\n1234local paginated = Cmt:paginated(&quot;where id &lt;= ?&quot; , 100, &#123; per_page = 10,    prepare_results = function(posts)    return postsend\n\n\n查询第一分页数据：\n1local page1 = paginated:get_page(1)\n\nlapis分页接口这样设计是可以接受的：\n看一下Python的接口设计：\n12345678910111213141516171819def listing(request):        words_list = Author.objects.order_by(&#x27;-dateTime&#x27;)[:100]        paginator = Paginator(words_list, 16)        page = request.GET.get(&#x27;page&#x27;)        try:                contacts = paginator.page(page)        except PageNotAnInteger:                contacts = paginator.page(1)        except EmptyPage:                contacts = paginator.page(paginator.num_pages)        t = loader.get_template(&#x27;tests/list.html&#x27;)        c = RequestContext(request, &#123;                &#x27;words_list&#x27;:contacts,        &#125;)        return HttpResponse(t.render(c))\n\n把直接从Model里取出的数据全集，直接给分页器，当分页器持有这些数据后，通过自己的接口，来操作返回分页的数据结果。\n在Django中,第一次正常的查询动作和分页动作执行是分开的，先按条件查询，返回所有数据集合，然后，再作为入参给分页器对像。\n而Lapis的方式是二和一的，赋予查询条件查询和返回结果给分页，是一个动作，model和分页器，不是两个数据结构，是一个对象控制的，这是好还是不好呢？各有好处！\nwww.lua.ren\n","slug":"old_topic/2016-09-17-265","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"0c2b4d50783b3962d80c6ee9ac8f9c11","title":"地理位置信息库PyGeoIP","content":"地理位置信息库PyGeoIP\n1234567wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz &amp;&amp; gzip -d GeoLiteCity.dat.gzwget http://geolite.maxmind.com/download/geoip/database/GeoLiteCityv6-beta/GeoLiteCityv6.dat.gz &amp;&amp; gzip -d GeoLiteCityv6.dat.gzwget http://download.maxmind.com/download/geoip/database/asnum/GeoIPASNum.dat.gz &amp;&amp; gzip -d GeoIPASNum.dat.gz\n\n\n地理位置坐标查询：\n1http://www.gpsspg.com/maps.htm\n\n经过测试GeoLite免费库是不支持中国内地的，这样就需要开一个自己库收集数据，在GeoLite库里查不到的时候，再去自制库里取一下。另外一部分库的来源是公司自有的库。\n","slug":"old_topic/2016-09-17-266","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"701efda480792ff7d53cd8c1072352cf","title":"用Supervisor管理Python应用","content":"作者：糖果\nPython的WEB应用框架相对比较丰富，常见的有flask、tornado、django这种，这种应用可以被定义成WSGI形式的WEB应用，用gunicorn启动服务，不过有一点，没有一个统一的关闭，启动，关机的重起服务。\n安装Supervisor就可以比较好的解决这个问题:\nSupervisor安装:\n1sudo apt-get install supervisor\n\n\nsupervisor的配置：一般创建配置文件都是在下面这个目录，创建一个文件进行配置，例子文件叫luaren.conf\n1234[program:luaren]command=/usr/bin/gunicorn -w 1 luaren:appdirectory=/test/luarenuser=nginx\n\n查看服务装态\n1/usr/bin/supervisorctl status\n\n启动服务\n1/usr/bin/supervisorctlstart luaren\n\n关闭服务\n1/usr/bin/supervisorctlstop luaren\n\n\n\nhttp://www.lua.ren\n原文来至于糖果实验室\n","slug":"old_topic/2016-09-17-263","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"074f77a9b17de10d6ce47d49abfb9adf","title":"关于Linux环境变量命令ENV","content":"这个测试有几种入口，export，或是用户请求url，我们先从本地做测试，然后搭建一个bshell的CGI环境。\n12export testcase=ls\\;lseval ret=$testcase\n\n\n\n\n我们看一下C实现\n123456789#include &lt;stdio.h&gt;extern char**environ;int main ()&#123;   char**var;   for (var =environ;*var !=NULL;++var)       printf (&quot;%s\\n&quot;,*var);1    return 0;&#125;\n\n然后分析一下C写的CGI和BShell写的CGI的区别。\n","slug":"old_topic/2016-09-17-267","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"1f0e7f34ab02983eb011a2f068cfda64","title":"Threading的Timer是否可以被wait和communicate阻塞","content":"作者：糖果\n测试的内容是将Timer的使用和Popen的使用混合在一起，测试当wait()和communicate()被调用时，是否会阻塞主进程的Timer。\n找到Timer在Python2.7里的源码位置：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# The timer class was contributed by Itamar Shtull-Trauringdef Timer(*args, **kwargs):    &quot;&quot;&quot;Factory function to create a Timer object.    Timers call a function after a specified number of seconds:        t = Timer(30.0, f, args=[], kwargs=&#123;&#125;)        t.start()        t.cancel()     # stop the timer&#x27;s action if it&#x27;s still waiting    &quot;&quot;&quot;    return _Timer(*args, **kwargs)class _Timer(Thread):    &quot;&quot;&quot;Call a function after a specified number of seconds:            t = Timer(30.0, f, args=[], kwargs=&#123;&#125;)            t.start()            t.cancel()     # stop the timer&#x27;s action if it&#x27;s still waiting    &quot;&quot;&quot;    return _Timer(*args, **kwargs)class _Timer(Thread):    &quot;&quot;&quot;Call a function after a specified number of seconds:            t = Timer(30.0, f, args=[], kwargs=&#123;&#125;)            t.start()            t.cancel()     # stop the timer&#x27;s action if it&#x27;s still waiting    &quot;&quot;&quot;    def __init__(self, interval, function, args=[], kwargs=&#123;&#125;):        Thread.__init__(self)        self.interval = interval        self.function = function        self.args = args        self.kwargs = kwargs        self.finished = Event()    def cancel(self):        &quot;&quot;&quot;Stop the timer if it hasn&#x27;t finished yet&quot;&quot;&quot;        self.finished.set()    def run(self):        self.finished.wait(self.interval)        if not self.finished.is_set():            self.function(*self.args, **self.kwargs)        self.finished.set()\n\n\nTimer重要作用还是“倒计时”执行某个函数，最多支持4个入参。\n看一下communicate的源码，多少能看出他和wait()的关系。\n12345678910111213141516171819202122232425262728293031323334def communicate(self, input=None):    &quot;&quot;&quot;Interact with process: Send data to stdin.  Read data from    stdout and stderr, until end-of-file is reached.  Wait for    process to terminate.  The optional input argument should be a    string to be sent to the child process, or None, if no data    should be sent to the child.    communicate() returns a tuple (stdout, stderr).&quot;&quot;&quot;    # Optimization: If we are only using one pipe, or no pipe at    # all, using select() or threads is unnecessary.    if [self.stdin, self.stdout, self.stderr].count(None) &gt;= 2:        stdout = None        stderr = None        if self.stdin:            if input:                try:                    self.stdin.write(input)                except IOError as e:                    if e.errno != errno.EPIPE and e.errno != errno.EINVAL:                        raise            self.stdin.close()        elif self.stdout:            stdout = _eintr_retry_call(self.stdout.read)            self.stdout.close()        elif self.stderr:            stderr = _eintr_retry_call(self.stderr.read)            self.stderr.close()        self.wait()        return (stdout, stderr)    return self._communicate(input)\n\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def _communicate(self, input):    stdout = None # Return    stderr = None # Return    if self.stdout:        stdout = []        stdout_thread = threading.Thread(target=self._readerthread,                                         args=(self.stdout, stdout))        stdout_thread.setDaemon(True)        stdout_thread.start()    if self.stderr:        stderr = []        stderr_thread = threading.Thread(target=self._readerthread,                                         args=(self.stderr, stderr))        stderr_thread.setDaemon(True)        stderr_thread.start()    if self.stdin:        if input is not None:            try:                self.stdin.write(input)            except IOError as e:                if e.errno != errno.EPIPE:                    raise        self.stdin.close()    if self.stdout:        stdout_thread.join()    if self.stderr:        stderr_thread.join()    # All data exchanged.  Translate lists into strings.    if stdout is not None:        stdout = stdout[0]    if stderr is not None:        stderr = stderr[0]    # Translate newlines, if requested.  We cannot let the file    # object do the translation: It is based on stdio, which is    # impossible to combine with select (unless forcing no    # buffering).    if self.universal_newlines and hasattr(file, &#x27;newlines&#x27;):        if stdout:            stdout = self._translate_newlines(stdout)        if stderr:            stderr = self._translate_newlines(stderr)    self.wait()    return (stdout, stderr)\n\n区别就是前面对stdout和stdout处理，最后调用了wait()。\n下面这个程序，是一个用Timer循环调用自己的程序，并且调用函数时，用args函数给被调用函数传参。\n12345678910111213def CandyLab(a,b):        print(a,b)        print &quot;CandyLab&quot;        returndef Orchina():        print &quot;Orchina&quot;        t = Timer( 1, Orchina);        t.start()        returnt = Timer( 1, CandyLab, args=(&quot;valueA&quot;,&quot;valueB&quot;));t.start()\n\nTimer在定义调用函数后，当执行t.start()时， timer进入倒时间状态，这个时间是在形参中指定的，下面这段代码中Orchina这个函数是在starty调用后的10秒时间后，被调用，而t.start()调用后，不会阻塞计数，还会继续调用后面的函数。\n123456def Orchina():        print &quot;Orchina&quot;        returnt = Timer( 10, Orchina);t.start()\n\n\n只有当主要的运行t.cancel函数时，计时才会被取消，定时期停止，CandyLab函数也不会被执行。\n进一步的简单的实例代码：\n12345678910111213141516import timefrom threading import Thread, Timerdef CandyLab():        print &quot;CandyLab&quot;        returndef Orchina():        print &quot;Orchina&quot;        returnt = Timer( 10, CandyLab);t.start()Orchina()time.sleep(3)t.cancel()\n\n运行结果：\n1Orchina\n\n不会立刻执行CanyLab(),正常执行CandyLab()这个函数需要10秒的时间，从t.start()执行时开始记时，程序不柱塞等10秒执行CanyLab()，是按顺序立刻的执行t.start()后面的语句，Orchina()显示输出”Orchina”, 等3秒结束10秒记时，t.cancel()执行后，CanyLab（）这个函数，之后就不会被执行了。\n如果没有sleep3秒后的t.cancel操作，在10秒钟记时完毕时，CandyLab()这个函数会被执行。\n1234567891011121314import timefrom threading import Thread, Timerdef CandyLab():        print &quot;CandyLab&quot;        returndef Orchina():        print &quot;Orchina&quot;        returnt = Timer( 10, CandyLab);t.start()Orchina()\n结果：\n12OrchinaCandyLab\n\n\n还有一种情况就是循环的调用自己，当满足某个条件时，再进行t.cancel的取消动作。\n12345678def CandyLab():        print &quot;CandyLab&quot;        t = Timer( 1, CandyLab);        t.start()        returnCandyLab()\n结果：就是循环输出\n1234CandyLabCandyLabCandyLab...\n\n\n下面是Timer调用函数进传参，用到了args函数：\n12345678910111213def CandyLab(a,b):        print(a,b)        print &quot;CandyLab&quot;        returndef Orchina():        print &quot;Orchina&quot;        t = Timer( 1, Orchina);        t.start()        returnt = Timer( 1, CandyLab, args=(&quot;valueA&quot;,&quot;valueB&quot;));t.start()\n\n输出结果是：\n12(&#x27;valueA&#x27;, &#x27;valueB&#x27;)CandyLab\n\n下面我们将Timer和SubProcess混合使用：Timer不在subprocess.py里，是在threading.py中，wait()在阻塞主进程时，会不会阻塞Timer.\n先看一下 os.system和os.popen的区别，os.system是直接执行相应的系统命令，把输出结果返回到标准输出上，返回值就是一个表示调用状态的整数，而os.popen调用是返回的是一个对象，对象持出管道中输出的内容，而不是直接输出到stdout上。\n123456import osret = os.popen(&#x27;ls&#x27;)print ret.read()ret = os.system(&#x27;ls&#x27;)print ret \n\n看一下os.py中popen2的源码：\n123456789101112131415161718def popen2(cmd, mode=&quot;t&quot;, bufsize=-1):    &quot;&quot;&quot;Execute the shell command &#x27;cmd&#x27; in a sub-process.  On UNIX, &#x27;cmd&#x27;    may be a sequence, in which case arguments will be passed directly to    the program without shell intervention (as with os.spawnv()).  If &#x27;cmd&#x27;    is a string it will be passed to the shell (as with os.system()). If    &#x27;bufsize&#x27; is specified, it sets the buffer size for the I/O pipes.  The    file objects (child_stdin, child_stdout) are returned.&quot;&quot;&quot;    import warnings    msg = &quot;os.popen2 is deprecated.  Use the subprocess module.&quot;    warnings.warn(msg, DeprecationWarning, stacklevel=2)    import subprocess    PIPE = subprocess.PIPE    p = subprocess.Popen(cmd, shell=isinstance(cmd, basestring),                         bufsize=bufsize, stdin=PIPE, stdout=PIPE,                         close_fds=True)    return p.stdin, p.stdout__all__.append(&quot;popen2&quot;)\n\n通过源码可以看出来， 其内部调用的还是subprocess.Popen，既然是这样，在某些场合其实不用再去调用subprocess，直接调用os.popen也是可以的方案之一。\n接下来，我们就看subproces中的Popen, subprocess中，已经对Popen这个类有了很多的注释，下面是原文：\nclass Popen(args, bufsize=0, executable=None,            stdin=None, stdout=None, stderr=None,            preexec_fn=None, close_fds=False, shell=False,            cwd=None, env=None, universal_newlines=False,            startupinfo=None, creationflags=0):\nArguments are:\nargs should be a string, or a sequence of program arguments.  Theprogram to execute is normally the first item in the args sequence orstring, but can be explicitly set by using the executable argument.\nOn UNIX, with shell=False (default): In this case, the Popen classuses os.execvp() to execute the child program.  args should normallybe a sequence.  A string will be treated as a sequence with the stringas the only item (the program to execute).\nOn UNIX, with shell=True: If args is a string, it specifies thecommand string to execute through the shell.  If args is a sequence,the first item specifies the command string, and any additional itemswill be treated as additional shell arguments.\n从调用时序上来看，在声明Popen对象时，在__init__函数就调用了_execute_child函数， 而_execute_child函数，靠的就是用 os.execvp() 来调用子程序。\n我们节选一下Popen的代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384class Popen(object):    _child_created = False  # Set here since __del__ checks it    def __init__(self, args, bufsize=0, executable=None,                 stdin=None, stdout=None, stderr=None,                 preexec_fn=None, close_fds=False, shell=False,                 cwd=None, env=None, universal_newlines=False,                 startupinfo=None, creationflags=0):        &quot;&quot;&quot;Create new Popen instance.&quot;&quot;&quot;        _cleanup()        if not isinstance(bufsize, (int, long)):            raise TypeError(&quot;bufsize must be an integer&quot;)        if mswindows:            if preexec_fn is not None:                raise ValueError(&quot;preexec_fn is not supported on Windows &quot;                                 &quot;platforms&quot;)            if close_fds and (stdin is not None or stdout is not None or                              stderr is not None):                raise ValueError(&quot;close_fds is not supported on Windows &quot;                                 &quot;platforms if you redirect stdin/stdout/stderr&quot;)        else:            # POSIX            if startupinfo is not None:                raise ValueError(&quot;startupinfo is only supported on Windows &quot;                                 &quot;platforms&quot;)            if creationflags != 0:                raise ValueError(&quot;creationflags is only supported on Windows &quot;                                 &quot;platforms&quot;)        self.stdin = None        self.stdout = None        self.stderr = None        self.pid = None        self.returncode = None        self.universal_newlines = universal_newlines        (p2cread, p2cwrite,         c2pread, c2pwrite,         errread, errwrite), to_close = self._get_handles(stdin, stdout, stderr)        try:            self._execute_child(args, executable, preexec_fn, close_fds,                                cwd, env, universal_newlines,                                startupinfo, creationflags, shell, to_close,                                p2cread, p2cwrite,                                c2pread, c2pwrite,                                errread, errwrite)        except Exception:            # Preserve original exception in case os.close raises.            exc_type, exc_value, exc_trace = sys.exc_info()            for fd in to_close:                try:                    if mswindows:                        fd.Close()                    else:                        os.close(fd)                except EnvironmentError:                    pass            raise exc_type, exc_value, exc_trace        if mswindows:            if p2cwrite is not None:                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)            if c2pread is not None:                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)            if errread is not None:                errread = msvcrt.open_osfhandle(errread.Detach(), 0)        if p2cwrite is not None:            self.stdin = os.fdopen(p2cwrite, &#x27;wb&#x27;, bufsize)        if c2pread is not None:            if universal_newlines:                self.stdout = os.fdopen(c2pread, &#x27;rU&#x27;, bufsize)            else:                self.stdout = os.fdopen(c2pread, &#x27;rb&#x27;, bufsize)        if errread is not None:            if universal_newlines:                self.stderr = os.fdopen(errread, &#x27;rU&#x27;, bufsize)            else:                self.stderr = os.fdopen(errread, &#x27;rb&#x27;, bufsize)\n\n然后是在_execute_child函数中调用os.execvp() \n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142def _execute_child(self, args, executable, preexec_fn, close_fds,                   cwd, env, universal_newlines,                   startupinfo, creationflags, shell, to_close,                   p2cread, p2cwrite,                   c2pread, c2pwrite,                   errread, errwrite):    &quot;&quot;&quot;Execute program (POSIX version)&quot;&quot;&quot;    if isinstance(args, types.StringTypes):        args = [args]    else:        args = list(args)    if shell:        args = [&quot;/bin/sh&quot;, &quot;-c&quot;] + args        if executable:            args[0] = executable    if executable is None:        executable = args[0]    def _close_in_parent(fd):        os.close(fd)        to_close.remove(fd)    # For transferring possible exec failure from child to parent    # The first char specifies the exception type: 0 means    # OSError, 1 means some other error.    errpipe_read, errpipe_write = self.pipe_cloexec()    try:        try:            gc_was_enabled = gc.isenabled()            # Disable gc to avoid bug where gc -&gt; file_dealloc -&gt;            # write to stderr -&gt; hang.  http://bugs.python.org/issue1336            gc.disable()            try:                self.pid = os.fork()            except:                if gc_was_enabled:                    gc.enable()                raise            self._child_created = True            if self.pid == 0:                # Child                try:                    # Close parent&#x27;s pipe ends                    if p2cwrite is not None:                        os.close(p2cwrite)                    if c2pread is not None:                        os.close(c2pread)                    if errread is not None:                        os.close(errread)                    os.close(errpipe_read)                    # When duping fds, if there arises a situation                    # where one of the fds is either 0, 1 or 2, it                    # is possible that it is overwritten (#12607).                    if c2pwrite == 0:                        c2pwrite = os.dup(c2pwrite)                    if errwrite == 0 or errwrite == 1:                        errwrite = os.dup(errwrite)                    # Dup fds for child                    def _dup2(a, b):                        # dup2() removes the CLOEXEC flag but                        # we must do it ourselves if dup2()                        # would be a no-op (issue #10806).                        if a == b:                            self._set_cloexec_flag(a, False)                        elif a is not None:                            os.dup2(a, b)                    _dup2(p2cread, 0)                    _dup2(c2pwrite, 1)                    _dup2(errwrite, 2)                    # Close pipe fds.  Make sure we don&#x27;t close the                    # same fd more than once, or standard fds.                    closed = &#123; None &#125;                    for fd in [p2cread, c2pwrite, errwrite]:                        if fd not in closed and fd &gt; 2:                            os.close(fd)                            closed.add(fd)                    if cwd is not None:                        os.chdir(cwd)                    if preexec_fn:                        preexec_fn()                    # Close all other fds, if asked for - after                    # preexec_fn(), which may open FDs.                    if close_fds:                        self._close_fds(but=errpipe_write)                    if env is None:                        os.execvp(executable, args)                    else:                        os.execvpe(executable, args, env)                except:                    exc_type, exc_value, tb = sys.exc_info()                    # Save the traceback and attach it to the exception object                    exc_lines = traceback.format_exception(exc_type,                                                           exc_value,                                                           tb)                    exc_value.child_traceback = &#x27;&#x27;.join(exc_lines)                    os.write(errpipe_write, pickle.dumps(exc_value))                # This exitcode won&#x27;t be reported to applications, so it                # really doesn&#x27;t matter what we return.                os._exit(255)            # Parent            if gc_was_enabled:                gc.enable()        finally:            # be sure the FD is closed no matter what            os.close(errpipe_write)        # Wait for exec to fail or succeed; possibly raising exception        # Exception limited to 1M        data = _eintr_retry_call(os.read, errpipe_read, 1048576)    finally:        if p2cread is not None and p2cwrite is not None:            _close_in_parent(p2cread)        if c2pwrite is not None and c2pread is not None:            _close_in_parent(c2pwrite)        if errwrite is not None and errread is not None:            _close_in_parent(errwrite)        # be sure the FD is closed no matter what        os.close(errpipe_read)    if data != &quot;&quot;:        try:            _eintr_retry_call(os.waitpid, self.pid, 0)        except OSError as e:            if e.errno != errno.ECHILD:                raise        child_exception = pickle.loads(data)        raise child_exception\n最后我们模拟工程中的一段代码，测度wait()子程序，把主程序阻塞，会不会影响主进程的timer的计时：\n先一个subprocess.Popen\n1234567import shlexcmd_str=&#x27;ps -aux&#x27;#p=subprocess.Popen(args)p=subprocess.Popen(args,shell=True,stdout=subprocess.PIPE)out=p.stdout.readlines()print out\n\n在Popen初始形加，加入stdout的定义，所有命令行输出的文本会被定向到PIPE管道中。通过下面实际的例子，观察程序的结果：一种是timer是否能提示结束子程序，另一种是communicate是否能阻塞timer。\n12345678910111213141516171819202122import shlexfrom threading import Timerimport subprocesscmd_str=&#x27;ps -aux&#x27;def CandyLab(p):        print &quot;CandyLab&quot;        p.terminate()        returndef Orchina():        print &quot;Orchina&quot;        t = Timer( 1, Orchina);        t.start()        returnp=subprocess.Popen(&quot;python popentst.py&quot;,shell=True)t = Timer( 3, CandyLab, args=(p,));t.start()p.communicate()t.cancel\n\npopentst.py\n123import timetime.sleep(5)print &quot;sleep&quot;\n\ntest.py\n12345678910111213141516171819202122import shlexfrom threading import Timerimport subprocesscmd_str=&#x27;ps -aux&#x27;def CandyLab(p):        print &quot;CandyLab&quot;        #p.terminate()        returndef Orchina():        print &quot;Orchina&quot;        t = Timer( 1, Orchina);        t.start()        returnp=subprocess.Popen(&quot;python popentst.py&quot;,shell=True)t = Timer( 1, CandyLab, args=(p,));t.start()p.communicate()t.cancel\n\nTimer的时间比Sleep设置的时间短，如果阻塞timer，子程序的print应该先打印出来，结果没有。无论是commicate()还是wait()都是不能阻塞timer的，想用timer提前结束一个子程序，也要经过处理。\nTimer直接关联的类是Event,然后是Conditon，之后是Lock，太长不分析，本篇的最初的测试目地已经达到了。\n","slug":"old_topic/2016-09-17-268","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d2259f558f383bf9636ac7b5a9eaea5a","title":"ORC索引页显示的Lapis实现","content":"作者：糖果\nORC是是用LOR框架完成的，这次尝试实现用Lapis来实现，ORC索引页面的显示， 国为ORC是后端前端分开的， 实际上后端只要根据用输入返回按接口定义的JSON数据就好。\n这个实验会涉及到几个最学用的点：\n1.简单的用SQL对业务表进行left join，这个和语言平台无关。2.OR的LUA框架返回JSON, JSON数据的编解码。3.常规不使用ORM访问数据库。4.Lapis模板，在模板中进行子模板渲染。1234567891011121314151617181920local lapis = require &quot;lapis&quot;local app = lapis.Application()local db = require(&quot;lapis.db&quot;)app:enable(&quot;etlua&quot;)app:get(&quot;/topics/all&quot;, function(self)    page_no = 1    page_size = 10    category = 3      local sql = &quot;select t.*, c.name as category_name, u.avatar as avatar from topic t &quot; ..                                &quot;left join user u on t.user_id=u.id &quot; ..                                &quot;left join category c on t.category_id=c.id &quot; ..                                &quot;where t.category_id=1 &quot;    local res, err = db.query(sql)    return &#123; json = &#123; data = &#123;totalCount=&quot;54&quot;, currentPage=&quot;1&quot;,topics = res, totalPage=2&#125;, success=true &#125;&#125;end)return app\n\n\n值的注意的是，db.query(sql)返回的结果res本身就是JSON形式，不需要进入JSON编解码。  因为LORj框架是不提供ORM的，所以ORC所有返回接口几乎都是纯SQL。 因为Lapis的底层用的也是resty-mysql,他们之间执行SQL是兼容的。\n下面是节选的Lapis的Mysql库的源码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859    local mysql = require(&quot;resty.mysql&quot;)    return function(q)      if logger then        logger.query(q)      end      local db = ngx and ngx.ctx.resty_mysql_db      if not (db) then        local err        db, err = assert(mysql:new())        db:set_timeout(timeout)        local options = &#123;          database = database,          user = user,          password = password,          ssl = ssl,          ssl_verify = ssl_verify        &#125;        if path then          options.path = path        else          options.host = host          options.port = port        end        assert(db:connect(options))        if ngx then          ngx.ctx.resty_mysql_db = db          after_dispatch(function()            return db:set_keepalive(max_idle_timeout, pool_size)          end)        end      end      local start_time      if ngx and config.measure_performance then        ngx.update_time()        start_time = ngx.now()      end      local res, err, errcode, sqlstate = assert(db:query(q))      local result      if err == &#x27;again&#x27; then        result = &#123;          res        &#125;        while err == &#x27;again&#x27; do          res, err, errcode, sqlstate = assert(db:read_result())          table.insert(result, res)        end      else        result = res      end      if start_time then        ngx.update_time()        increment_perf(&quot;db_time&quot;, ngx.now() - start_time)        increment_perf(&quot;db_count&quot;, 1)      end      return result    end  end&#125;\n\n\n\nORC的前端代码，除了其它和这个实验不相关的Layout，主要的代码如下：\nmeta.etlua\n1&lt;script src=&quot;/static/js/juicer.js&quot;&gt;&lt;/script&gt;\n\n\n\n\n12345&lt;% render(&quot;views.meta&quot;) %&gt;&lt;script src=&quot;/static/js/index.js&quot;&gt;&lt;/script&gt;\n\n这里的index.js的代码也不是很多：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134(function (L) &#123;    var _this = null;    L.Index = L.Index || &#123;&#125;;    _this = L.Index = &#123;        data: &#123;            current_category: &quot;0&quot;        &#125;,        init: function (current_category) &#123;            _this.data.current_category = current_category || &quot;0&quot;;            _this.loadTopics(&quot;default&quot;);            //_this.loadTopics(&quot;ir-black&quot;);            _this.initEvents();        &#125;,/*        scrollTop: function () &#123;            $(&#x27;html, body&#x27;).animate(&#123;scrollTop: 0&#125;, 0);        &#125;,*/        initEvents: function () &#123;            $(document).on(&quot;click&quot;, &quot;#topic-type-tab a&quot;, function () &#123;                $(&quot;#topic-type-tab a&quot;).each(function () &#123;                    $(this).removeClass(&quot;active&quot;);                &#125;);                $(this).addClass(&quot;active&quot;);            &#125;);            $(&quot;#default-topics-btn&quot;).click(function () &#123;                _this.loadTopics(&quot;default&quot;);            &#125;);            $(&quot;#recent-reply-topics-btn&quot;).click(function () &#123;                _this.loadTopics(&quot;recent-reply&quot;);            &#125;);            $(&quot;#good-topics-btn&quot;).click(function () &#123;                _this.loadTopics(&quot;good&quot;);            &#125;);                                    $(&quot;#noreply-topics-btn&quot;).click(function () &#123;                _this.loadTopics(&quot;noreply&quot;);            &#125;);        &#125;,        loadTopics: function (type, pageNo) &#123;            pageNo = pageNo || 1;            $.ajax(&#123;                url: &#x27;/topics/all&#x27;,                type: &#x27;get&#x27;,                cache: false,                data: &#123;                    page_no: 1,                    type: type,                    category: _this.data.current_category                &#125;,                dataType: &#x27;json&#x27;,                success: function (result) &#123;                    if (result.success) &#123;                        if (!result.data || (result.data &amp;&amp; result.data.topics.length &lt;= 0)) &#123;                            $(&quot;#topics-body&quot;).html(&#x27;&lt;div class=&quot;alert alert-info&quot; role=&quot;alert&quot;&gt;此分类下没有任何内容&lt;/div&gt;&#x27;);                        &#125; else &#123;                            _this.page(result, type, 1);                        &#125;                    &#125; else &#123;                        $(&quot;#topics-body&quot;).html(&#x27;&lt;div class=&quot;alert alert-danger&quot; role=&quot;alert&quot;&gt;&#x27; + result.msg + &#x27;&lt;/div&gt;&#x27;);                    &#125;                &#125;,                error: function () &#123;                    $(&quot;#topics-body&quot;).html(&#x27;&lt;div class=&quot;alert alert-danger&quot; role=&quot;alert&quot;&gt;error to send request.&lt;/div&gt;&#x27;);                &#125;            &#125;);        &#125;,        page: function (result, type, pageNo) &#123;            var data = result.data || &#123;&#125;;            var $container = $(&quot;#topics-body&quot;);            $container.empty();            var tpl = $(&quot;#topic-item-tpl&quot;).html();            var html = juicer(tpl, data);            $container.html(html);            var currentPage = data.currentPage;            var totalPage = data.totalPage;            var totalCount = data.totalCount;            if (totalPage &gt; 1) &#123;                $(&quot;#pagebar&quot;).show();                $.fn.jpagebar(&#123;                    renderTo: $(&quot;#pagebar&quot;),                    totalpage: totalPage,                    totalcount: totalCount,                    pagebarCssName: &#x27;pagination2&#x27;,                    currentPage: currentPage,                    onClickPage: function (pageNo) &#123;                        $.fn.setCurrentPage(this, pageNo);                        $.ajax(&#123;                            url: &#x27;/topics/all&#x27;,                            type: &#x27;get&#x27;,                            cache: false,                            data: &#123;                                page_no: pageNo,                                type: type,                                category: _this.data.current_category                            &#125;,                            dataType: &#x27;json&#x27;,                            success: function (result) &#123;                                var data = result.data || &#123;&#125;;                                var $container = $(&quot;#topics-body&quot;);                                $container.empty();                                var tpl = $(&quot;#topic-item-tpl&quot;).html();                                var html = juicer(tpl, data);                                $container.html(html);                               // _this.scrollTop();                            &#125;,                            error: function () &#123;                                $(&quot;#topics-body&quot;).html(&#x27;&lt;div class=&quot;alert alert-danger&quot; role=&quot;alert&quot;&gt;error to find topics page.&lt;/div&gt;&#x27;);                            &#125;                        &#125;);                    &#125;                &#125;);            &#125; else &#123;                $(&quot;#pagebar&quot;).hide();            &#125;        &#125;    &#125;;&#125;(APP));\n\nORC并没有使用传统的框架分页器对象，结合框架模板语言来实现分页，LOR框架也暂时不提供这些功能。用的是Juicer前端模板来实现把后端返回的JSON数据的字段，渲染到前端的Layout标签中。\n123var tpl = $(&quot;#topic-item-tpl&quot;).html();var html = juicer(tpl, data);$container.html(html);\n\n\njuicer把data数据提供给了topic-item-tpl这个标签类，并在前端页面嵌入了 {@each topics as t}语法，取得JSON数据的值， t.title, t.avatar等。\n上面这段代码，把后端返回JSON数据返回在前端渲染，主要靠的是juicer。按目前ORC这种写法， 前后端都是通过JSON数据建立联系，ORM,Etlua标记，分页器这种中间模块都没用到。下面的实验就是把这些功能，应用到ORC上。\nPS:ORC=Openrest China\n下一篇实验是对ORC的内容页进行Lapis的代码实现移植。\n","slug":"old_topic/2016-09-17-269","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"fc17f56f18c6188c98c1c7bfedd06596","title":"ElasticSearch的LUA客户端","content":"作者：糖果\n从Github上看，有一位叫做Dhaval Kapil老师完成了ElasticSearch for Lua的工作，另一位来自阿根廷的叫做Cristian Haunsen的老师，完成了ElasticSearch for Lapis的客户端程序写作工作,dhavalkapil还有一个博客可以访问：dhavalkapil.com\n这次实验的目标，是测试一下本地直接运行ES for Lua，然后在Lapis中访问ES，我们的日志在ES，可以用Lua，也可以用Python完成ES的访问工作， Python没有问题，Lua就看这个实验了。\n测试代码，如下：\n123456789101112131415161718192021local elasticsearch = require &quot;elasticsearch&quot;local client = elasticsearch.client&#123;    hosts = &#123;      &#123; -- Ignoring any of the following hosts parameters is allowed.        -- The default shall be set        protocol = &quot;http&quot;,        host = &quot;localhost&quot;,        port = 9200      &#125;    &#125;,    -- Optional parameters    params = &#123;      pingTimeout = 2    &#125;&#125;-- Will connect to default host/portlocal client = elasticsearch.client()local data, err = client:info()\n\n\nFull list of params（全参数列表）:\npingTimeout : The timeout of a connection for ping and sniff request. Default is 1.selector : The type of selection strategy to be used. Default is RoundRobinSelector.connectionPool : The type of connection pool to be used. Default is StaticConnectionPool.connectionPoolSettings : The connection pool settings,maxRetryCount : The maximum times to retry if a particular connection fails.logLevel : The level of logging to be done. Default is warning.Getting info of elasticsearch server（取得ES服务器信息）1local data, err = client:info()\n\n\nIndex a document（创建索引文档）Everything is represented as a lua table.(一切皆为Lua Table)\n12345678local data, err = client:index&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;,  body = &#123;    my_key = &quot;my_param&quot;  &#125;&#125;\n\nGet a document（取得文档）12345data, err = client:get&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;&#125;\n\nDelete a document（删除文档）12345data, err = client:delete&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;&#125;\n\nSearching a document （检索文档）You can search a document using either query string:（使有查询字符进行检索）\n12345data, err = client:search&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  q = &quot;my_key:my_param&quot;&#125;\n\nOr either a request body:(或是请求体)1234567891011data, err = client:search&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  body = &#123;    query = &#123;      match = &#123;        my_key = &quot;my_param&quot;      &#125;    &#125;  &#125;&#125;\n\nUpdate a document（更新文档）12345678910data, err = client:update&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;,  body = &#123;    doc = &#123;      my_key = &quot;new_param&quot;    &#125;  &#125;&#125;\n\n原文\nPS：本文测式用代码都来自至官方ES-LUA的Github的Readme。\n","slug":"old_topic/2016-09-17-270","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"648f312df5b060ebee6fd3985469f698","title":"我与Coding的开发日常","content":"《我与Coding的开发日常》经历在那个时期，Paas云、虚拟机、Docker、VPS，本地服务，然后连上SSH，打开编辑器，让电流信号穿过各种这些设备。那时有一个梦想，如果有一天，只需要一个简单终端，就可以进入丰富的服务器资源世界，忘记各种平台参数配置，用键盘打开一扇通向乌托邦世界的门，那是你想要到的地方。\n有时就是这么的神奇，突如其来的想法，就是想看看coding.net这个域名被用来做什么， 结果就结识了coding。那时国内还有其它同类的代码托管平台，比如Gitcafe,特有的绿界面，管理之前代码，如果用现在流行的话，Coding的界面风格，在当时就像一股清新的洪流，只要一个浏览器，你想要做的事，几乎都可以在WEB IDE下完成，这无限的接近了，当初理想的服务器开发环境状态，新建一个环境，只需要在控制台上，点几下按钮就完成了。\n那时，用coding提供的环境，做各种实验，简直如鱼得水，还留下了几篇以Coding为背景的博文。\n点滴记录（博客就是这么来的）\n经常性的使用WEB IDE对vim进行测试，很灵活。VIM的IDE实验记\n\n在coding上部署C,Lua开发环境很轻松。Lua中脚本中加载.so库\n\nLapis是一个Lua web框架，飞快速度就能的WEB IDE中搭建WEB服务。WEB IDE环境运行Lua网页应用\n\n用GoTTY可以扩展WEB IDE里人terminal。GoTTY简介：共享字符终端，变网页应用\n\n在WEB IDE中测试Python三大框架，全部通过。如何创建部署WSGI类型的（Django, Tornado, Flask）Python应用\n\nCoding其实是可以很好的支持SVN的。在Coding.net上使用SVN部署代码\n\n\n\n私有项目（赚点外快）WEB IDE不断的升级，配置起来就越发方便，而当听到Gitcafe和Coding合并的消息时，又开启一个新的时期，之前在Gitcafe里的代码，同时也是可以做到在coding里部署运行的，这样一来，直接把Gitcafe的代码轻松导入，统一管理。与某个团体的合作也是在Coding上完成的，在项目中加入冒泡功能后，我们又在项目中自由讨论，涉及到客户信息，就不具体说了，总之用赚了外快。\n开源项目（小伙伴的集散地）随着Coding愈发强大，我们也把开源社区里小伙伴从Github上拉来，拉入Coding,一个特有的原因就是，在coding下，我们可以管理文件发任务，分享共享开发环境。\n2016年初，在Openresty社区环境下，开源社区小伙伴有Lua开发一个web框架，一个社区软件。\n\nOpenresty China后来这个项目上线了，就是现在的orchina.org\n\nLOR框架我们方便在coding的WEB-IDE下共享我们的开发环境，节省时间，高效。\n\nPages服务（Coding上奔跑的博客）coding不只是平时开发独立项目和测试用的，Coding同时还可以做成发布平台，在Coding上，应用Coding Pages服务创建自己的博客，也成为一种博客创建的可行方案，当时把Coding Pages服务搭建的过程也记录了下来：\n[使用Pages服务创建静态博客(上)]http://lua.ren/topic/215/%E4%BD%BF%E7%94%A8pages%E6%9C%8D%E5%8A%A1%E5%88%9B%E5%BB%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2-%E4%B8%8A)使用Pages服务创建静态博客(下)\n\n现在应用Pages服务上线的一个站点，叫 MoonScript ，上面记载了一些Lua和Moonscript相关的内容。\n响应反馈（神回复）最开始反馈问题，运营美女们会第一时间反应，快到我都没反应过来她们已经有反应了的程度。提bug，是直接的方式是用冒泡的，复杂的问题就直接建立一个项目，上传数据，后来冒泡支持打赏功能了，突然一天来了一个消息， @八哥 的打赏了。\n有一次给@八哥反馈问题：我在公司发消息，他会回。我在回家的路上发消息，他会回。我到家了发消息，他会回。我上床用手机coding发消息，他还会回。…….\nMarkdown写作平台\n这篇文章的诞生就是在coding平台上，我项目的“文件”里创建了这篇Markdown,同时共享了这篇文章，之后会同步到用Coding的Pages服务搭建的网站moonscirpt.cn上，也发布了这篇文章。\n冒泡里的互动（Happy Coding）花样编码\n各种互动\n八哥打赏了\n其实，还有很多和coding有关的故事，就这样不知道不觉中，coding已经两岁吧，这过程中亲眼经历了coding一天天的功能的丰满， 冒泡里的红火人气，刷coding已经是每天的例行内容，已经把很多其他平台的项目都搬家到了coding，coding已经变成了一个工作开始的起点，一个愈发强大的平台，祝福coding，谢谢coding，一直以来为大家带来的这一切！\n","slug":"old_topic/2016-09-17-271","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3a13d5b5280559c0590f0f89fa75e589","title":"OSSEC常用操作","content":"\n系统类型是  CentOS\n\n修改启动脚本使 OSSEC HIDS 在系统启动时自动运行 \n\n已正确完成系统配置.\n\n要启动 OSSEC HIDS:\n /var/ossec/bin/ossec-control start\n\n\n要停止 OSSEC HIDS:\n /var/ossec/bin/ossec-control stop\n\n\n要查看或修改系统配置,请编辑  /var/ossec/etc/ossec.conf\n\n\n\n系统类型是  CentOS Linux.\n\n修改启动脚本使 OSSEC HIDS 在系统启动时自动运行 \n\n已正确完成系统配置.\n\n要启动 OSSEC HIDS:\n /var/ossec/bin/ossec-control start\n\n\n要停止 OSSEC HIDS:\n /var/ossec/bin/ossec-control stop\n\n\n要查看或修改系统配置,请编辑  /var/ossec/etc/ossec.conf\n\n\n","slug":"old_topic/2016-09-17-272","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"0550bcc982fec659342e6f2a412d44ab","title":"HoneyMap的hpfeeds-cleint命令行使用方法","content":"作者：糖果\nhpfeeds-client是一个Python写的客户端程序。\n第一种是在世界地图上，点亮一个点：\n1hpfeeds-client --host localhost  -p 10000 -i honeymap -s cfdd6a68be69464666ae60b66dae69f6 -c geoloc.events publish &quot;&#123;countrycode:&#x27;NA&#x27;, latitude:37.7749, longitude:-122.4194, city:&#x27;San Francisco&#x27;&#125;&quot;\n\n另一种是在世界地图上，点亮二个点：\n12hpfeeds-client --host localhost  -p 10000 -i geoloc -s cfdd6a68be69464666ae60b66dae69f6 -c geoloc.events publish &#x27;&#123;&quot;countrycode&quot;:&quot;NA&quot;, &quot;latitude&quot;:37.7749, &quot;longitude&quot;:-122.4194, &quot;city&quot;:&quot;San Francisco&quot;,&quot;countrycode2&quot;:&quot;NA&quot;, &quot;latitude2&quot;:37.7749, &quot;longitude2&quot;:50.4194, &quot;city2&quot;:&quot;Bei Jing&quot;&#125;&#x27;","slug":"old_topic/2016-09-17-273","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"92cca58992d4502022c1dbbf5585cfdb","title":"又见QT","content":"MinGW\nhttps://sourceforge.net/projects/mingw/?source=top3_dlp_t5\nPyQT5\nhttps://riverbankcomputing.com/software/pyqt/download5\nPyQT4\nhttps://www.riverbankcomputing.com/software/pyqt/download\nqt\nhttp://36.110.79.137/AESd/Nu624VeIMKxH7LxH3K5_/official_releases/online_installers/qt-unified-windows-x86-online.exe\nhttp://download.qt.io/official_releases/online_installers/qt-unified-windows-x86-online.exe.mirrorlist\nhttp://download.qt.io/development_releases/qt/5.3/5.3.0-rc/\nQFTP\nhttps://qt.gitorious.org/qt/qtftp\n","slug":"old_topic/2016-09-17-274","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ac0402ecf46546727fdbca4cc5ec0bdf","title":"Lua获取网络时间","content":"作者：ani_di版权所有，转载务必保留此链接 http://blog.csdn.net/ani_di\nLua获取网络时间网络授时服务是一些网络上的时间服务器提供的时间，一般用于本地时钟同步。 授时服务有很多种，一般我们选择RFC-868。这个协议的工作流程是：（S代表Server，C代表Client）\nS: 检测端口37U: 连接到端口37S: 以32位二进制数发送时间U: 接收时间U: 关闭连接S: 关闭连接协议非常简单，用TCP连接上后，服务器直接把时间发送回来。发送的是从1900年1月1日午夜到现在的秒数。\n使用luasocket实现的方案有很多种，Lua不一定是最简单的，选择只是出于个人兴趣。直接上代码吧\n\n– Network Time Protocal– Author: ani_di\n\n源码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package.cpath = package.cpath .. &#x27;;D:\\\\tools\\\\Lua\\\\5.1\\\\clibs\\\\?.dll;?.dll&#x27;local socket = require &quot;socket.core&quot;server_ip = &#123;        -- &quot;129.6.15.29&quot;,        &quot;132.163.4.101&quot;,        &quot;132.163.4.102&quot;,        &quot;132.163.4.103&quot;,        &quot;128.138.140.44&quot;,        &quot;192.43.244.18&quot;,        &quot;131.107.1.10&quot;,        &quot;66.243.43.21&quot;,        &quot;216.200.93.8&quot;,        &quot;208.184.49.9&quot;,        &quot;207.126.98.204&quot;,        &quot;207.200.81.113&quot;,        &quot;205.188.185.33&quot;&#125;function nstol(str)    assert(str and #str == 4)    local t = &#123;str:byte(1,-1)&#125;    local n = 0    for k = 1, #t do        n= n*256 + t[k]    end    return nend-- get time from a ip address, use tcp protoclfunction gettime(ip)    print(&#x27;connect &#x27;, ip)    local tcp = socket.tcp()    tcp:settimeout(10)    tcp:connect(ip, 37)    success, time = pcall(nstol, tcp:receive(4))    tcp:close()    return success and time or nilendfunction nettime()    for _, ip in pairs(server_ip) do        time = gettime(ip)        if time then             return time        end    endend\n\n代码原理不细说，非常简单。唯一值得一提的是socket库包含。最开始用的这句 require “socket”\n在解释器中表现很好，但在用C中调用会找不到相应的module。错误提示\nno field package.preload[&#39;socket&#39;]\nno file &#39;.\\socket.lua&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\lua\\socket.lua&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\lua\\socket\\init.lua&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\socket.lua&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\socket\\init.lua&#39;\nno file &#39;D:\\tools\\Lua\\5.1\\lua\\socket.luac&#39;\nno file &#39;.\\socket.dll&#39;\nno file &#39;.\\socket51.dll&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\socket.dll&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\socket51.dll&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\clibs\\socket.dll&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\clibs\\socket51.dll&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\loadall.dll&#39;\nno file &#39;F:\\Projects\\Lua\\nettime\\clibs\\loadall.dll&#39;.\n\n网上也有好多类似的提问，大抵是没仔细看作者的Guide。显著的有这么一句\nThe other two environment variables instruct the compatibility module to look for dynamic libraries and extension modules in the appropriate directories and with the appropriate filename extensions.&gt;\nLUAPATH=/?.lua;?.lua LUACPATH=/?.dll;?.dll\n至于”socket.core”，windows默认安装位于“\\socket\\core.dll”。\nC宿主调用\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;lua.h&gt;#include &lt;lauxlib.h&gt;#include &lt;lualib.h&gt;#include &lt;time.h&gt;#include &lt;Windows.h&gt;int load(lua_State* L, const char* func, unsigned int* utc) &#123;   lua_getglobal(L, func);   if (lua_pcall(L, 0, 1, 0)) &#123;        printf(&quot;Error Msg pcall %s.\\n&quot;, lua_tostring(L, -1));        return -1;   &#125;   if (!lua_isnumber(L,-1)) &#123;       printf(&quot;time should be a number\\n&quot; );       return -2;   &#125;   *utc = lua_tonumber(L,-1);   lua_pop(L, -1);   return 0;&#125;void TimetToFileTime( time_t t, LPFILETIME pft )&#123;    LONGLONG ll = Int32x32To64(t, 10000000) + 116444736000000000;    pft-&gt;dwLowDateTime = (DWORD) ll;    pft-&gt;dwHighDateTime = ll &gt;&gt;32;&#125;int main()&#123;   lua_State* L = luaL_newstate();   unsigned int utc = 0;   luaL_openlibs(L);  if (luaL_loadfile(L, &quot;nettime.lua&quot;) || lua_pcall(L, 0, 0, 0)) &#123;       printf(&quot;Error Msg load %s.\\n&quot;, lua_tostring(L, -1));       return -1;   &#125;   do &#123;    if(load(L,&quot;nettime&quot;, &amp;utc) == 0) &#123;        time_t tt = utc - 2208988800L;        SYSTEMTIME st;        FILETIME ft;        TimetToFileTime(tt, &amp;ft);        if (FileTimeToSystemTime(&amp;ft, &amp;st))        &#123;            printf(&quot;Today is: %d-%d-%d\\n&quot;, st.wYear, st.wMonth, st.wDay);            SetSystemTime(&amp;st);        &#125;        break;    &#125; else &#123;        puts(&quot;No network!&quot;);        Sleep(10000);    &#125;   &#125; while (1);   lua_close(L);   return 0;&#125;\n\n糖果收集编辑\n","slug":"old_topic/2016-09-17-275","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a7777311d1e67a84d45b8c65389d0ce5","title":"微博API发送微博","content":"使用微博的API和SDK的其中的关键一步是取得token. 而取得token是需要通过oauth2认证才可以得到。\n下面是一段取得token的代码逻辑：\n123456789APP_KEY =&#x27;012345678&#x27;APP_SECRET = &#x27;01234567891011121314151617181920&#x27;CALL_BACK= &#x27;http://www.lua.ren/callback&#x27;client = weibo.APIClient(APP_KEY, APP_SECRET, CALL_BACK)auth_url = client.get_authorize_url()login_url = &#x27;https://api.weibo.com/oauth2/authorize&#x27;params = urllib.urlencode(&#123;&#x27;action&#x27; : &#x27;submit&#x27;,&#x27;response_type&#x27; : &#x27;code&#x27;,&#x27;redirect_uri&#x27; : CALL_BACK,&#x27;client_id&#x27; : APP_KEY,&#x27;userId&#x27; : &#x27;userid&#x27;,&#x27;passwd&#x27; : &#x27;password&#x27;,&#125;)url = client.get_authorize_url()\n\n\nAPP_KEY各APP_SECRET是申请OPEN API时被分配的，CALL_BACK是在微博开放API后台自定义的，当你用浏览器访问client.get_authorize_url()函数返回的url时，微博开发接口会调用这个callback的url，调用中包含了code这个字段，通过code可以取得token。\n只有取得了token之后，才可以正常的访问微博的API。\n代码如下：\n12r = client.request_access_token(code)client.set_access_token(r.access_token, r.expires_in)\n\n\n发送微博代码：\n123content = &#x27;test&#x27;if content:    client.statuses.update.post(status=content)","slug":"old_topic/2016-09-17-276","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"65ce57f5fdb9c6ca938fd44776fc3ed9","title":"TMUX最常用操作命令","content":"作者：糖果\n一般情况下，当你用SSH链接VPS，然后关掉terminal的操作窗口时，所有的当前操作都结束了。而如果用TMUX,当前正在运行的非后台操作会话还会存在，下面是TMUX最常用的操作了。\n1.创建新会话tmux new -s  candylab\n2.选择新会话tmux attach -t  candylab\n3.显示会话列表tmux ls\n4.翻页Ctrl + b + (PageUp PageDown)\n5.退出当前tmux会话Ctrl + b + d是退出当前会话，但是用tmux ls盾，这个会话，还是会存在的，如果exit命令,当前的tmux会话就彻底结束了，tmux ls中也少了当前的会话。\n6.上下分屏Ctrl + b + %\n7.左右分屏Ctrl + b + “\n8.重命名当前会话Ctrl + b + $ 重命名session\n糖果实验室\n1.花园黄金牧场婴儿奶粉1段新生儿0-6个月宝宝100g小罐试用\n2.屁屁乐护臀霜60g 婴儿护臀膏 新生儿护臀霜PP乐 针对宝宝PP护理\n3.加菲猫 婴儿橄榄油 宝宝润肤油新生儿BB油 保湿抚触按摩油 不油腻\n4.壹裤超薄款婴儿纸尿裤 干爽透气 四码任选S/M/L/XL男女宝宝尿不湿\n5.拖鞋女夏家居室内浴室防滑洗澡托鞋地板情侣男居家家用凉拖鞋可爱\n6.美孕嘉 孕产妇产褥垫产妇护理垫一次性床单防水看成人护垫20片\n7.欧思朵孕产妇产褥垫护理垫一次性床单床垫防水看护垫老人垫10片装\n8.一次性医用塑料脸盆 家用塑料脚盆 医用洗脸塑料盆加厚便盆\n9.爱得利产妇卫生巾产后妇婴两用巾纸孕妇产褥期大号月子恶露专用\n10.鲁茜电动吸奶器 自动挤奶器吸乳器 孕产妇拔奶器 吸力大静音产后\n11.子初宝宝湿巾婴儿润肤柔湿巾手口湿巾纸新生儿bb湿纸巾80抽带盖\n12.纱布口水巾婴儿洗脸巾小毛巾纯棉宝宝小方巾新生儿手绢婴幼儿手帕\n","slug":"old_topic/2016-09-17-277","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f9e8867ab3929a213362390d7a6ff2ff","title":"Lua的Require理解","content":"作者：ms2008\n整理编辑：糖果\n在 lua 中加载的其他文件的代码，通常可以使用 dofile、loadfile、require 函数等来完成。其中 dofile 每次加载都要编译执行，效率比较低，所以不推荐使用；同样 loadfile 虽然只需编译一次，但是并没有把结果缓存到 lua vm 中；因而，我们这里总是推荐使用第三种方式 require。\nrequire 能够避免多次重复加载模块，一个模块被加载后会被缓存到 pacakge.loaded。 如果需要重新加载模块，可以清理 package.loaded.test = nil。\n需要注意的是，require() 函数并没有使用全局变量，它是在 package.loaded 表里缓存已经加载的 Lua module 的。而 package.loaded 是挂载在 Lua VM 的 registry 表里的，不同于全局变量的环境表。\n另外：\nLua module 不一定是 table，也可以是 function，只是 table 比较常见罢了。function 的一个例子是 LuaJIT 2.1 的 require(“table.new”).在 Lua module 文件里的顶层作用域里声明的 local 变量一般会通过 upvalue 的形式挂载到 Lua module 里使用到这些变量的 function 里，而这些 function 一般会注册到 Lua module 的 table 里面，或者进一步以 upvalue 的形式挂载到这样的其他 function 中\n所以，lua module 的顶层作用域是不可以用来声明需要变动的值的。并且，在 Lua 里加载模块的正确方式是：\nlocal foo = require “foo”\n直接写：\nrequire “foo”\n其实是错误的，因为它依赖于 module() 函数创建和模块同名的 Lua 全局变量的副作用。而使用 module() 函数在 Lua 社区里也是不推荐的（以至于 Lua 5.2 语言里干脆移除了 module 这个内建函数）。\n最后，lua 的 vm 和 luajit 的 vm 有些行为是不同的，这一点在 or 的 github 就有提到：\nAs the standard Lua 5.1 interpreter’s VM is not fully resumable, the methods ngx.location.capture, ngx.location.capture_multi, ngx.redirect, ngx.exec, and ngx.exit cannot be used within the context of a Lua pcall() or xpcall() or even the first line of the for … in … statement when the standard Lua 5.1 interpreter is used and the attempt to yield across metamethod/C-call boundary error will be produced. Please use LuaJIT 2.x, which supports a fully resumable VM, to avoid this.\n原文链接\n","slug":"old_topic/2016-09-17-278","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d50433282a5b8a29764977173d70c1a2","title":"Tail Call 到底有啥用？","content":"作者：ms2008\n整理编辑：糖果\n在聊今天这个话题之前，我们需要知道什么叫 tail call。先来看下，lua 程序设计是怎么定义的：\n尾调用是一种类似在函数结尾的 goto 调用，当函数最后一个动作是调用另外一个函数时，我们称这种调用尾调用。例如：\nfunction f(x)    return g(x)end\ng 的调用是尾调用。\n例子中 f 调用 g 后不会再做任何事情，这种情况下当被调用函数 g 结束时程序不需要返回到调用者 f；所以尾调用之后程序不需要在栈中保留关于调用者的任何信息。一些编译器比如 Lua 解释器利用这种特性在处理尾调用时不使用额外的栈，我们称这种语言支持正确的尾调用。\n由于尾调用不需要使用栈空间，那么尾调用递归的层次可以无限制的。\n是不是有些迷糊？那我继续来解释下「详情可以参考廖雪峰的blog」：\n我们知道在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。递归函数的优点是定义简单，逻辑清晰。但是使用递归函数有个要命的缺点就是需要注意防止栈溢出！\n在计算机中，函数调用是通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。可以试试这个求阶乘的用例：\n\n解决递归调用栈溢出的方法是通过尾递归优化。尾递归是指，在函数返回的时候，调用自身本身，并且，return 语句不能包含表达式。这样，编译器或者解释器就可以把尾递归做优化，使递归本身无论调用多少次，都只占用一个栈帧，不会出现栈溢出的情况。\n上面的 fact(n) 函数由于 return n * fact(n - 1) 引入了乘法表达式，所以就不是尾递归了。要改成尾递归方式，需要多一点代码，主要是要把每一步的乘积传入到递归函数中：\n\n可以看到，return fact_iter(n-1, nown) 仅返回递归函数本身，n-1 和 nown 在函数调用前就会被计算，不影响函数调用。\n任何递归函数都存在栈溢出的问题。尾递归调用时，如果做了优化，栈不会增长，因此，无论多少次调用也不会导致栈溢出。这也正是 tail call 的威力所在。\n遗憾的是，大多数编程语言没有针对尾递归做优化，当然 lua 除外 :)\n","slug":"old_topic/2016-09-17-279","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"34fb78ae79ed28901f3aef22da440208","title":"OpenResty 中的连接池","content":"OpenResty 中的连接池\n作者：ms2008编辑整理：糖果\n注：set_keepalive 和 close 互斥(一个 socket 对象不能执行多次 setkeepalive 操作，会报：连接已关闭)\n连接池的大小是对每一个 nginx worker 而言的。如果有 N 个 worker，最多就会有 N * pool_size 个连接。比如设置 keepalive=100，开始启动时候是0连接来一个请求，获取一个 socket(空闲的)，完成请求后，socket&lt;100 时候，就把 socket 放到池子里。每当新请求来的时候，先去池子里面获取空闲 socket，如果获取不到就创建新连接，完成请求后，新连接的数量如果超过设置的 keepalive 值就不放池子里面了。当并发连接数大大超过了连接池的容量，就会产生很多的短连接，此时就应该增加连接池的大小。\n连接池常见问题及调试方法：\n在测试时配置了 lua_code_cache off，即禁用了 Lua 代码缓存，此时连接池的生命期是每请求的，因为 cosocket 连接池是在 Lua VM 里面分配的，而在禁用 Lua 代码缓存时，Lua VM 是每请求一个实例。ngx_drizzle 模块的连接池实现并不受 Lua 代码缓存的影响（出于显而易见的原因）。调试的办法是启用 lua_code_cache（默认开启）。\n调用 set_keepalive() 方法时传入的 max_idle 参数较短（比如示例代码里的 10 秒），这意味着空闲连接在连接池里只会最久逗留这么长的时间，超过就被自动关闭（除非在此之前又为其他请求所复用）。于是你手工在命令行上先运行 ab，再运行 netstat 命令时，这中间的时间窗口很容易超出 max_idle 限制。而 ngx_drizzle 模块并没有 max idle 保护这个功能。调试的办法是使用 0 作为 max_idle，让连接池里的空闲连接永不过期（除非 MySQL server 自己主动关闭或者 nginx 进程退出）。\n使用的 MySQL 查询会返回多个结果集，而默认 query() 方法只会读取并返回第一个结果集，你需要在 query() 方法返回 “again” 这个错误字符串时，自己继续调用 read_result() 方法，直至不再返回 “again” 错误串。如果你在没有读取所有结果集之前就调用 set_keepalive() 方法，连接池一般会拒绝接收这样的连接，因为该连接的读取缓冲区里还有未读完的数据，此时允许其他会话复用该连接的话，会导致难以调试的错误。调试的办法是，总是对 set_keepalive() 的返回值进行恰当的错误处理，并把错误记入 nginx 错误日志。\n值得一提的是，nginx 的多 worker 进程模型并不像 Apache prefork mpm 或者 php-fpm 那样，即并不是一个 worker 进程对应一个下游连接。nginx 的多 worker 进程只是为了用满多个 CPU 核而已，每个 worker 进程可以处理很多的并发连接。ngx_lua 的连接池和 nginx 核心中针对 upstream 模块的连接池一样是在每一个 worker 进程的级别上由许多并发连接共享的。\n原文连接\n","slug":"old_topic/2016-09-17-280","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"25b1e87350d6efc1b47c2b7e104bcc7d","title":"OpenResty China的登陆处理与发贴限制","content":"作者：糖果\nOpenresty China是饭总之前创建，现在由我来维护一个线上的版本。最开始的时候，对于orchina.org的用户来说的，是有三天内不能发贴的限制的，但之后我们想用一个用户激活的标志来控制是否允许用户发帖，从路由和视图几角度来看，如下：\n1.Login登陆模块。\n Openresty China用的是Lor框架，封装出了Session功能：\n/app/routes/auth.lua 这个文件中，集中处理了登陆登出的功能， 在登陆时，在session保存了一个变量，用于之后是否可发贴的判断逻辑。\n123456789101112131415161718192021222324252627282930313233343536373839404142auth_router:post(&quot;/login&quot;, function(req, res, next)    local username = req.body.username     local password = req.body.password    if not username or not password or username == &quot;&quot; or password == &quot;&quot; then        return res:json(&#123;            success = false,            msg = &quot;用户名和密码不得为空.&quot;        &#125;)    end    local isExist = false    local userid = 0    password = utils.encode(password .. &quot;#&quot; .. pwd_secret)    local result, err = user_model:query(username, password)    local user = &#123;&#125;    if result and not err then        if result and #result == 1 then            isExist = true            user = result[1]             userid = user.id        end    else        isExist = false    end    if isExist == true then        req.session.set(&quot;user&quot;, &#123;            username = username,            userid = userid,            create_time = user.create_time or &quot;&quot;,            is_active = user.is_active        &#125;)        return res:json(&#123;            success = true,            msg = &quot;登录成功.&quot;        &#125;)    else        return res:json(&#123;            success = false,            msg = &quot;用户名或密码错误，请检查!&quot;        &#125;)    endend)\n\n首先是判断是否有登陆这个用户的ID，如果的确存在这个用户，就把这个用户的用户名，id,和create_time 用户创建时间保存到session中，这个数据的种子就是这这个时机埋的。 之后我们不用时间计算是否可以发展，引入is_active字段。\n1local result, err = user_model:query(username, password)\n整个发贴限制的流程中，只有这么一句从数据库中，读出数据的处理，然后设定到session。\n/app/model/user.lua\n1234function user_model:query(username, password)   local res, err =  db:query(&quot;select * from user where username=? and password=?&quot;, &#123;username, password&#125;)   return res, errend\n\n2.发表新文章的模块。发表新文章的一个地方，是在导航条上， /app/views/header.html\n12345678&lt;ul class=&quot;dropdown-menu&quot; role=&quot;menu&quot;&gt;    &lt;li class=&quot;&quot;&gt;&lt;a href=&quot;/user/&#123;&#123;locals.username&#125;&#125;/index&quot;&gt;我的主页&lt;/a&gt;&lt;/li&gt;    &lt;li class=&quot;&quot;&gt;&lt;div class=&quot;divider&quot;&gt;&lt;/div&gt;&lt;/li&gt;    &lt;li class=&quot;&quot;&gt;&lt;a href=&quot;/settings&quot;&gt;个人设置&lt;/a&gt;&lt;/li&gt;    &lt;li class=&quot;&quot;&gt;&lt;a href=&quot;/topic/new&quot;&gt;发布新文章&lt;/a&gt;&lt;/li&gt;    &lt;li class=&quot;&quot;&gt;&lt;div class=&quot;divider&quot;&gt;&lt;/div&gt;&lt;/li&gt;    &lt;li class=&quot;&quot;&gt;&lt;a rel=&quot;nofollow&quot; href=&quot;/auth/logout&quot;&gt;退出&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;\n\n“发布新文章”直接跳转的路由是/topic/new：\napp/routes/topic.lua\n123456789101112131415161718topic_router:get(&quot;/new&quot;, function(req, res, next)    local diff_days, diff, is_active  = utils.days_after_registry(req)--[[        if diff_days&lt;3 then        return res:render(&quot;error&quot;, &#123;            errMsg = &quot;注册时间不到3天，不允许发布文章&quot;        &#125;)    end--]]---[[    if  is_active == 0 then        return res:render(&quot;error&quot;, &#123;            errMsg = &quot;用户未激活，不能发布文章! 加入QQ群：522410959 进行激活。&quot;        &#125;)    end--]]        res:render(&quot;topic/new&quot;)end)\n\n最开始的逻辑，是用/app/libs/utils.lua中的days_after_registry，求出用户创建用户的天数，如果超过了三天，才可以发布文章，如果天数不够，就调用/app/views/error.html模板，把错误信息显示出来 。\nutils.lua\n123456789101112131415161718192021function _M.days_after_registry(req)    local diff = 0    local diff_days = 0 -- default value, days after registry    local is_active= 0    if req and req.session then        local user = req.session.get(&quot;user&quot;)        local create_time = user.create_time---[[        if create_time then            local now = date() -- seconds            create_time = date(create_time)            diff = date.diff(now, create_time):spandays()            diff_days = mfloor(diff)        end--]]        is_active = user.is_active        --diff_days = is_active     end    return diff_days, diff, is_activeend\n\ndays_after_registry函数中，取是session中的user信息，然后取得create_time和当前系统时间比较，返回差的天数。因为我们在数据库中新建了一个is_active字段单独存放用户是否要激活的状态数据，就不要进行这种时是计算了，直接取出is_active字段进行判断。\n1234567if  is_active == 0 then    return res:render(&quot;error&quot;, &#123;        errMsg = &quot;用户未激活，不能发布文章! 加入QQ群：522410959 进行激活。&quot;    &#125;)endres:render(&quot;topic/new&quot;)\n\n3.最后一步，显示出错信息。调用/app/views/error.html模板，把错误信息显示出来 。\n123456789101112131415161718192021222324252627&lt;body data-controller-name=&quot;sessions&quot;&gt;&#123;(header.html)&#125;&lt;div id=&quot;main&quot; class=&quot;main-container container&quot;&gt;    &lt;div class=&quot;row&quot; style=&quot;margin-top:30px;&quot;&gt;        &lt;div class=&quot;col-md-12&quot;&gt;            &lt;div class=&quot;panel panel-default&quot;&gt;                &lt;div class=&quot;panel-heading&quot;&gt;错误&lt;/div&gt;                &lt;div class=&quot;panel-body&quot;&gt;                   &lt;div class=&quot;panel-body markdown&quot;&gt;                        &#123;&#123; errMsg &#125;&#125;                    &lt;/div&gt;                &lt;/div&gt;            &lt;/div&gt;        &lt;/div&gt;    &lt;/div&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt;    $(document).ready(function()&#123;            &#125;);&lt;/script&gt;&#123;(footer.html)&#125;&lt;/body&gt;\n\n到此，这个机能调整完毕。\n","slug":"old_topic/2016-09-17-282","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3d930fa3cf2f5987b2f125f1dac087cf","title":"Python的命令行解析工具OptParse","content":"作者：糖果\n无论是用C语言，还是用Java，有时都会写一些命令行的工具，解析用户在命令输入的参数，而Python有自己特色的命令行参数解析库，就是optparse。hpfeed-cli的源码就是用optparse来解析命令行参数的，hpfeed是给威胁地图发送威胁数据的，使用的是hpfeed协议，hpfeed-cli是一个在terminal中直接运行的命令行程序，有着非常复杂的参数输入。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import sysimport optparseimport datetimeimport loggingimport stringdef main(opts, action, pubdata=None):    outfd = None    print action    print data    print options    return 0def opts():    usage = &quot;usage: %prog -i ident -s secret --host host -p port -c channel1 [-c channel2, ...] &lt;action&gt; [&lt;data&gt;]&quot;    parser = optparse.OptionParser(usage=usage)    parser.add_option(&quot;-c&quot;, &quot;--chan&quot;,    action=&quot;append&quot;, dest=&#x27;channels&#x27;, nargs=1, type=&#x27;string&#x27;,    help=&quot;channel (can be used multiple times)&quot;)    parser.add_option(&quot;--debug&quot;,    action=&quot;store_const&quot;, dest=&#x27;debug&#x27;,    help=&quot;enable debug log output&quot;, default=False, const=True)    options, args = parser.parse_args()    if len(args) &lt; 1:        parser.error(&#x27;You need to give &quot;subscribe&quot; or &quot;publish&quot; as &lt;action&gt;.&#x27;)    if args[0] not in [&#x27;subscribe&#x27;, &#x27;publish&#x27;, &#x27;sendfile&#x27;]:        parser.error(&#x27;You need to give &quot;subscribe&quot; or &quot;publish&quot; as &lt;action&gt;.&#x27;)    if options.debug:        logging.basicConfig(level=logging.DEBUG)    else:        logging.basicConfig(level=logging.CRITICAL)    action = args[0]    data = None    if action == &#x27;publish&#x27;:        data = &#x27; &#x27;.join(args[1:])    elif action == &#x27;sendfile&#x27;:        data = &#x27; &#x27;.join(args[1:])    return options, action, dataif __name__ == &#x27;__main__&#x27;:        options, action, data = opts()        try:                sys.exit(main(options, action, pubdata=data))        except KeyboardInterrupt:                sys.exit(0)\n\n\n从命令行输入的数据来看， 把数据归为三类：\n1.action(动作)2.data(动作对应的数据)3.options（动作具体的选项）以上的action其实是命令行定义的动作，简单说就是执行那种类型的命令，这个命令是命令行的子命令，理论上可以很多，而data就是执行action命令时需要的数据，这数据可以是一个列表。options也可以设置很多个，和option来设置命令执行的方式和区别。\n我们根据以上程序的设定来执行一下这个程序，在命令行输入：\n1python blog-client.py sendfile data_element1 data_element2 data_element3 -c channel --debug\n\n然后，分别看一个 ，action，data，options的值。\n123sendfiledata_element1 data_element2 data_element3&#123;&#x27;channels&#x27;: [&#x27;channel&#x27;], &#x27;debug&#x27;: True&#125;\n\naction是字符串：sendfiledata是列表：data_element1 data_element2 data_element3options是map列表：{‘channels’: [‘channel’], ‘debug’: True}这样我们就将用户命令行输入的参数都解析到适当的数据结构中了，接着要做的就是根据参数定义，执行我们业务逻辑代码。关于这个库的使用的API，几个：\n1234optparse.OptionParser(usage=usage)parser.add_optionparser.parse_argsparser.error\n\n这个可以结合代码，领会一下意思吧!\n","slug":"old_topic/2016-09-17-283","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"713e977b7d1b8fcae8cb4a255a6ea756","title":"Lua判断空表的正确姿势","content":"作者:ms2008\n编辑:糖果\n1if t == &#123;&#125; then\n\n这样的结果就是 t == {} 永远返回 false，是一个逻辑错误。因为这里比较的是 table t 和一个匿名 table 的内存地址。\n1if table.maxn(t) == 0 then\n\n\n这样做也不保险，除非 table 的 key 都是数字，而没有 hash 部分。\n1if next(t) == nil then\n\n\nnext 其实就是 pairs 遍历 table 时用来取下一个内容的函数。在项目的 module 中最好封装一下，免得 module 本地也有 next 函数。封装后判断的 lua table 是否为空的函数如下：\n123function table_is_empty(t)     return _G.next(t) == nil end\n\n\n糖果实验室编辑整理\n","slug":"old_topic/2016-09-17-284","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3da5126be99ac536e265734e0863e856","title":"VIM打开中文乱码","content":"今天在coding下用vim，打开含有中文的文件乱码，找了一下解决方案。\n在.vimrc中，加入下面的文件编码指定：\nset fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936set termencoding=utf-8set encoding=utf-8\n","slug":"old_topic/2016-09-17-285","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d0c8e98a99d762e5cd826b84f51c4857","title":"OpenrestyChina一个Merge引起的BUG","content":"作者：糖果\n因为在对应一个issue时，遗漏了reset_last_reply的最后一个形参last_reply_time，造成了主页列表的最后回复人无法显示。\n12345function topic_model:reset_last_reply(topic_id, user_id, user_name, last_reply_time) -- 更新最后回复人        local now = utils.now()        db:query(&quot;update topic set last_reply_id=?, last_reply_name=?, last_reply_time=? where id=?&quot;,                &#123;tonumber(user_id), user_name, last_reply_time, tonumber(topic_id)&#125;)end\n\n\n后来因为这个问题，不引发了一个计论就是，LOR到底是不是MVC结构的，或是说到底有没有C控制。\n","slug":"old_topic/2016-09-17-286","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"173cf106caf72fbe34b81903048e26a6","title":"用ORC自动生成的OpenResty配置文件和目录结构","content":"作者：糖果\nORC是LOR的本地改动版，可以通简单的命令快速的生成Openresty的配置文件和目录结构：\n安装ORC，然后执行下下面的操作：\n1.安装\nsudo sh install.sh\n2.生成工程\norc project testcase\n3.控制工程\n进入testcase目录\norc start dev\norc stop dev\norc reload dev\n","slug":"old_topic/2016-09-17-287","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"c6a3fbdf3ee60556386c48d2c1ba423b","title":"ORC的启动脚本的封装脚本","content":"这种是在生成shell的方式时，都shell的一种封装，尽量在shell用上去，看着简洁点。\n1234567891011121314151617181920212223242526272829#####################################################################                                                                                                     # usage:                                                                                                                                                                  # sh start.sh -- start application @dev                                                                                                                                   # sh start.sh $&#123;env&#125; -- start application @$&#123;env&#125;                                                                                                                                                                                                                                                                                                   # examples:                                                                                                                                                               # sh start.sh prod -- use conf/nginx-prod.conf to start OpenResty                                                                                                         # sh start.sh -- use conf/nginx-dev.conf to start OpenResty                                                                                                               #####################################################################                                                                                                                                                                                                                                                                               if [ -n &quot;$1&quot; ];then                                                                                                                                                           PROFILE=&quot;$1&quot;                                                                                                                                                          else                                                                                                                                                                          PROFILE=dev                                                                                                                                                           fi                                                                                                                                                                                                                                                                                                                                                  if  [ $2 = &quot;start&quot; ];then                                                                                                                                                     echo &quot;start&quot;                                                                                                                                                              sh ./build/start.sh $&#123;PROFILE&#125;                                                                                                                                        elif [ $2 = &quot;stop&quot; ];then                                                                                                                                                     echo &quot;stop&quot;                                                                                                                                                               sh ./build/stop.sh $&#123;PROFILE&#125;                                                                                                                                         elif [ $2 = &quot;reload&quot; ];then                                                                                                                                                   echo &quot;reload&quot;                                                                                                                                                             sh ./build/reload.sh $&#123;PROFILE&#125;                                                                                                                                       else                                                                                                                                                                          echo &quot;Input parameter error!&quot;                                                                                                                                         fi                                                                                                                                                                           ","slug":"old_topic/2016-09-17-288","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"bc567916c4dc0d8169bd26d18e348d36","title":"test","content":"作者：糖果\n因为在对应一个issue时，遗漏了reset_last_reply的最后一个形参last_reply_time，造成了主页列表的最后回复人无法显示。\n12345function topic_model:reset_last_reply(topic_id, user_id, user_name, last_reply_time) -- 更新最后回复人        local now = utils.now()        db:query(&quot;update topic set last_reply_id=?, last_reply_name=?, last_reply_time=? where id=?&quot;,                &#123;tonumber(user_id), user_name, last_reply_time, tonumber(topic_id)&#125;)end\n\n\n后来因为这个问题，不引发了一个计论就是，LOR到底是不是MVC结构的，或是说到底有没有C控制。\n","slug":"old_topic/2016-09-17-290","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"b7052f2cb0876a8891b2752d70c19ef0","title":"issues","content":"\ncategory: Guidesredirect_from:    - /docs/v0.4.0/guides/issues/    - /docs/latest/guides/issues/title: “常见问题”sort_title: “3”\n\nOrange依赖的OpenResty版本是多少？Orange的监控插件需要统计http的某些状态数据，所以需要编译OpenResty时添加--with-http_stub_status_module。由于使用了*_block指令，所以OpenResty的版本最好在1.9.7.3以上.\nstart.sh脚本无法启动检查OpenResty和lor是否安装成功。命令行要能直接执行Nginx -v和lord -v，并且Orange依赖的OpenResty版本应在1.9.7.3++，lor版本在v0.1.0+\n找不到libuuid.soOrange现在依赖libuuid来生成规则id，centos用户可尝试使用yum install  libuuid-devel安装，其他用户请自行google对应平台的安装方式。\n默认的Dashboard登录账户是什么？admin/orange_admin，登录后再修改或添加其他普通账户即可\n","slug":"old_topic/2016-09-17-292","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"34e290003619093bbec60504e43213d8","title":"contributing.md","content":"\ncategory: Guidesredirect_from:    - /docs/v0.4.0/guides/contributing/    - /docs/latest/guides/contributing/title: “参与开发”sort_title: “5”\n\n如何做？\nFork 源码\n\n克隆Fork后的仓库至你的电脑\n 1$ git clone https://github.com/&lt;username&gt;/orange.git\n创建一个特性分支\n 1$ git checkout -b new_feature\n在new_feature分支上对Orange进行修改\n\n提交分支:\n 1$ git push origin new_feature\n创建pull request， 并描述具体的改动\n\n\n注意事项\n应详细描述所做改动要解决的问题\n在收到PR时会第一时间审核并Merge你的改动，请确保改动的地方不存在排版等问题\n\n问题反馈在使用Orange过程中碰到任何问题，可以到 GitHub 上提问\n贡献者排名不分先后。\n\nsumory\n\n","slug":"old_topic/2016-09-17-294","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d8c0c50cf48649c0a5b21963dbcc373c","title":"usages","content":"\ncategory: Guidesredirect_from:    - /docs/v0.4.0/guides/usages/    - /docs/latest/guides/usages/title: “使用场景”sort_title: “2”\n\nOrange是基于插件设计的，基本思想是通过实现各种插件灵活的在Nginx的各个执行阶段进行逻辑处理。\nOrange提供的默认插件功能如下：\n\n全局的监控插件，可统计API访问情况、Nginx连接情况、流量统计、QPS等\n自定义监控，可根据配置的规则筛选监控项，统计其各个指标\nrewrite插件，可通过UI配置各种rewrite策略，省去手写nginx rewrite，然后重启的麻烦\nredirect插件，实现请求重定向功能\nHTTP Basic Authorization，为API动态配置鉴权\n简单地WAF应用防火墙，可提取各个请求参数，通过各种匹配规则甄别需要禁止的流量\n分流插件，可分为三个使用场景：\n作为proxy，如代理后端的多个HTTP应用\n用于AB测试\n用于动态分流，API版本控制等\n\n\n\n其它插件，用户可根据具体需要按规范编写即可。\n典型使用案例以下使用案例对于成体系、各职责/配置比较健全的团队来说可能并不存在，但仍可能具有一些参考意义。\nCase 1想象下面的场景：\n\n原来的Nginx配置文件中包含大量的rewrite语句，每次更改需要重启\n有时候rewrite特别难写，比如我需要把来自于某个Host并且uri以/user开头的请求rewrite到以/some_host/user开头，如果是在Nginx里写，一般要通过if判断Host，再rewrite，可能需要多次调试和reload才能成功。这对于有经验的运维或是开发可能并不是难事，但对刚接手的新人或是不熟悉Nginx的运维人员来说，就是一件头疼事儿了\n再想像一下，如果再加上几个限制条件，比如需要来自某些IP访问某个Host并且Header里含有某个标识变量的请求执行某个rewrite，Orz…\n原来对于某个移动端API，客户端已经发布了很多个版本，每个版本的该API内部实现可能都不太一样，如果需要后端去兼容这个更改，可能就需要在代码中添加大量的if/else，或者给同一个职责的API取不同的名字(其它更好的实践暂且不表)。长此以往，API的版本管理可能就是一团乱麻\n\n这时，通过Orange的rewrite/redirect插件就能很方便的解决这个问题，并且实时生效无需重启或是reload：\n\norange的rewrite/redirect规则配置非常简单，基本上只需要了解一些Nginx/lua正则表达式的知识即可解决上述场景中提到的问题，无须更改Nginx配置文件\norange可以提取请求中的各个变量或是标识，比如URI、Header、QueryString、Referer、Host等等，然后根据这些提取出来的值做匹配规则运算，匹配成功的就可以执行各种rewrite、redirect操作将uri变得更有条理，也更好管理。\n\nCase 2在内部系统中，大量模块或者异构的子系统之间都是通过HTTP交互的，这时不可避免的要引入一个七层负载，选型最多的基本上也就是Nginx了。对于内部网关的管理，可能存在的问题：\n\n由于是内部使用，运维对外网隔离比较严格，但内网隔离性可能就会略差，这是就可能发生内部服务API被调用者误调用或者乱调用的问题\n为了使用方便，内部的一些通用API是不需要鉴权的，但当需要排查问题的时候，如果有多个使用方，很难甄别到底是谁调用的\n\nOrange提供的WAF插件可以解决这个问题：\n\n如对API请求做白名单限制，白名单可以以比较常用的IP、Header作为判断条件\nOrange提供的默认插件都有Log功能，可将某条匹配规则的Log开启，这样出现问题时就可以根据匹配规则的Log，然后结合Nginx本身的访问日志来甄别流量来源了\n\nCase 3应用的AB测试或者流量切分，虽然业界已经有很多方案可供参考，各个公司或团队也有相应实现，Orange给出了另一种动态解决方案\n\n由自定义的条件表达式选择出某部分流量，动态分流到指定的upstream server，结束后只需要关闭这条规则即可\n线上问题排查，如果某个API出了问题，可临时添加一条规则，将测试账户的流量打到某台机器或者某个新的bug fix的upstream server，待排查完后清除规则、升级bug fix版本\n\n","slug":"old_topic/2016-09-17-291","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"5a02071a23aad12b54752e188cb304af","title":"about.md","content":"\ncategory: Guidesredirect_from:    - /docs/v0.4.0/guides/about/    - /docs/latest/guides/about/title: “关于Orange”sort_title: “1”\n\n欢迎使用Orange，使用过程中如碰到问题，请到Github进行提问。\n关于Orange是一个基于OpenResty的API Gateway，提供API及自定义规则的监控和管理，如访问统计、流量切分、API重定向、API鉴权、WEB防火墙等功能。它有以下特性：\n\n通过MySQL存储来简单支持集群部署\n支持多种条件匹配和变量提取\n支持通过自定义插件方式扩展功能\n默认内置的插件\n全局状态统计\n自定义监控\nURL重写\nURI重定向\n访问速度控制Rate Limiting\nHTTP Basic Auth\nHTTP Key Auth\n简单防火墙WAF\n代理、ABTesting、分流\n\n\n提供管理界面用于管理内置插件\n开放API: 灵活配置插件、查看运行状态、统计数据等\n\nAPI内置插件以HTTP Restful形式开放全部API，详细可查看API文档\n注意\n现实中由于用户的业务系统多种多样，对于复杂应用，Orange并不是一个开箱即用的组件，需要调整一些配置才能集成到现有系统中。\n\nOrange提供的的配置文件和示例都是最简配置，用户使用时请根据具体项目或业务需要自行调整，这些调整可能包括但不限于:\n\n使用的各个shared dict的大小， 如ngx.shared.status\nnginx.conf配置文件中各个server、location的配置及其权限控制，比如orange dashboard/API的server应该只对内部有权限的机器开放访问\n根据不同业务而设置的不同nginx配置，如timeout、keepalive、gzip、log、connections等等\n\n\n\nLicenceOrange采用MIT协议开源\n其它Orange的插件设计参考了Kong，Kong是一个功能比较全面的API Gateway实现，推荐关注。\n","slug":"old_topic/2016-09-17-295","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"c6b802344a7db113e27182cf9f5f5282","title":"condition.md","content":"\ncategory: Conceptredirect_from:    - /docs/v0.4.0/concept/condition/    - /docs/latest/concept/condition/title: “匹配条件”sort_title: “5”\n\n每个条件的格式如下：\n123456&#123;    &quot;type&quot;: &quot;&quot;,    &quot;operator&quot;: &quot;&quot;,    &quot;name&quot;:&quot;&quot;, //可能为空    &quot;value&quot;: &quot;&quot;&#125;\n\n实例：\n123456789101112&#123;    &quot;type&quot;: &quot;Header&quot;,    &quot;operator&quot;: &quot;=&quot;,    &quot;name&quot;: &quot;uid&quot;,    &quot;value&quot;: &quot;123&quot;&#125;,&#123;    &quot;type&quot;: &quot;Host&quot;,    &quot;operator&quot;: &quot;=&quot;,    &quot;value&quot;: &quot;127.0.0.1&quot;&#125;\n\n以下针对每个条件的格式作解释：\ntype即要匹配的数据来源，也就是支持的条件提取方式，目前包括以下几种：\n\nURI\nIP\nHeader K/V\nQuery K/V\nPost Params K/V\nHost\nReferer\nUserAgent\n\noperator即匹配符，指的是要对提取出的值做的操作，包含：\n\n=\n!=\nmatch 正则匹配\nnot_match 正则匹配后再取非\n&gt;\n&gt;=\n&lt;\n&lt;=\n\nname, 当type为K/V型的来源，如”Header”、”Query”、”PostParams”时此字段不为空，即要从这项来源中提取值对应的key。\nvalue即要匹配的目标值，需要拿提取出的值来跟这个值使用operator做匹配操作。\n","slug":"old_topic/2016-09-17-296","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9e8b3fa4d1f8d6867588c5e0e53a5120","title":"expression.md","content":"\ncategory: Conceptredirect_from:    - /docs/v0.4.0/concept/expression/    - /docs/latest/concept/expression/title: “匹配符、表达式设计”sort_title: “7”\n\nOrange各模块使用的一些匹配项、匹配符和表达式概念。\n匹配项\nURI\nIP\nHeader K/V\nQuery K/V\nHost\nReferer\nPostParams K/V\nUserAgent\nMethod\n\n匹配符\n=\n!=\nmatch\nnot_match\n&gt;\n&gt;=\n&lt;\n&lt;=\n\n表达式\n单一条件表达式\n全真表达式\n至少一个为真表达式\n复杂表达式\n\n","slug":"old_topic/2016-09-17-297","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4fed7f9c4d2e8a8444b5a393192d3669","title":"extractor.md","content":"\ncategory: Conceptredirect_from:    - /docs/v0.4.0/concept/extractor/    - /docs/latest/concept/extractor/title: “变量提取模块”sort_title: “3”\n\n变量提取模块，是一系列变量提取器的集合，一般格式如下：\n1234567891011121314&quot;extractor&quot;: &#123;    &quot;type&quot;: 1,//提取器类型，1指索引式提取，2指模板式提取    &quot;extractions&quot;: [        &#123;//一个提取器            &quot;type&quot;: &quot;Query&quot;,            &quot;name&quot;: &quot;wd&quot;        &#125;,        &#123;            &quot;type&quot;: &quot;Header&quot;,            &quot;name&quot;: &quot;from&quot;,            &quot;default&quot;: &quot;this_is_default_value&quot;        &#125;    ]&#125;\n\n关于两种变量提取器的描述，可以参看#issues15\n","slug":"old_topic/2016-09-17-299","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"337e548c7c0e42c8b3ee91f47e09d683","title":"handle.md","content":"\ncategory: Conceptredirect_from:    - /docs/v0.4.0/concept/handle/    - /docs/latest/concept/handle/title: “后续处理模块”sort_title: “4”\n\n后续处理模块，它包含了一些后续处理需要的配置、参数等信息，比如是否需要记录日志、响应状态码、要跳转到的URL、要代理的下游upstream server等等。详细请参看各个插件的配置。\n","slug":"old_topic/2016-09-17-300","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ee91c36a84884fbd0171736f39b1f0db","title":"extraction.md","content":"\ncategory: Conceptredirect_from:    - /docs/v0.4.0/concept/extraction/    - /docs/latest/concept/extraction/title: “变量提取器”sort_title: “6”\n\n每个提取器的格式如下：\n1234&#123;    &quot;type&quot;: &quot;&quot;,    &quot;name&quot;: &quot;&quot;&#125;,\n\n实例：\n12345678&#123;    &quot;type&quot;: &quot;Query&quot;,    &quot;name&quot;: &quot;username&quot;&#125;,&#123;    &quot;type&quot;: &quot;Header&quot;,    &quot;name&quot;: &quot;id&quot;&#125; \n\n以下针对每个条件的格式作解释：\ntype即要提取的数据来源，目前包括以下几种：\n\nHeader K/V\nQuery K/V\nPost Params K/V\nHost\nURI\nIP\nMethod\n\nname指的是如果是K/V行的提取来源，name指要提取的key\n如以下示例要提取QueryString里的username这个变量：\n1234&#123;    &quot;type&quot;: &quot;Query&quot;,    &quot;name&quot;: &quot;username&quot;&#125;\n\n","slug":"old_topic/2016-09-17-298","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d1e289c6fe68119c3bd6635eff90f158","title":"rule.md","content":"\ncategory: Conceptredirect_from:    - /docs/v0.4.0/concept/rule/    - /docs/latest/concept/rule/title: “规则”sort_title: “1”\n\n** 规则 ** 是Orange中的一个概念，它可能包括一个条件判断模块、一个变量提取模块和一个后续处理模块。一般情况下，插件的一条规则会包含条件判断模块和一个处理模块，根据需要选择是否使用变量提取模块，如分流插件就需要变量提取模块，但防火墙插件则不需要。\n下面通过一个具体的实例看一下它的组成。\n格式以重定向插件的一条规则的结构为例，介绍如下(以json格式描述):\n12345678910111213141516171819202122232425262728293031323334&#123;    &quot;enable&quot;: true,    &quot;name&quot;: &quot;用户访问重定向&quot;,    &quot;id&quot;: &quot;F7F73D94-AEEB-4B61-9E59-AEDBF200B941&quot;,    &quot;time&quot;: &quot;2016-05-04 16:05:03&quot;,    &quot;judge&quot;: &#123;        &quot;type&quot;: 1,        &quot;conditions&quot;: [            &#123;                &quot;type&quot;: &quot;URI&quot;,                &quot;operator&quot;: &quot;match&quot;,                &quot;value&quot;: &quot;^/user&quot;            &#125;        ]    &#125;,    &quot;extractor&quot;: &#123;        &quot;type&quot;: 1,        &quot;extractions&quot;: [            &#123;                &quot;type&quot;: &quot;Query&quot;,                &quot;name&quot;: &quot;username&quot;            &#125;,            &#123;                &quot;type&quot;: &quot;Header&quot;,                &quot;name&quot;: &quot;id&quot;            &#125;        ]    &#125;,    &quot;handle&quot;: &#123;        &quot;trim_qs&quot;: false,        &quot;url_tmpl&quot;: &quot;/u/$&#123;2&#125;/$&#123;1&#125;&quot;,        &quot;log&quot;: true    &#125;&#125;\n\n字段描述各个字段的解释如下：\nenable是否开启这条规则  \nname规则名称\nid这条规则的id，用于修改和删除  \ntime添加或者更改时间\njudge规则适配器，用于筛选请求，详见规则适配器\nextractor变量提取模块，用于提取出请求中的变量供后续使用，详见变量提取模块\nhandle这条规则对应的后续处理，如果这条规则有一个下游触发动作，此值不为空。不同的插件这个字段的子字段可能不同。\n重定向插件的该字段子字段描述如下：\n123log: 当执行这个动作时，是否要记录日志url_tmpl: 后续要redirect到的url模板，可在里面使用`变量提取模块`提取出来的值trim_qs: 是否要清除原始请求的QueryString\n\n\njudge.conditions条件集合，每个条件即为对某项值的判断，这个值是从HTTP请求中提取出来的。详见匹配条件\nextractor.extractions从哪些项中提取变量。详见变量提取器\n","slug":"old_topic/2016-09-17-302","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"af3dedc41147fb62d7e9d45739663031","title":"waf.md","content":"\ncategory: APIredirect_from:    - /docs/latest/api/waf/title: “WAF防火墙”sort_title: “9”flag: “2”\n\n1) 开启或关闭此插件请求\n\n\n\nURI\nMethod\n\n\n\n/waf/enable\nPost\n\n\n参数 \n\n\n\n名称\n类型\n说明\n\n\n\nenable\nint\n0关闭1开启\n\n\n返回结果 \n1234&#123;    &quot;msg&quot;:&quot;关闭成功&quot;,    &quot;success&quot;:true&#125;\n\n2) 获取所有配置信息请求\n\n\n\nURI\nMethod\n\n\n\n/waf/configs\nGet\n\n\n参数无 \n返回结果 \n123456789101112131415161718192021222324252627282930&#123;    &quot;data&quot;: &#123;        &quot;enable&quot;: true,        &quot;rules&quot;: [            &#123;                &quot;enable&quot;: true,                &quot;handle&quot;: &#123;                    &quot;log&quot;: true, //是否记录此条规则的匹配日志                    &quot;code&quot;: 403, // 返回的http状态码                    &quot;stat&quot;: true, //是否将此次记录加入到统计中                    &quot;perform&quot;: &quot;deny&quot; // deny or allow, deny则拒绝后续访问，以code为http状态码返回，allow则放过这条请求                &#125;,                &quot;id&quot;: &quot;C4DDC90B-F05C-4F69-94E1-6FCBC4F88392&quot;,                &quot;time&quot;: &quot;2016-06-21 16:04:58&quot;,                &quot;name&quot;: &quot;禁用管理功能&quot;,                &quot;judge&quot;: &#123; // “条件判断模块”配置                    &quot;type&quot;: 0,                    &quot;conditions&quot;: [                        &#123;                            &quot;type&quot;: &quot;URI&quot;,                            &quot;operator&quot;: &quot;match&quot;,                            &quot;value&quot;: &quot;^/admin/&quot;                        &#125;                    ]                &#125;            &#125;        ]    &#125;,    &quot;success&quot;: true&#125;\n\n\n3) 新建某条规则请求\n\n\n\nURI\nMethod\n说明\n\n\n\n/waf/configs\nPut\nContent-Type:application/x-www-form-urlencoded; charset=UTF-8\n\n\n参数 \n\n\n\n名称\n类型\n说明\n\n\n\nrule\nstring\n指一条”规则”json格式的字符串\n\n\n“规则”格式示例如下，具体格式可参考”获取所有配置”API中返回数据中的data.rules[0]格式:\n1234567891011121314151617181920212223242526&#123;    &quot;name&quot;: &quot;waf规则修改示例&quot;,    &quot;judge&quot;: &#123;        &quot;type&quot;: 1,        &quot;conditions&quot;: [            &#123;                &quot;type&quot;: &quot;URI&quot;,                &quot;operator&quot;: &quot;match&quot;,                &quot;value&quot;: &quot;/waf&quot;            &#125;,            &#123;                &quot;type&quot;: &quot;PostParams&quot;,                &quot;name&quot;: &quot;uid&quot;,                &quot;operator&quot;: &quot;=&quot;,                &quot;value&quot;: &quot;456&quot;            &#125;        ]    &#125;,    &quot;handle&quot;: &#123;        &quot;log&quot;: true, //是否记录此条规则的匹配日志        &quot;code&quot;: 403, // 返回的http状态码        &quot;stat&quot;: true, //是否将此次记录加入到统计中        &quot;perform&quot;: &quot;deny&quot; // deny or allow, deny则拒绝后续访问，以code为http状态码返回，allow则放过这条请求    &#125;,    &quot;enable&quot;: true&#125;\n\n返回结果 \n1234&#123;    &quot;success&quot;: true,    &quot;msg&quot;: &quot;新建规则成功&quot;&#125;\n\n4) 编辑某条规则信息请求\n\n\n\nURI\nMethod\n说明\n\n\n\n/waf/configs\nPost\nContent-Type:application/x-www-form-urlencoded; charset=UTF-8\n\n\n参数 \n\n\n\n名称\n类型\n说明\n\n\n\nrule\nstring\n指修改后的”规则”\n\n\n“规则”格式示例如下:\n123456789101112131415161718192021&#123;    &quot;id&quot;:&quot;C4DDC90B-F05C-4F69-94E1-6FCBC4F88392&quot;,    &quot;name&quot;: &quot;跳转&quot;,    &quot;judge&quot;: &#123;        &quot;type&quot;: 0,        &quot;conditions&quot;: [            &#123;                &quot;type&quot;: &quot;URI&quot;,                &quot;operator&quot;: &quot;match&quot;,                &quot;value&quot;: &quot;/abc&quot;            &#125;        ]    &#125;,    &quot;handle&quot;: &#123;        &quot;log&quot;: true, //是否记录此条规则的匹配日志        &quot;code&quot;: 405, // 返回的http状态码        &quot;stat&quot;: true, //是否将此次记录加入到统计中        &quot;perform&quot;: &quot;deny&quot; // deny or allow, deny则拒绝后续访问，以code为http状态码返回，allow则放过这条请求    &#125;,    &quot;enable&quot;: true&#125;\n\n返回结果 \n1234&#123;    &quot;success&quot;: true,    &quot;msg&quot;: &quot;修改成功&quot;&#125;\n\n5) 删除某条规则请求\n\n\n\nURI\nMethod\n说明\n\n\n\n/waf/configs\nDelete\nContent-Type:application/x-www-form-urlencoded; charset=UTF-8\n\n\n参数 \n\n\n\n名称\n类型\n说明\n\n\n\nrule_id\nstring\n指一条”规则”的id\n\n\n返回结果 \n1234&#123;    &quot;success&quot;: true,    &quot;msg&quot;: &quot;删除成功&quot;&#125;\n\n\n\n6) 获取数据库中此插件的最新配置请求\n\n\n\nURI\nMethod\n\n\n\n/waf/fetch_config\nGet\n\n\n参数无\n返回结果 \n1234567&#123;    &quot;success&quot;: true,    &quot;data&quot;: &#123;        &quot;enable&quot;: true, //是否开启了此插件        &quot;rules&quot;: [] // 该插件包含的规则列表    &#125;&#125;\n\n具体规则格式见以上API描述\n7) 将数据库中最新配置更新到此orange节点请求\n\n\n\nURI\nMethod\n说明\n\n\n\n/waf/sync\nPost\nContent-Type:application/x-www-form-urlencoded; charset=UTF-8\n\n\n参数无\n返回结果 \n1234&#123;    &quot;success&quot;: true, //成功或失败    &quot;msg&quot;: &quot;&quot; //描述信息&#125;\n\n8) 获取防火墙统计信息请求\n\n\n\nURI\nMethod\n\n\n\n/waf/stat\nGet\n\n\n参数 \n无\n返回结果 \n123456789&#123;    &quot;data&quot;: &#123;        &quot;statistics&quot;: [&#123;            &quot;count&quot;: 7, //命中规则的请求个数            &quot;rule_id&quot;: &quot;C4DDC90B-F05C-4F69-94E1-6FCBC4F88392&quot;,// 规则id        &#125;]    &#125;,    &quot;success&quot;: true&#125;\n","slug":"old_topic/2016-09-17-303","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e3aed5e630276c44941c876b650cbd89","title":"api_server.md","content":"\ncategory: Advancedredirect_from:    - /docs/latest/advanced/api_server/title: “如何使用Open API”sort_title: “2”\n\nOrange提供了各种API用于实现第三方需求， 如：\n\n根据API实现个性化的Dashboard\n通过API获取监控信息\n运维上的一些需求\n通过API增删改各种插件配置\n\n默认的API Server在7777端口监听，详细使用方法参看[API]（/docs/api/）部分。\n","slug":"old_topic/2016-09-17-304","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a24b531fc5b1bbf2067f7e954574a317","title":"dashboard_usage.md","content":"\ncategory: Advancedredirect_from:    - /docs/latest/advanced/dashboard_usage/title: “如何使用Dashboard”sort_title: “1”\n\n启动Orange后，浏览器输入http://localhost:9999即可访问内置的Dashboard。\n从v0.1.1版本开始，Orange Dashboard(默认在9999端口监听)可开启授权验证，只有通过授权的账户才能使用控制台。\n请注意，目前仅当选择store为mysql时，才能使用该功能。\n其相关的配置在orange.conf中:\n12345678 &quot;dashboard&quot;: &#123;    &quot;auth&quot;: false, //是否开启授权验证，开启时需要先登录才能使用Dashboard    &quot;session_secret&quot;: &quot;y0ji4pdj61aaf3f11c2e65cd2263d3e7e5&quot;, // 用于加密cookie的盐，自行更改即可    &quot;whitelist&quot;: [//不需要判断是否登录的白名单url        &quot;^/auth/login$&quot;,        &quot;^/error/$&quot;    ]&#125;\n\n在MySQL表dashboard_user中存储了Dashboard的用户信息，请导入该表到库中，参见sql文件install/orange-v0.4.0.sql\n默认的管理员用户名和密码如下，登录后可更改密码或添加其他用户：\n12用户名：admin密码：orange_admin\n\n\n","slug":"old_topic/2016-09-17-306","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"6c3ff5d54ee84215c9897a80659f0b5f","title":"build_plugin.md","content":"\ncategory: Advancedredirect_from:    - /docs/latest/advanced/build_plugin/title: “创建自定义插件”sort_title: “3”\n\nto be continued…\n","slug":"old_topic/2016-09-17-305","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"6cade316b90b96b8add415272fdf2bc9","title":"judge.md","content":"\ncategory: Conceptredirect_from:    - /docs/v0.4.0/concept/judge/    - /docs/latest/concept/judge/title: “条件判断模块”sort_title: “2”\n\n条件判断模块，是一系列匹配条件和使用方式的集合。它由以下几部分组成\n\ntype: 0表示只有一个匹配条件，1表示对所有条件与操作，2表示对所有条件或操作，3表示按照另一个字段expression对所有条件求值\nexpression: 当type为3时，此字段不为空，它的格式是一个lua的逻辑判断表达式。表达式中每个值的格式为v[index], 比如v[1]对应的就是第一个条件的值。示例：(v[1] or v[2]) and v[3]，即前两个条件至少一个为真并且第三个条件为真时，规则为真。\nconditions: 匹配条件集合\n\n","slug":"old_topic/2016-09-17-301","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e3b28e08d06ce54864d09189bebacd02","title":"简介","content":"简介OpenResty（也称为 ngx_openresty）是一个全功能的 Web 应用服务器。它打包了标准的 Nginx 核心，很多的常用的第三方模块，以及它们的大多数依赖项。\n通过糅合众多设计良好的 Nginx 模块，OpenResty 有效地把 Nginx 服务器转变为一个强大的 Web 应用服务器，基于它开发人员可以使用 Lua 编程语言对 Nginx 核心以及现有的各种 Nginx C 模块进行脚本编程，构建出可以处理一万以上并发请求的极端高性能的 Web 应用。\nOpenResty 致力于将你的服务器端应用完全运行于 Nginx 服务器中，充分利用 Nginx 的事件模型来进行非阻塞 I/O 通信。不仅仅是和 HTTP 客户端间的网络通信是非阻塞的，与MySQL、PostgreSQL、Memcached 以及 Redis 等众多远方后端之间的网络通信也是非阻塞的。\n因为 OpenResty 软件包的维护者也是其中打包的许多 Nginx 模块的作者，所以 OpenResty 可以确保所包含的所有组件可以可靠地协同工作。\nOpenResty 最早是雅虎中国的一个公司项目，起步于 2007 年 10 月。当时兴起了 OpenAPI 的热潮，用于满足各种 Web Service 的需求，就诞生了 OpenResty。在公司领导的支持下，最早的 OpenResty 实现从一开始就开源了。最初的定位是服务于公司外的开发者，像其他的 OpenAPI 那样，但后来越来越多地是为雅虎中国的搜索产品提供内部服务。这是第一代的 OpenResty，当时的想法是，提供一套抽象的 web service，能够让用户利用这些 web service 构造出新的符合他们具体业务需求的 Web Service 出来，所以有些“meta web servie”的意味，包括数据模型、查询、安全策略都可以通过这种 meta web service 来表达和配置。同时这种 web service 也有意保持 REST 风格。与这种概念相对应的是纯 AJAX 的 web 应用，即 web 应用几乎都使用客户端 JavaScript 来编写，然后完全由 web service 让 web 应用“活”起来。用户把 .html, .js, .css, .jpg 等静态文件下载到 web browser 中，然后 js 开始运行，跨域请求雅虎提供的经过站长定制过的 web service，然后应用就可以运行起来。不过随着后来的发展，公司外的用户毕竟还是少数，于是应用的重点是为公司内部的其他团队提供 web service，比如雅虎中国的全能搜索产品，及其外围的一些产品。从那以后，开发的重点便放在了性能优化上面。章亦春在加入淘宝数据部门的量子团队之后，决定对 OpenResty 进行重新设计和彻底重写，并把应用重点放在支持像量子统计这样的 web 产品上面，所以量子统计 3.0 开始也几乎完全是 web service 驱动的纯 AJAX 应用。\n这是第二代的 OpenResty，一般称之为 ngx_openresty，以便和第一代基于 Perl 和 Haskell 实现的 OpenResty 加以区别。章亦春和他的同事王晓哲一起设计了第二代的 OpenResty。在王晓哲的提议下，选择基于 nginx 和 lua 进行开发。\n为什么要取 OpenResty 这个名字呢？OpenResty 最早是顺应 OpenAPI 的潮流做的，所以 Open 取自“开放”之意，而Resty便是 REST 风格的意思。虽然后来也可以基于 ngx_openresty 实现任何形式的 web service 或者传统的 web 应用。\n也就是说 Nginx 不再是一个简单的静态网页服务器，也不再是一个简单的反向代理了。第二代的 openresty 致力于通过一系列 nginx 模块，把nginx扩展为全功能的 web 应用服务器。\nngx_openresty 是用户驱动的项目，后来也有不少国内用户的参与，从 openresty.org 的点击量分布上看，国内和国外的点击量基本持平。\nngx_openresty 目前有两大应用目标：\n\n通用目的的 web 应用服务器。在这个目标下，现有的 web 应用技术都可以算是和 OpenResty 或多或少有些类似，比如 Nodejs, PHP 等等。ngx_openresty 的性能（包括内存使用和 CPU 效率）算是最大的卖点之一。\nNginx 的脚本扩展编程，用于构建灵活的 Web 应用网关和 Web 应用防火墙。有些类似的是 NetScaler。其优势在于 Lua 编程带来的巨大灵活性。\n\nngx_openresty 从一开始就是公司实际的业务需求的产物。在过去的几年中的大部分开发工作也是由国内外许多公司和个人的实际业务需求驱动的。这种模型在实践中工作得非常好，可以确保我们做的就是大家最迫切需要的。在此过程中，慢慢形成了 ngx_openresty 的两大应用方向，也就是前面提到的那两大方向。是我们的用户帮助我们确认了这两个方向，事实上，这并不等同于第一代 OpenResty 的方向，而是变得更加底层和更加通用了。\n开源精神的核心是分享而非追求流行。毕竟开源界不是娱乐圈，也不是时尚圈。如果我们的开源项目有越来越多的人开始使用，只是一个“happy accident”，我们自然会很高兴，但这并不是我们真正追求的。\n开放源码只是开源项目生命周期中的“万里长征第一步”，国内的许多开源项目止步于开放源码，而没有后续投入长期的时间和精力去跟进响应用户的各种需求和反馈，但不免夭折。这种现象在国外的不少开源项目中也很常见。\n国外成功的开源项目比较多，或许跟许多发达国家的程序员们的精神状态有关系。比如我认识的一些国外的黑客都非常心思单纯，热情似火。他们在精神上的束缚非常少，做起事来多是不拘一格。有的人即便长期没有工作单纯靠抵押和捐赠过活，也会不遗余力地投身于开源项目。而我接触到的国内许多程序员的精神负担一般比较重，经济上的压力也比较大，自然难有“玩开源”的心思。\n不过，国内也是有一些程序员拥有国外优秀黑客的素质的，而且他们通过网络和全球的黑客紧密联系在一起，所以我们完全可以期待他们未来有振奋人心的产出。在互联网时代的今天，或许按国界的划分来讨论这样的问题会变得越来越不合时宜。\n摘自：OpenResty 作者章亦春访谈实录\n","slug":"old_topic/2016-09-17-308","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"66c1d79a932fd4e754d2057db394f613","title":"与其他 location 配合","content":"与其他 location 配合nginx 世界的 location 是异常强大的，毕竟 nginx 的主要应用场景是在负载均衡、API server，在不同 server、location 之间跳转更是家常便饭。利用不同 location 的功能组合，我们可以完成内部调用、流水线方式跳转、外部重定向等几大不同方式，下面将给大家介绍几个主要应用，就当抛砖引玉。\n内部调用例如对数据库、内部公共函数的统一接口，可以把它们放到统一的 location 中。通常情况下，为了保护这些内部接口，都会把这些接口设置为 internal 。这么做的最主要好处就是可以让这个内部接口相对独立，不受外界干扰。\n示例代码：\n1234567891011121314151617181920location = /sum &#123;    # 只允许内部调用    internal;    # 这里做了一个求和运算只是一个例子，可以在这里完成一些数据库、    # 缓存服务器的操作，达到基础模块和业务逻辑分离目的    content_by_lua_block &#123;        local args = ngx.req.get_uri_args()        ngx.say(tonumber(args.a) + tonumber(args.b))    &#125;&#125;location = /app/test &#123;    content_by_lua_block &#123;        local res = ngx.location.capture(                        &quot;/sum&quot;, &#123;args=&#123;a=3, b=8&#125;&#125;                        )        ngx.say(&quot;status:&quot;, res.status, &quot; response:&quot;, res.body)    &#125;&#125;\n\n紧接着，稍微扩充一下，并行请求的效果，示例如下：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445location = /sum &#123;    internal;    content_by_lua_block &#123;        ngx.sleep(0.1)        local args = ngx.req.get_uri_args()        ngx.print(tonumber(args.a) + tonumber(args.b))    &#125;&#125;location = /subduction &#123;    internal;    content_by_lua_block &#123;        ngx.sleep(0.1)        local args = ngx.req.get_uri_args()        ngx.print(tonumber(args.a) - tonumber(args.b))    &#125;&#125;location = /app/test_parallels &#123;    content_by_lua_block &#123;        local start_time = ngx.now()        local res1, res2 = ngx.location.capture_multi( &#123;                        &#123;&quot;/sum&quot;, &#123;args=&#123;a=3, b=8&#125;&#125;&#125;,                        &#123;&quot;/subduction&quot;, &#123;args=&#123;a=3, b=8&#125;&#125;&#125;                    &#125;)        ngx.say(&quot;status:&quot;, res1.status, &quot; response:&quot;, res1.body)        ngx.say(&quot;status:&quot;, res2.status, &quot; response:&quot;, res2.body)        ngx.say(&quot;time used:&quot;, ngx.now() - start_time)    &#125;&#125;location = /app/test_queue &#123;    content_by_lua_block &#123;        local start_time = ngx.now()        local res1 = ngx.location.capture_multi( &#123;                        &#123;&quot;/sum&quot;, &#123;args=&#123;a=3, b=8&#125;&#125;&#125;                    &#125;)        local res2 = ngx.location.capture_multi( &#123;                        &#123;&quot;/subduction&quot;, &#123;args=&#123;a=3, b=8&#125;&#125;&#125;                    &#125;)        ngx.say(&quot;status:&quot;, res1.status, &quot; response:&quot;, res1.body)        ngx.say(&quot;status:&quot;, res2.status, &quot; response:&quot;, res2.body)        ngx.say(&quot;time used:&quot;, ngx.now() - start_time)    &#125;&#125;\n\n测试结果：\n12345678➜  ~ curl 127.0.0.1/app/test_parallelsstatus:200 response:11status:200 response:-5time used:0.10099983215332➜  ~ curl 127.0.0.1/app/test_queuestatus:200 response:11status:200 response:-5time used:0.20199990272522\n\n利用 ngx.location.capture_multi 函数，直接完成了两个子请求并行执行。当两个请求没有相互依赖，这种方法可以极大提高查询效率。两个无依赖请求，各自是 100ms，顺序执行需要 200ms，但通过并行执行可以在 100ms 完成两个请求。实际生产中查询时间可能没这么规整，但思想大同小异，这个特性是很有用的。\n\n该方法，可以被广泛应用于广告系统（1：N模型，一个请求，后端从N家供应商中获取条件最优广告）、高并发前端页面展示（并行无依赖界面、降级开关等）。\n流水线方式跳转现在的网络请求，已经变得越来越拥挤。各种不同 API 、下载请求混杂在一起，就要求不同厂商对下载的动态调整有各种不同的定制策略，而这些策略在一天的不同时间段，规则可能还不一样。这时候我们还可以效仿工厂的流水线模式，逐层过滤、处理。\n示例代码：\n12345678910111213location ~ ^/static/([-_a-zA-Z0-9/]+).jpg &#123;    set $image_name $1;    content_by_lua_block &#123;        ngx.exec(&quot;/download_internal/images/&quot;                .. ngx.var.image_name .. &quot;.jpg&quot;);    &#125;;&#125;location /download_internal &#123;    internal;    # 这里还可以有其他统一的 download 下载设置，例如限速等    alias ../download;&#125;\n\n注意，ngx.exec 方法与 ngx.redirect 是完全不同的，前者是个纯粹的内部跳转并且没有引入任何额外 HTTP 信号。 这里的两个 location 更像是流水线上工人之间的协作关系。第一环节的工人对完成自己处理部分后，直接交给第二环节处理人（实际上可以有更多环节），它们之间的数据流是定向的。\n\n外部重定向不知道大家什么时候开始注意的，百度的首页已经不再是 HTTP 协议，它已经全面修改到了 HTTPS 协议上。但是对于大家的输入习惯，估计还是在地址栏里面输入 baidu.com ，回车后发现它会自动跳转到 https://www.baidu.com ，这时候就需要的外部重定向了。\n1234567891011location = /foo &#123;    content_by_lua_block &#123;        ngx.say([[I am foo]])    &#125;&#125;location = / &#123;    rewrite_by_lua_block &#123;        return ngx.redirect(&#x27;/foo&#x27;);    &#125;&#125;\n\n执行测试，结果如下：\n1234567891011121314151617181920212223242526➜  ~  curl 127.0.0.1 -iHTTP/1.1 302 Moved TemporarilyServer: openresty/1.9.3.2rc3Date: Sun, 22 Nov 2015 11:04:03 GMTContent-Type: text/htmlContent-Length: 169Connection: keep-aliveLocation: /foo&lt;html&gt;&lt;head&gt;&lt;title&gt;302 Found&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;302 Found&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.9.3.2rc3&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;➜  ~  curl 127.0.0.1/foo -iHTTP/1.1 200 OKServer: openresty/1.9.3.2rc3Date: Sun, 22 Nov 2015 10:43:51 GMTContent-Type: text/htmlTransfer-Encoding: chunkedConnection: keep-aliveI am foo\n\n当我们使用浏览器访问页面 http://127.0.0.1 就可以发现浏览器会自动跳转到 http://127.0.0.1/foo 。\n与之前两个应用实例不同的，外部重定向是可以跨域名的。例如从 A 网站跳转到 B 网站是绝对允许的。在 CDN 场景的大量下载应用中，一般分为调度、存储两个重要环节。调度就是通过根据请求方 IP 、下载文件等信息寻找最近、最快节点，应答跳转给请求方完成下载。\n","slug":"old_topic/2016-09-17-311","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"7971c98c6c54521c1f721d0c7bf2b182","title":"日志输出","content":"日志输出你如何测试和调试你的代码呢？Lua 的两个主力作者是这样回复的：\nLuiz Henrique de Figueiredo：我主要是一块一块的构建，分块测试。我很少使用调试器。即使用调试器，也只是调试 C 代码。我从不用调试器调试 Lua 代码。对于 Lua 来说，在适当的位置放几条打印语句通常就可以胜任了。\nRoberto Ierusalimschy：我差不多也是这样。当我使用调试器时，通常只是用来查找代码在哪里崩溃了。对于 C 代码，有个像 Valgrind 或者 Purify 这样的工具是必要的。\n摘自《编程之魂 – 采访 Lua 发明人的一篇文章》。\n由此可见掌握日志输出是多么重要，下至入门同学，上至 Lua 作者，使用日志输出来确定问题，是很必要的基本手段。\n标准日志输出OpenResty 的标准日志输出原句为 ngx.log(log_level, ...) ，几乎可以在任何 ngx_lua 阶段进行日志的输出。\n请看下面的示例：\n1234567891011121314151617181920212223242526#user  nobody;worker_processes  1;error_log  logs/error.log error;    # 日志级别#pid        logs/nginx.pid;events &#123;    worker_connections  1024;&#125;http &#123;    server &#123;        listen    80;        location / &#123;            content_by_lua_block &#123;                local num = 55                local str = &quot;string&quot;                local obj                ngx.log(ngx.ERR, &quot;num:&quot;, num)                ngx.log(ngx.INFO, &quot; string:&quot;, str)                print([[i am print]])                ngx.log(ngx.ERR, &quot; object:&quot;, obj)            &#125;        &#125;    &#125;&#125;\n\n访问网页，生成日志（logs/error.log 文件）结果如下：\n1234562016/01/22 16:43:34 [error] 61610#0: *10 [lua] content_by_lua(nginx.conf:26):5: num:55, client: 127.0.0.1, server: , request: &quot;GET /hello HTTP/1.1&quot;, host: &quot;127.0.0.1&quot;2016/01/22 16:43:34 [error] 61610#0: *10 [lua] content_by_lua(nginx.conf:26):7: object:nil, client: 127.0.0.1, server: , request: &quot;GET /hello HTTP/1.1&quot;, host: &quot;127.0.0.1&quot;\n\n大家可以在单行日志中获取很多有用的信息，例如：时间、日志级别、请求ID、错误代码位置、内容、客户端 IP 、请求参数等等，这些信息都是环境信息，可以用来辅助完成更多其他操作。当然我们也可以根据自己需要定义日志格式，具体可以参考 nginx 的 log_format 章节。\n细心的读者发现了，中间的两行日志哪里去了？这里不卖关子，其实是日志输出级别的原因。上面的例子，日志输出级别使用的 error，只有等于或大于这个级别的日志才会输出。这里还有一个知识点就是 OpenResty 里面的 print 语句是 INFO 级别。\n有关 Nginx 的日志级别，请看下表：\n123456789ngx.STDERR     -- 标准输出ngx.EMERG      -- 紧急报错ngx.ALERT      -- 报警ngx.CRIT       -- 严重，系统故障，触发运维告警系统ngx.ERR        -- 错误，业务不可恢复性错误ngx.WARN       -- 告警，业务中可忽略错误ngx.NOTICE     -- 提醒，业务比较重要信息ngx.INFO       -- 信息，业务琐碎日志信息，包含不同情况判断等ngx.DEBUG      -- 调试\n\n他们是一些常量，越往上等级越高。读者朋友可以尝试把 error log 日志级别修改为 info，然后重新执行一下测试用例，就可以看到全部日志输出结果了。\n对于应用开发，一般使用 ngx.INFO 到 ngx.CRIT 就够了。生产中错误日志开启到 error 级别就够了。如何正确使用这些级别呢？可能不同的人、不同的公司可能有不同见解。\n网络日志输出如果你的日志需要归集，并且对时效性要求比较高那么这里要推荐的库可能就让你很喜欢了。 lua-resty-logger-socket ，可以说很好的解决了上面提及的几个特性。\nlua-resty-logger-socket 的目标是替代 Nginx 标准的 ngx_http_log_module 以非阻塞 IO 方式推送 access log 到远程服务器上。对远程服务器的要求是支持 syslog-ng 的日志服务。\n引用官方示例：\n12345678910111213141516171819202122232425262728293031lua_package_path &quot;/path/to/lua-resty-logger-socket/lib/?.lua;;&quot;;    server &#123;        location / &#123;            log_by_lua &#x27;                local logger = require &quot;resty.logger.socket&quot;                if not logger.initted() then                    local ok, err = logger.init&#123;                        host = &#x27;xxx&#x27;,                        port = 1234,                        flush_limit = 1234,                        drop_limit = 5678,                    &#125;                    if not ok then                        ngx.log(ngx.ERR, &quot;failed to initialize the logger: &quot;,                                err)                        return                    end                end                -- construct the custom access log message in                -- the Lua variable &quot;msg&quot;                local bytes, err = logger.log(msg)                if err then                    ngx.log(ngx.ERR, &quot;failed to log message: &quot;, err)                    return                end            &#x27;;        &#125;    &#125;\n\n例举几个好处：\n\n基于 cosocket 非阻塞 IO 实现\n日志累计到一定量，集体提交，增加网络传输利用率\n短时间的网络抖动，自动容错\n日志累计到一定量，如果没有传输完毕，直接丢弃\n日志传输过程完全不落地，没有任何磁盘 IO 消耗\n\n","slug":"old_topic/2016-09-17-312","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4b4caaa9aaa4e586708012dea3b735d1","title":"不同阶段共享变量","content":"不同阶段共享变量在 OpenResty 的体系中，可以通过共享内存的方式完成不同工作进程的数据共享，可以通过 Lua 模块方式完成单个进程内不同请求的数据共享。如何完成单个请求内不同阶段的数据共享呢？最典型的例子，估计就是在 log 阶段记录一些请求的特殊变量。\nngx.ctx 表就是为了解决这类问题而设计的。参考下面例子：\n1234567891011location /test &#123;     rewrite_by_lua &#x27;         ngx.ctx.foo = 76     &#x27;;     access_by_lua &#x27;         ngx.ctx.foo = ngx.ctx.foo + 3     &#x27;;     content_by_lua &#x27;         ngx.say(ngx.ctx.foo)     &#x27;; &#125;\n\n首先 ngx.ctx 是一个表，所以我们可以对他添加、修改。它用来存储基于请求的 Lua 环境数据，其生存周期与当前请求相同 (类似 Nginx 变量)。它有一个最重要的特性：单个请求内的 rewrite (重写)，access (访问)，和 content (内容) 等各处理阶段是保持一致的。\n额外注意，每个请求，包括子请求，都有一份自己的 ngx.ctx 表。例如：\n1234567891011121314151617location /sub &#123;    content_by_lua &#x27;        ngx.say(&quot;sub pre: &quot;, ngx.ctx.blah)        ngx.ctx.blah = 32        ngx.say(&quot;sub post: &quot;, ngx.ctx.blah)    &#x27;;&#125;location /main &#123;    content_by_lua &#x27;        ngx.ctx.blah = 73        ngx.say(&quot;main pre: &quot;, ngx.ctx.blah)        local res = ngx.location.capture(&quot;/sub&quot;)        ngx.print(res.body)        ngx.say(&quot;main post: &quot;, ngx.ctx.blah)    &#x27;;&#125;\n\n访问 GET /main 输出\n1234main pre: 73sub pre: nilsub post: 32main post: 73\n\n任意数据值，包括 Lua 闭包与嵌套表，都可以被插入这个“魔法”表，也允许注册自定义元方法。\n也可以将 ngx.ctx 覆盖为一个新 Lua 表，例如，\n1ngx.ctx = &#123; foo = 32, bar = 54 &#125;\n\nngx.ctx 表查询需要相对昂贵的元方法调用，这比通过用户自己的函数参数直接传递基于请求的数据要慢得多。所以不要为了节约用户函数参数而滥用此 API，因为它可能对性能有明显影响。\n由于 ngx.ctx 保存的是指定请求资源，所以这个变量是不能直接共享给其他请求使用的。\n","slug":"old_topic/2016-09-17-310","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"bb3459175ba9079fc75c2b75c372ea8d","title":"Socket 编程发展","content":"Socket 编程发展Linux Socket 编程领域，为了处理大量连接请求场景，需要使用非阻塞 I/O 和复用。select、poll 和 epoll 是 Linux API 提供的 I/O 复用方式，自从 Linux 2.6 中加入了 epoll 之后，高性能服务器领域得到广泛的应用，现在比较出名的 Nginx 就是使用 epoll 来实现 I/O 复用支持高并发，目前在高并发的场景下，Nginx 越来越收到欢迎。\n据 w3techs 在2015年8月10日的统计数据表明，在全球 Top 1000 的网站中，有 43.7% 的网站在使用 Nginx，这使得 Nginx 超越了 Apache，成为了高流量网站最信任的 Web 服务器足足有两年时间。已经确定在使用Nginx的站点有：Wikipedia，WordPress，Reddit，Tumblr，Pinterest，Dropbox，Slideshare，Stackexchange 等，可以持续罗列好几个小时，他们太多了。\n下图是统计数据：\n\nselect 模型下面是 select 函数接口：\n12int select (int n, fd_set *readfds, fd_set *writefds,        fd_set *exceptfds, struct timeval *timeout);\n\nselect 函数监视的文件描述符分 3 类，分别是 writefds、readfds和 exceptfds。调用后 select 函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout 指定等待时间，如果立即返回设为 null 即可）。当 select 函数返回后，通过遍历 fd_set，来找到就绪的描述符。\nselect 目前几乎在所有的平台上支持，其良好跨平台支持是它的一大优点。select 的一个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在 Linux 上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。\npoll 模型1int poll (struct pollfd *fds, unsigned int nfds, int timeout);\n\n不同与select使用三个位图来表示三个fdset的方式，poll 使用一个 pollfd 的指针实现。\n12345struct pollfd &#123;    int fd; /* file descriptor */    short events; /* requested events to watch */    short revents; /* returned events witnessed */&#125;;\n\npollfd 结构包含了要监视的 event 和发生的 event，不再使用 select “参数-值”传递的方式。同时，pollfd 并没有最大数量限制（但是数量过大后性能也是会下降）。 和 select 函数一样，poll 返回后，需要轮询 pollfd 来获取就绪的描述符。\n从上面看，select 和 poll 都需要在返回后，通过遍历文件描述符来获取已经就绪的 socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。\nepoll 模型epoll 的接口如下：\n12345678910111213141516int epoll_create(int size)；int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；            typedef union epoll_data &#123;                void *ptr;                int fd;                __uint32_t u32;                __uint64_t u64;            &#125; epoll_data_t;            struct epoll_event &#123;                __uint32_t events;      /* Epoll events */                epoll_data_t data;      /* User data variable */            &#125;;int epoll_wait(int epfd, struct epoll_event * events,                int maxevents, int timeout);\n\n主要是 epoll_create，epoll_ctl 和 epoll_wait 三个函数。epoll_create 函数创建 epoll 文件描述符，参数 size 并不是限制了 epoll 所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。epoll_ctl 完成对指定描述符 fd 执行 op 操作控制，event 是与 fd 关联的监听事件。op 操作有三种：添加 EPOLL_CTL_ADD，删除 EPOLL_CTL_DEL，修改 EPOLL_CTL_MOD。分别添加、删除和修改对 fd 的监听事件。epoll_wait 等待 epfd 上的 IO 事件，最多返回 maxevents 个事件。\n在 select/poll 中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而 epoll 事先通过 epoll_ctl() 来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似 callback 的回调机制，迅速激活这个文件描述符，当进程调用 epoll_wait 时便得到通知。\nepoll 的优点主要是一下几个方面：\n\n监视的描述符数量不受限制，它所支持的 fd 上限是最大可以打开文件的数目，这个数字一般远大于 2048,举个例子,在 1GB 内存的机器上大约是 10 万左右，具体数目可以 cat /proc/sys/fs/file-max 察看,一般来说这个数目和系统内存关系很大。select 的最大缺点就是进程打开的 fd 是有数量限制的。这对于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache 就是这样实现的)，不过虽然 linux 上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。\nIO 的效率不会随着监视 fd 的数量的增长而下降。epoll 不同于 select 和 poll 轮询的方式，而是通过每个 fd 定义的回调函数来实现的。只有就绪的 fd 才会执行回调函数。\n支持水平触发和边沿触发两种模式：\n水平触发模式，文件描述符状态发生变化后，如果没有采取行动，它将后面反复通知，这种情况下编程相对简单，libevent 等开源库很多都是使用的这种模式。\n边沿触发模式，只告诉进程哪些文件描述符刚刚变为就绪状态，只说一遍，如果没有采取行动，那么它将不会再次告知。理论上边缘触发的性能要更高一些，但是代码实现相当复杂（Nginx 使用的边缘触发）。\n\n\nmmap 加速内核与用户空间的信息传递。epoll 是通过内核与用户空间 mmap 同一块内存，避免了无谓的内存拷贝。\n\n","slug":"old_topic/2016-09-17-307","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"7feb1bc48352a2bd04c7a6d1cf8eb726","title":"helloworld","content":"HelloWorldHelloWorld 是我们亘古不变的第一个入门程序。但是 OpenResty 不是一门编程语言，跟其他编程语言的 HelloWorld 不一样，让我们看看都有哪些不一样吧。\n创建工作目录OpenResty 安装之后就有配置文件及相关的目录的，为了工作目录与安装目录互不干扰，并顺便学下简单的配置文件编写，我们另外创建一个 OpenResty 的工作目录来练习，并且另写一个配置文件。我选择在当前用户目录下创建 openresty-test 目录，并在该目录下创建 logs 和 conf 子目录分别用于存放日志和配置文件。\n12345678$ mkdir ~/openresty-test ~/openresty-test/logs/ ~/openresty-test/conf/$$ tree ~/openresty-test/Users/yuansheng/openresty-test├── conf└── logs2 directories, 0 files\n\n创建配置文件在 conf 目录下创建一个文本文件作为配置文件，命名为 nginx.conf，文件内容如下:\n12345678910111213141516171819worker_processes  1;        #nginx worker 数量error_log logs/error.log;   #指定错误日志文件路径events &#123;    worker_connections 1024;&#125;http &#123;    server &#123;\t\t#监听端口，若你的6699端口已经被占用，则需要修改        listen 6699;        location / &#123;            default_type text/html;            content_by_lua_block &#123;                ngx.say(&quot;HelloWorld&quot;)            &#125;        &#125;    &#125;&#125;\n\n提示：openresty 1.9.3.1 及以下版本，请使用 content_by_lua 命令；在 openresty 1.9.3.2 以上，content_by_lua 改成了 content_by_lua_block。可使用 nginx -V 命令查看版本号。\n万事俱备只欠东风我们启动 nginx 即可，输入命令形式为：nginx -p ~/openresty-test，如果没有提示错误。如果提示 nginx 不存在，则需要在环境变量中加入安装路径，可以根据你的操作平台，参考前面的安装章节（一般需要重启生效）。\n启动成功后，我们可以查看 nginx 进程是否存在，并通过访问 HTTP 页面查看应答内容。操作提示如下：\n1234567891011121314➜  ~ nginx -p ~/openresty-test➜  ~ ps -ef | grep nginx  501 88620     1   0 10:58AM ?? 0:00.00 nginx: master process nginx -p                                    /Users/yuansheng/openresty-test  501 88622 88620   0 10:58AM ?? 0:00.00 nginx: worker process➜  ~ curl http://localhost:6699 -iHTTP/1.1 200 OKServer: openresty/1.9.7.3Date: Sun, 20 Mar 2016 03:01:35 GMTContent-Type: text/htmlTransfer-Encoding: chunkedConnection: keep-aliveHelloWorld\n\n在浏览器中完成同样的访问：\n\n","slug":"old_topic/2016-09-17-314","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3c01632b3d6ff48483bb42fd53fbe2b7","title":"cosocket.md","content":"怎样理解 cosockettodo: waiting to todo\n","slug":"old_topic/2016-09-17-313","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"880333deb35be82c4d3989968275351e","title":"子查询","content":"子查询Nginx 子请求是一种非常强有力的方式，它可以发起非阻塞的内部请求访问目标 location。目标 location 可以是配置文件中其他文件目录，或 任何 其他 nginx C 模块，包括 ngx_proxy、ngx_fastcgi、ngx_memc、ngx_postgres、ngx_drizzle，甚至 ngx_lua 自身等等 。\n需要注意的是，子请求只是模拟 HTTP 接口的形式， 没有 额外的 HTTP/TCP 流量，也 没有 IPC (进程间通信) 调用。所有工作在内部高效地在 C 语言级别完成。\n子请求与 HTTP 301/302 重定向指令 (通过 ngx.redirect) 完全不同，也与内部重定向 ((通过 ngx.exec) 完全不同。\n在发起子请求前，用户程序应总是读取完整的 HTTP 请求体 (通过调用 ngx.req.read_body 或设置 lua_need_request_body 指令为 on).\n该 API 方法（ngx.location.capture_multi 也一样）总是缓冲整个请求体到内存中。因此，当需要处理一个大的子请求响应，用户程序应使用 cosockets 进行流式处理，\n下面是一个简单例子：\n12res = ngx.location.capture(uri)\n\n返回一个包含四个元素的 Lua 表 (res.status, res.header, res.body, 和 res.truncated)。\nres.status (状态) 保存子请求的响应状态码。\nres.header (头) 用一个标准 Lua 表储子请求响应的所有头信息。如果是“多值”响应头，这些值将使用 Lua (数组) 表顺序存储。例如，如果子请求响应头包含下面的行：\n1234Set-Cookie: a=3Set-Cookie: foo=barSet-Cookie: baz=blah\n\n则 res.header[&quot;Set-Cookie&quot;] 将存储 Lua 表 &#123;&quot;a=3&quot;, &quot;foo=bar&quot;, &quot;baz=blah&quot;&#125;。\nres.body (体) 保存子请求的响应体数据，它可能被截断。用户需要检测 res.truncated (截断) 布尔值标记来判断 res.body 是否包含截断的数据。这种数据截断的原因只可能是因为子请求发生了不可恢复的错误，例如远端在发送响应体时过早中断了连接，或子请求在接收远端响应体时超时。\nURI 请求串可以与 URI 本身连在一起，例如，\n12res = ngx.location.capture(&#x27;/foo/bar?a=3&amp;b=4&#x27;)\n\n因为 Nginx 内核限制，子请求不允许类似 @foo 命名 location。请使用标准 location，并设置 internal 指令，仅服务内部请求。\n例如，发送一个 POST 子请求，可以这样做：\n12345res = ngx.location.capture(    &#x27;/foo/bar&#x27;,    &#123; method = ngx.HTTP_POST, body = &#x27;hello, world&#x27; &#125;)\n\n除了 POST 的其他 HTTP 请求方法请参考 HTTP method constants。method 选项默认值是 ngx.HTTP_GET。\nargs 选项可以设置附加的 URI 参数，例如：\n1234ngx.location.capture(&#x27;/foo?a=1&#x27;,    &#123; args = &#123; b = 3, c = &#x27;:&#x27; &#125; &#125;)\n\n等同于\n12ngx.location.capture(&#x27;/foo?a=1&amp;b=3&amp;c=%3a&#x27;)\n\n也就是说，这个方法将根据 URI 规则转义参数键和值，并将它们拼接在一起组成一个完整的请求串。args 选项要求的 Lua 表的格式与 ngx.encode_args 方法中使用的完全相同。\nargs 选项也可以直接包含 (转义过的) 请求串：\n1234ngx.location.capture(&#x27;/foo?a=1&#x27;,    &#123; args = &#x27;b=3&amp;c=%3a&#x27; &#125; &#125;)\n\n这个例子与上个例子的功能相同。\n请注意，通过 ngx.location.capture 创建的子请求默认继承当前请求的所有请求头信息，这有可能导致子请求响应中不可预测的副作用。例如，当使用标准的 ngx_proxy 模块服务子请求时，如果主请求头中包含 “Accept-Encoding: gzip”，可能导致子请求返回 Lua 代码无法正确处理的 gzip 压缩过的结果。通过设置 proxy_pass_request_headers 为 off ，在子请求 location 中忽略原始请求头。\n注：ngx.location.capture 和 ngx.location.capture_multi 指令无法抓取包含以下指令的 location： add_before_body, add_after_body, auth_request, echo_location, echo_location_async, echo_subrequest, 或 echo_subrequest_async 。\n123456789101112location /foo &#123;    content_by_lua &#x27;        res = ngx.location.capture(&quot;/bar&quot;)    &#x27;;&#125;location /bar &#123;    echo_location /blah;&#125;location /blah &#123;    echo &quot;Success!&quot;;&#125;\n\n12$ curl -i http://example.com/foo\n\n他们将不会按照预期工作。\n","slug":"old_topic/2016-09-17-309","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"00e0afc1c0a95123fda2364773b4d3e8","title":"简单API Server框架","content":"简单API Server框架实现一个最最简单的数学计算：加、减、乘、除，给大家演示如何搭建简单的 API Server。\n按照前面几章的写法，先来看看加法、减法示例代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142worker_processes  1;        #nginx worker 数量error_log logs/error.log;   #指定错误日志文件路径events &#123;    worker_connections 1024;&#125;http &#123;    server &#123;        listen 80;        # 加法        location /addition &#123;           content_by_lua_block &#123;                local args = ngx.req.get_uri_args()                ngx.say(args.a + args.b)            &#125;        &#125;        # 减法        location /subtraction &#123;            content_by_lua_block &#123;                local args = ngx.req.get_uri_args()                ngx.say(args.a - args.b)            &#125;        &#125;        # 乘法        location /multiplication &#123;            content_by_lua_block &#123;                local args = ngx.req.get_uri_args()                ngx.say(args.a * args.b)            &#125;        &#125;        # 除法        location /division &#123;            content_by_lua_block &#123;                local args = ngx.req.get_uri_args()                ngx.say(args.a / args.b)            &#125;        &#125;    &#125;&#125;\n\n代码写多了一眼就可以看出来，这么简单的加减乘除，居然写了这么长，而且还要对每个 API 都写一个 location ，作为有追求的人士，怎能容忍这种代码风格？\n\n首先是需要把这些 location 合并；\n其次是这些接口的实现放到独立文件中，保持 nginx 配置文件的简洁；\n\n基于这两点要求，可以改成下面的版本，看上去有那么几分模样的样子：\n\n\n\n\n\n\n\n\n\nnginx.conf 内容：\n1234567891011121314151617181920212223242526272829303132worker_processes  1;        #nginx worker 数量error_log logs/error.log;   #指定错误日志文件路径events &#123;    worker_connections 1024;&#125;http &#123;    # 设置默认 lua 搜索路径，添加 lua 路径    # 此处写相对路径时，对启动 nginx 的路径有要求，必须在 nginx 目录下启动，require 找不到    # comm.param 绝对路径当然也没问题，但是不可移植，因此应使用变量 $prefix 或     # $&#123;prefix&#125;，OR 会替换为 nginx 的 prefix path。        # lua_package_path &#x27;lua/?.lua;/blah/?.lua;;&#x27;;    lua_package_path &#x27;$prefix/lua/?.lua;/blah/?.lua;;&#x27;    # 对于开发研究，可以对代码 cache 进行关闭，这样不必每次都重新加载 nginx。    lua_code_cache off;    server &#123;        listen 80;        # 在代码路径中使用nginx变量        # 注意： nginx var 的变量一定要谨慎，否则将会带来非常大的风险        location ~ ^/api/([-_a-zA-Z0-9/]+) &#123;            # 准入阶段完成参数验证            access_by_lua_file  lua/access_check.lua;            #内容生成阶段            content_by_lua_file lua/$1.lua;        &#125;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n其他文件内容：\n123456789101112131415--========== &#123;$prefix&#125;/lua/addition.lualocal args = ngx.req.get_uri_args()ngx.say(args.a + args.b)--========== &#123;$prefix&#125;/lua/subtraction.lualocal args = ngx.req.get_uri_args()ngx.say(args.a - args.b)--========== &#123;$prefix&#125;/lua/multiplication.lualocal args = ngx.req.get_uri_args()ngx.say(args.a * args.b)--========== &#123;$prefix&#125;/lua/division.lualocal args = ngx.req.get_uri_args()ngx.say(args.a / args.b)\n\n既然对外提供的是 API Server，作为一个服务端程序员，怎么可以容忍输入参数不检查呢？万一对方送过来的不是数字或者为空，这些都要过滤掉嘛。参数检查过滤的方法是统一，在这几个 API 中如何共享这个方法呢？这时候就需要 Lua 模块来完成了。\n\n使用统一的公共模块，完成参数验证；\n验证入口最好也统一，不要分散在不同地方；\n\n\n\n\n\n\n\n\n\n\nnginx.conf 内容：\n1234567891011121314151617worker_processes  1;        #nginx worker 数量error_log logs/error.log;   #指定错误日志文件路径events &#123;    worker_connections 1024;&#125;http &#123;    server &#123;        listen 80;        # 在代码路径中使用nginx变量        # 注意： nginx var 的变量一定要谨慎，否则将会带来非常大的风险        location ~ ^/api/([-_a-zA-Z0-9/]+) &#123;            access_by_lua_file  lua/access_check.lua;            content_by_lua_file lua/$1.lua;        &#125;    &#125;&#125;\n\n\n\n\n\n\n\n\n\n\n新增文件内容：\n12345678910111213141516171819202122232425262728--========== &#123;$prefix&#125;/lua/comm/param.lualocal _M = &#123;&#125;-- 对输入参数逐个进行校验，只要有一个不是数字类型，则返回 falsefunction _M.is_number(...)    local arg = &#123;...&#125;    local num    for _,v in ipairs(arg) do        num = tonumber(v)        if nil == num then            return false        end    end    return trueendreturn _M--========== &#123;$prefix&#125;/lua/access_check.lualocal param= require(&quot;comm.param&quot;)local args = ngx.req.get_uri_args()if not param.is_number(args.a, args.b) then    ngx.exit(ngx.HTTP_BAD_REQUEST)    returnend\n\n看看curl测试结果吧：\n12345678910$  nginx  curl &#x27;127.0.0.1:80/api/addition?a=1&#x27;&lt;html&gt;&lt;head&gt;&lt;title&gt;400 Bad Request&lt;/title&gt;&lt;/head&gt;&lt;body bgcolor=&quot;white&quot;&gt;&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;&lt;hr&gt;&lt;center&gt;openresty/1.9.3.1&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;$  nginx  curl &#x27;127.0.0.1:80/api/addition?a=1&amp;b=3&#x27;4\n\n基本是按照预期执行的。参数不全、错误时，会提示400错误。正常处理，可以返回预期结果。\n来整体看一下目前的目录关系：\n12345678910111213141516.├── conf│   ├── nginx.conf├── logs│   ├── error.log│   └── nginx.pid├── lua│   ├── access_check.lua│   ├── addition.lua│   ├── subtraction.lua│   ├── multiplication.lua│   ├── division.lua│   └── comm│       └── param.lua└── sbin    └── nginx\n\n怎么样，有点 magic 的味道不？其实你的接口越是规范，有固定规律可寻，那么 OpenResty 就总是很容易能找到适合你的位置。当然这里你也可以把 access_check.lua 内容分别复制到加、减、乘、除实现的四个 Lua 文件中，肯定也是能用的。这里只是为了给大家提供更多的玩法，需要的时候可以有更多的选择。\n本章目的是搭建一个简单API Server，记住这绝对不是终极版本。这里面还有很多需要进一步去考虑的地方，但是作为最基本的框架已经有了。\n","slug":"old_topic/2016-09-17-316","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d5ff1ed8ad9b9d2c1a73f4d27ebd5027","title":"获取 uri 参数","content":"获取 uri 参数上一章节，主要介绍了一下如何使用不同 location 进行协作，对 location 进行糅合，往往都是要需要参数的二次调整。如何正确获取传递参数、设置参数，就是你的必修课了。本章目的是给出在 OpenResty 的世界中，我们如何正确获取、设置 uri 参数。\n获取请求 uri 参数首先看一下官方 API 文档，获取一个 uri 有两个方法：ngx.req.get_uri_args、ngx.req.get_post_args，二者主要的区别是参数来源有区别。\n参考下面例子：\n12345678910111213141516171819server &#123;   listen    80;   server_name  localhost;   location /print_param &#123;       content_by_lua_block &#123;           local arg = ngx.req.get_uri_args()           for k,v in pairs(arg) do               ngx.say(&quot;[GET ] key:&quot;, k, &quot; v:&quot;, v)           end           ngx.req.read_body() -- 解析 body 参数之前一定要先读取 body           local arg = ngx.req.get_post_args()           for k,v in pairs(arg) do               ngx.say(&quot;[POST] key:&quot;, k, &quot; v:&quot;, v)           end       &#125;   &#125;&#125;\n\n输出结果：\n12345➜  ~  curl &#x27;127.0.0.1/print_param?a=1&amp;b=2%26&#x27; -d &#x27;c=3&amp;d=4%26&#x27;[GET ] key:b v:2&amp;[GET ] key:a v:1[POST] key:d v:4&amp;[POST] key:c v:3\n\n从这个例子中，我们可以很明显看到两个函数 ngx.req.get_uri_args、ngx.req.get_post_args 获取数据来源是有明显区别的，前者来自 uri 请求参数，而后者来自 post 请求内容。\n传递请求 uri 参数当我们可以获取到请求参数，自然是需要这些参数来完成业务控制目的。大家都知道，URI 内容传递过程中是需要调用 ngx.encode_args 进行规则转义。\n参看下面例子：\n12345678910111213location /test &#123;    content_by_lua_block &#123;        local res = ngx.location.capture(                 &#x27;/print_param&#x27;,                 &#123;                    method = ngx.HTTP_POST,                    args = ngx.encode_args(&#123;a = 1, b = &#x27;2&amp;&#x27;&#125;),                    body = ngx.encode_args(&#123;c = 3, d = &#x27;4&amp;&#x27;&#125;)                &#125;             )        ngx.say(res.body)    &#125;&#125;\n\n输出结果：\n12345➜  ~  curl &#x27;127.0.0.1/test&#x27;[GET]  key:b v:2&amp;[GET]  key:a v:1[POST] key:d v:4&amp;[POST] key:c v:3\n\n与我们预期是一样的。\n如果这里不调用ngx.encode_args ，可能就会比较丑了，看下面例子：\n12345678local res = ngx.location.capture(&#x27;/print_param&#x27;,         &#123;            method = ngx.HTTP_POST,            args = &#x27;a=1&amp;b=2%26&#x27;,  -- 注意这里的 %26 ,代表的是 &amp; 字符            body = &#x27;c=3&amp;d=4%26&#x27;        &#125;     )ngx.say(res.body)\n\nPS：对于 ngx.location.capture 这里有个小技巧，args 参数可以接受字符串或Lua 表的，这样我们的代码就更加简洁直观。\n12345678local res = ngx.location.capture(&#x27;/print_param&#x27;,         &#123;            method = ngx.HTTP_POST,            args = &#123;a = 1, b = &#x27;2&amp;&#x27;&#125;,            body = &#x27;c=3&amp;d=4%26&#x27;        &#125;     )ngx.say(res.body)","slug":"old_topic/2016-09-17-318","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"61064bea0a023b51846839ff3c2e6c07","title":"获取请求 body","content":"获取请求 body在 Nginx 的典型应用场景中，几乎都是只读取 HTTP 头即可，例如负载均衡、正反向代理等场景。但是对于 API Server 或者 Web Application ，对 body 可以说就比较敏感了。由于 OpenResty 基于 Nginx ，所以天然的对请求 body 的读取细节与其他成熟 Web 框架有些不同。\n最简单的 “Hello ****”我们先来构造最简单的一个请求，POST 一个名字给服务端，服务端应答一个 “Hello ****”。\n123456789101112http &#123;    server &#123;        listen    80;        location /test &#123;            content_by_lua_block &#123;                local data = ngx.req.get_body_data()                ngx.say(&quot;hello &quot;, data)            &#125;        &#125;    &#125;&#125;\n\n测试结果：\n12➜  ~  curl 127.0.0.1/test -d jackhello nil\n\n大家可以看到 data 部分获取为空，如果你熟悉其他 web 开发框架，估计立刻就觉得 OpenResty 弱爆了。查阅一下官方 wiki 我们很快知道，原来我们还需要添加指令 lua_need_request_body 。究其原因，主要是 Nginx 诞生之初主要是为了解决负载均衡情况，而这种情况，是不需要读取 body 就可以决定负载策略的，所以这个点对于 API Server 和 Web Application 开发的同学有点怪。\n参看下面例子：\n123456789101112131415http &#123;    server &#123;        listen    80;        # 默认读取 body        lua_need_request_body on;        location /test &#123;            content_by_lua_block &#123;                local data = ngx.req.get_body_data()                ngx.say(&quot;hello &quot;, data)            &#125;        &#125;    &#125;&#125;\n\n再次测试，符合我们预期：\n12➜  ~  curl 127.0.0.1/test -d jackhello jack\n\n如果你只是某个接口需要读取 body（并非全局行为），那么这时候也可以显示调用 ngx.req.read_body() 接口，参看下面示例：\n12345678910111213http &#123;    server &#123;        listen    80;        location /test &#123;            content_by_lua_block &#123;                ngx.req.read_body()                local data = ngx.req.get_body_data()                ngx.say(&quot;hello &quot;, data)            &#125;        &#125;    &#125;&#125;\n\nbody 偶尔读取不到？ngx.req.get_body_data() 读请求体，会偶尔出现读取不到直接返回 nil 的情况。\n如果请求体尚未被读取，请先调用 ngx.req.read_body (或打开 lua_need_request_body 选项强制本模块读取请求体，此方法不推荐）。\n如果请求体已经被存入临时文件，请使用 ngx.req.get_body_file 函数代替。\n如需要强制在内存中保存请求体，请设置 client_body_buffer_size 和 client_max_body_size 为同样大小。\n参考下面代码：\n12345678910111213141516171819202122232425262728293031http &#123;    server &#123;        listen    80;        # 强制请求 body 到临时文件中（仅仅为了演示）        client_body_in_file_only on;        location /test &#123;            content_by_lua_block &#123;                function getFile(file_name)                    local f = assert(io.open(file_name, &#x27;r&#x27;))                    local string = f:read(&quot;*all&quot;)                    f:close()                    return string                end                ngx.req.read_body()                local data = ngx.req.get_body_data()                if nil == data then                    local file_name = ngx.req.get_body_file()                    ngx.say(&quot;&gt;&gt; temp file: &quot;, file_name)                    if file_name then                        data = getFile(file_name)                    end                end                ngx.say(&quot;hello &quot;, data)            &#125;        &#125;    &#125;&#125;\n\n测试结果：\n123➜  ~  curl 127.0.0.1/test -d jack&gt;&gt; temp file: /Users/rain/Downloads/nginx/client_body_temp/0000000018hello jack\n\n由于 Nginx 是为了解决负载均衡场景诞生的，所以它默认是不读取 body 的行为，会对 API Server 和 Web Application 场景造成一些影响。根据需要正确读取、丢弃 body 对 OpenResty 开发是至关重要的。\n","slug":"old_topic/2016-09-17-317","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"0bda74f0522febe0cd0d3ac546ef8e60","title":"如何发起新 HTTP 请求","content":"如何发起新 HTTP 请求OpenResty 最主要的应用场景之一是 API Server，有别于传统 Nginx 的代理转发应用场景，API Server 中心内部有各种复杂的交易流程和判断逻辑，学会高效的与其他 HTTP Server 调用是必备基础。本文将介绍 OpenResty 中两个最常见 HTTP 接口调用方法。\n我们先来模拟一个接口场景，一个公共服务专门用来对外提供加了“盐” md5 计算，业务系统调用这个公共服务完成业务逻辑，用来判断请求本身是否合法。\n利用 proxy_pass参考下面示例，利用 proxy_pass 完成 HTTP 接口访问的成熟配置+调用方法。\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455http &#123;    upstream md5_server&#123;        server 127.0.0.1:81;        # ①        keepalive 20;               # ②    &#125;    server &#123;        listen    80;        location /test &#123;            content_by_lua_block &#123;                ngx.req.read_body()                local args, err = ngx.req.get_uri_args()                -- ③                local res = ngx.location.capture(&#x27;/spe_md5&#x27;,                    &#123;                        method = ngx.HTTP_POST,                        body = args.data                    &#125;                )                if 200 ~= res.status then                    ngx.exit(res.status)                end                if args.key == res.body then                    ngx.say(&quot;valid request&quot;)                else                    ngx.say(&quot;invalid request&quot;)                end            &#125;        &#125;        location /spe_md5 &#123;            proxy_pass http://md5_server;   -- ④            #For HTTP, the proxy_http_version directive should be set to “1.1” and the “Connection”             #header field should be cleared.（from:http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive)            proxy_http_version 1.1;            proxy_set_header Connection &quot;&quot;;        &#125;    &#125;    server &#123;        listen    81;           -- ⑤        location /spe_md5 &#123;            content_by_lua_block &#123;                ngx.req.read_body()                local data = ngx.req.get_body_data()                ngx.print(ngx.md5(data .. &quot;*&amp;^%$#$^&amp;kjtrKUYG&quot;))            &#125;        &#125;    &#125;&#125;\n\n重点说明：① 上游访问地址清单(可以按需配置不同的权重规则)；② 上游访问长连接，是否开启长连接，对整体性能影响比较大（大家可以实测一下）；③ 接口访问通过 ngx.location.capture 的子查询方式发起；④ 由于 ngx.location.capture 方式只能是 nginx 自身的子查询，需要借助 proxy_pass 发出 HTTP 连接信号；⑤ 公共 API 输出服务；\n这里大家可以看到，借用 nginx 周边成熟组件力量，为了发起一个 HTTP 请求，我们需要绕好几个弯子，甚至还有可能踩到坑（upstream 中长连接的细节处理），显然没有足够优雅，所以我们继续看下一章节。\n利用 cosocket立马开始我们的新篇章，给大家展示优雅的解决方式。\n1234567891011121314151617181920212223242526272829303132333435363738394041424344http &#123;    server &#123;        listen    80;        location /test &#123;            content_by_lua_block &#123;                ngx.req.read_body()                local args, err = ngx.req.get_uri_args()                local http = require &quot;resty.http&quot;   -- ①                local httpc = http.new()                local res, err = httpc:request_uri( -- ②                    &quot;http://127.0.0.1:81/spe_md5&quot;,                        &#123;                        method = &quot;POST&quot;,                        body = args.data,                      &#125;                )                if 200 ~= res.status then                    ngx.exit(res.status)                end                if args.key == res.body then                    ngx.say(&quot;valid request&quot;)                else                    ngx.say(&quot;invalid request&quot;)                end            &#125;        &#125;    &#125;    server &#123;        listen    81;        location /spe_md5 &#123;            content_by_lua_block &#123;                ngx.req.read_body()                local data = ngx.req.get_body_data()                ngx.print(ngx.md5(data .. &quot;*&amp;^%$#$^&amp;kjtrKUYG&quot;))            &#125;        &#125;    &#125;&#125;\n\n重点解释：① 引用 resty.http 库资源，它来自 github https://github.com/pintsized/lua-resty-http。② 参考 resty-http 官方 wiki 说明，我们可以知道 request_uri 函数完成了连接池、HTTP 请求等一系列动作。\n题外话，为什么这么简单的方法我们还要求助外部开源组件呢？其实我也觉得这个功能太基础了，真的应该集成到 OpenResty 官方包里面，只不过目前官方默认包里还没有。\n如果你的内部请求比较少，使用 ngx.location.capture+proxy_pass 的方式还没什么问题。但如果你的请求数量比较多，或者需要频繁的修改上游地址，那么 resty.http就更适合你。\n另外 ngx.thread.* 与 resty.http 相互结合也是很不错的玩法，推荐大家有时间研究一下。\n","slug":"old_topic/2016-09-17-315","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9c6306013a86b8a64bcd14635d2ba068","title":"CentOS 平台安装","content":"CentOS 平台安装源码包准备我们首先要在官网下载 OpenResty 的源码包。官网上会提供很多的版本，各个版本有什么不同也会有说明，我们可以按需选择下载。笔者选择下载的源码包为 ngx_openresty-1.9.7.1.tar.gz（请大家跟进使用最新版本，这里只是个例子）。\n依赖库安装将这些相关的库perl 5.6.1+,libreadline, libpcre, libssl安装在系统中。按照以下步骤：\n\n输入以下命令yum install readline-devel pcre-devel openssl-devel perl，一次性安装需要的库。\n相关库安装成功。安装成功后会有 “Complete！” 字样。\n\nOpenResty 安装\n在命令行中切换到源码包所在目录。\n\n解压源码包，tar xzvf ngx_openresty-1.9.7.1.tar.gz。若你下载的源码包版本不一样，将相应的版本号改为你所下载的即可。\n\n切换工作目录到 cd ngx_openresty-1.9.7.1。\n\n了解默认激活的组件。OpenResty 官网有组件列表,我们可以参考，列表中大部分组件默认激活，也有部分默认不激活。默认不激活的组件，我们可以在编译的时激活，后面步骤详说明。\n\n配置安装目录及需要激活的组件。使用选项 –prefix=install_path，指定安装目录（默认为/usr/local/openresty）。\n 使用选项 –with-Components 激活组件，–without 则是禁止组件。 你可以根据自己实际需要选择 with 或 without。如下命令，OpenResty 将配置安装在 /opt/openresty 目录下（注意使用 root 用户）,并激活luajit、http_iconv_module 并禁止 http_redis2_module 组件。\n 1234# ./configure --prefix=/opt/openresty\\\t\t\t--with-luajit\\            --without-http_redis2_module \\            --with-http_iconv_module\n在上一步中，最后没有什么 error 的提示就是最好的。若有错误，最后会显示具体原因可以看源码包目录下的 build/nginx-VERSION/objs/autoconf.err文件查看。若没有错误，则会出现如下信息：\n 123Type the following commands to build and install:    gmake    gmake install\n编译：根据上一步命令提示，输入gmake。\n\n安装：输入gmake install。\n\n上面的步骤顺利完成之后，安装已经完成。可以在你指定的安装目录下看到一些相关目录及文件。\n\n\n设置环境变量为了后面启动 OpenResty 的命令简单一些，不用在 OpenResty 的安装目录下进行启动，我们设置环境变量来简化操作。将 nginx 目录添加到 PATH 中。打开文件 /etc/profile，在文件末尾加入export PATH=$PATH:/opt/openresty/nginx/sbin，若你的安装目录不一样，则做相应修改。注意：这一步操作需要重新加载环境变量才会生效，可通过命令source /etc/profile或者重启服务器等方式实现。\n接下来，我们就可以进入到后面的章节 HelloWorld 学习。\n","slug":"old_topic/2016-09-17-320","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"eddb21444824ae593031f4e574f2f2f6","title":"Ubuntu 平台安装","content":"Ubuntu 平台安装源码包准备我们首先要在官网下载 OpenResty 的源码包。官网上会提供很多的版本，各个版本有什么不同也会有说明，我们可以按需选择下载。笔者选择下载的源码包为 ngx_openresty-1.9.7.1.tar.gz。\n相关依赖包的安装首先你要安装 OpenResty 需要的多个库请先配置好你的apt源，配置源的过程在这就不阐述了，然后执行以下命令安装OpenResty编译或运行时所需要的软件包。\n12# apt-get install libreadline-dev libncurses5-dev libpcre3-dev \\    libssl-dev perl make build-essential\n\n如果你只是想测试一下OpenResty，并不想实际使用，那么你也可以不必去配置源和安装这些依赖库，请直接往下看。\nOpenResty 安装\n在命令行中切换到源码包所在目录。\n\n解压源码包，tar xzvf ngx_openresty-1.9.7.1.tar.gz。若你下载的源码包版本不一样，将相应的版本号改为你所下载的即可。\n\n切换工作目录到 cd ngx_openresty-1.9.7.1。\n\n了解默认激活的组件。OpenResty 官网有组件列表,我们可以参考，列表中大部分组件默认激活，也有部分默认不激活。默认不激活的组件，我们可以在编译的时激活，后面步骤详说明。\n\n配置安装目录及需要激活的组件。使用选项 –prefix=install_path，指定安装目录（默认为/usr/local/openresty）。\n 使用选项 –with-Components 激活组件，–without 则是禁止组件。 你可以根据自己实际需要选择 with 或 without。如下命令，OpenResty 将配置安装在 /opt/openresty 目录下（注意使用 root 用户）,并激活luajit、http_iconv_module 并禁止 http_redis2_module 组件。\n 1234# ./configure --prefix=/opt/openresty\\            --with-luajit\\            --without-http_redis2_module \\            --with-http_iconv_module\n在上一步中，最后没有什么 error 的提示就是最好的。若有错误，最后会显示具体原因可以看源码包目录下的 build/nginx-VERSION/objs/autoconf.err文件查看。若没有错误，则会出现如下信息：\n 123Type the following commands to build and install:    gmake    gmake install\n编译：根据上一步命令提示，输入gmake。\n\n安装：输入gmake install。\n\n上面的步骤顺利完成之后，安装已经完成。可以在你指定的安装目录下看到一些相关目录及文件。\n\n\n设置环境变量为了后面启动 OpenResty 的命令简单一些，不用在 OpenResty 的安装目录下进行启动，我们设置环境变量来简化操作。将 nginx 目录添加到 PATH 中。打开文件 /etc/profile，在文件末尾加入export PATH=$PATH:/opt/openresty/nginx/sbin，若你的安装目录不一样，则做相应修改。注意：这一步操作需要重新加载环境变量才会生效，可通过命令source /etc/profile或者重启服务器等方式实现。\n接下来，我们就可以进入到后面的章节 HelloWorld 学习。\n","slug":"old_topic/2016-09-17-321","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4180c84379ce1a0a588121e5cfa4f15f","title":"环境搭建","content":"环境搭建实践的前提是搭建环境，本节的几个小节将介绍在几种常见操作平台上 OpenResty 的安装。\n为了降低用户安装门槛，对于不同系统安装，部分章节存在比较大的重复内容。读者只需要选择自己需要的平台并尝试安装即可。除了 windows 版本是以二进制发行，其他平台由于系统自身的兼容性，推荐的都是源码编译方式。\n在 OpenResty 的规划路线中，准备发行独立的 opm 安装工具（截止到目前，目前还没完成，名称可能依然会变），帮会我们完成从环境到周边库的下载、更新。\n","slug":"old_topic/2016-09-17-319","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"dbbe8ecea366b89ee238486a58b71f70","title":"Mac OS X 平台安装","content":"Mac OS X 平台安装源码包准备我们首先要在官网下载OpenResty的源码包。官网上会提供很多的版本，各个版本有什么不同也会有说明，我们可以按需选择下载。笔者选择下载的源码包 ngx_openresty-1.9.7.1.tar.gz。\n相关库的安装将这些相关库安装到系统中，推荐如 Homebrew 这类包管理方式完成包管理：\n12$ brew update$ brew install pcre openssl\n\nOpenResty 安装\n在命令行中切换到源码包所在目录。\n\n输入命令tar xzvf ngx_openresty-1.9.7.1.tar.gz，按回车键解压源码包。若你下载的源码包版本不一样，将相应的版本号改为你所下载的即可，或者直接拷贝源码包的名字到命令中。此时当前目录下会出现一个ngx_openresty-1.9.7.1文件夹。\n\n在命令行中切换工作目录到ngx_openresty-1.9.7.1。输入命令cd ngx_openresty-1.9.7.1。\n\n配置安装目录及需要激活的组件。使用选项 –prefix=install_path ，指定其安装目录（默认为/usr/local/openresty）。使用选项 –with-Components 激活组件， –without 则是禁止组件，你可以根据自己实际需要选择 with 及 without 。输入如下命令，OpenResty 将配置安装在 /opt/openresty 目录下（注意使用root用户），激活 LuaJIT、HTTP_iconv_module 并禁止 http_redis2_module 组件。\n 12345./configure --prefix=/opt/openresty\\            --with-cc-opt=&quot;-I/usr/local/include&quot;\\            --with-luajit\\            --without-http_redis2_module \\            --with-ld-opt=&quot;-L/usr/local/lib&quot;\n在上一步中，最后没有什么error的提示就是最好的。若有错误，最后会显示error字样，具体原因可以看源码包目录下的build/nginx-VERSION/objs/autoconf.err文件查看。若没有错误，则会出现如下信息，提示下一步操作：\n 123Type the following commands to build and install:gmakegmake install\n编译。根据上一步命令提示，输入gmake。\n\n安装。输入gmake install，这里可能需要输入你的管理员密码。\n\n上面的步骤顺利完成之后，安装已经完成。可以在你指定的安装目录下看到一些相关目录及文件。\n\n\n设置环境变量为了后面启动OpenResty的命令简单一些，不用在OpenResty的安装目录下进行启动，我们通过设置环境变量来简化操作。将OpenResty目录下的 nginx/sbin 目录添加到 PATH 中。\n接下来，我们就可以进入到后面的章节 Hello World 学习。\n","slug":"old_topic/2016-09-17-323","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"8da56c97a3037418bdb94143c7040828","title":"防止 SQL 注入","content":"防止 SQL 注入所谓 SQL 注入，就是通过把 SQL 命令插入到 Web 表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的 SQL 命令。具体来说，它是利用现有应用程序，将（恶意）的 SQL 命令注入到后台数据库引擎执行的能力，它可以通过在 Web 表单中输入（恶意）SQL 语句得到一个存在安全漏洞的网站上的数据库，而不是按照设计者意图去执行 SQL 语句。比如先前的很多影视网站泄露 VIP 会员密码大多就是通过 Web 表单递交查询字符暴出的，这类表单特别容易受到 SQL 注入式攻击。\nSQL 注入例子下面给了一个完整的可复现的 SQL 注入例子，实际上注入的 SQL 语句写法有很多，下例是比较简单的。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778location /test &#123;    content_by_lua_block &#123;        local mysql = require &quot;resty.mysql&quot;        local db, err = mysql:new()        if not db then            ngx.say(&quot;failed to instantiate mysql: &quot;, err)            return        end        db:set_timeout(1000) -- 1 sec        local ok, err, errno, sqlstate = db:connect&#123;            host = &quot;127.0.0.1&quot;,            port = 3306,            database = &quot;ngx_test&quot;,            user = &quot;ngx_test&quot;,            password = &quot;ngx_test&quot;,            max_packet_size = 1024 * 1024 &#125;        if not ok then            ngx.say(&quot;failed to connect: &quot;, err, &quot;: &quot;, errno, &quot; &quot;, sqlstate)            return        end        ngx.say(&quot;connected to mysql.&quot;)        local res, err, errno, sqlstate =            db:query(&quot;drop table if exists cats&quot;)        if not res then            ngx.say(&quot;bad result: &quot;, err, &quot;: &quot;, errno, &quot;: &quot;, sqlstate, &quot;.&quot;)            return        end        res, err, errno, sqlstate =            db:query(&quot;create table cats &quot;                     .. &quot;(id serial primary key, &quot;                     .. &quot;name varchar(5))&quot;)        if not res then            ngx.say(&quot;bad result: &quot;, err, &quot;: &quot;, errno, &quot;: &quot;, sqlstate, &quot;.&quot;)            return        end        ngx.say(&quot;table cats created.&quot;)        res, err, errno, sqlstate =            db:query(&quot;insert into cats (name) &quot;                     .. &quot;values (\\&#x27;Bob\\&#x27;),(\\&#x27;\\&#x27;),(null)&quot;)        if not res then            ngx.say(&quot;bad result: &quot;, err, &quot;: &quot;, errno, &quot;: &quot;, sqlstate, &quot;.&quot;)            return        end        ngx.say(res.affected_rows, &quot; rows inserted into table cats &quot;,                &quot;(last insert id: &quot;, res.insert_id, &quot;)&quot;)        -- 这里有 SQL 注入（后面的 drop 操作）        local req_id = [[1&#x27;; drop table cats;--]]        res, err, errno, sqlstate =            db:query(string.format([[select * from cats where id = &#x27;%s&#x27;]], req_id))        if not res then            ngx.say(&quot;bad result: &quot;, err, &quot;: &quot;, errno, &quot;: &quot;, sqlstate, &quot;.&quot;)            return        end        local cjson = require &quot;cjson&quot;        ngx.say(&quot;result: &quot;, cjson.encode(res))        -- 再次查询，table 被删        res, err, errno, sqlstate =            db:query([[select * from cats where id = 1]])        if not res then            ngx.say(&quot;bad result: &quot;, err, &quot;: &quot;, errno, &quot;: &quot;, sqlstate, &quot;.&quot;)            return        end        db:set_keepalive(10000, 100)    &#125;&#125;\n\n其他变种，大家可以自行爬行搜索引擎了解。\nOpenResty 中如何规避其实大家可以大概网络爬行一下看看如何解决 SQL 注入，可以发现实现方法很多，比如替换各种关键字等。在 OpenResty 中，其实就简单很多了，只需要对输入参数进行一层过滤即可。\n对于 MySQL ，可以调用 ndk.set_var.set_quote_sql_str ，进行一次过滤即可。\n123456789-- for MySQLlocal req_id = [[1&#x27;; drop table cats;--]]res, err, errno, sqlstate =    db:query(string.format([[select * from cats where id = &#x27;%s&#x27;]],    ndk.set_var.set_quote_sql_str(req_id)))if not res then    ngx.say(&quot;bad result: &quot;, err, &quot;: &quot;, errno, &quot;: &quot;, sqlstate, &quot;.&quot;)    returnend\n\n如果恰巧你使用的是 PostgreSQL ，调用 ndk.set_var.set_quote_pgsql_str 过滤输入变量。读者这时候可以再次把这段代码放到刚刚的示例代码中，如果您可以得到下面的错误，恭喜您，以正确的姿势防止 SQL 注入。\nbad result: You have an error in your SQL syntax; check the manual that\ncorresponds to your MySQL server version for the right syntax to use near\n&#39;1\\&#39;; drop table cats;--&#39;&#39;&#39; at line 1: 1064: 42000.\n\n","slug":"old_topic/2016-09-17-324","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"87aedabb20fddf723d258c16e257ae86","title":"Windows 平台安装","content":"Windows 平台安装1、下载 Windows 版的 OpenResty 压缩包，这里我下载的是 openresty_for_windows_1.7.10.2001_64bit ，你也可以选择 32bit 的版本。如果你对源码感兴趣，下面是源码地址 https://github.com/LomoX-Offical/nginx-openresty-windows。\n2、解压到要安装的目录，这里我选择D盘根目录，你可以根据自己的喜好选择位置。\n3、进入到 openresty_for_windows_1.7.10.2001_64bit 目录，双击执行 nginx.exe 或者使用命令 start nginx 启动 nginx，如果没有错误现在 nginx 已经开始运行了。\n4、验证 nginx 是否成功启动：\n\n使用 tasklist /fi &quot;imagename eq nginx.exe&quot; 命令查看 nginx 进程，其中一个是 master 进程，另一个是 worker 进程，如下图：\n\n  \n\n在浏览器的地址栏输入 localhost，加载 nginx 的欢迎页面。成功加载说明 nginx 正在运行。如下图：\n\n  \n另外当 nginx 成功启动后，master 进程的 pid 存放在 logs\\nginx.pid 文件中。\nPS：OpenResty 当前也发布了 windows 版本，两个版本编译方式还是有区别的，这里更推荐这个版本。\n","slug":"old_topic/2016-09-17-322","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9aa16bf014a426133910ab8bd80b8292","title":"输出响应体","content":"输出响应体HTTP响应报文分为三个部分：\n\n响应行\n响应头\n响应体\n\n\n对于 HTTP 响应体的输出，在 OpenResty 中调用 ngx.say 或 ngx.print 即可。经过查看官方 wiki ，这两者都是输出响应体，区别是 ngx.say 会对输出响应体多输出一个 \\n 。如果你用的是浏览器完成的功能调试，使用这两着是没有区别的。但是如果使用各种终端工具，这时候使用 ngx.say 明显就更方便了。\nngx.say 与 ngx.print 均为异步输出首先需要明确一下的，是这两个函数都是异步输出的，也就是说当调用 ngx.say 后并不会立刻输出响应体。参考下面的例子：\n1234567891011121314151617181920server &#123;    listen    80;    location /test &#123;        content_by_lua_block &#123;            ngx.say(&quot;hello&quot;)            ngx.sleep(3)            ngx.say(&quot;the world&quot;)        &#125;    &#125;    location /test2 &#123;        content_by_lua_block &#123;            ngx.say(&quot;hello&quot;)            ngx.flush() -- 显式的向客户端刷新响应输出            ngx.sleep(3)            ngx.say(&quot;the world&quot;)        &#125;    &#125;&#125;\n\n测试接口可以观察到， /test 响应内容实在触发请求 3s 后一起接收到响应体，而 /test2 则是先收到一个 hello 停顿 3s 后又接收到后面的 the world。\n再看下面的例子：\n123456789101112server &#123;    listen    80;    lua_code_cache off;    location /test &#123;        content_by_lua_block &#123;            ngx.say(string.rep(&quot;hello&quot;, 1000))            ngx.sleep(3)            ngx.say(&quot;the world&quot;)        &#125;    &#125;&#125;\n\n执行测试，可以发现首先收到了所有的 “hello” ，停顿大约 3 秒后，接着又收到了 “the world” 。\n通过两个例子对比，可以知道，因为是异步输出，两个响应体的输出时机是 不一样 的。\n如何优雅处理响应体过大的输出如果响应体比较小，这时候相对就比较随意。但是如果响应体过大（例如超过 2G），是不能直接调用 API 完成响应体输出的。响应体过大，分两种情况：\n\n输出内容本身体积很大，例如超过 2G 的文件下载\n输出内容本身是由各种碎片拼凑的，碎片数量庞大，例如应答数据是某地区所有人的姓名\n\n第①个情况，要利用 HTTP 1.1 特性 CHUNKED 编码来完成，一起来看看 CHUNKED 编码格式样例：\n\n可以利用 CHUNKED 格式，把一个大的响应体拆分成多个小的应答体，分批、有节制的响应给请求方。\n参考下面的例子：\n123456789101112131415161718192021location /test &#123;    content_by_lua_block &#123;        -- ngx.var.limit_rate = 1024*1024        local file, err = io.open(ngx.config.prefix() .. &quot;data.db&quot;,&quot;r&quot;)        if not file then            ngx.log(ngx.ERR, &quot;open file error:&quot;, err)            ngx.exit(ngx.HTTP_SERVICE_UNAVAILABLE)        end        local data        while true do            data = file:read(1024)            if nil == data then                break            end            ngx.print(data)            ngx.flush(true)        end        file:close()    &#125;&#125;\n\n按块读取本地文件内容（每次 1KB），并以流式方式进行响应。笔者本地文件 data.db 大小是 4G ， Nginx 服务可以稳定运行，并维持内存占用在 几MB 范畴。\n注：其实 nginx 自带的静态文件解析能力已经非常好了。这里只是一个例子，实际中过大响应体都是后端服务生成的，为了演示环境相对封闭，所以这里选择本地文件。\n第②个情况，其实就是要利用 ngx.print 的特性了，它的输入参数可以是单个或多个字符串参数，也可以是 table 对象。\n参考官方示例代码：\n123456local table = &#123;     &quot;hello, &quot;,     &#123;&quot;world: &quot;, true, &quot; or &quot;, false,         &#123;&quot;: &quot;, nil&#125;&#125; &#125; ngx.print(table)\n\n将输出：\n1hello, world: true or false: nil\n\n也就是说当有非常多碎片数据时，没有必要一定连接成字符串后再进行输出。完全可以直接存放在 table 中，用数组的方式把这些碎片数据统一起来，直接调用 ngx.print(table) 即可。这种方式效率更高，并且更容易被优化。\n","slug":"old_topic/2016-09-17-325","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9292b5d7db49cf3a15a4dacf7bf55d0e","title":"跨平台的库选择","content":"跨平台的库选择大家看过上面三个json的例子就发现，都是围绕cjson库的。原因也比较简单，就是cjson是默认绑定到openresty上的。很多开发喜欢 windows 系统，可以选择 dkjson（编解码效率没有cjson快，优势是纯Lua，完美跨任何平台）。\n并且我们的代码肯定不会因为 win、linux 的并存而写两套程序。那么我们就必须要把json处理部分封装一下，隐藏系统差异造成的差异化处理。\n12345678910111213local _M = &#123; _VERSION = &#x27;1.0&#x27; &#125;-- require(&quot;ffi&quot;).os 获取系统类型local json = require(require(&quot;ffi&quot;).os == &quot;Windows&quot; and &quot;dkjson&quot; or &quot;cjson&quot;)function _M.json_decode( str )    return json.decode(str)endfunction _M.json_encode( data )    return json.encode(data)endreturn _M\n\n在我们的应用中，对于操作系统版本差异、操作系统位数差异、同时支持不同数据库使用等，几乎都是使用这个方法完成的，十分值得推荐。\n额外说个点，github上有个项目cloudflare/lua-resty-json，从官方资料上介绍decode的速度更快，我们也做了小范围应用。所以上面的json_decode对象来源，就可以改成这个库。\n外面总是有新鲜玩意，多抬头多发现，充实自己，站在巨人肩膀上，总是能够更容易够到高峰。\n","slug":"old_topic/2016-09-17-327","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"dcced3e4781903088f00b4d841a17520","title":"编码为array还是object","content":"编码为array还是object\n首先大家请看这段源码：\n12345-- http://www.kyne.com.au/~mark/software/lua-cjson.php-- version: 2.1 devellocal json = require(&quot;cjson&quot;)ngx.say(&quot;value --&gt; &quot;, json.encode(&#123;dogs=&#123;&#125;&#125;))\n\n输出结果\n\n\n\n\n\n\n\n\n\nvalue –&gt; {“dogs”:{}}\n注意看下encode后key的值类型，”{}” 代表key的值是个object，”[]” 则代表key的值是个数组。对于强类型语言(c/c++, java等)，这时候就有点不爽。因为类型不是他期望的要做容错。对于Lua本身，是把数组和字典融合到一起了，所以他是无法区分空数组和空字典的。\n参考openresty-cjson中额外贴出测试案例，我们就很容易找到思路了。\n123456789101112131415161718192021-- 内容节选lua-cjson-2.1.0.2/tests/agentzh.t=== TEST 1: empty tables as objects--- lualocal cjson = require &quot;cjson&quot;print(cjson.encode(&#123;&#125;))print(cjson.encode(&#123;dogs = &#123;&#125;&#125;))--- out&#123;&#125;&#123;&quot;dogs&quot;:&#123;&#125;&#125;=== TEST 2: empty tables as arrays--- lualocal cjson = require &quot;cjson&quot;cjson.encode_empty_table_as_object(false)print(cjson.encode(&#123;&#125;))print(cjson.encode(&#123;dogs = &#123;&#125;&#125;))--- out[]&#123;&quot;dogs&quot;:[]&#125;\n\n综合本章节提到的各种问题，我们可以封装一个json encode的示例函数：\n123456789101112131415161718function json_encode( data, empty_table_as_object )  --Lua的数据类型里面，array和dict是同一个东西。对应到json encode的时候，就会有不同的判断  --对于linux，我们用的是cjson库：A Lua table with only positive integer keys of type number will be encoded as a JSON array. All other tables will be encoded as a JSON object.  --cjson对于空的table，就会被处理为object，也就是&#123;&#125;  --dkjson默认对空table会处理为array，也就是[]  --处理方法：对于cjson，使用encode_empty_table_as_object这个方法。文档里面没有，看源码  --对于dkjson，需要设置meta信息。local a= &#123;&#125;；a.s = &#123;&#125;;a.b=&#x27;中文&#x27;;setmetatable(a.s,  &#123; __jsontype = &#x27;object&#x27; &#125;);ngx.say(comm.json_encode(a))    local json_value = nil    if json.encode_empty_table_as_object then        json.encode_empty_table_as_object(empty_table_as_object or false) -- 空的table默认为array    end    if require(&quot;ffi&quot;).os ~= &quot;Windows&quot; then        json.encode_sparse_array(true)    end    pcall(function (data) json_value = json.encode(data) end, data)    return json_valueend","slug":"old_topic/2016-09-17-326","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"6e867546fc7beccba02bf189db02a81f","title":"稀疏数组","content":"稀疏数组请看示例代码（注意data的数组下标）：\n12345678910-- http://www.kyne.com.au/~mark/software/lua-cjson.php-- version: 2.1 devellocal json = require(&quot;cjson&quot;)local data = &#123;1, 2&#125;data[1000] = 99-- ... do the other thingsngx.say(json.encode(data))\n\n运行日志报错结果：\n123452015/06/27 00:23:13 [error] 2714#0: *40 lua entry thread aborted: runtime error: ...ork/git/github.com/lua-resty-memcached-server/t/test.lua:13: Cannot serialise table: excessively sparse arraystack traceback:coroutine 0:    [C]: in function &#x27;encode&#x27;    ...ork/git/github.com/lua-resty-memcached-server/t/test.lua:13: in function &lt;...ork/git/github.com/lua-resty-memcached-server/t/test.lua:1&gt;, client: 127.0.0.1, server: localhost, request: &quot;GET /test HTTP/1.1&quot;, host: &quot;127.0.0.1:8001&quot;\n\n如果把data的数组下标修改成5，那么这个json.encode就会是成功的。结果是：[1,2,null,null,99]\n为什么下标是1000就失败呢？实际上这么做是cjson想保护你的内存资源。她担心这个下标过大直接撑爆内存（贴心小棉袄啊）。如果我们一定要让这种情况下可以encode，就要尝试encode_sparse_array api了。有兴趣的同学可以自己试一试。我相信你看过有关cjson的代码后，就知道cjson的一个简单危险防范应该是怎样完成的。\n","slug":"old_topic/2016-09-17-329","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"759fac4aaf0afc50492499e7963a1c92","title":"json解析的异常捕获","content":"json解析的异常捕获首先来看最最普通的一个json解析的例子（被解析的json字符串是错误的，缺少一个双引号）：\n123456789101112-- http://www.kyne.com.au/~mark/software/lua-cjson.php-- version: 2.1 devellocal json = require(&quot;cjson&quot;)local str  = [[ &#123;&quot;key:&quot;value&quot;&#125; ]]local t    = json.decode(str)ngx.say(&quot; --&gt; &quot;, type(t))-- ... do the other thingsngx.say(&quot;all fine&quot;)\n\n代码执行错误日志如下：\n123452015/06/27 00:01:42 [error] 2714#0: *25 lua entry thread aborted: runtime error: ...ork/git/github.com/lua-resty-memcached-server/t/test.lua:8: Expected colon but found invalid token at character 9stack traceback:coroutine 0:    [C]: in function &#x27;decode&#x27;    ...ork/git/github.com/lua-resty-memcached-server/t/test.lua:8: in function &lt;...ork/git/github.com/lua-resty-memcached-server/t/test.lua:1&gt;, client: 127.0.0.1, server: localhost, request: &quot;GET /test HTTP/1.1&quot;, host: &quot;127.0.0.1:8001&quot;\n\n这可不是我们期望的，decode失败，居然500错误直接退了。改良了一下我们的代码：\n1234567local json = require(&quot;cjson&quot;)function json_decode( str )    local json_value = nil    pcall(function (str) json_value = json.decode(str) end, str)    return json_valueend\n\n如果需要在Lua中处理错误，必须使用函数pcall（protected call）来包装需要执行的代码。pcall接收一个函数和要传递给后者的参数，并执行，执行结果：有错误、无错误；返回值true或者或false, errorinfo。pcall以一种”保护模式”来调用第一个参数，因此pcall可以捕获函数执行中的任何错误。有兴趣的同学，请更多了解下Lua中的异常处理。\n另外，可以使用CJSON 2.1.0，该版本新增一个cjson.safe模块接口，该接口兼容cjson模块，并且在解析错误时不抛出异常，而是返回nil。\n1234567local json = require(&quot;cjson.safe&quot;)local str  = [[ &#123;&quot;key:&quot;value&quot;&#125; ]]local t    = json.decode(str)if t then    ngx.say(&quot; --&gt; &quot;, type(t))end","slug":"old_topic/2016-09-17-328","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9c523cb4f2eea401eabec06d4f595a71","title":"Crontab在SAE中的应用。","content":"例行性工作（crontab)\n【闲话】\n现在是在用蓝牙和手机无限键盘在写这篇博客，测试一下，发现用系统默认的输入法比较痛苦，不知道为什么，光标焦点在手机屏幕上飞来飞去，根本就没有办法正常的进行编辑，换了一个输入法以后，此问题基本上不发生了。\n［问题］什么事crontab?\n如果简单的翻译成例行性工作没错，但是对于为首次接受此概念的人说，理解上还是模棱两可的。\n整体来说，crontab是用户的一个时间计划安排表，用户自定义时间表，去安排各种程序任务的执行。\n［输入］cron是Linux上的一个服务程序，并且此程序要求用户有特定的数据输入。\nLinux系统：在Linux系统上有特定的配置文件，接受用户的配置输入数据，位置实在 /etc/m目录下，文件名是crontab。cat /etc/crontab\nSAE云平台：\n在SAE平台上，同样通过配置文件接受用户的输入设定数据。\n","slug":"old_topic/2016-09-17-33","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"28809696492fdd0430c0dee1a4d49fd3","title":"Jekyll快速生成文件头命令","content":"作者：糖果\n需要快速生成Markdown的文件头，命令行方式，是相对比较快的：\n1python md-cli.py publish -t LOR -g [getting_started] -k announcements -d &quot;July 3, 2016&quot; -s summary  -b mydoc_sidebar -p lor_README_zh.html -f lor -n test.md\n\n重新修改参数，配置可定向输出到指定目录。\n1python md-cli.py publish -t LOR -g [getting_started] -k announcements -d &quot;July 3, 2016&quot; -s summary  -b mydoc_sidebar -p lor_README_zh.html -f lor -n test -o mdtest\n\n我们用一个简单的循环，来遍历所有的Markdown文件。\n12345filelist=`ls *.md`for file in $filelistdo    python md-cli.py publish -t &quot;openresty best practices&quot; -g [openresty] -k announcements -d &quot;July 3, 2016&quot; -s &quot;openresty best practices&quot; -b mydoc_sidebar -p lor_README_zh.html -f lor -n $&#123;file%.md&#125; -o mdtestdone","slug":"old_topic/2016-09-17-330","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"61bc08174646a443dbaf5e7d8fa7202b","title":"解决jekyll主题无法处理重名问题","content":"作者：糖果\njekyll会把多个同名的markdown文件，只生成一个html文件，需要批量的改所有markdown文件的前缀。\nrename -n ‘s/^/2016-09-18-/‘ *.markdown\n","slug":"old_topic/2016-09-17-332","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e25c5c7f0fb0f1b7524c295299b5bd3f","title":"HTML转换PDF工具Prince的软件包依赖","content":"HTML转换PDF工具Prince的软件包依赖libxml2 libtiff5 libgif4 libfontconfig\n","slug":"old_topic/2016-09-17-331","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ab4e3b90afa2a7d7ef0c9c51547de844","title":"swagger-codegen","content":"swagger-codegen generate -c config -i http://host:port/api/api-docs -l lua -o ./graylog\n","slug":"old_topic/2016-09-17-336","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9f9ccabafd985ea40e1240cace104a30","title":"GrayLog.py环境Python2.6和Python2.7环境共存","content":"作者：糖果\n需要部署Graylog.py，但有的机器Python版本是2.6.6的， 这个版本运行graylog.py有问题，需要新装一个Python2.7。\n12345wget https://www.python.org/ftp/python/2.7.8/Python-2.7.8.tgztar xf Python-2.7.8.tgzcd Python-2.7.8./configure --prefix=/usr/localmake &amp;&amp; make install\n\n如果之前用jpython2.6装过pip或是easy setup，新装的包都放在python2.6的packge sites下，因为我们需要让python2.7能找到graylog，需要用python2.7装一人pip或是ez_setup， 我们选择安装ez_setup。\n然后再选择用easy_setup安装pip。下载一个安装包：https://github.com/arbylee/setuptools\n解压开，然后安装easy setup。\n12python2.7 ez_setup.pyeasy_install-2.7 pip\n\n如果在当前用户中路径中，不能直接找到python2.7和easy_install-2.7执行程序，就使用绝对路径指出他们的绝对位置去执行。\n一般python2.7的位置是：/usr/local/bin/python2.7\n123pip2.7 install [packagename]pip2.7 install --upgrade [packagename]pip2.7 uninstall [packagename]\n\n\n1234pip2.7 install virtualenvvirtualenv-2.7 mygraylogsource mygraylog/bin/activatedeactivate\n\n1234python     pythhon2.7pip     pip2.7easy_install easy_install-2.7virtualenv virtualenv-2.7\n\n默认是使用python2.6.6的，在创建新环境时，指定使用–python==2.7virtualenv testgraylog –python=python2.7source ./bin/activate进入默认是2.7的环境，  不用在python文件头部指定2.6或是2.7。\n编辑整理：糖果\n","slug":"old_topic/2016-09-17-333","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"3cd539c713805eb0b4ee7b03f42a3f03","title":"各种资源下载","content":"esxi的下载ttps://my.vmware.com/web/vmware/evalcenter?p=free-esxi6\nesxi配置http://wiki.intra.sina.com.cn/pages/viewpage.action?pageId=9620049\njava程序权控制http://java.com/zh_CN/download/help/win_controlpanel.xml\nr710 远程管理卡管理系统http://www.shaoqun.com/a/96282.aspx\nDellDRAC,虚构介质分离或所选虚拟磁盘驱动器的虚拟介质重定向已由另一用户使用http://www.makaidong.com/%E8%A1%8C%E4%B8%9A%E5%BA%94%E7%94%A8/440495.shtml\nMysql下载地址https://downloads.mariadb.com/archive/index/p/mysql/v/5.5.28wget https://downloads.mariadb.com/archives/mysql-5.5/MySQL-devel-5.5.28-1.el6.x86_64.rpmwget https://downloads.mariadb.com/archives/mysql-5.5/MySQL-client-5.5.28-1.el6.x86_64.rpmwget https://downloads.mariadb.com/archives/mysql-5.5/MySQL-server-5.5.28-1.el6.x86_64.rpmmysql-libs-5.1.73-3.el6_5.x86_64\n安装说明http://blog.seweal.com/post/centos-mysql-install-rpm\n安装包下载https://downloads.mariadb.com/archive/index/p/mysql/v/5.5.28https://downloads.mariadb.com/archive/index/p/mysql/v/5.5.28MySQL-python-1.2.3-0.3.c1.1.el6.x86_64\nMySQL用户权限(Host,User,Password)管理(mysql.user)http://blog.csdn.net/typa01_kk/article/details/49126365\n内核学习路线http://www.360doc.com/content/14/0612/16/17038653_386027485.shtml\nLinux的内核学习路线http://www.nowamagic.net/librarys/veda/detail/2266\nStomp.py代码的官方文档。http://jasonrbriggs.github.io/stomp.py/annotated.html\n如果使用rabbitmqhttp://www.cnblogs.com/shanyou/p/4067250.html\npika客户端https://pika.readthedocs.org/en/0.9.14/modules/parameters.html#pika.connection.ConnectionParameters\nstomp客户端https://github.com/jasonrbriggs/stomp.pyhttps://github.com/jasonrbriggs/stomp.py/archive/master.zip\ndocker mysql主从安装https://segmentfault.com/a/1190000004328677docker学习(5) 在mac中创建mysql docker容器http://www.cnblogs.com/yjmyzz/p/run-mysql-in-docker-using-mac.html\nDocker Compose ile MySQL Master Slave Kurulumuhttp://ecylmz.com/articles/docker-compose-mysql-master-slave-replication/\ndocker安装mysqlhttp://www.docker.org.cn/thread/13.html\nluasoaphttps://luarocks.org/modules/tomasguisasola/luasoap\narachni\ntcpdump的使用http://linuxwiki.github.io/NetTools/tcpdump.html\n管理系统安全设计 1.0 —— 雨帆版https://www.zybuluo.com/yufan/note/247528\n多级域句配置http://www.ynpxrz.com/n764539c2023.aspx\n","slug":"old_topic/2016-09-17-335","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"01173aa02c4077fa378e3b1fa24d186b","title":"运行openresty的docker容器","content":"编辑作者：糖果\n找了些资料，用了一下docker的openrsty的测试。\n直接拉取1.9版的Openresty。\n1docker pull openresty/openresty:1.9.15.1-trusty\n\n\n将特理机的8080端口和docker的80端口映射。将不当前config/nginx.conf映射到docker的usr/local/openresty/nginx/conf/nginx.conf，log文件同理。\n12#!/usr/bin/env bashdocker run -d --name=&quot;nginx&quot; -p 8080:80 -v $PWD/config/nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf:ro -v $PWD/logs:/usr/local/openresty/nginx/logs openresty/openresty:1.9.15.1-trusty\n\n写一句支持nginx lua的测试脚本。\n12345678910111213141516worker_processes  1;error_log logs/error.log;events &#123;    worker_connections 1024;&#125;http &#123;    server &#123;        listen 80;        location / &#123;            default_type text/html;            content_by_lua &#x27;                ngx.say(&quot;&lt;p&gt;hello, world&lt;/p&gt;&quot;)            &#x27;;        &#125;    &#125;&#125;\n\n\n停止docker，可以stop，也可以kill。\n12#!/usr/bin/env bashdocker kill nginx &amp;&amp; docker rm nginx\n\n登陆docker hub\n1docker login\n\n提交一个版本\n1docker commit xxxxxxx  candylab/openrestytest\n\n提交文件到hub上\n1docker push candylab/openrestytest\n\n\n\n还有一个–net选项， –net=host，是直接桥接网卡。docker run -d –net=host openresty\n","slug":"old_topic/2016-09-17-338","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"bc2b21685789386351af0e07c572df47","title":"在Lapis上用moonscript渲染和接收json","content":"编辑整理：糖果\n12345678910111213lapis = require &quot;lapis&quot;                                                                                                                                                   import json_params from require &quot;lapis.application&quot;                                                                                                                                                                                                                                                                                                 class App extends lapis.Application                                                                                                                                         &quot;/&quot;: =&gt;                                                                                                                                                                     &#123;                                                                                                                                                                           json: &#123;                                                                                                                                                                     success: true                                                                                                                                                             message: &quot;hello world&quot;                                                                                                                                                  &#125;                                                                                                                                                                       &#125;                                                                                                                                                                       &quot;/json&quot;: json_params =&gt;                                                                                                                                                     @params.value    \n\n用curl进行测试：\n1curl -H &quot;Content-type: application/json&quot;  -d &#x27;&#123;&quot;value&quot;: &quot;hello&quot;&#125;&#x27;  0.0.0.0:8080/json","slug":"old_topic/2016-09-17-337","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"03eb1b6e42f3161910ec1f1a5c8f6a96","title":"ENV的C语言实现","content":"env的实现，就是下面一小段的C语言实现。\n12345678910#include &lt;stdio.h&gt;  extern char**environ;  int main ()  &#123;     char**var;     char *str;     for (var =environ;*var !=NULL;++var)         printf (&quot;%s\\n&quot;,*var);    return 0;  &#125;","slug":"old_topic/2016-09-17-341","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"536954b105435d66f03c8d7dea4328e4","title":"sysnergy 键盘共享软件","content":"sysnergy 键盘共享软件\nhttp://www.veryhuo.com/down/html/90189.htmlhttp://c4.72zx.com/download/Synergyx32%201.7.4_3@5666.exehttp://www.onlinedown.net/soft/5666.htm\n","slug":"old_topic/2016-09-17-334","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a0f1485d8813f2781144a51b0a71a712","title":"Scrapy快速写爬虫","content":"看到别人的教程，学着测了一下，不错。\n1scrapy startproject ren\n\n直接保存到文件中\n123456789101112131415# -*- coding: utf-8 -*-import scrapyclass LuarenSpider(scrapy.Spider):    name = &quot;luaren&quot;     allowed_domains = [&quot;lua.ren&quot;]    start_urls = [        &#x27;http://lua.ren/&#x27;,        &#x27;http://lua.ren/topic/342/&#x27;    ]                  def parse(self, response):        filename = response.url.split(&quot;/&quot;)[-2]         with open(filename, &#x27;wb&#x27;) as f:             f.write(response.body)\n\n\n保存到ORM中\nORM定义\n1234567# -*- coding: utf-8 -*-import scrapyclass RenItem(scrapy.Item):    title = scrapy.Field()    link = scrapy.Field()    desc = scrapy.Field()\n\n\n爬虫\n12345678910111213141516171819# -*- coding: utf-8 -*-import scrapyfrom ren.items import RenItemclass LuarenSpider(scrapy.Spider):    name = &quot;luaren&quot;     allowed_domains = [&quot;lua.ren&quot;]    start_urls = [        &#x27;http://lua.ren/&#x27;,        &#x27;http://lua.ren/topic/342/&#x27;    ]                  def parse(self, response):        for sel in response.xpath(&#x27;//ul/li&#x27;):            item = RenItem()             item[&#x27;title&#x27;] = sel.xpath(&#x27;a/text()&#x27;).extract()            item[&#x27;link&#x27;] = sel.xpath(&#x27;a/@href&#x27;).extract()            item[&#x27;desc&#x27;] = sel.xpath(&#x27;text()&#x27;).extract()            yield item\n\n\n先生成一堆的代码， 添加代码，按url进行依次访问，然的把body reponse通过回调返回给用用户处理，用户在cb中写自己的代码， xpath解析返回的数据，整个机制不是很复杂，不多说了。\n运行与保存结果为JSON数据。\n12scrapy crawl luarenscrapy crawl luaren -o items.json","slug":"old_topic/2016-09-17-342","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"dbc3ab64f8a793e30ff0dafc0aa1a042","title":"OpenResty向graylog推送数据","content":"编辑作者：糖果\naccess_log syslog:server=0.0.0.0:55555 graylog2_format;\nerror_log syslog:server=0.0.0.0:55555;\n\n","slug":"old_topic/2016-09-17-339","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"df2fd49163891cc3e511275bc9921624","title":"MoonScript与Simple.http","content":"MoonScript调用Lapis的Simple.http，其实调用的就是OpenResty的http的接口。\ncandylab.moon\n123456http = require &quot;lapis.nginx.http&quot;body, status_code, headers = http.simple &#123;    url: &#x27;http://moonscript.cn&#x27;     method: &quot;GET&quot;    headers: &#123;&#125; &#125;\n\ncandylab.lua\n123456local http = require(&quot;lapis.nginx.http&quot;)local body, status_code, headers = http.simple(&#123;    url = &#x27;http://moonscript.cn&#x27;,    method = &quot;GET&quot;,    headers = &#123; &#125;&#125;)","slug":"old_topic/2016-09-17-343","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e264d16f8d37da4ca95ff610b1733e03","title":"MoonScript版的ngx.timer","content":"实际如果是直接调用ngx.timer的API，moonscript和lua的ngx.timer的函数写法差别不是很大。\ncandylab.moon\n123456789handler = (fill, params)-&gt;    ok, err = ngx.timer.at(1, handler, &quot;params-data&quot;)    ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok, &quot; err:&quot;, err)         ok, err = ngx.timer.at(6, handler, &quot;params-data&quot;)               if not ok then    ngx.log(ngx.ERR, &quot;err:&quot;, err)\n\ncandylab.lua\n12345678910111213local http = require(&quot;lapis.nginx.http&quot;)local handlerhandler = function(fill, params)  local ok, err = ngx.timer.at(1, handler, &quot;params-data&quot;)  return ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok, &quot; err:&quot;, err)endlocal ok, err = ngx.timer.at(6, handler, &quot;params-data&quot;)if not ok then  return ngx.log(ngx.ERR, &quot;err:&quot;, err)end","slug":"old_topic/2016-09-17-344","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"9e3061a0f19c04425ccac351efe5e0da","title":"Openresty定时器ngx.timer通过Redis的pubsub进行通信","content":"做一个小实验：\n先打开一个redis-cli, 监听所有事件：\n12127.0.0.1:6379&gt;  config set notify-keyspace-events KEA 127.0.0.1:6379&gt; psubscribe __key*@0__:* \n\n再开一个redis-cli,进行publish与subscribe操作：\n12127.0.0.1:6379&gt; publish chatroom &quot;123&quot;127.0.0.1:6379&gt; publish chatroom &quot;abc&quot;\n\n然于，打开一个python redis client进行subscribe:\n123456789r = redis.StrictRedis(host=&#x27;localhost&#x27;, port=6379, db=0, password=&#x27;candylab.net&#x27;)ps = rc.pubsub()ps.subscribe(&#x27;chatroom&#x27;)for item in ps.listen():      if item[&#x27;type&#x27;] == &#x27;message&#x27;:          print item[&#x27;data&#x27;]  \n\n\nPython Redis客户端\nLUA Redis客户端\nLUA Redis客户端\n实际上我们是可以，在OpenResty的定时器处理过程中对Redis进行操作的， 这种对redis的数据操作的API是不会在OpenResty的各个阶段被disabled，所以我们可以通过redis进行表数据共享，通过订阅与支持Redis客户端口的相应语言进行耦合通信与协作工作,比如我们可以通过publish IP数据让订阅者对当地的Iptable进行封禁。\n实际上下面的思路是，用Openrsty的Timer生成心跳，让OpenResty通过publish吐出一个二维结构的计划任务表，让对应订阅者去执行，这样在Openresty阶段做的就是这张表的维护与发布，基于OpenResty本身Timer设定的心跳的基础上。\n","slug":"old_topic/2016-09-17-345","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"55c8ceefd620d530c7de11d61153ba84","title":"MoonScript与Redis客户端","content":"所谓的Redis LUA客户端有两种版本，一种就是本地可运行版本，还有一个版本是OpenResty的版本，下面介绍的这段Moonscript段代码是本地版的。\n作者：糖果\ncandylab.moon\n123456789redis = require &quot;redis&quot;client = redis.connect &#x27;127.0.0.1&#x27;, 6379auth_flg = client\\auth &quot;www.moonscript.cn&quot;if not auth_flg     print(&quot;Auth NG!!!&quot;)client\\publish &quot;chatroom&quot;, &quot;www.candylab.net&quot;\n\n\ncandylab.lua\n1234567local redis = require(&quot;redis&quot;)local client = redis.connect(&#x27;127.0.0.1&#x27;, 6379)local auth_flg = client:auth(&quot;www.moonscript.cn&quot;)if not auth_flg then  print(&quot;Auth NG!!!&quot;)endreturn client:publish(&quot;chatroom&quot;, &quot;www.candylab.net&quot;)\n程序员改Bug的时候\n","slug":"old_topic/2016-09-17-346","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"4b277b3bf21c49d9a15db633f740d15e","title":"从实现角度看Openresty + LUA = WAF","content":"作者：糖果\n1.WAF存在形态WAF就是WEB防火墙，Nginx Lua和Openresty的出现，让基于LUA开发的WAF更有可能。对所有会造成安全威胁的HTTP请求数据，都应该成为安全检查策略应该关注的内容，笼统上来讲ORWAF的式样要求的输入数据，就是可以在WEB服务器端见到的所有的HTTP数据，而这些数据对OpenResty这种WEB服务器来讲，几乎都是可见的。\n常见的WEB开发是不能关注所有的安全式样，比如XSS、SQL注入、CC等所有的这些涉及安全的功能需求，并且这些需求随着外部安全气象发生变化的，需要不断的更新策略，这些是安全共通业务而不是产品业务。\n基于大日志数据分析的WEB安全分析模块，是一种接近实时拦截，而不是准实时的安全防火墙机制。常见的OR(OpenResty)更多的是针对正则的实时拦截策略。基于LOG日志分析是一种异步的处理机制实时读取日志，不会直接对产品业务线的性能有太多的干扰，而基于OR(OpenResty)LUA WAF大多数时是以代理的形式，串行的部署在正常的WEB业务前进行拦截的，是影响业务响应时间的，在应急事件响应中与日常安全防护过程中，这两种形式各有利弊。\nOpenResty + LUA = WAF目前的天花板，是带宽的上限和自身性能扩展的限制。\n2.WAF需求与实现从实现的角度，整体上可以把WAF看成是一个WEB请求数据的过滤器，在HTTP文本流中过滤威胁字符串和恶意访问模式。而策略是什么？就是定义， 对HTTP请求中的数据，按那些“关键字”、“正则”等规则定义进行查找，然后做出预定的响应的描述。\n所以，对规则与响应动作的描述成为WAF实现的一个重点项目之一。\n把WAF分成几大块的话，有以下枝干机能：\n\n数据取得与组织（Stream、Pipeline等）。\n规则与响应定义的解析(正则、JSON、YAML等)。\n响应动作的执行发生。（Nginx状态、IP Table）。\n\n如果OR + LUA = WAF是以代理形式存在的， 那业务的WEB服务一般是放在UpStream上的。WAF就是一个与否判断状态机， True：有威胁进行拦截。 False:无威胁放行请求给上游业务服务。\n对于最小化的开源WAF来讲，就是要实现上面提及的功能特性。软件实现的过程，就是把需求式样翻译成程序语言的过程，代码是对需求式样的一种计算机语言描述。Candy WAF的由来就是为了对以上WAF式样进行程序语言实例化。\n有Dashboard就会有针对策略的维护操作， Dashboard的后台的产出是数据定义，所以后台的实现可以有更多解决方案选择，如Python、PHP、GO这些WEB开发语方和框架工具。\n对Openresty来说，OR抽象出了高级别的几个处理阶段，如下：\n\n3.WAF与一般WEB业务框架的差异一般的OR + LUA的WEB框架，主要活劝处理阶段是在Content_by_lua阶段，主杆的框架功能构成部分，比如说路由、HTTP Request请求数据集、Response响应模板渲染等。而这些功能是一般WEB开发阶段需求的机能，和WAF存在部分的交集，但不同的地方是，WAF不只是在content_by_lua阶段工作，其它常见的阶段比如说，在init阶段处理WAF数据初始化，在log阶段输出log日志等阶段都做处理。\n而如果WAF的功能是REST化的，那么WAF就需要WEB框架提供的JSON REST路由支持，这些功能可以用固定模式的硬编码在WAF与直接实现，也可以抽出一个简单的WEB框架独立完成，这样WAF就主要集中处理安全策略相关的代码实现，被抽出成共通框架的WAF代码更精简，抽出的框架代码也可以被复用，如果写成固定的代码，更多的是可被编辑，而不是被独立的复用。\n4.WAF处理数据的先后流程a. Init阶段a-1). 初始化解析策略规则定义。\nb. Content阶段b-1). HTTP请求数据取得与数据结构定义组织，往往WAF更高级的业务处理抽象概念会在这个阶段产生（Stream、Pipeline等）。这个阶段的抽象更多的是类设计模式的抽象，而不是共通机能的抽出。\nb-2). 请求数据的过滤检索模式，模糊的看WAF是一个放大很多倍的大规模的字符串处理函数集合(Input、Filter等)。\nb-3). 拦截响应，WAF可以直接执行拦截动作，而可以产生成一个有意定义的数据操作定义让基它守护程序去实执行。\nc. Log段段c-1).  产生日志与流量监控数据。\n5.WAF后台WAF后台的作用是对WAF策略定义的维护，包括新建、编辑、撤销等操作，可以做到与WAF数据相关，功能不依赖，Dashboard的输出，是WAF在Init阶段的输入，需要被初始化的策略数据。当然除此之外，还有其它功能，涉及状态显示、日志分析、分布调度。\n以上是一个简单的功能规划，还可以更多的发散扩展功能。\n原文\n和我司实习生的工作日常\n","slug":"old_topic/2016-09-17-347","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"07e149df00baf09dc3d8d5e82a638745","title":"用RESTY-HTTP实现Graylog的Widget更新与查询","content":"作者：糖果\nMoonScript for GrayLog是之前写的一个基于Lapis与Simple HTTP的Graylog日志查询SDK，支持Stream查询，最近为了做自动化分析，加入了新的接口中调用功能，加入了对Dashboardwidgets和更新与查询，通过这个程序，实现一些反扫逻辑。\n\n    @putRequest:(req_url, data) =&gt;\n        http = require &quot;resty.http&quot;\n        httpc = http.new()\n        metadata = &#123;\n          method:&quot;PUT&quot;,\n          body: data,\n          headers: self.headers_info\n        &#125;\n\n        res, err = httpc\\request_uri(req_url, metadata)\n\n        if not res\n          ngx.say(&quot;failed to request: &quot;, err)\n          return\n        return res.body\n\n\n    @updateWidget: (dashboardId, widgetId,jsonBody) =&gt;\n        errList = &#123;&#125;\n        if type(dashboardId) == &#39;nil&#39;\n            table.insert(errList, &quot;dashboard id is nil\\n&quot;)\n\n        if type(widgetId) == &#39;nil&#39;\n            table.insert(errList, &quot;widget id is nil\\n&quot;)\n\n        if type(jsonBody) == &#39;nil&#39;\n            table.insert(errList, &quot;json body is nil\\n&quot;)\n\n        num = table.getn(errList) \n        if num &gt; 0 \n            return errList\n\n\n        url = &quot;http://&quot;..self.host..&quot;:&quot;..self.port\n        req_url = url..&#39;/dashboards/&#39;..dashboardId..&#39;/widgets/&#39;..widgetId\n\n        self.headers_info = &#123;\n            &#39;Authorization&#39;: self.auth, \n            &#39;Accept&#39;: &#39;*/*&#39;,\n            &#39;Content-Type&#39;:&#39;application/json&#39;\n        &#125;\n\n        self\\putRequest req_url, jsonBody\n        return 1\n\n\n    @getRequest:(req_url) =&gt;\n        http = require &quot;resty.http&quot;\n        httpc = http.new()\n        metadata = &#123;\n          method:&quot;GET&quot;,\n          headers: self.headers_info\n        &#125;\n\n        res, err = httpc\\request_uri(req_url, metadata)\n\n        if not res\n          ngx.say(&quot;failed to request: &quot;, err)\n          return\n\n        ngx.status = res.status\n        return res.body\n\n\n    @getWidgetValue: (dashboardId, widgetId) =&gt;\n        errList = &#123;&#125;\n        if type(dashboardId) == &#39;nil&#39;\n            table.insert(errList, &quot;dashboard id is nil\\n&quot;)\n\n        if type(widgetId) == &#39;nil&#39;\n            table.insert(errList, &quot;widget id is nil\\n&quot;)\n\n        num = table.getn(errList) \n        if num &gt; 0 \n            return errList\n\n        url = &quot;http://&quot;..self.host..&quot;:&quot;..self.port\n        req_url = url..&#39;/dashboards/&#39;..dashboardId..&#39;/widgets/&#39;..widgetId..&#39;/value&#39;\n\n        self.headers_info = &#123;\n            &#39;Authorization&#39;: self.auth, \n            &#39;Accept&#39;: &#39;application/json&#39;,\n        &#125;\n\n        ret = self\\getRequest req_url\n        return ret\n        \n\n这次没有使用过去端末加JSON数据请求的方式，把simple http换成了RESTY-HTTP,项目名改了，叫“Finder”。\n本文请不要用于商业目地，非商业转载请署名原作者与原文链接。https://www.moonscript.cn/openresty/resty-http-for-graylog/\n","slug":"old_topic/2016-09-17-350","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f203242dc5cc75b60df934903f73a39e","title":"Lua 5.1 リファレンスマニュアル","content":"以下是引用原文：\n程序员改Bug的时候 ​​​​\n\n\n\n\n\n\n\n\n\n\n\nLua Lua 5.1 リファレンスマニュアル\nCopyright © 2006 Lua.org, PUC-Rio. All rights reserved.目次\n索引Top0 - 日本語訳について1 - 概要2 - 言語2.1 - 字句の構成2.2 - 値と型2.2.1 - 変換2.3 - 変数2.4 - 文2.4.1 - チャンク2.4.2 - ブロック2.4.3 - 代入2.4.4 - 制御構造2.4.5 - for文2.4.6 - 文としての関数呼び出し2.4.7 - ローカル宣言2.5 - 式2.5.1 - 算術演算子2.5.2 - 関係演算子2.5.3 - 論理演算子2.5.4 - 連結2.5.5 - 長さ演算子2.5.6 - 優先順位2.5.7 - テーブルコンストラクタ2.5.8 - 関数呼び出し2.5.9 - 関数定義2.6 - 可視ルール2.7 - エラー処理2.8 - メタテーブル2.9 - 環境2.10 - ガベージコレクション2.10.1 - ガベージコレクションメタメソッド2.10.2 - 弱参照テーブル2.11 - コルーチン3 - アプリケーションプログラムインタフェイス3.1 - スタック3.2 - スタックサイズ3.3 - 擬似インデックス3.4 - Cのクロージャ3.5 - レジストリ3.6 - Cでのエラー処理3.7 - 関数と型3.8 - デバッグインタフェイス4 - 補助ライブラリ4.1 - 関数と型5 - 標準ライブラリ5.1 - 基本関数5.2 - コルーチン操作5.3 - モジュール5.4 - 文字列操作5.5 - テーブル操作5.6 - 数学関数5.7 - 入出力機能5.8 - OS機能5.9 - デバッグライブラリ6 - スタンドアロンのLua前バージョンとの非互換Luaの完全な構文索引\n関数\n_G_VERSIONassertcollectgarbagecoroutine.createcoroutine.resumecoroutine.runningcoroutine.statuscoroutine.wrapcoroutine.yielddebug.debugdebug.getfenvdebug.gethookdebug.getinfodebug.getlocaldebug.getmetatabledebug.getregistrydebug.getupvaluedebug.setfenvdebug.sethookdebug.setlocaldebug.setmetatabledebug.setupvaluedebug.tracebackdofileerrorfile:closefile:flushfile:linesfile:readfile:seekfile:setvbuffile:writegetfenvgetmetatableio.closeio.flushio.inputio.linesio.openio.outputio.popenio.readio.tmpfileio.typeio.writeipairsloadloadfileloadstringmath.absmath.acosmath.asinmath.atan2math.atanmath.ceilmath.coshmath.cosmath.degmath.expmath.floormath.fmodmath.frexpmath.ldexpmath.log10math.logmath.maxmath.minmath.modfmath.powmath.radmath.randommath.randomseedmath.sinhmath.sinmath.sqrtmath.tanhmath.tanmodulenextos.clockos.dateos.difftimeos.executeos.exitos.getenvos.removeos.renameos.setlocaleos.timeos.tmpnamepackage.cpathpackage.loadedpackage.loadlibpackage.pathpackage.preloadpackage.seeallpairspcallprintrawequalrawgetrawsetrequireselectsetfenvsetmetatablestring.bytestring.charstring.dumpstring.findstring.formatstring.gmatchstring.gsubstring.lenstring.lowerstring.matchstring.repstring.reversestring.substring.uppertable.concattable.inserttable.maxntable.removetable.sorttonumbertostringtypeunpackxpcallAPI\nlua_Alloclua_CFunctionlua_Debuglua_Hooklua_Integerlua_Numberlua_Readerlua_Statelua_Writerlua_atpaniclua_calllua_checkstacklua_closelua_concatlua_cpcalllua_createtablelua_dumplua_equallua_errorlua_gclua_getallocflua_getfenvlua_getfieldlua_getgloballua_gethooklua_gethookcountlua_gethookmasklua_getinfolua_getlocallua_getmetatablelua_getstacklua_gettablelua_gettoplua_getupvaluelua_insertlua_isbooleanlua_iscfunctionlua_isfunctionlua_islightuserdatalua_isnillua_isnumberlua_isstringlua_istablelua_isthreadlua_isuserdatalua_lessthanlua_loadlua_newstatelua_newtablelua_newthreadlua_newuserdatalua_nextlua_objlenlua_pcalllua_poplua_pushbooleanlua_pushcclosurelua_pushcfunctionlua_pushfstringlua_pushintegerlua_pushlightuserdatalua_pushlstringlua_pushnillua_pushnumberlua_pushstringlua_pushthreadlua_pushvaluelua_pushvfstringlua_rawequallua_rawgetlua_rawgetilua_rawsetlua_rawsetilua_registerlua_removelua_replacelua_resumelua_setallocflua_setfenvlua_setfieldlua_setgloballua_sethooklua_setlocallua_setmetatablelua_settablelua_settoplua_setupvaluelua_statuslua_tobooleanlua_tocfunctionlua_tointegerlua_tolstringlua_tonumberlua_topointerlua_tostringlua_tothreadlua_touserdatalua_typelua_typenamelua_xmovelua_yield補助ライブラリ\nluaL_BufferluaL_RegluaL_addcharluaL_addlstringluaL_addsizeluaL_addstringluaL_addvalueluaL_argcheckluaL_argerrorluaL_buffinitluaL_callmetaluaL_checkanyluaL_checkintluaL_checkintegerluaL_checklongluaL_checklstringluaL_checknumberluaL_checkoptionluaL_checkstackluaL_checkstringluaL_checktypeluaL_checkudataluaL_errorluaL_getmetafieldluaL_getmetatableluaL_gsubluaL_loadbufferluaL_loadfileluaL_loadstringluaL_newmetatableluaL_newstateluaL_openlibsluaL_optintluaL_optintegerluaL_optlongluaL_optlstringluaL_optnumberluaL_optstringluaL_prepbufferluaL_pushresultluaL_refluaL_registerluaL_typenameluaL_typerrorluaL_unrefluaL_where最終更新: Fri Feb 10 17:15:37 BRST 2006 Lua 5.1 リファレンスマニュアル\nby Roberto Ierusalimschy, Luiz Henrique de Figueiredo, Waldemar CelesCopyright © 2006 Lua.org, PUC-Rio. All rights reserved.\n0 - 日本語訳について\nこの文書は、 Lua 5.1 Reference Manual を原著者に無断で日本語に訳した、非公式の Lua 5.1 リファレンスマニュアルである。\n1 - 概要\nLuaは拡張プログラミング言語である。 データ記述機能を持ち、汎用の手続き型プログラミングをサポートするようデザインされた。 オブジェクト指向プログラミング、関数型プログラミング、データ駆動型プログラミングもサポートしている。 Luaは、パワフルで軽いスクリプト言語として、それらが必要なあらゆるプログラムに使われることを意図している。 Luaは クリーンな C (つまり、ANSI C と C++ の共通のサブセット) で書かれ、ライブラリとして実装されている。\n拡張言語であるため、Luaは「メイン」プログラムを持たない。 ホストクライアント (エンベッディングプログラム、あるいは単にホスト とも呼ぶ) に 組み込まれて 動くだけである。 このホストプログラムは、Luaコードを実行する関数を呼び出したり、Luaの変数を読み書きしたり、Luaから呼ばれるCの関数を登録したりできる。 Cの関数を使ってカスタマイズすることで、共通の構文を持つプログラミング言語で様々な領域を広範囲にカバーすることができる。 Luaのディストリビューションには lua と呼ばれるサンプルのホストプログラムが含まれている。 これはLuaライブラリを使った完全なスタンドアロンのLuaインタプリタを提供している。\nLuaはフリーソフトウェアであり、ライセンスにも書かれているように、いかなる保証もなくあるがまま提供される。 このマニュアルに記述されている実装はLuaの公式ウェブサイト www.lua.org で提供されている。\n他のすべてのリファレンスマニュアルと同様、この文書はあちこちが無味乾燥である。 Luaのデザインの背後にある決定についての議論は、Luaのウェブサイトにある技術文書を参照のこと。 Luaによるプログラミングの詳しい紹介は、Roberto著 Programming in Lua を参照。\n2 - 言語\nこのセクションでは、Luaの字句、構文、意味論について記述する。 言い換えると、このセクションでは、どういったトークンが有効か、それらをどう組み合わせられるのか、そしてその組み合わせは何を意味するのかについて記述している。\n言語構造は一般的な拡張BNF記法を使って説明する。 {a} は a の0回以上の繰り返し、[a] は a が省略可能であることを表す。 非終端記号は italic で表され、キーワードは bold、他の終端記号はシングルクォートで囲まれた type writer フォントで表現される。 Luaの完全な構文はこのマニュアルの最後にある。\n2.1 - 字句の構成\nLuaの 名前 (識別子 とも呼ばれる) は、文字、数字、アンダースコアを組み合わせた任意の文字列である。 ただし数字で始まってはならない。 これは多くの言語の名前の定義に一致する。 「文字」の定義は現在のロケールに依存する。 現在のロケールでアルファベットとみなされる文字はどれも識別子に使える。 識別子は名前変数やテーブルフィールドに使われる。\n以下の キーワード は予約されており、名前としては使えない。\n   and       break     do        else      elseif\n   end       false     for       function  if\n   in        local     nil       not       or\n   repeat    return    then      true      until     while\n\nLua は大文字小文字を区別する言語である。 and は予約語だが、And と AND は、2つの異なった、有効な名前である。 慣習的に、アンダースコアと大文字で始まる名前 (例えば _VERSION) は、 Luaが使う内部のグローバル変数として予約されている。\n以下の文字列は、その他のトークンである。\n   +     -     *     /     %     ^     #\n   ==    ~=    &lt;=    &gt;=    &lt;     &gt;     =\n   (     )     &#123;     &#125;     [     ]\n   ;     :     ,     .     ..    ...\n\n文字列リテラル は対になるシングルクォートかダブルクォートで囲まれ、 以下の C のようなエスケープシーケンスを含むことができる。\n\\a — ベル\\b — バックスペース\\f — 改ページ\\n — 改行\\r — 復帰\\t — 水平タブ\\v — 垂直タブ\\ — バックスラッシュ (円記号)&quot; — 引用符 (ダブルクォート)&#39; — アポストロフィ (シングルクォート)上記に加えて、 \\改行´ (バックスラッシュに本物の改行が続いたもの) を記述して文字列中に改行を含めることができる。 さらに \\ddd´ (dddは最大3桁の10進数) というエスケープシーケンスを使って 文字列中の文字をそのコード値で指定することもできる。 (数値エスケープの後に数字が続く場合は、ぴったり3桁使って表現しなければならない。) Luaの文字列は `\\0´ で表されるゼロを含み、いかなる8ビット値も含むことができる。\nダブル(またはシングル)クォートで囲まれた文字列リテラルの中に、 ダブル(またはシングル)クォート、改行、バックスラッシュ、または埋め込まれたゼロを置くためには、 エスケープシーケンスを使わなければならない。 他のすべての文字は直接リテラルの中に入れて構わない (ファイルシステムに対しては制御文字が問題を起こすかもしれないが、Luaは大丈夫である。)\n文字列リテラルは 長括弧 で囲む長い形式を使って定義することもできる。 n 段の開き長括弧 は、 開き角括弧に n 個のイコールと、さらに開き角括弧を続けたものである。 つまり、0段の開き長括弧は [[ と書き、 1段の開き長括弧は [=[ と書き、以下同様である。 閉じ長括弧 も同様である。 例えば4段の閉じ長括弧は ]====] と書く。 長い文字列は任意の段数の開き長括弧で始まり、同じ段数の閉じ長括弧で終わる。 この角カッコ形式のリテラルは、複数行に渡って記述できる。 エスケープシーケンスは一切解釈されず、異なる段数の閉じ長括弧は無視する。 これは、正しい段数の閉じ長括弧と埋め込まれたゼロ以外の任意の内容を入れられる。\n便利なように、開き長括弧のすぐ後に改行が続いたときは、その改行は文字列に含まれない。 例えば、ASCII (つまり a´ が97、改行が10、1´ が49であるような文字コード) が使われているシステムでは、 以下の4つのリテラルは同じ文字列を表現している。\n  (1)   &#39;alo\\n123&quot;&#39;\n  (2)   &quot;alo\\n123\\&quot;&quot;\n  (3)   &#39;\\97lo\\10\\04923&quot;&#39;\n  (4)   [[alo\n        123&quot;]]\n  (5)   [==[\n        alo\n        123&quot;]==]\n\n数値定数 には省略可能な小数部と省略可能な指数部を書くことができる。 Luaは接頭辞 0x を付けた整数の16進定数も受け付ける。 有効な数値定数の例を挙げると\n   3       3.0     3.1416  314.16e-2   0.31416E1  0xff  0x56\n\nコメント は文字列の外ならどこでも、二つのハイフン (–) で始めることができる。 もし – の直後に開き長括弧以外のテキストがあれば、そのコメントは 短いコメント であり、行末まで続く。 そうでなければ、それは 長いコメント であり、対応する閉じ長括弧まで続く。 長いコメントはコードを一時的に無効にするためによく使われる。\n2.2 - 値と型\nLuaは 動的な型の言語 である。 つまり、変数は型を持たず、値が型を持つ。 型定義の構文はない。 すべての値は自分自身で型を保持している。\nLuaのすべての値は ファーストクラスの値 である。 つまり、いかなる値も変数に格納でき、他の関数に引数で渡すことができ、戻り値として返すことができる。\nLuaには8つの基本型がある。 nil、ブーリアン、数値、文字列、関数、ユーザーデータ、スレッド、テーブル である。 nil は nil 値の型である。その主な性質は他のいかなる値とも異なることであり、通常、役に立つ値がないことを表す。 ブーリアン は false と true の値を持つ型である。 nil と false は共に条件判断で偽となり、他の値は真となる。 数値 は実数 (double) を表現する。 (しかし数値の内部表現としてfloatやlongなど他の型を使うようLuaインタプリタをビルドし直すのは簡単である。 ファイル luaconf.h を参照。) 文字列 は文字の配列を表現する。 Luaは8ビットクリーンであり、 文字列にはゼロ (`\\0´) を含むいかなる8ビット文字も含むことができる (2.1 を参照)。\nLuaはLuaで書かれた関数もCで書かれた関数も呼べる (2.5.8 を参照)。\nユーザーデータ は任意のCのデータをLuaの変数に格納するために用意された。 この型は生のメモリブロックに相当し、代入と等価比較を除いて、Luaでは演算が定義されていない。 しかしながら、メタテーブル を用いることで、 プログラマはユーザーデータに対する演算を定義することができる (2.8 を参照)。 ユーザーデータはLua内で作ったり変更することはできず、CのAPIを通してのみ可能である。 これは完全にホストプログラムに所有されたデータであることを保証する。\nスレッド は実行されているそれぞれのスレッドを表現し、コルーチンを実装するために使われる (2.11 を参照)。 LuaのスレッドとOSのスレッドを混同しないように。 Luaはスレッドをサポートしないシステム上でもコルーチンをサポートする。\nテーブル は連想配列である。 すなわち数値だけでなく任意の値 (nil を除く) をキーにできる配列である。 テーブルは 異種混合 できる。 つまりあらゆる型の値 (nil を除く) を持つことができる。 テーブルはLuaの唯一のデータ構造であり、 普通の配列の他、記号表、集合、レコード、グラフ、ツリーなどを表現するために使われる。 レコードを表現するときは、フィールド名をインデックスとして使う。 このための a.name という表現が a[“name”] のシンタックスシュガーとして用意されている。 また、Luaでテーブルを作るための便利な表現がいくつかある (2.5.7 を参照)。\nインデックスと同様、テーブルフィールドの値には任意の型 (nil を除く) を格納できる。 特に、関数がファーストクラスであるため、テーブルフィールドは関数を格納することができる。 そのためテーブルは メソッド を持つことができる (2.5.9 を参照)。\nテーブル、関数、スレッド、ユーザーデータの値は オブジェクト である。 変数はこれらの実際の値は持たず、それらを 参照 しているだけである。 代入、引数渡し、関数の戻り値は、常に値への参照を扱い、値のコピーは行われない。\nライブラリ関数 type は与えられた値の型を表す文字列を返す。\n2.2.1 - 変換\nLuaは文字列と数値を実行時に自動的に変換する。 すべての数学演算は、文字列に適用されると、一般的な変換ルールに基づいてその文字列を数値に変換しようとする。 逆に、文字列が期待されるところで数値が使れると、その数値は一般的な形式の文字列に変換される。 数値が文字列に変換される方法を完璧にコントロールする場合は、 文字列ライブラリの format 関数を使う (string.format を参照)。\n2.3 - 変数\n変数は値を格納する場所である。 Luaには、グローバル変数、ローカル変数、テーブルフィールドの三種類の変数がある。\n単発の名前はグローバル変数かローカル変数を表す (または関数の仮引数かもしれないが、それはローカル変数の一種である)。\nvar ::= Name\n\n(2.1 を参照) で定義されているように、名前は識別子を表す。\n明示的にローカルと宣言されない限り、変数はグローバルとみなされる (2.4.7 を参照)。 ローカル変数は レキシカルスコープ を持ち、 そのスコープ内で定義された関数から自由にアクセスできる (2.6 を参照)。\n最初の代入が行われる前の変数の値は nil である。\nテーブルをインデックス付けするためには角カッコを使う。\nvar ::= prefixexp `[´ exp `]´\n\n最初の式 (prefixexp) はテーブル、 二番目の式 (exp) はテーブル内のエントリを指定する値でなければならない。 テーブルのインデックスを指定する式は限定された構文を持つ。 詳細は 2.5 を参照。\n構文 var.Name は var[“Name”] の単なるシンタックスシュガーであり、 テーブルフィールドを示すために使う。\nvar ::= prefixexp `.´ Name\n\nグローバル変数とテーブルフィールドへアクセスする効果はメタテーブルによって変えられる。 インデックス付き変数 t[i] へのアクセスは gettable_event(t,i) の呼び出しと等価である (gettable_event 関数の完全な説明は 2.8 を参照。 この関数はLuaで定義したり呼ぶことはできず、単に説明のため用いているだけである)。\nすべてのグローバル変数は、環境テーブル または単に 環境 (2.9 を参照) と呼ばれる通常のLuaのテーブル内に、フィールドとして存在している。 各関数はそれぞれ独自に環境への参照を持ち、 その関数内でのすべてのグローバル変数は、その環境テーブルを参照する。 関数が作られたとき、関数は、それが作られた関数から見える環境を受け継ぐ。 Luaの関数の環境テーブルを取得するには getfenv を呼ぶ。 変更するには setfenv を呼ぶ。 (Cの関数の環境はデバッグライブラリでのみ操作できる (5.9 を参照)。)\nグローバル変数 x へのアクセスは _env.x と等価であり、 以下と等価である。\n   gettable_event(_env, &quot;x&quot;)\n\nただし、_env は関数が実行されている環境を表す (gettable_event 関数の完全な説明は 2.8 を参照。 この関数はLuaで定義したり読んだりできない。 同様に変数 _env はLuaで定義されていない。 これはただ説明のために用いているだけである)。\n2.4 - 文\nLuaはPascalやCと同じように一般的な文のセットをサポートしている。 代入、制御構造、関数呼び出し、テーブルコンストラクタや変数の宣言などである。\n2.4.1 - チャンク\nLuaの実行の単位は チャンク と呼ばれる。 チャンクは、単純に、順番に実行される文の連なりである。 それぞれの文末には省略可能なセミコロンを置いても良い。\nchunk ::= &#123;stat [`;´]&#125;\n\n空文は存在しないため、`;;´ は許されていない。Luaはチャンクを、可変個の引数を持つ無名関数の本体として扱っている (2.5.9 を参照)。 従って、チャンクはローカル変数を宣言でき、引数を受け取ることができ、戻り値を返せる。\nチャンクはファイルやホストプログラム内の文字列として格納されているであろう。 チャンクが実行されるとき、まず仮想マシンの命令にコンパイルされ、それからコンパイル済みコードが仮想マシンのインタプリタによって実行される。\nチャンクはバイナリ形式のコンパイル済みコードであっても良い。 詳細は luac プログラムを参照。 ソースプログラムとコンパイル済み形式はどちらを用いても良い。 Luaは自動的にファイル形式を検出し、適切に振る舞う。\n2.4.2 - ブロック\n文の列はブロックである。 構文的には、ブロックはチャンクと等しい。\nblock ::= chunk\n\nブロックは明示的に単一の文とすることもある。\nstat ::= do block end\n\n明示的なブロックは変数宣言スコープをコントロールするのに便利である。 明示的なブロックはまた、 他のブロックの途中に return 文や break 文を入れるために使うこともある。\n2.4.3 - 代入\nLuaは多重代入を許している。 だから、代入文では左辺に変数リスト、右辺に式リストを書く。 どちらのリストもそれぞれの要素をカンマで区切る。\nstat ::= varlist1 `=´ explist1\nvarlist1 ::= var &#123;`,´ var&#125;\nexplist1 ::= exp &#123;`,´ exp&#125;\n\n式については 2.5 で議論する。\n代入の前に、値リストは変数リストの長さに調節される。 もし必要な数よりも値が多ければ、余分な値は捨てられる。 もし必要な数よりも値が少なければ、必要なだけ nil が追加される。 もし式リストの最後が関数呼び出しなら、調節の前に、その関数のすべての戻り値が値リストに追加される (ただし呼び出しをカッコで囲った場合を除く、2.5 を参照)。\n代入文は、まずすべての式を評価し、それから、代入が行われる。 だから、このコード\n   i = 3\n   i, a[i] = i+1, 20\n\nは、i に4が代入される前に a[i] の i が (3に) 評価されるため、 a[3] に20が代入される。 a[4] は何の影響もない。 同様に、       x, y = y, xは x と y の値を交換する。グローバル変数とテーブルフィールドへの代入の効果は、メタテーブルによって変えられる。 インデックス付き変数への代入 t[i] = val は settable_event(t,i,val) と等価である (settable_event 関数の完全な記述は 2.8 を参照。 この関数はLuaで定義したり呼ぶことはできず、 ただ説明のため用いているだけである)。\nグローバル変数への代入 x = val は代入 _env.x = val と等価であり、 以下と等価である。\n   settable_event(_env, &quot;x&quot;, val)\n\nただし、_env は関数が実行されている環境を表す (変数 _env はLuaに定義されていない。 これはただ説明のために用いているだけである)。\n2.4.4 - 制御構造\n制御構造 if、while、repeat は一般的な意味とよく知られた構文をしている。\nstat ::= while exp do block end\nstat ::= repeat block until exp\nstat ::= if exp then block &#123;elseif exp then block&#125; [else block] end\n\nLuaには for 文もある。 これは2つの種類がある (2.4.5 を参照)。\n制御構造の条件式は任意の値をとれる。 false と nil は共に偽である。 nil と false 以外のすべての値は真になる (特に、数値の0や空文字列は真であることに注意)。\nrepeat–until ループでは、 内側のブロックは until キーワードのところではなく条件式の後に終わる。 つまり、条件式はループブロックの内側で宣言されたローカル変数を参照できる。\nreturn 文は関数やチャンク (これはただの関数である) から値を返すために使う。 関数やチャンクは1個以上の値を返すことができる。 return 文の構文は以下の通り。\nstat ::= return [explist1]\n\nbreak 文は while、repeat、for ループの実行を終了し、 ループの次までスキップする。\nstat ::= break\n\nbreak は最も内側のループを終わらせる。\nreturn 文と break 文はブロックの 最後 の文としてのみ書くことが許される。 return や break をブロックの途中で使うことが本当に必要なら、 明示的な内部ブロックを使う次のような慣用句を使えば良い。\ndo return end\ndo break end\n\nこれで return も break も (内部) ブロックの最後の文になる。\n2.4.5 - for文\nfor 文には、数値用と汎用の2つの形式がある。\n数値用 for ループは制御変数が等差数列を辿ってコードブロックを繰り返す。 以下がその構文である。\nstat ::= for Name `=´ exp `,´ exp [`,´ exp] do block end\n\nblock は name が最初の exp で始まって二番目のexp に達するまで、 三番目の exp ずつ進む間、繰り返される。 より正確には、次のような for 文\n   for var = e1, e2, e3 do block end\n\nは次のコードに等しい。       do         local _var, _limit, _step = tonumber(e1), tonumber(e2), tonumber(e3)         if not (_var and _limit and _step) then error() end         while (_step&gt;0 and _var&lt;=_limit) or (_step&lt;=0 and _var&gt;=_limit) do           local var = _var           block           _var = _var + _step         end       end以下の点に注意:\n3つの制御式はループが始まる前に一度だけ評価される。これらは数値でなければならない。_var、_limit、_step は見えない変数である。 この名前は説明のために用いられているだけである。もし三番目の式 (ステップ) が省略されたら、1が使われる。for ループを脱出するためには break を使う。ループ変数 var はループ内でローカルである。 for 文の外側でその値を使うことはできない。 もしループ変数 var の値が必要なら、 ループを出る前に別の変数に代入する必要がある。汎用 for 文は イテレータ と呼ばれる関数を通して働く。 それぞれの繰り返しについて、新しい値を生成するためにイテレータ関数が呼ばれ、nil になったところで止まる。 汎用 for ループは以下の構文である。\nstat ::= for Name &#123;`,´ Name&#125; in explist1 do block end\n\n次のような for 文\n   for var_1, ..., var_n in explist do block end\n\nは次のコードと等価である。       do         local _f, _s, _var = explist         while true do           local var_1, … , var_n = _f(_s, _var)           _var = var_1           if _var == nil then break end           block         end       end以下の点に注意:\nexplist は一度だけ評価され、 イテレータ 関数、状態、繰り返し変数 の初期値、でなければならない。_f、_s、_var は見えない変数である。 この名前は説明のために用いられているだけである。for ループを脱出するためには break を使う。ループ変数 var はループ内でローカルである。 for 文の外側でその値を使うことはできない。 もしループ変数 var の値が必要なら、 ループを出る前に別の変数に代入する必要がある。\n2.4.6 - 文としての関数呼び出し\n副作用を許しているため、関数呼び出しは文として実行できる。\nstat ::= functioncall\n\nこの場合、戻り値はすべて捨てられる。 関数呼び出しは 2.5.8 で説明する。\n2.4.7 - ローカル宣言\nローカル変数はブロックの中どこででも宣言できる。 宣言は初期値の代入を伴ってもよい。\nstat ::= local namelist [`=´ explist1]\n\nもしあれば、多重代入と同じ構文で初期値が代入される (2.4.3 を参照)。 そうでなければ、変数はすべて nil で初期化される。\nチャンクもまたブロックであるから (2.4.1 を参照)、 明示的なブロックの外側のチャンクでもローカル変数を宣言できる。 そのようなローカル変数のスコープはチャンクの終わりまで続く。\nローカル変数の可視ルールは 2.6 で説明する。\n2.5 - 式\nLuaの基本の式を以下に示す。\nexp ::= prefixexp\nexp ::= nil | false | true\nexp ::= Number\nexp ::= String\nexp ::= function\nexp ::= tableconstructor\nexp ::= `...´\nexp ::= exp binop exp\nexp ::= unop exp\nprefixexp ::= var | functioncall | `(´ exp `)´\n\n数値と文字列リテラルは 2.1 で説明した。 変数は 2.3 で説明した。 関数定義は 2.5.9 で説明する。 関数呼び出しは 2.5.8 で説明する。 テーブルコンストラクタは 2.5.7 で説明する。 3つのドットで表される可変引数式は、可変引数関数の中でだけ使える。 これは 2.5.9 で説明する。\n二項演算子は算術演算子 (2.5.1 を参照)、 関係演算子 (2.5.2 を参照)、 論理演算子 (2.5.3 を参照) がある。 単項演算子は単項マイナス (2.5.1 を参照)、 単項 not (2.5.3 を参照)、 そして単項 長さ演算子 (2.5.5 を参照) がある。\n関数呼び出しと可変引数式は複数の値を返す。 式が文として使われた場合 (2.4.6 を参照) (関数呼び出しに対してのみ可能)、 結果のリストはゼロ個に調節され、つまりすべての戻り値が捨てられる。 他の式の中やリストの途中で使われた場合は、 結果のリストは1個に調節され、残りはすべて捨てられる。 式がリストの最後の要素として使われた場合は、 調節は行われない (カッコで囲った場合を除く)。\nいくつか例を挙げる。\n   f()                -- 戻り値は0個に調節される\n   g(f(), x)          -- f()の戻り値は1個に調節される\n   g(x, f())          -- xに加えてf()のすべての戻り値をgに渡す\n   a,b,c = f(), x     -- f()の戻り値は1個に調節される (そしてcにはnilが入る)\n   a,b = ...          -- aに可変引数の最初の値、bに2番目の値が入る\n                      -- (対応する引数がなかった場合、a、bにはnilが入る)\n   a,b,c = x, f()     -- f()の戻り値は2個に調節される\n   a,b,c = f()        -- f()の戻り値は3個に調節される\n   return f()         -- f()の戻り値をすべて返す\n   return ...         -- 渡された可変引数をすべて返す\n   return x,y,f()     -- x、yとf()のすべての戻り値を返す\n   &#123;f()&#125;              -- f()のすべての戻り値からなるリストを作る\n   &#123;...&#125;              -- 渡された可変引数すべての値からなるリストを作る\n   &#123;f(), nil&#125;         -- f()の戻り値が1個に調節される\n\nカッコに囲まれた式は常にただ1つの値を返す。 つまり、たとえ f が複数の値を返しても、(f(x,y,z)) は常に単一の値となる。 (f(x,y,z)) の値は、f が返す最初の値である。 あるいは f が何も返さなければ、nil となる。\n2.5.1 - 算術演算子\nLuaは一般的な算術演算子をサポートしている。 + (加算)、 - (減算)、* (乗算)、 / (除算)、% (剰余)、^ (累乗)、 および単項の - (符号反転)。 もしオペランドが数値、あるいは数値に変換できる文字列 (2.2.1を参照) なら、すべての演算は通常の意味を持つ。 累乗は任意の指数に対して動作する。 例えば、x^(-0.5) は x の平方根の逆数を計算する。 剰余は以下のように定義されている。\n   a % b == a - math.floor(a/b)*b\n\nつまり、負の無限大に向かって丸められた割り算の余りである。\n2.5.2 - 関係演算子\nLuaの関係演算子は以下の通りである。\n   ==    ~=    &lt;     &gt;     &lt;=    &gt;=\n\nこれらの演算子は常に false か true いずれかの結果を返す。\n等価 (==) はまずオペランドの型を比較する。 もし型が異なっていたら、結果は false である。 そうでなければ、オペランドの値が比較される。 数値と文字列は一般的な方法で比較する。 オブジェクト (テーブル、ユーザーデータ、スレッド、関数) は 参照 を比較し、 2つのオブジェクトが 同じ オブジェクトである場合だけを等しいとみなす。 新しいオブジェクト (テーブル、ユーザーデータ、関数) を作ったときは常に、 この新しいオブジェクトは、以前に存在していたオブジェクトと異なる。\n“eq”メタメソッドを使って、テーブルやユーザーデータをLuaが比較する方法を変えられる (2.8 を参照)。\n2.2.1 の変換ルールは等価比較には適用されない。 そのため、”0”==0 は false に評価され、 t[0] と t[“0”] は異なったテーブルエントリを示す。\n演算子 ~= は正確に等価 (==) の否定である。\n関係演算子は次のように働く。 引数が両方数値ならば、それらは適切に比較される。 もし両方の引数が文字列ならば、現在のロケールに従ってその値が比較される。そうでなければ、Luaは”lt”または”le”メタメソッドを試みる (2.8 を参照)。\n2.5.3 - 論理演算子\nLuaの論理演算子は次の通りである。\n   and   or    not\n\n制御構造 (2.4.4 を参照) と同じく、 すべての論理演算子は false と nil の両方を偽、それ以外のすべてを真とみなす。\n否定演算子 not は常に false か true を返す。 論理積演算子 and は、最初の引数が false か nil ならその値を返し、そうでなければ二番目の引数を返す。 論理和演算子 or は最初の引数が false か nil 以外ならその値を返し、そうでなければ二番目の引数を返す。 and と or は共にショートカット評価を行う。 つまり、二番目のオペランドは、それが必要なときだけ評価される。 いくつかの例を示す。\n   10 or 20            --&gt; 10\n   10 or error()       --&gt; 10\n   nil or &quot;a&quot;          --&gt; &quot;a&quot;\n   nil and 10          --&gt; nil\n   false and error()   --&gt; false\n   false and nil       --&gt; false\n   false or nil        --&gt; nil\n   10 and 20           --&gt; 20\n\n(このマニュアルでは `–&gt;´ で式の結果を示す。)\n2.5.4 - 連結\nLuaの文字列連結演算子はふたつのドット (`..´) で表す。 もし両方のオペランドが文字列か数値なら、それらは 2.2.1 で述べたルールに従って文字列に変換される。 そうでなければ、”concat”メタメソッドが呼ばれる (2.8 を参照)。\n2.5.5 - 長さ演算子\n長さ演算子は単項演算子 # で表される。 文字列の長さはそのバイト数である (つまり、各文字が1バイトだとした場合の、文字列の長さである)。\nテーブル t の長さは、 t[n] が nil でなく t[n+1] が nil であるような整数 n と定義されている。 また、t[1] が nil なら n はゼロになりうる。 nil でない値が1から n まで格納されている普通の配列では、 その長さは最後のインデックス n を正しく返す。 配列に「穴」がある場合 (つまり間に nil がある場合)、 #t はどれかの nil のひとつ前を返すかもしれない (つまり、その nil が配列の終わりであるように見えるのだ)。\n2.5.6 - 優先順位\nLuaでの演算子の優先順位を以下の表に示す。 優先順位は低い方から順に\n   or\n   and\n   &lt;     &gt;     &lt;=    &gt;=    ~=    ==\n   ..\n   +     -\n   *     /     %\n   not   #     - (unary)\n   ^\n\n普通通りに、カッコを使って式の優先順位を変えることができる。 連結 (..´) と累乗 (^´) は右結合である。 他の二項演算子はすべて左結合である。\n2.5.7 - テーブルコンストラクタ\nテーブルコンストラクタはテーブルを作る式である。 コンストラクタが評価されるたびに新しいテーブルが作られる。 空のテーブルを作ることも、いくつかのフィールドに初期値を持ったテーブルを作ることもできる。 コンストラクタの構文は以下の通りである。\ntableconstructor ::= `&#123;´ [fieldlist] `&#125;´\nfieldlist ::= field &#123;fieldsep field&#125; [fieldsep]\nfield ::= `[´ exp `]´ `=´ exp | Name `=´ exp | exp\nfieldsep ::= `,´ | `;´\n\n[exp1] = exp2 形式のフィールドは、 キー exp1 と値 exp2 を持つエントリをテーブルに追加する。 name = exp 形式のフィールドは [“name”] = exp と等価である。 最後の exp 形式のフィールドは、[i] = exp と同じである。 ここで i は1から始まる連続した整数であり、他の形式のフィールドはこのカウンタに影響を与えない。 例えば\n   a = &#123; [f(1)] = g; &quot;x&quot;, &quot;y&quot;; x = 1, f(x), [30] = 23; 45 &#125;\n\nは以下と等価である。       do         local t = {}         t[f(1)] = g         t[1] = “x”         – 最初のexp         t[2] = “y”         – 2番目のexp         t.x = 1            – temp[“x”] = 1         t[3] = f(x)        – 3番目のexp         t[30] = 23         t[4] = 45          – 4番目のexp         a = t       endもし最後のフィールドが exp 形式で、その式が関数呼び出しか可変引数式であれば、 その戻り値がすべてリストに追加される (2.5.8 を参照)。 これを避けるには、関数呼び出し(あるいは可変引数式)をカッコで囲む (2.5 を参照)。\n自動生成コードに便利なように、各フィールドの終わりに省略可能なセミコロンを付けても良い。\n2.5.8 - 関数呼び出し\nLuaの関数呼び出しは以下の構文である。\nfunctioncall ::= prefixexp args\n\n関数呼び出しでは、 まず prefixexp と args が評価される。 もし prefixexp の値が 関数 であれば、与えられた引数でその関数が呼ばれる。 そうでなければ、prefixexp の “call” メタメソッドが呼ばれる。 そのとき prefixexp が最初の引数として渡され、二番目以降に元々の引数が続く (2.8 を参照)。\n書式\nfunctioncall ::= prefixexp `:´ Name args\n\nは「メソッド」と呼ばれる。 呼び出し v:name(…) は v.name(v, …) のシンタックスシュガーであり、 v の評価がただ一度である点だけが異なる。引数は以下の構文を持つ。\nargs ::= `(´ [explist1] `)´\nargs ::= tableconstructor\nargs ::= String\n\n引数のすべての式は呼び出し前に評価される。 f{…} は f({…}) のシンタックスシュガーであり、新しいテーブルひとつが引数となる。 f’…’ (および f”…” や f[[…]]) は f(‘…’) のシンタックスシュガーであり、引数は文字列リテラルひとつである。\nLuaのフリーフォーマット構文の例外として、 関数呼び出しの `(´ の直前で改行することはできない。 この制限によって言語の曖昧さが避けられる。 つまり、この制限がなかった場合、もし次のように書くと\n   a = f\n   (g).x(a)\n\nLuaは単一の式 a = f(g).x(a) と解釈したかもしれない。 この場合、2つの文にしたければ間にセミコロンが必要である。 だか実際には、f を呼びたければ (g) の前の改行を取り除かなければならない。\nreturn functioncall のような呼び出し形式は 終端呼び出し と呼ばれる。 Luaは 終端呼び出し最適化 (または 終端再帰最適化) を実装している。 終端呼び出しでは、呼び出された関数は呼び出し側関数のスタックエントリを再利用する。 その結果、終端呼び出しのネスト数の制限なしに (無限に再帰呼び出しして) プログラムを実行できる。 しかしながら、終端呼び出しは呼び出し側関数に関するデバッグ情報を消してしまう。 終端呼び出しは、単一の関数呼び出しで return するという特別な状況でのみ起こることに注意。 この構文では、呼び出した関数の戻り値がそのまま呼び出し側関数の戻り値になる。 よって、以下の例はどれも終端呼び出しではない。\n   return (f(x))        -- 戻り値が1個に調節されている\n   return 2 * f(x)      -- 戻り値が加工されている\n   return x, f(x)       -- 戻り値が追加されている\n   f(x); return         -- 戻り値が捨てられている\n   return x or f(x)     -- 戻り値が1個に調節されている\n\n2.5.9 - 関数定義\n関数定義の構文を以下に示す。\nfunction ::= function funcbody\nfuncbody ::= `(´ [parlist1] `)´ block end\n\n以下のシンタックスシュガーは関数定義を単純化する。\nstat ::= function funcname funcbody\nstat ::= local function Name funcbody\nfuncname ::= Name &#123;`.´ Name&#125; [`:´ Name]\n\n以下の文\n   function f () ... end\n\nは次のように変換される。       f = function () … end以下の文\n   function t.a.b.c.f () ... end\n\nは次のように変換される。       t.a.b.c.f = function () … end以下の文\n   local function f () ... end\n\nは次のように変換される。       local f; f = function () … end次のようにではない。       local f = function () … end(この違いは、関数の中で f を参照できるかどうかである。)関数定義は実行可能な式であり、関数 型の値を持つ。 Luaがチャンクをコンパイルすると、 その中にある関数の本体もコンパイルされる。 そして、Luaが関数定義を実行したとき、 関数は インスタンス化 (または クローズ) される。 この関数インスタンス (または クロージャ) は式の最終的な値である。 同じ関数の異なるインスタンスは異なるローカル変数と異なる環境テーブルを参照する場合がある。\n仮引数はローカル変数として振る舞い、渡された実引数の値で初期化される。\nparlist1 ::= namelist [`,´ `...´]  |  `...´\n\n関数が呼ばれると、実引数リストは仮引数リストの長さに調節される。 ただし、仮引数リストの最後が3つのドット (`…´) である 可変引数 の場合を除く。 可変引数では実引数が調節されず、 代わりに余分の実引数はすべて 可変引数式 によって関数に渡される。 可変引数式もまた3つのドットで書く。 この式の値は、すべての余分の実引数からなるリストである。 これは複数の戻り値を持つ関数に似ている。 可変引数式が他の式の中やリストの途中で使われた場合は、 結果のリストは要素が1個に調節される。 リストの最後の要素で使われた場合は、 調節は行われない(カッコで囲った場合を除く)。\n例として、以下の定義を考える。\n   function f(a, b) end\n   function g(a, b, ...) end\n   function r() return 1,2,3 end\n\nこの場合、実引数から仮引数と可変引数式へ以下のようにマッピングされる。\n   呼び出し         仮引数\n\n   f(3)             a=3, b=nil\n   f(3, 4)          a=3, b=4\n   f(3, 4, 5)       a=3, b=4\n   f(r(), 10)       a=1, b=10\n   f(r())           a=1, b=2\n\n   g(3)             a=3, b=nil, ... --&gt;  (なし)\n   g(3, 4)          a=3, b=4,   ... --&gt;  (なし)\n   g(3, 4, 5, 8)    a=3, b=4,   ... --&gt;  5  8\n   g(5, r())        a=5, b=1,   ... --&gt;  2  3\n\n関数の結果を返すには return 文を使う (2.4.4 を参照)。 return 文に出会わずに制御が関数の終わりまで達したら、関数は何も返さない。\nコロン 構文を使って メソッド を定義できる。 メソッドとは、暗黙の引数 self を余分に持つ関数である。 つまり、以下の構文\n   function t.a.b.c:f (...) ... end\n\nは、以下の文のシンタックスシュガーである。       t.a.b.c.f = function (self, …) … end\n2.6 - 可視ルール\nLuaはレキシカルスコープを持つ言語である。 変数のスコープは、それが宣言された文の 次 から始まり、 その宣言を含む最も内側のブロックのendで終わる。 以下の例を考えよう。\n  x = 10                – グローバル変数  do                    – 新しいブロック    local x = x         – 新しい変数 x&#39;、値は 10     print(x)            --&gt; 10     x = x+1     do                  -- 別のブロック       local x = x+1     -- 別の新しい x’      print(x)          –&gt; 12    end    print(x)            –&gt; 11  end  print(x)              –&gt; 10  (グローバル変数)local x = x のような宣言に注意。 新しく定義された x はまだスコープに入っていないので、 右辺の x は外側の変数を参照する。\nレキシカルスコープのルールにより、 ローカル変数はそのスコープの内側に定義された関数から自由にアクセスできる。 内部関数から使われるローカル変数は、 内部関数の中では 上位値 または 外部ローカル変数 と呼ばれる。\nlocal 文を実行するたびに新しいローカル変数が宣言されることに注意。 以下の例を考えよ。\n  a = {}  local x = 20  for i=1,10 do    local y = 0    a[i] = function () y=y+1; return x+y end  endこのループは10個のクロージャ (つまり匿名関数の10個のインスタンス) を作る。 クロージャはすべて同じ x を共有するが、 それぞれ異なった y を持つ。\n2.7 - エラー処理\nLuaは組み込み拡張言語であるから、 すべてのLuaアクションはホストプログラムのCのコードがLuaライブラリの関数を呼ぶことによってスタートする (lua_pcall を参照)。 Luaのコンパイル中や実行中でエラーが起きたときは、制御がCに返され、 適切な動作を行うことができる (例えばエラーメッセージを出すとか)。\nLuaコードは error 関数を呼ぶことで明示的にエラーを起こすことができる。 もしLua内でエラーを捕らえる必要があれば、 pcall 関数を使えばよい。\n2.8 - メタテーブル\nLuaのどの値も メタテーブル を持つことができる。 メタテーブル はLuaの通常のテーブルであるが、 その値に対して特殊な演算をしたときの挙動を定義する。 メタテーブルのフィールドを設定することで、オブジェクトの動作をいくつかの面で変えることができる。 例えば、数値以外の値が加算のオペランドになったとき、 Luaはメタテーブルの “__add” フィールドをチェックする。 もしそれが見つかれば、加算を行うためにその関数が呼ばれる。\nメタテーブルのキーを イベント、値を メタメソッド と呼ぶ。 前の例でいうと、”add” がイベントで、加算を行う関数がメタメソッドである。\ngetmetatable 関数で任意の値のメタテーブルを取り出すことができる。\nテーブルのメタテーブルは setmetatable 関数で変更できる。 他の型のメタテーブルをLuaで変えることはできない (デバッグライブラリを除く)。 そのためにはCのAPIを使わなければならない。\nテーブルとユーザーデータは独立したメタテーブルを持つことができる (複数のテーブルやユーザーデータが同じメタテーブルを共有することもできる)。 他の型の値は、型ごとに単一のメタテーブルを共有する。 つまりすべての数値に対してひとつだけメタテーブルが存在し、 すべての文字列に対してひとつだけメタテーブルが存在し、 以下同様である。\nメタテーブルは、算術演算、関係比較、連結、長さ演算子、インデックス付けについて、オブジェクトがどう振る舞うかを制御する。 また、ユーザーオブジェクトに関しては、オブジェクトがガベージコレクトされたときに呼ばれる関数も定義できる。 各演算には イベント と呼ばれる特殊なキーが関連付けられている。 Luaが値に対してこれらの演算を行うとき、 その値がメタテーブルを持っていてイベントが設定されているかチェックされる。 キーに割り当てられた値 (メタメソッド) はLuaがその演算をどう行うかをコントロールする。\nメタテーブルがコントロールできる演算を以下に示す。 各演算は関連付けられた名前で区別される。 各演算のキーは、その名前の前に2つのアンダースコア `__´ が付く文字列である。 例えば、”add”演算のキーは、文字列 “__add” である。 これらの演算の効果は、いかに演算が実行されるかを記述したLuaの関数で説明する。\nここにLuaのコードを示しているのは、単に説明のためである。 実際はインタプリタにハードコードされており、この擬似コードよりも効率的に動作する。 ここで使われている関数 (rawget、tonumber など) は 5.1 に記述されている。 与えられたオブジェクトのメタメソッドを取り出すコードとして、以下の表現を用いているが、\n  metatable(obj)[event]これは次のように読んでもらいたい。  rawget(metatable(obj) or {}, event)つまり、メタメソッドへのアクセスで他のメタメソッドを呼び出すことはなく、 オブジェクトがメタメソッドを持っていなくてもエラーを起こすことはない (その場合は単に nil を返す)。\n“add”: + 演算。以下の getbinhandler 関数は二項演算でLuaがどのようにハンドラを選ぶかを定義する。 まずLuaは最初のオペランドについて試みる。 もしその型が、その演算についてハンドラを定義していなければ、 二番目のオペランドを試みる。\n function getbinhandler (op1, op2, event)   return metatable(op1)[event] or metatable(op2)[event] endこの関数を使って op1 + op2 の挙動を示すと、\n function add_event (op1, op2)   local o1, o2 = tonumber(op1), tonumber(op2)   if o1 and o2 then  – 両方のオペランドが数値か?     return o1 + o2   – この +´ はプリミティブな加算    else  -- 少なくとも片方は数値ではない      local h = getbinhandler(op1, op2, &quot;__add&quot;)      if h then        -- 両方のオペランドに対してハンドラを呼ぶ        return h(op1, op2)      else  -- ハンドラがない、デフォルトの動作        error(&quot;...&quot;)      end    end  end &quot;sub&quot;: - 演算。 &quot;add&quot;演算と同じように動作する。 &quot;mul&quot;: * 演算。 &quot;add&quot;演算と同じように動作する。 &quot;div&quot;: * 演算。 &quot;add&quot;演算と同じように動作する。 &quot;mod&quot;: % 演算。 &quot;add&quot;演算と同じように動作する。 Behavior similar to the &quot;add&quot; operation, プリミティブ演算として o1 - floor(o1/o2)*o2 を使う。 &quot;pow&quot;: ^ (累乗) 演算。 &quot;add&quot;演算と同じように動作する。 プリミティブ演算として関数 pow (Cの数学ライブラリ) を使う。 &quot;unm&quot;: 単項 - 演算。  function unm_event (op)    local o = tonumber(op)    if o then  -- オペランドは数値か？      return -o  -- この -´ はプリミティブな符号反転   else  – オペランドは数値でない     – オペランドからハンドラを取り出す     local h = metatable(op).__unm     if h then       – オペランドに対してハンドラを呼ぶ       return h(op)     else  – ハンドラがない、デフォルトの動作       error(“…”)     end   end end“concat”: .. (連結) 演算。 function concat_event (op1, op2)   if (type(op1) == “string” or type(op1) == “number”) and      (type(op2) == “string” or type(op2) == “number”) then     return op1 .. op2  – プリミティブ文字列連結   else     local h = getbinhandler(op1, op2, “__concat”)     if h then       return h(op1, op2)     else       error(“…”)     end   end end“len”: # 演算。 function len_event (op)   if type(op) == “string” then     return strlen(op)         – プリミティブの文字列長   elseif type(op) == “table” then     return #op                – プリミティブのテーブル長   else     local h = metatable(op).__len     if h then       – オペランドに対してハンドラを呼ぶ       return h(op)     else  – ハンドラがない、デフォルトの動作       error(“…”)     end   end endテーブルの長さの説明は 2.5.5 を参照。“eq”: == 演算。 関数 getcomphandler は、比較演算子のメタメソッドをLuaがどのように選ぶかを定義する。 両方のオブジェクトが同じ型で、その演算に対して同じメタメソッドを持つ場合だけ、 メタメソッドが選択される。 function getcomphandler (op1, op2, event)   if type(op1) ~= type(op2) then return nil end   local mm1 = metatable(op1)[event]   local mm2 = metatable(op2)[event]   if mm1 == mm2 then return mm1 else return nil end end“eq”イベントは次のように定義される。 function eq_event (op1, op2)   if type(op1) ~= type(op2) then  – 型が異なるか?     return false   – 異なるオブジェクト   end   if op1 == op2 then   – プリミティブのイコール     return true   – オブジェクトは等しい   end   – メタメソッドを試す   local h = getcomphandler(op1, op2, “__eq”)   if h then     return h(op1, op2)   else     return false   end enda ~= b は not (a == b) と等価である。“lt”: &lt; 演算。 function lt_event (op1, op2)   if type(op1) == “number” and type(op2) == “number” then     return op1 &lt; op2   – 数値の比較   elseif type(op1) == “string” and type(op2) == “string” then     return op1 &lt; op2   – 辞書順の比較   else     local h = getcomphandler(op1, op2, “__lt”)     if h then       return h(op1, op2)     else       error(“…”);     end   end enda &gt; b は b &lt; a と等価である.“le”: &lt;= 演算。 function le_event (op1, op2)   if type(op1) == “number” and type(op2) == “number” then     return op1 &lt;= op2   – 数値の比較   elseif type(op1) == “string” and type(op2) == “string” then     return op1 &lt;= op2   – 辞書順の比較   else     local h = getcomphandler(op1, op2, “__le”)     if h then       return h(op1, op2)     else       h = getcomphandler(op1, op2, “__lt”)       if h then         return not h(op2, op1)       else         error(“…”);       end     end   end enda &gt;= b は b &lt;= a と等価である。 “le”メタメソッドがなければ、 Luaは a &lt;= b を not (b &lt; a) とみなして”lt”を試みることに注意。“index”: table[key] インデックスアクセス。 function gettable_event (table, key)   local h   if type(table) == “table” then     local v = rawget(table, key)     if v ~= nil then return v end     h = metatable(table).__index     if h == nil then return nil end   else     h = metatable(table).__index     if h == nil then       error(“…”);     end   end   if type(h) == “function” then     return h(table, key)      – ハンドラを呼ぶか、   else return h[key]          – 演算を繰り返す   end end“newindex”: table[key] = value インデックス代入。 function settable_event (table, key, value)   local h   if type(table) == “table” then     local v = rawget(table, key)     if v ~= nil then rawset(table, key, value); return end     h = metatable(table).__newindex     if h == nil then rawset(table, key, value); return end   else     h = metatable(table).__newindex     if h == nil then       error(“…”);     end   end   if type(h) == “function” then     return h(table, key,value)    – ハンドラを呼ぶか、   else h[key] = value             – 演算を繰り返す。   end end“call”: 値を関数呼び出ししたときに呼ばれる。 function function_event (func, …)   if type(func) == “function” then     return func(…)   – プリミティブの関数呼び出し   else     local h = metatable(func).__call     if h then       return h(func, …)     else       error(“…”)     end   end end\n2.9 - 環境\nスレッド、関数、ユーザーデータ型のオブジェクトは、 メタテーブルに加えてもうひとつ、 関連付けれられたテーブルを持つ。 これを 環境 と呼ぶ。 メタテーブル同様、環境も普通のテーブルである。\nユーザーデータに関連付けられた環境はLuaにとっては意味を持たない。 これはプログラマのために、 ユーザーデータにテーブルを関連付ける機能として存在するだけである。\nスレッドに関連付けられた環境は グローバル環境 と呼ぶ。 これは、スレッドと、スレッドが作成した (loadfile、loadstring または load を使って) ネストされていない関数のデフォルトの環境として使われ、 Cのコードで直接アクセスできる (3.3 を参照)。\nCの関数に関連付けられた環境はCのコードで直接アクセスできる (3.3 を参照)。 またその関数で作成する他のCの関数のデフォルトの環境として使われる。\nLuaの関数に関連付けられた環境は、 その関数の中でアクセスするグローバル変数を解決するために使われる (2.3 を参照)。 またその関数で作成する他のLuaの関数のデフォルトの環境として使われる。\nsetfenv を呼ぶと走行中のスレッドや Lua の関数の環境を変更できる。 getfenv を呼ぶと走行中のスレッドや Lua の関数の環境を取得できる。 他のオブジェクト (ユーザーデータ、Cの関数、他のスレッド) の環境を操作するには、CのAPIを使わなければならない。\n2.10 - ガベージコレクション\nLuaは自動的にメモリを管理する。 つまり、新しいオブジェクトのためのメモリ確保や、オブジェクトが要らなくなったときの解放について、悩まなくてよい。 Luaは死んだオブジェクト (もうアクセスできなくなったオブジェクト) を回収する ガベージコレクタ を時々実行することで、自動的にメモリを管理する。 テーブル、ユーザーデータ、関数、スレッド、文字列といったすべてのLuaオブジェクトは自動管理の対象である。\nLuaはインクリメンタルマークアンドスイープコレクタを実装している。 ガベージコレクションの周期を制御するために2つの数値、 ガベージコレクタ停止値 と ガベージコレクタステップ係数 を使うことができる。\nガベージコレクタ停止値は、 どれだけ経ったら新しいサイクルを開始するかを制御する。 値が大きいほどコレクタが消極的になる。 1より小さな値にすると、コレクタがすぐに新しいサイクルを開始する。 2にすると、使われているメモリの合計が2倍になったらコレクタが新しいサイクルを開始する。\nステップ係数は、メモリ確保に対するコレクタの相対速度を制御する。 値が大きいほどコレクタは積極的になるが、 各インクリメンタルステップのサイズが大きくなる。 1より小さな値にすると、コレクタは非常に遅くなり、結果としてサイクルが終わらないかもしれない。 デフォルトの2では、メモリ確保の「2倍」の速度でコレクタが動作する。\nCの lua_gc か Luaの collectgarbage を呼ぶと、これらの値を変更できる。 いずれもパーセント値で引数を取る (従って 100 を渡すと 1.00 を意味する)。 これらの関数でコレクタを直接制御できる (停止させたり再開させたり)。\n2.10.1 - ガベージコレクションメタメソッド\nCのAPIを使う場合、ユーザーデータにガベージコレクタメタメソッドを設定できる (2.8を参照)。 このメタメソッドは ファイナライザ と呼ばれることもある。 ファイナライザはLuaのガベージコレクタを外部リソースと共に使えるようにする (ファイルやネットワーク接続、データベース接続などを閉じたり、独自に確保したメモリを解放するとか)。\nメタテーブルに __gc フィールドを持つユーザーデータがガベージになっても、ガベージコレクタはそれをすぐには回収しない。 その代わり、Luaはそれをリストに入れる。 他のオブジェクトの回収が終わったあと、Luaはリスト内のユーザーデータに対して以下の関数と同等のことを行う。\n function gc_event (udata)   local h = metatable(udata).__gc   if h then     h(udata)   end end各ガベージコレクションサイクルの終わりに、 作られたときと 逆の順番で ユーザーデータのファイナライザが呼ばれる。 つまり、最初に呼ばれるファイナライザは、一番最近に作られたユーザーデータのものである。\n2.10.2 - 弱参照テーブル\n弱参照テーブル は 弱参照 な要素を持つテーブルである。 弱参照はガベージコレクタに無視される。 言い換えると、オブジェクトへの参照が弱参照のみであれば、ガベージコレクタはそのオブジェクトを回収してしまう。\n弱参照テーブルは、キー、値、あるいはその両方が弱参照である。 弱参照キーを持つテーブルは、キーは回収されるが、その値は回収されない。 弱参照キーと弱参照値の両方を持つテーブルでは、キーも値も回収の対象になる。 キーと値のどちらか一方が回収されると、キーと値のペア全体がテーブルから除去される。 テーブルの弱参照の性質は、メタテーブルの __mode フィールドで制御できる。 もし __mode フィールドが文字列で、文字 k´ が含まれていたら、テーブルのキーが弱参照となる。 もし __mode フィールドが文字 v´ を含んでいたら、テーブルの値が弱参照となる。\nメタテーブルとして使った後に、そのテーブルの __mode フィールドの値を変更するべきではない。 このメタテーブルで制御されているテーブルの弱参照の挙動が未定義となる。\n2.11 - コルーチン\nLuaはコルーチンをサポートしている。 協調的マルチスレッド と呼ばれることもある。 Luaのコルーチンは独立に実行されるスレッドを表現している。 マルチスレッドシステムのスレッドとは違って、 コルーチンはyield関数を呼んで明示的に実行を中断しなければならない。\nコルーチンを作るには coroutine.create を呼ぶ。 これはひとつだけ引数をとり、それにコルーチンのメイン関数を渡す。 create 関数は新しいコルーチンを作成し、その スレッド オブジェクトを返す。 コルーチンはすぐには実行されない。\ncoroutine.create から返されたスレッドを最初の引数に渡して最初に coroutine.resume を呼んだとき、 そのメイン関数の最初の行からコルーチンの実行が始まる。 coroutine.resume に余分の引数を指定すると、それらはコルーチンのメイン関数に渡される。 コルーチンが開始されたら、終わりに達するか yield を呼ぶまで実行される。\nコルーチンは2つの方法で実行を終われる。 メイン関数からreturnして (明示的にか、最後の命令が終わって暗黙的にか) 正常終了したときと、 保護されないエラーが起きて異常終了したときである。 最初の場合では、true と、メイン関数からの戻り値を、coroutine.resume が返す。 エラーの場合は、coroutine.resume は false とエラーメッセージを返す。\nコルーチンは coroutine.yield を呼ぶことで中断される。 コルーチンが中断されると、対応する coroutine.resume からすぐに戻る。 コルーチンの中で呼ばれた関数の中で中断されても同様である (つまり、メイン関数から直接的/間接的に呼ばれた、メイン関数以外の関数の中でも)。 この場合も、coroutine.resume は true を返す。 coroutine.yield に引数が渡されていれば、それも返される。 次に同じコルーチンをresumeすると、中断した場所から実行が再開される。 coroutine.resume に余分な引数を渡すと、coroutine.yield からそれらが返される。\ncoroutine.wrap 関数は coroutine.create と同様にコルーチンを作成するが、 コルーチン自身を返すのではなく、コルーチンをresumeする関数を返す。 その関数に渡された引数は coroutine.resume に追加の引数として渡される。 coroutine.resume からの戻り値は、最初のひとつ (ブーリアン型のエラーコード) を除いた残りが返される。 coroutine.resume と違って、 この関数はエラーを捕らえることはなく、内部で起きたエラーは呼び出した側に伝搬する。\n例として、次のコードを考える。\nfunction foo (a)  print(“foo”, a)  return coroutine.yield(2*a)end\nco = coroutine.create(function (a,b)      print(“co-body”, a, b)      local r = foo(a+1)      print(“co-body”, r)      local r, s = coroutine.yield(a+b, a-b)      print(“co-body”, r, s)      return b, “end”end)\nprint(“main”, coroutine.resume(co, 1, 10))print(“main”, coroutine.resume(co, “r”))print(“main”, coroutine.resume(co, “x”, “y”))print(“main”, coroutine.resume(co, “x”, “y”))これを実行すると、以下の出力を得る。co-body 1       10foo     2main    true    4co-body rmain    true    11      -9co-body x       ymain    true    10      endmain    false   cannot resume dead coroutine\n3 - アプリケーションプログラムインタフェイス\nこのセクションではLuaのためのCのAPIを説明する。 これは、ホストプログラムがLuaに働きかけるためのCの関数のセットである。 すべてのAPI関数と、関連する型、定数は、ヘッダーファイル lua.h で定義されている。\nこのマニュアルでは「関数」という言葉を使うが、代わりにマクロとして提供されているものもある。 そのようなマクロはすべて、各引数がちょうど一度だけ評価され、いかなる隠れた副作用も発生しない (ただし最初の引数を除く。ここには常にLuaステートを渡す)。\nほとんどのCのライブラリと同様に、 LuaのAPI関数は引数の妥当性や一貫性をチェックしない。 しかし、ファイル luaconf.h の中のマクロ luai_apicheck を適切に定義してLuaを再コンパイルすると、この動作を変更できる。\n3.1 - スタック\nLuaはCとの間で値を受け渡しするために 仮想スタック を使う。 スタック内の各要素は、Luaの値 (nil、数値、文字列など) を表している。\nLuaがCを呼ぶときは、以前のスタックの状態やまだアクティブなCの関数が使っているスタックに影響されないように、新しいスタックを用意する。 このスタックはCの関数に渡された引数が格納されており、 Cの関数から呼び出し側に返す戻り値を格納するためにも使われる (lua_CFunction を参照)。\n利便性のため、ほとんどの問い合わせ用API関数は厳密なスタックの規則に従っていない。 代わりに、インデックス を使って、スタック内の任意の要素にアクセスできる。 プラスのインデックスはスタック内の 絶対 位置を表し (1 から始まる)、 マイナスのインデックスはスタックトップからの相対 オフセット を表す。 具体的に言うと、スタックに n 個の要素があるとして、 インデックス1は最初の要素 (つまり、空のスタックに最初に積まれた要素) を表し、 インデックス n は最後の要素を表す。 インデックス-1も最後の要素 (つまりスタックトップにある要素) を表し、 インデックス -n は最初の要素を表す。 有効な インデックスは1からスタックトップの間だけである (つまり 1 &lt;= abs(index) &lt;= top)。\n3.2 - スタックサイズ\nLuaのAPIを使うときは、一貫性を保証する責任がある。 特に、スタックオーバーフローに気を付けなければならない。 スタックサイズを伸ばすためには関数 lua_checkstack を使う。\nLuaがCを呼ぶときは、 最低でも全体で LUA_MINSTACK 個のスタック要素が利用可能である。 LUA_MINSTACK は20に定義されており、 スタックにどんどん要素を積むようなループがあったりしなければ、 普通はスタック空間を気にしなくても良い。\n多くの問い合わせ関数には、スタック空間内で利用可能な任意のインデックス値を使える。 つまり、lua_checkstack を使って設定できる最大スタックの長さまでのインデックスである。 このようなインデックスは 受け入れ可能なインデックス と呼ぶ。 もっと正確には、受け入れ可能なインデックス は以下のように定義される。\n (index &lt; 0 &amp;&amp; abs(index) &lt;= top) || (index &gt; 0 &amp;&amp; index &lt;= stackspace)\n\n0は決して受け入れ可能なインデックスにならない。\n3.3 - 擬似インデックス\n特に明記されていなければ、 どの関数も 疑似インデックス と呼ばれる有効なインデックスを受け付ける。 これはスタック内に無いいくつかのLuaの値にCのコードからアクセスするためのものである。 疑似インデックスは、スレッドの環境、関数の環境、レジストリ、Cの関数の上位値にアクセスするために使う (3.4 を参照)。\nスレッドの環境 (グローバル変数がある場所) は常に擬似インデックス LUA_GLOBALSINDEX の位置にある。 走行中のCの関数の環境は常に擬似インデックス LUA_ENVIRONINDEX の位置にある。\nグローバル変数の値にアクセスしたり変更するためには、 環境テーブルに対して普通のテーブル操作を行う。 例えば、グローバル変数の値にアクセスするには以下を行う。\n   lua_getfield(L, LUA_GLOBALSINDEX, varname);\n\n3.4 - Cのクロージャ\nCの関数を作成するとき、いくつかの値を関連付けて Cのクロージャ を作ることができる。 これらの値は 上位値 と呼ばれ、 その関数が呼ばれたときにいつでもアクセスできる。 (lua_pushcclosure を参照)。\nCの関数が呼ばれると、特別な疑似インデックスにこれらの値が配置される。 これらの疑似インデックスはマクロ lua_upvalueindex で生成される。 関数に関連付けられた最初の値は lua_upvalueindex(1) の位置にあり、残りも同様である。 現在の関数の上位値の数よりも大きい n で lua_upvalueindex(n) を呼び出しても、 受け入れ可能な (ただし有効でない) インデックスが生成される。\n3.5 - レジストリ\nLuaはレジストリを提供している。 これは定義済みのテーブルで、好きなLuaの値を格納するためにCのコードから使うことができる。 このテーブルは常に疑似インデックス LUA_REGISTRYINDEX に置かれている。 どのCのライブラリもデータを保持するためにこのテーブルを使えるが、 衝突を避けるため他のライブラリが使っていないキーを選ぶ必要がある。 典型的には、ライブラリ名を含む文字列とか、自分のコードで使っているCオブジェクトのアドレスを持つライトユーザーデータを、キーとして使うと良い。\nレジストリ内の整数キーは、補助ライブラリで実装されているリファレンスメカニズムで使われており、それゆえ他の目的に使うべきでない。\n3.6 - Cでのエラー処理\n内部的に、Luaはエラー処理のためにCの longjmp の機能を使う。 (C++を使っているのなら、例外を使うこともできる。luaconf.h ファイルを参照。) Luaがエラーに直面すると (メモリ不足とか、型エラーとか、構文エラーとか、実行時エラーなど)、 エラーを 発生 させ、つまるところロングジャンプが行われる。 保護された環境 は復帰点をセットするために setjmp を使い、 エラーは最も最近作られたアクティブ復帰点にジャンプすることになる。\nAPIのほとんどの関数はエラー、例えばメモリ確保エラーなどを起こす可能性がある。 以下の関数は保護モード (つまり、実行するために保護された環境を作る) で実行するため、決してエラーを起こさない。 lua_newstate, lua_close, lua_load, lua_pcall, and lua_cpcall。\nlua_error を呼ぶと、CのコードからLuaのエラーを発生させることが出来る。\n3.7 - 関数と型\n以下にCのAPIのすべての関数と型をアルファベット順に示す。\nlua_Alloc\n      typedef void * (*lua_Alloc) (void *ud,\n                                   void *ptr,\n                                   size_t osize,\n                                   size_t nsize);\n\nLuaステートが使うメモリアロケータ関数の型である。 メモリアロケータ関数は realloc に似た機能を提供しなければならないが、 まったく同じではない。 引数は以下の通り。 ud: lua_newstate に渡されたポインタ。 ptr: 割り当て/再割り当て/解放するブロックへのポインタ。 osize: 元のブロックサイズ。 nsize: 新しいブロックサイズ。 osize がゼロの場合、またその場合に限り、ptr は NULLになる。 nsize がゼロの場合、アロケータは NULL を返さなければならない。 osize がゼロでない場合、ptr が指すメモリブロックを解放すべきである。 nsize がゼロでない場合、要求を満たせなければアロケータは NULL を返す。 nsize がゼロでなく osize がゼロの場合、アロケータは malloc のように振る舞うべきである。 nsize と osize が共にゼロでない場合、 osize &gt;=nsize であれば、Luaはアロケータが決して失敗しないものと仮定している。\nアロケータ関数の簡単な実装を示そう。 これは lua_newstate が補助ライブラリで使っている。\nstatic void *l_alloc (void *ud, void ptr, size_t osize, size_t nsize) {  (void)ud;     / not used /  (void)osize;  / not used /  if (nsize == 0) {    free(ptr);  / ANSIはfree(NULL)は効果がないと規定している /    return NULL;  }  else    / ANSIはrealloc(NULL, size)はmalloc(size)と同じと規定している */    return realloc(ptr, nsize);}\nlua_atpanic\n      lua_CFunction lua_atpanic (lua_State *L, lua_CFunction panicf);\n\n新しいパニック関数を設定し、古いものを返す。\n保護された環境の外側でエラーが起きると、Luaは パニック関数 を呼び、それから exit(EXIT_FAILURE) を呼んでホストアプリケーションを終了する。 パニック関数が戻らなければ(例えばロングジャンプするとかで)、終了しないようにできる。\nパニック関数はスタックの一番上にあるエラーメッセージにアクセスできる。\nlua_call\n      void lua_call (lua_State *L, int nargs, int nresults);\n\n関数を呼ぶ。\n関数を呼ぶには、以下の手順に従わなければならない。 まず、呼びたい関数をスタックに積む。 次に、その関数に渡す引数を順番通りに積む。 つまり最初の引数を最初に積む。 最後に、lua_call を呼ぶ。 nargs はスタックに積んだ引数の数である。 すべての引数と関数の値は関数を呼んだときにスタックから取り除かれる。 関数が戻るとき、スタックに戻り値が積まれる。 戻り値の数は nresults 個に調節される。 ただし nresults が LUA_MULTRET の場合は調節されない。 この場合、関数の すべての 戻り値が積まれる。 Luaは戻り値をスタック空間に合うようにする。 関数の戻り値は順番通りに (最初の戻り値が最初に) スタックに積まれる。 従って呼び出し後のスタックの一番上は、その最後の戻り値である。\n呼び出した関数の中で起きたエラーは上に伝搬される(longjmpを使って)。\n以下のLuaコードと等価なことをホストプログラムからはどうすれば良いのかの例を示す。\n   a = f(&quot;how&quot;, t.x, 14)\n\nこれをCで書くと:    lua_getfield(L, LUA_GLOBALSINDEX, “f”);          /* 呼ぶ関数 /    lua_pushstring(L, “how”);                                 / 最初の引数 /    lua_getfield(L, LUA_GLOBALSINDEX, “t”);            / テーブルt&#39; */     lua_getfield(L, -1, &quot;x&quot;);                 /* t.xの結果(2番目の引数)を積む */     lua_remove(L, -2);                           /* スタックから t’ を取り除く /    lua_pushinteger(L, 14);                                   / 3番目の引数 /    lua_call(L, 3, 1);         / 3個の引数と1個の戻り値で関数を呼ぶ /    lua_setfield(L, LUA_GLOBALSINDEX, “a”);        / グローバル変数 `a’ に代入 */上のコードは「整合が取れている」ことに注目。 最終的にスタックは元の状態に戻っている。 これは良いプログラミング作法であると考えられる。\nlua_CFunction\n      typedef int (*lua_CFunction) (lua_State *L);\n\nCの関数の型。\n適切にLuaとやりとりするに、Cの関数は、 引数と戻り値の受け渡し方法を定義する以下の手順に従わなければならない。 Cの関数はLuaからの引数をスタックに順番通り受け取る (最初の引数が最初に積まれる)。 つまり、関数の開始時点では、 lua_gettop(L) は関数が受け取った引数の数を返す。 最初の引数(もしあれば)はインデックス1で、最後の引数はインデックス lua_gettop(L) である。 Luaに値を返すには、Cの関数は単にスタックにその値を順番通り (最初の戻り値を最初に) 積み、戻り値の数を返すだけで良い。 戻り値より下のスタックにある余計な値はすべてLuaによって捨てられる。 Luaの関数と同様、Luaから呼ばれるCの関数でも、たくさんの戻り値を返すことができる。\n例として、可変個の数値の引数を取り、その平均と合計を返す関数を以下に示す。\n   static int foo (lua_State *L) &#123;\n     int n = lua_gettop(L);    /* 引数の数 */\n     lua_Number sum = 0;\n     int i;\n     for (i = 1; i &lt;= n; i++) &#123;\n       if (!lua_isnumber(L, i)) &#123;\n         lua_pushstring(L, &quot;関数 `average&#39; の引数が正しくありません&quot;);\n         lua_error(L);\n       &#125;\n       sum += lua_tonumber(L, i);\n     &#125;\n     lua_pushnumber(L, sum/n);        /* 最初の戻り値 */\n     lua_pushnumber(L, sum);         /* 2番目の戻り値 */\n     return 2;                   /* 戻り値の数 */\n   &#125;\n\nlua_checkstack\n      int lua_checkstack (lua_State *L, int extra);\n\nスタックに少なくとも extra 個の空きスロットがあることを保証する。 もしスタックをそのサイズまで伸ばせなければ false を返す。 スタックがすでに指定された長さよりも長ければ、 わざわざスタックを縮めたりせず、何も変えない。\nlua_close\n      void lua_close (lua_State *L);\n\n渡されたLuaステート内のすべてのオブジェクトを破棄し (もしあればガベージコレクションメタメソッドも呼び)、 ステート内で使われていたすべての動的メモリを解放する。 プラットフォームによっては、 ホストプログラムが終了するときにすべてのリソースが自動的に解放されるため、 この関数を呼ぶ必要がないかもしれない。 一方、デーモンやウェブサーバのような長時間実行するプログラムでは、 消費リソースが増大するのを避けるために、 必要なくなったステートはすぐに解放する必要があるだろう。\nlua_concat\n      void lua_concat (lua_State *L, int n);\n\nスタックトップから n 個の値を連結し、それらを取り除き、結果をスタックトップに載せる。 もし n が1ならは、結果はその1つの文字列である (要するに何もしない)。 もし n が0ならば、結果は空文字列である。 連結は通常のLuaの意味論に従って行われる (2.5.4 を参照)。\nlua_cpcall\n      int lua_cpcall (lua_State *L, lua_CFunction func, void *ud);\n\nCの関数 func を保護モードで呼ぶ。 func はスタックに1個の引数、ud を持つライトユーザーデータが載った状態で開始する。 エラーが起こった場合、 lua_cpcall は lua_pcall と同じエラーコードを返し、エラーオブジェクトをスタックトップに置く。 そうでなければ0を返し、スタックは何も変えない。 func から返される値はすべて捨てられる。\nlua_createtable\n      void lua_createtable (lua_State *L, int narr, int nrec);\n\n新しい空のテーブルを作り、スタックに積む。 この新しいテーブルは narr 個の配列要素と nrec 個の非配列要素のための割り当て済み空間を持っている。 この事前割り当ては、そのテーブルがたくさんの要素を持つであろうとわかっている場合に役に立つ。 それ以外の場合は、関数 lua_newtable を使っても良い。\nlua_dump\n      int lua_dump (lua_State *L, lua_Writer writer, void *data);\n\n関数をバイナリチャンクとしてダンプする。 スタックトップにLuaの関数を1つ受け取り、1つのバイナリチャンクを生成する。 これは、再びロードされたとき、ダンプされたものと同等の関数を作る。 チャンクの各部を生成するとき、 lua_dump はそれらを書き込むために関数 writer (lua_Writer を参照) を、data を与えて呼ぶ。\n戻り値は writer の最後の呼び出しが返したエラーコードである。 0はエラーなしを表す。\nこの関数はスタックからLuaの関数を取り除かない。\nlua_equal\n      int lua_equal (lua_State *L, int index1, int index2);\n\n受け入れ可能なインデックス index1 と index2 の位置にある2つの値が等しければ1を返す。 そうでなければ0を返す。 どちらかのインデックスが有効でないときも0を返す。 比較はLuaの == 演算子の意味論に従って行われる (つまり、メタメソッドを呼ぶ場合がある)。\nlua_error\n      int lua_error (lua_State *L);\n\nLuaエラーを生成する。 呼ぶ前に、エラーメッセージ (実際にはどんな型の値でも良い) をスタックトップに置かなければならない。 この関数はロングジャンプを行うので、決して戻ってこない (luaL_error を参照)。\nlua_gc\n      int lua_gc (lua_State *L, int what, int data);\n\nガベージコレクタを制御する。\nこの関数は引数 what の値に応じていくつかの仕事を行う。\nLUA_GCSTOP— ガベージコレクタを停止させる。LUA_GCRESTART— ガベージコレクタを再開させる。LUA_GCCOLLECT— フルガベージコレクションサイクルを実行する。LUA_GCCOUNT— Luaが使っている現在のメモリ量を (キロバイトで) 返す。LUA_GCCOUNTB— Luaが使っている現在のメモリ量のバイト数を1024で割った余りを返す。LUA_GCSTEP— ガベージコレクションのインクリメンタルステップひとつを実行する。 ステップの「サイズ」は data で制御する。 大きな値は大きなステップを意味するが、具体的には定まっていない。 ステップサイズを制御したければ、 data の値を実験的に調整しなければならない。 そのステップでガベージコレクションサイクルが終われば、この関数は1を返す。LUA_GCSETPAUSE— コレクタの 停止値 (see 2.10 を参照) の新しい値として data ÷100を設定する。 関数は以前の停止値を返す。LUA_GCSETSTEPMUL— コレクタの ステップ係数 (2.10 を参照) の新しい値として 引数 ÷100を設定する。 関数は以前のステップ係数の値を返す。\nlua_getallocf\n      lua_Alloc lua_getallocf (lua_State *L, void **ud);\n\n渡されたステートのメモリアロケータ関数を返す。 ud が NULL でなければ、 Luaは lua_newstate に渡されたポインタを *ud に格納する。\nlua_getfenv\n      void lua_getfenv (lua_State *L, int index);\n\n指定したインデックスの値の環境テーブルをスタックに積む。\nlua_getfield\n      void lua_getfield (lua_State *L, int index, const char *k);\n\n値 t[k] をスタックに積む。 ただし t は指定した有効なインデックス index の値である。 Luaの中でと同様に、この関数は “index” イベントのメタメソッドを呼ぶ場合がある (2.8 を参照)。\nlua_getglobal\n      void lua_getglobal (lua_State *L, const char *name);\n\nグローバル変数 name の値をスタックに積む。 これはマクロとして定義されている。\n#define lua_getglobal(L,s)  lua_getfield(L, LUA_GLOBALSINDEX, s)\nlua_getmetatable\n      int lua_getmetatable (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値のメタテーブルをスタックに積む。 インデックスが有効でないか、その値がメタテーブルを持っていなければ、 この関数は0を返し、スタックには何も積まない。\nlua_gettable\n      void lua_gettable (lua_State *L, int index);\n\n値 t[k] をスタックに積む。 ただし t は渡された有効なインデックス index の値で、 k はスタックトップの値である。\nこの関数はスタックからキーを (そこに結果を置く前に) 取り除く。 Luaの中でと同様に、この関数は “index” イベントのメタメソッドを呼ぶ場合がある (2.8 を参照)。\nlua_gettop\n      int lua_gettop (lua_State *L);\n\nスタックトップの要素のインデックスを返す。 インデックスは1から始まるので、この戻り値はスタックの要素数と等しい (そしてゼロはスタックが空であることを意味する)。\nlua_insert\n      void lua_insert (lua_State *L, int index);\n\n指定した位置より上の要素をずらして空きスペースを作り、スタックトップの要素をその位置に移動する。 疑似インデックスは、実際のスタック位置ではないため、指定できない。\nlua_Integer\n      typedef ptrdiff_t lua_Integer;\n\n整数値を表現するための、Lua APIで使われる型。\nデフォルトでは ptrdiff_t である。 これは通常、マシンが「快適に」扱える最大の整数型である。\nlua_isboolean\n      int lua_isboolean (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値がブーリアン型であれば1、そうでなければ0を返す。\nlua_iscfunction\n      int lua_iscfunction (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値がCの関数であれば1、そうでなければ0を返す。\nlua_isfunction\n      int lua_isfunction (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値が関数 (CかLuaどちらかの) であれば1、そうでなければ0を返す。\nlua_islightuserdata\n      int lua_islightuserdata (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値がライトユーザーデータであれば1、そうでなければ0を返す。\nlua_isnil\n      int lua_isnil (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値が nil であれば1、そうでなければ0を返す。\nlua_isnumber\n      int lua_isnumber (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値が数値か、数値に変換できる文字列であれば1、そうでなければ0を返す。\nlua_isstring\n      int lua_isstring (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値が文字列か数値であれば1、そうでなければ0を返す。 (数値の場合、それは文字列に変換される)\nlua_istable\n      int lua_istable (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値がテーブルであれば1、そうでなければ0を返す。\nlua_isthread\n      int lua_isthread (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値がスレッドであれば1、そうでなければ0を返す。\nlua_isuserdata\n      int lua_isuserdata (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値がユーザーデータ (フルかライトどちらかの) であれば1、そうでなければ0を返す。\nlua_lessthan\n      int lua_lessthan (lua_State *L, int index1, int index2);\n\n受け入れ可能なインデックス index1 の値が受け入れ可能なインデックス index2 の値よりも小さければ1、そうでなければ0を返す。 どちらかのインデックスが有効でない場合も0を返す。 比較はLuaの &lt; 演算子の意味論に従って行われる (つまり、メタメソッドを呼ぶ場合がある)。\nlua_load\n      int lua_load (lua_State *L, lua_Reader reader, void *data,\n                                  const char *chunkname);\n\nLuaチャンクをロードする。 エラーがなければ、 lua_load はコンパイルしたチャンクをLuaの関数としてスタックトップに積む。 そうでなければ、エラーメッセージを積む。 lua_load の戻り値は以下の通り。\n0 — エラーなし。LUA_ERRSYNTAX — コンパイル時に構文エラーが発生。LUA_ERRMEM — メモリ割り当てエラー。lua_load はチャンクがテキストかバイナリかを自動的に検出し、それに応じてチャンクをロードする (プログラム luac を参照)。\nlua_load はチャンクを読み込むためにユーザが提供する reader 関数を使う (see lua_Reader を参照)。 data 引数はそのリーダ関数に渡される値である。\nchunkname 引数はチャンクに名前を与える。 これはエラーメッセージやデバッグ情報で使われる (3.8 を参照)。\nlua_newstate\n      lua_State *lua_newstate (lua_Alloc f, void *ud);\n\n新しい独立したステートを作る。 ステートを作れなければ (メモリ不足のために)、NULL を返す。 引数 f はアロケータ関数である。 Luaはこのステートのためのすべてのメモリ確保をこの関数を使って行う。 2番目の引数 ud は、そのアロケータに毎回渡されるポインタである。\nlua_newtable\n      void lua_newtable (lua_State *L);\n\n新しい空のテーブルを作ってスタックに積む。 lua_createtable(L, 0, 0) と同等である。\nlua_newthread\n      lua_State *lua_newthread (lua_State *L);\n\n新しいスレッドを作ってスタックに積み、 その新しいスレッドを表す lua_State へのポインタを返す。 この関数が返した新しいステートは元のステートとすべてのグローバルオブジェクト (テーブルとか) を共有するが、独立した実行スタックを持つ。\nスレッドを閉じたり破棄する明示的な関数はない。 スレッドは他のLuaオブジェクト同様、ガベージコレクションの対象である。\nlua_newuserdata\n      void *lua_newuserdata (lua_State *L, size_t size);\n\nこの関数は指定されたサイズのメモリブロックを割り当て、 そのアドレスを持つ新しいフルユーザーデータをスタックに積み、 そのアドレスを返す。\nユーザーデータはLua内でCの値を表現する。 フルユーザーデータ はメモリブロックを表す。 これは (テーブルと同じように) オブジェクトである。 作成する必要があり、独自のメタテーブルを持つことができ、 ガベージコレクションされるのを検出できる。 フルユーザーデータは (rawequalの下では) それ自身と比較したときだけ等しい。\nLuaが gc メタメソッドを持つフルユーザーデータを回収するとき、 Luaはメタメソッドを呼び、ユーザーデータにファイナライズ済みの印を付ける。 このユーザーデータがもう一度回収されると、Luaは対応するメモリを解放する。\nlua_next\n      int lua_next (lua_State *L, int index);\n\nスタックからキーを取り出し。 指定したインデックスのテーブルからキー・値のペア (取り出したキーの「次」のペア) を積む。 これ以上要素がなければ、 lua_next は (何も積まずに) 0を返す。\n典型的な巡回は次のようになる。\n   /* テーブルはスタックの `t&#39; の位置にあるとする */\n   lua_pushnil(L);  /* 最初のキー */\n   while (lua_next(L, t) != 0) &#123;\n     /* 「キー」インデックス-2、「値」はインデックス-1の位置にある */\n     printf(&quot;%s - %s\\n&quot;,\n       lua_typename(L, lua_type(L, -2)), lua_typename(L, lua_type(L, -1)));\n     lua_pop(L, 1);  /* 「値」を除去し、「キー」は次の繰り返しのために残す */\n   &#125;\n\nテーブルを巡回する間、 キーが本物の文字列であるかどうか判らないなら、キーに対して直接 lua_tolstring を呼んではならない。 lua_tolstring は指定したインデックスにある値を 変える ため、次の lua_next の呼び出しを混乱させることを覚えておくように。\nlua_Number\n      typedef double lua_Number;\n\nLuaの数値の型。 デフォルトでは、これはdoubleであるが、 luaconf.h で変えることができる。\nコンフィギュレーションファイルを変更することで、 Luaが数値に対して他の型 (floatやlongなど) を使うようにできる。\nlua_objlen\n      size_t lua_objlen (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値の「長さ」を返す。 文字列の場合はその文字列の長さ、 テーブルの場合は長さ演算子 (`#´) の結果、 ユーザーデータの場合は割り当てられたメモリブロックのサイズ、 それ以外の場合は0を返す。\nlua_pcall\n      lua_pcall (lua_State *L, int nargs, int nresults, int errfunc);\n\n関数を保護モードで呼ぶ。\nnargs と nresults は lua_call と同じである。 もしエラーがなければ lua_pcall は lua_call とまったく同じように動作する。 しかし、何かエラーが起きた場合は、 lua_pcall はそれを捕らえて、 1つの値 (エラーメッセージ) をスタックに積んでエラーコードを返す。 lua_call 同様、 lua_pcall は常に関数とその引数をスタックから取り除く。\nもし errfunc が0であれば、スタックに返されたエラーメッセージは正確に元のエラーメッセージである。 そうでなければ、errfunc は エラーハンドラ関数 のスタックインデックスを指定する (現在の実装では、疑似インデックスは指定できない)。 実行時エラーが起きると、エラーメッセージを引数としてこの関数が呼ばれ、 その戻り値が lua_pcall から返されるエラーメッセージとなる。\n典型的には、エラーハンドラ関数は、エラーメッセージにスタックトレースのようなデバッグ情報を付け加えるのに使う。 そういった情報は lua_pcall から戻った後にはもうスタックから除去されているため、集めることができない。\nlua_pcall 関数は成功時は0を返し、 エラーの場合は以下のエラーコードのいずれかを返す (lua.h で定義されている)。\nLUA_ERRRUN — 実行時エラー。LUA_ERRMEM — メモリ確保エラー。 このようなエラーでは、Luaはエラーハンドラ関数を呼ばない。LUA_ERRERR — エラーハンドラ関数実行中のエラー。\nlua_pop\n      void lua_pop (lua_State *L, int n);\n\nスタックから n 個の要素を取り除く。\nlua_pushboolean\n      void lua_pushboolean (lua_State *L, int b);\n\n値 b のブーリアン値をスタックに積む。\nlua_pushcclosure\n      void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n);\n\n新しいCのクロージャをスタックに積む。\nCの関数を作るとき、いくつかの値を関連付けて Cのクロージャ を作ることができる (see 3.4)。 これらの値はその関数が呼ばれたときにいつでもアクセスできる。 Cの関数に値を関連付けるには、 まずそれらの値をスタックに積む (複数の値がある場合は、最初の値を最初に積む)。 次に lua_pushcclosureを呼び、 Cの関数を作ってスタックにプッシュする。 引数 n は関数に関連付ける値の数を示す。 lua_pushcclosure はスタックからそれらの値を取り除く。\nlua_pushcfunction\n      void lua_pushcfunction (lua_State *L, lua_CFunction f);\n\nCの関数をスタックに積む。 この関数はCの関数へのポインタを受け取り、関数 型のLua値をスタックに積む。 この値が呼ばれると、対応するCの関数が呼ばれる。\nLuaに登録する関数は引数と戻り値を受け渡すために、 正しい手順に従わなければ鳴らない (lua_CFunction を参照)。\nlua_pushcfunction(L, f) の呼び出しは lua_pushcclosure(L, f, 0) と同等である。\nlua_pushfstring\n      const char *lua_pushfstring (lua_State *L, const char *fmt, ...);\n\n書式化文字列をスタックに積み、この文字列を指すポインタを返す。 これはCの関数 sprintf に似ているが、いくつか重要な違いがある。\n結果を格納する空間を割り当てる必要がない。 結果はLuaの文字列であり、Luaはメモリの確保を (そしてガベージコレクションによる解放も) 自分で行う。変換指定子はかなり制限されている。 フラグや幅、精度は指定できない。 変換師は単純な%%´ (文字 %´)%s´ (長さ制限のないゼロ終端文字列) %f´ (lua_Number)%p´ (16進数としてのポインタ) %d´ (int)`%c´ (文字としての int)だけが使える。\nlua_pushinteger\n      void lua_pushinteger (lua_State *L, lua_Integer n);\n\n値 n を持つ数値をスタックに積む。\nlua_pushlightuserdata\n      void lua_pushlightuserdata (lua_State *L, void *p);\n\nライトユーザーデータをスタックに積む。\nユーザーデータはLua内でCの値を表現する。 ライトユーザーデータ はポインタを表す。 それは (数値と同じように) 値である。 作成はせず、メタテーブルも持たず、(作成しないので) 回収もされない。 ライトユーザーデータは、同じCのアドレスを持つ「どの」ライトユーザーデータとも等しい。\nlua_pushlstring\n      void lua_pushlstring (lua_State *L, const char *s, size_t len);\n\ns が指すサイズ len の文字列をスタックに積む。 Luaは与えられた文字列を内部的にコピーする (または再利用する) ため、 sが指すメモリは関数が戻ったあとすぐに解放あるいは再利用してよい。 文字列は埋め込まれたゼロを含んでいても良い。\nlua_pushnil\n      void lua_pushnil (lua_State *L);\n\nnil値をスタックに積む。\nlua_pushnumber\n      void lua_pushnumber (lua_State *L, lua_Number n);\n\n値 n を持つ数値をスタックに積む。\nlua_pushstring\n      void lua_pushstring (lua_State *L, const char *s);\n\nsが指すゼロ終端文字列をスタックに積む。 Luaは与えられた文字列を内部的にコピーする (または再利用する) ため、 s が指すメモリを関数が戻ったあとすぐに解放あるいは再利用してよい。 文字列は埋め込まれたゼロを含むことができない。 最初のゼロで終端するものと仮定される。\nlua_pushthread\n      void lua_pushthread (lua_State *L);\n\nLが表すスレッドをスタックに積む。\nlua_pushvalue\n      void lua_pushvalue (lua_State *L, int index);\n\n指定した有効なインデックスにある要素のコピーをスタックに積む。\nlua_pushvfstring\n      const char *lua_pushvfstring (lua_State *L, const char *fmt, va_list argp);\n\nlua_pushfstring と同じであるが、 可変引数の代わりに va_list を渡す点が異なる。\nlua_rawequal\n      int lua_rawequal (lua_State *L, int index1, int index2);\n\n受け入れ可能なインデックス index1 と index2 が プリミティブに等しい (つまりメタメソッドを呼ばない) とき1を返す。 そうでなければ0を返す。 どちらかのインデックスが有効でないときも0を返す。\nlua_rawget\n      void lua_rawget (lua_State *L, int index);\n\nlua_gettable と同じであるが、 生のアクセスを行う (つまりメタメソッドを呼ばない) 点が異なる。\nlua_rawgeti\n      void lua_rawgeti (lua_State *L, int index, int n);\n\n値 t[n] をスタックに積む。 ただし t は指定した有効なインデックス index の値である。 これは生のアクセスを行う。 つまりメタメソッドを呼ばない。\nlua_rawset\n      void lua_rawset (lua_State *L, int index);\n\nlua_settable と同じであるが、 生の代入である点が異なる (メタメソッドを呼ばない)。\nlua_rawseti\n      void lua_rawseti (lua_State *L, int index, int n);\n\nt[n] = v と同じことを行う。 ただし t は指定した有効なインデックス index の値で、 v はスタックトップの値である。\nこの関数は値をスタックから取り除く。 これは生の代入を行う。 つまりメタメソッドを呼ばない。\nlua_Reader\n      typedef const char * (*lua_Reader)\n                           (lua_State *L, void *data, size_t *size);\n\nlua_load で使うリーダー関数。 チャンクの新たなピースが必要になるたびに、data 引数を付けてリーダーが呼ばれる。 リーダーはチャンクの新たなピースを埋めたメモリブロックを指すポインタを返し、 その長さを size にセットしなければならない。 ブロックはリーダー関数がもう一度呼ばれるまで存在しなければならない。 チャンクの最後に達したことを伝えるには NULL を返す。 リーダー関数は1以上の任意のサイズのピースを返すことができる。\nlua_register\n      void lua_register (lua_State *L, const char *name, lua_CFunction f);\n\nCの関数 f をグローバル変数 name の新しい値としてセットする。 これはマクロとして定義されている。\n#define lua_register(L,n,f)  (lua_pushcfunction(L, f), lua_setglobal(L, n))\nlua_remove\n      void lua_remove (lua_State *L, int index);\n\n指定した有効なインデックスの要素を取り除き、 上の要素をずらして隙間を埋める。 疑似インデックスは、実際のスタック位置でないため、指定できない。\nlua_replace\n      void lua_replace (lua_State *L, int index);\n\nスタックトップの要素を指定した位置へ移動する。 スタックトップの値は取り除く。 他のどの要素もずらさない。 つまり指定した位置の値を置き換える。\nlua_resume\n      int lua_resume (lua_State *L, int narg);\n\n指定したスレッドのコルーチンを再開する。\nコルーチンを開始するためには、まず新しいスレッドを作る (lua_newthread を参照)。 次にメイン関数と任意個の引数をスタックに積み、 nargs に引数の数を渡して。 lua_resume を呼ぶ。 コルーチンが中断されたり実行終了したら、呼び出しから戻る。 戻ってきたとき、スタックには lua_yield に渡された値か、本体の関数から返された値がすべて積まれている。 コルーチンがyieldした場合、lua_resume は LUA_YIELD を返す。 コルーチンがエラーなく実行終了した場合は0を返す。 エラーが起きた場合はエラーコードを返す (lua_pcall を参照)。 エラーの場合、スタックは巻き戻されておらず、従ってその上でデバッグAPIを使うことができる。 スタックトップにエラーメッセージが置かれる。 コルーチンを再開するには、yied から返される結果として渡す値だけをスタックに起き、 lua_resume を呼ぶ。\nlua_setallocf\n      void lua_setallocf (lua_State *L, lua_Alloc f, void *ud);\n\n指定されたステートのアロケータ関数を f と ud に変更する。\nlua_setfenv\n      int lua_setfenv (lua_State *L, int index);\n\nスタックからテーブルを取り除き、指定したインデックスの値の新しい環境として設定する。 指定したインデックスの値が関数、スレッド、ユーザーデータのどれでもなければ、 lua_setfenv は0を返す。 そうでなければ1を返す。\nlua_setfield\n      void lua_setfield (lua_State *L, int index, const char *k);\n\nt[k] = v を実行する。 ただし t は指定した有効なインデックス index の値で、 v はスタックトップの値である。\nこの関数は値をスタックから除去する。 Luaの中でのように、この関数は “newindex” イベントのメタメソッドを呼ぶ場合がある (2.8 を参照)。\nlua_setglobal\n      void lua_setglobal (lua_State *L, const char *name);\n\nスタックから値を取り除き、それをグローバル変数 name の新しい値として設定する。 これはマクロとして定義されている。\n#define lua_setglobal(L,s)   lua_setfield(L, LUA_GLOBALSINDEX, s)\nlua_setmetatable\n      int lua_setmetatable (lua_State *L, int index);\n\nスタックからテーブルを取り除き、それを指定した受け入れ可能なインデックスの値の新しいメタテーブルとして設定する。\nlua_settable\n      void lua_settable (lua_State *L, int index);\n\nt[k] = v を実行する。 ただし t は指定した有効なインデックス index の値で、 v はスタックトップの値で、 k はそのひとつ下の値である。\nこの関数はキーと値の両方をスタックから取り除く。 Luaの中でのように、この関数は “newindex” イベントのメタメソッドを呼ぶ場合がある (2.8 を参照)。\nlua_settop\n      void lua_settop (lua_State *L, int index);\n\n任意の受け入れ可能なインデックスまたは0を受け取り、 スタックトップをそのインデックスに設定する。 新しいトップが古いものより大きければ、新しい要素は nil で埋められる。 index が0の場合は、スタック要素がすべて削除される。\nlua_State\n      typedef struct lua_State lua_State;\n\nLuaインタプリタの状態全体を保持する不透明な構造体。 Luaライブラリはグローバル変数を使っていないので、完全に再入可能である。 ステートに関するすべての情報はこの構造体に保持されている。\nこのステートへのポインタは、 無からLuaステートを作成する lua_newstate を除いて、 ライブラリのすべての関数で最初の引数として渡さなければならない。\nlua_status\n      int lua_status (lua_State *L);\n\nスレッド L の状態を返す。\n通常のスレッドの状態は0である。 スレッドがエラー終了していればエラーコード、 スレッドが中断していれば LUA_YIELD を返す。\nlua_toboolean\n      int lua_toboolean (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値をCのブーリアン値 (0または1) に変換する。 Luaでの条件判断と同様に、 lua_toboolean は false と nil 以外のすべての値に対して1を返し、 そうでなければ0を返す。 有効でないインデックスを指定した場合も0を返す。 もし本当のブーリアン値だけを調べたい場合は、 lua_isboolean で値の型を判定すること。\nlua_tocfunction\n      lua_CFunction lua_tocfunction (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値をCの関数に変換する。 この値はCの関数でなければならなず、それ以外では NULL を返す。\nlua_tointeger\n      lua_Integer lua_tointeger (lua_State *L, int idx);\n\n指定した受け入れ可能なインデックスのLuaの値を符号付き整数型 lua_Integer に変換する。 このLuaの値は数値か、数値に変換できる文字列でなければならない (2.2.1 を参照)。 それ以外の場合、lua_tointeger は0を返す。\n数値が整数でなければ、何らかの未規定な方法で整数に丸める。\nlua_tolstring\n      const char *lua_tolstring (lua_State *L, int index, size_t *len);\n\n指定した受け入れ可能なインデックスのLuaの値を文字列 (const char*) に変換する。 もし len が NULL でなければ、 *len に文字列の長さも設定される。 このLuaの値は文字列か数値でなければならず、 それ以外の場合、この関数は NULL を返す。 もしその値が数値であれば、 lua_tolstring はスタック内のその実際の値を文字列に 変換する (この変換はテーブル巡回中のキーに対して lua_tolstring を使ったときに lua_next を混乱させる)。\nlua_tolstring はLuaステート内部の文字列を指す、完全にアラインメントされたポインタを返す。 この文字列は、その最後に必ずゼロ (`\\0´) を持つ (Cでよくやるように) が、 その途中にもゼロを含むことがある。 Luaはガベージコレクションを持っているため、 lua_tolstring の返したポインタが、その値がスタックから取り除かれた後も有効であり続けるという保証はない。\nlua_tonumber\n      lua_Number lua_tonumber (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスにあるLuaの値を数値に変換する (lua_Number を参照)。 このLuaの値は数値か、数値に変換できる文字列でなければならない (2.2.1 を参照)。 それ以外の場合、lua_tonumber は0を返す。\nlua_topointer\n      const void *lua_topointer (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値をCの汎用ポインタ (void*) に変換する。 この値は、ユーザーデータ、テーブル、スレッド、関数のいずれかである。 それ以外なら lua_topointer は NULL を返す。 Luaは異なるオブジェクトに対しては異なるポインタを返すことを保証する。 ポインタからその元の値に変換する直接的な方法は無い。\n典型的には、この関数はデバッグ情報のためにだけ使われる。\nlua_tostring\n      const char *lua_tostring (lua_State *L, int index);\n\nlen に NULL を渡して lua_tolstring を呼ぶのと同じ。\nlua_tothread\n      lua_State *lua_tothread (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値をLuaのスレッド (lua_State* で表される) に変換する。 この値はスレッドでなければならず、それ以外では NULL を返す。\nlua_touserdata\n      void *lua_touserdata (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値がフルユーザーデータであれば、そのブロックのアドレスを返す。 ライトユーザーデータであれば、そのポインタを返す。 どちらでもなければ NULL を返す。\nlua_type\n      int lua_type (lua_State *L, int index);\n\n指定した受け入れ可能なインデックスの値の型を返す。 有効でないインデックス (つまりその位置に要素がない) の場合は LUA_TNONE を返す。 lua_type が返す型は lua.h で定義されている以下の定数である。\nLUA_TNILLUA_TNUMBERLUA_TBOOLEANLUA_TSTRINGLUA_TTABLELUA_TFUNCTIONLUA_TUSERDATALUA_TTHREADLUA_TLIGHTUSERDATA\nlua_typename\n      const char *lua_typename  (lua_State *L, int tp);\n\ntp が示す型の名前を返す。 tp は lua_type が返す値のいずれかでなければならない。\nlua_Writer\n      typedef int (*lua_Writer)\n                      (lua_State *L, const void* p, size_t sz, void* ud);\n\nlua_dump で使うライター関数。 新しいチャンクのピースが生成されるたびに、 書き込みバッファ (p)、そのサイズ (sz)、 および lua_dump に渡した data 引数を渡して lua_dump がライターを呼ぶ。\nライターはエラーコードを返す。 0はエラーなしを意味する。 それ以外の値はエラーを意味し、 lua_dump にそれ以上ライターを呼ぶのをやめさせる。\nlua_xmove\n      void lua_xmove (lua_State *from, lua_State *to, int n);\n\n同じ グローバルステートの異なるスレッド間で値を交換する。\nこの関数は from のスタックから n 個の値を取り出し、 それらを to のスタックに積む。\nlua_yield\n      int lua_yield  (lua_State *L, int nresults);\n\nコルーチンを中断する。\nこの関数は以下のようにCの関数のreturn式でだけ呼べる。\n   return lua_yield (L, nresults);\n\nCの関数がこの方法で lua_yield を呼ぶとコルーチンの実行は中断され、 このコルーチンを開始した lua_resume の呼び出しから戻る。 引数 nresults は lua_resume から返したいスタック上の値の数である。\n3.8 - デバッグインタフェイス\nLuaは組み込みのデバッグ機能を持っていない。 代わりに、そのための関数と フック による特殊なインタフェイスを提供している。 このインタフェイスで、様々な種類のデバッガ、プロファイラ、およびインタプリタの「内部情報」を必要とするその他のツールを作れるようになっている。\nlua_Debug\n      typedef struct lua_Debug &#123;\n        int event;\n        const char *name;           /* (n) */\n        const char *namewhat;       /* (n) */\n        const char *what;           /* (S) */\n        const char *source;         /* (S) */\n        int currentline;            /* (l) */\n        int nups;                   /* (u) 上位値の数 */\n        int linedefined;            /* (S) */\n        int lastlinedefined;        /* (S) */\n        char short_src[LUA_IDSIZE]; /* (S) */\n        /* private part */\n        ...\n      &#125; lua_Debug;\n\nアクティブな関数に関する色々な情報を格納するのに使う構造体。 lua_getstack は後で使うために、この構造体の内部用メンバだけを埋める。 lua_Debug の他のフィールドを役に立つ情報で埋めるには、lua_getinfo を呼ぶ。\nlua_Debug の各フィールドは以下のような意味を持っている。\nsource — 関数が文字列中で定義されたならば、その文字列である。 関数がファイル中で定義されたならば、`@´ で始まり、その後にファイル名が続く。short_src — エラーメッセージに使う「可読」バージョンの source。linedefined — 関数定義の開始位置の行番号。lastlinedefined — 関数定義の終了位置の行番号。what — Luaの関数なら “Lua”、 Cの関数なら “C”、 チャンクのメイン部であれば “main”、 関数が終端呼び出ししたならば “tail”。 最後のケースでは、Luaはこの関数について他に何の情報も持っていない。currentline — 現在実行中の行番号。 この情報が利用可能でなければ、currentline は -1 に設定される。name — その関数に対する適当な名前。 Luaの関数はファーストクラスの値であるため、固定の名前は持っていない。 複数のグローバル変数に格納されている関数もあれば、テーブルフィールドにのみ格納されているものもある。 lua_getinfo は、その関数がどのように呼ばれたかを調べ、良さそうな名前を探す。 名前が見つからなければ、name は NULL に設定される。namewhat — name フィールドを説明する。 namewhat は、どのように関数が呼ばれたかによって、以下のいずれかになる。 “global”, “local”, “method”, “field”, “upvalue”, or “” (空文字列。他に適当なものがなければこれを使う)。nups — その関数の上位値の数。\nlua_gethook\n      lua_Hook lua_gethook (lua_State *L);\n\n現在のフック関数を返す。\nlua_gethookcount\n      int lua_gethookcount (lua_State *L);\n\n現在のフックカウントを返す。\nlua_gethookmask\n      int lua_gethookmask (lua_State *L);\n\n現在のフックマスクを返す。\nlua_getinfo\n      int lua_getinfo (lua_State *L, const char *what, lua_Debug *ar);\n\nlua_Debug の各フィールドを役に立つ情報で埋める。\nエラー (例えば what に不正なを指定したとか) のときは0を返す。 文字列 what の各文字は、構造体 ar のどのフィールドを埋めるかを選択する。 これは lua_Debug の定義で括弧内に書かれた文字で指示する。 S´ はフィールド source, linedefined, lastlinedefined, what を埋め、 l´ はフィールド currentline を埋め、以下同様。 さらに、`f´ を指定すると、指定されたレベルで走っている関数をスタックに積む。\nアクティブでない (スタック中にない) 関数の情報を得るには、 それをスタックに積んで what を文字 ‘&gt;’ で始まる文字列にする。 例えば、関数 f が定義された行番号を知りたい場合は、次のように書く。\n   lua_Debug ar;\n   lua_getfield(L, LUA_GLOBALSINDEX, &quot;f&quot;);  /* グローバル変数 `f&#39; を取得 */\n   lua_getinfo(L, &quot;&gt;S&quot;, &amp;ar);\n   printf(&quot;%d\\n&quot;, ar.linedefined);\n\nlua_getlocal\n      const char *lua_getlocal (lua_State *L, const lua_Debug *ar, int n);\n\n指定したアクティベーションレコードのローカル変数についての情報を得る。 引数 ar には、事前に lua_getstack を呼んで埋めるか、フック (lua_Hook を参照) に渡された引数を使うかして、有効なアクティベーションレコードを与えなければならない。 インデックス n は調べるローカル変数を指定する (1が最初の引数か最初のアクティブなローカル変数で、最後のアクティブなローカル変数まである)。 lua_getlocal はその変数の値をスタックに積み、その名前を返す。\n`(´ (開き括弧) で始まる変数名は内部変数を表している (ループ制御変数、テンポラリ変数、Cの関数のローカル変数など)。\nインデックスがアクティブなローカル変数の数より大きいときは、(何も積まずに) NULL を返す。\nlua_getstack\n      int lua_getstack (lua_State *L, int level, lua_Debug *ar);\n\nインタプリタランタイムスタックに関する情報を取得する。\nこの関数は lua_Debug の一部を、 指定したレベルで実行中の関数の アクティベーションレコード で埋める。 レベル0は現在走っている関数で、レベル n+1 はレベル n の呼び出し元の関数である。 エラーがなければ lua_getstack は1を返す。 スタックの深さよりも大きいレベルが指定された場合は0を返す。\nlua_getupvalue\n      const char *lua_getupvalue (lua_State *L, int funcindex, int n);\n\nクロージャの上位値に関する情報を取得する。 (Luaの関数の上位値は、その関数が使っている外部ローカル変数で、クロージャに取り込まれたもの。) lua_getupvalue はインデックス n の上位値を取得し、その値をスタックに積み、その名前を返す。 funcindex はスタック中のそのクロージャを指す。 (上位値は関数全体に渡って有効であり、特定の順序も持たない。そのため不定の順序で番号付けられている。)\nインデックスが上位値の数より大きい場合は、(何も積まずに) NULL を返す。 Cの関数では、どの上位値に対してもその名前に空文字列 “” を返す。\nlua_Hook\n      typedef void (*lua_Hook) (lua_State *L, lua_Debug *ar);\n\nデバッグフック関数の型。\nフックが呼ばれたとき、ar 引数の event フィールドに フックを起動したイベントが格納されている。 Luaはこれらのイベントを以下の定数で識別する。 LUA_HOOKCALL, LUA_HOOKRET, LUA_HOOKTAILRET, LUA_HOOKLINE, LUA_HOOKCOUNT。 さらにlineイベントでは、フィールド currentline も設定される。 ar の他のフィールドを得るには、 lua_getinfo を呼ぶ必要がある。 returnイベントでは、event は通常の LUA_HOOKRET の他に LUA_HOOKTAILRET が設定される場合がある。 後者はLuaが終端呼び出しした関数からの復帰をシミュレートしたもので、 この場合 lua_getinfo は役に立たない。\nLuaがフックを実行している間、他のフック呼び出しは向こうになる。 従って、フック内でLuaの関数やチャンクを呼び出した場合、フックを呼ばずに実行される。\nlua_sethook\n      int lua_sethook (lua_State *L, lua_Hook func, int mask, int count);\n\nデバッグフック関数を設定する。\nfunc はフック関数を指定する。 mask はどのイベントでフックが呼ばれるかを定数 LUA_MASKCALL, LUA_MASKRET, LUA_MASKLINE, LUA_MASKCOUNT の論理和で指定する。 count 引数はmaskが LUA_MASKCOUNT を含むときだけ意味を持つ。 それぞれのイベントについて以下の状況でフックが呼ばれる。\ncallフック は関数を呼ぶときに呼ばれる。 フックは新しい関数に入った直後、その関数が引数を取得する前に呼ばれる。returnフック は関数から戻るときに呼ばれる。 フックは関数から離れる直後に呼ばれる。 戻り値にはアクセスできない。lineフック はインタプリタが新しい行のコードの実行を開始しようとしているとき、 および同じ行内でもジャンプが行われたときに呼ばれる (このイベントはLuaの関数を実行している間だけ起こる)。countフック はインタプリタが count 命令を実行した直後に呼ばれる (このイベントはLuaの関数を実行している間だけ起こる)。mask にゼロを設定すればフックが無効になる。\nlua_setlocal\n      const char *lua_setlocal (lua_State *L, const lua_Debug *ar, int n);\n\n指定したアクティベーションレコードのローカル変数の値を設定する。 引数 ar および n は lua_getlocal と同じである (lua_getlocal を参照)。 この関数はlua_setlocal はスタックトップの値をその変数に格納し、その名前を返す。 またその値をスタックから取り除く。\nインデックスがアクティブなローカル変数の数よりも大きければ、(何も取り除かずに) NULL を返す。\nlua_setupvalue\n      const char *lua_setupvalue (lua_State *L, int funcindex, int n);\n\nクロージャの上位値の値を設定する。 引数 funcindex および n は lua_getupvalue と同じである (lua_getupvalue を参照)。 この関数はスタックトップの値をその上位値に格納し、その名前を返す。 またその値をスタックから取り除く。\nインデックスが上位値の数よりも大きければ、(何も取り除かずに) NULL を返す。\n4 - 補助ライブラリ\n補助ライブラリ はCとLuaのインタフェイスとなるいくつかの便利な関数を提供する。 基本APIはCとLuaの対話の基本的な関数を提供するが、補助ライブラリはいくつかの共通の作業をする高レベルな関数を提供する。\n補助ライブラリのすべての関数はヘッダーファイル lauxlib.h に定義され、接頭語 luaL_ が付いている。\n補助ライブラリのすべての関数は基本APIの上に構築されており、そのためこのAPIでできないことは何も提供していない。\n補助ライブラリにはCの関数の引数をチェックするための関数がいくつかある。 これらは常に luaL_check* または luaL_opt* という名前である。 これらの関数はチェックが妥当(satisfied?)でなかったときエラーを生成する。 エラーメッセージは引数で書式化される (“bad argument #1” など) ため、 他のスタック値に対してこれらの関数を使うべきではない。\n4.1 - 関数と型\n補助ライブラリのすべての関数と型をアルファベット順に示す。\nluaL_addchar\n      void luaL_addchar (luaL_Buffer B, char c);\n\n文字 c をバッファ B に追加する (luaL_Buffer を参照)。\nluaL_addlstring\n      void luaL_addlstring (luaL_Buffer *B, const char *s, size_t l);\n\ns が指す長さ l の文字列をバッファ B に追加する。 (luaL_Buffer を参照)。 文字列は埋め込まれたゼロを含んでいても良い。\nluaL_addsize\n      void luaL_addsize (luaL_Buffer B, size_t n);\n\nバッファエリア (luaL_prepbuffer を参照) に前回コピーされた長さ n の文字列をバッファ B に追加する。 (luaL_Buffer を参照)。\nluaL_addstring\n      void luaL_addstring (luaL_Buffer *B, const char *s);\n\ns が指すゼロ終端文字列をバッファ B に追加する (luaL_Buffer を参照)。 文字列に埋め込まれたゼロを含むことはできない。\nluaL_addvalue\n      void luaL_addvalue (luaL_Buffer *B);\n\nスタックトップの値をバッファ B に追加する (luaL_Buffer を参照)。 その値はスタックから取り除かれる。\nこれはバッファに追加する値をスタックから取る唯一の文字列バッファ用関数である。\nluaL_argcheck\n      void luaL_argcheck (lua_State *L, int cond, int numarg,\n                          const char *extramsg);\n\ncond が真であることを確認する。 もし違ったら、メッセージ “bad argument # to  ()” のエラーを生成する。 ただし func はコールスタックから取得する。\nluaL_argerror\n      int luaL_argerror (lua_State *L, int numarg, const char *extramsg);\n\nメッセージ “bad argument # to  ()” のエラーを生成する。 ただし func はコールスタックから取得する。\nこの関数は決して戻らないが、 Cの関数で return luaL_argerror … として使うのが慣習である。\nluaL_Buffer\n      typedef struct luaL_Buffer luaL_Buffer;\n\n文字列バッファ の型。\n文字列バッファはCのコードでLuaの文字列片(strings piecemeal)を組み立てるのに使う。 これは以下のように使用する。\nまず luaL_Buffer 型の変数 b を宣言する。次に luaL_buffinit(L, &amp;b) を呼んでそれを初期化する。そして luaL_add* 関数のどれかを使ってバッファに文字列片を追加する。最後に luaL_pushresult(&amp;b) を呼ぶ。 これは最終的な文字列をスタックトップに残す。通常の操作をしている間、 文字列バッファはいくつかのスタックスロットを使う。 従ってバッファを使っている間は、スタックトップがどこにあるか判っていると仮定できない。 バッファ操作の正しい(successive)呼び出しの間、整合が取れている限りはスタックを使うことができる。 つまり、バッファ操作を呼び出すときは、 スタックが前回バッファ操作した直後と同じ高さでなければならない。 (luaL_addvalue はこのルールの唯一の例外である。) luaL_pushresult を呼んだあと、 スタックはバッファが初期化される前の高さに戻り、その上に最終的な文字列が積まれる。\nluaL_buffinit\n      void luaL_buffinit (lua_State *L, luaL_Buffer *B);\n\nバッファ B を初期化する。 この関数はいかなる空間も割り当てない。 バッファは変数として宣言しなければならない (luaL_Buffer を参照)。\nluaL_callmeta\n      int luaL_callmeta (lua_State *L, int obj, const char *e);\n\nメタメソッドを呼ぶ。\nインデックス obj のオブジェクトがメタテーブルを持っていて、 このメタテーブルがフィールド e を持っていれば、 この関数はこのフィールドを呼び出し、引数としてそのオブジェクトを渡す。 この場合、この関数は1を返し、呼び出しの戻り値をスタックに積む。 メタテーブルがないかメタメソッドがない場合、 この関数は (スタックに何も積まずに) 0を返す。\nluaL_checkany\n      void luaL_checkany (lua_State *L, int narg);\n\n関数が位置 arg に任意の型 (nil を含む) の引数を持つかチェックする。\nluaL_checkint\n      int luaL_checkint (lua_State *L, int narg);\n\n関数の第 narg 引数が数値であるかをチェックし、 その値を int にキャストして返す。\nluaL_checkinteger\n      lua_Integer luaL_checkinteger (lua_State *L, int narg);\n\n関数の第 narg 引数が数値であるかをチェックし、 その値を lua_Integer にキャストして返す。\nluaL_checklong\n      long luaL_checklong (lua_State *L, int narg);\n\n関数の第 narg 引数が数値であるかをチェックし、 その値を long にキャストして返す。\nluaL_checklstring\n      const char *luaL_checklstring (lua_State *L, int narg, size_t *l);\n\n関数の第 narg 引数が文字列であるかをチェックし、その文字列を返す。 l が NULL でなければ、 *l に文字列の長さを格納する。\nluaL_checknumber\n      lua_Number luaL_checknumber (lua_State *L, int narg);\n\n関数の第 narg 引数が数値であるかをチェックし、 その数値を返す。\nluaL_checkoption\n      int luaL_checkoption (lua_State *L, int narg, const char *def,\n                            const char *const lst[]);\n\n関数の第 narg 引数が文字列であるかチェックし、 配列 lst (NULL終端でなければならない) からその文字列を検索する。 def が NULL でなければ、 関数が第 narg 引数を持たないかその引数が nil であった場合のデフォルト値として使う。\n文字列が見つかった配列インデックスを返す。 引数が文字列でないか文字列が見つからなければエラーを発生する。\nこの関数は文字列をCの列挙型に変換するのに役に立つ。 Luaのライブラリにおける通常の慣例では、オプションを選択するのに、数値でなく文字列を使う。\nluaL_checkstack\n      void luaL_checkstack (lua_State *L, int sz, const char *msg);\n\nスタックサイズを top + sz 個の要素に伸ばす。 スタックがそのサイズに伸ばせなければエラーを発生する。 msg はそのエラーメッセージに入れる追加の文字列である。\nluaL_checkstring\n      const char *luaL_checkstring (lua_State *L, int narg);\n\n関数の第 narg 引数が文字列であるかチェックし、その文字列を返す。\nluaL_checktype\n      void luaL_checktype (lua_State *L, int narg, int t);\n\n関数の第 narg 引数が型 t であるかチェックする。\nluaL_checkudata\n      void *luaL_checkudata (lua_State *L, int narg, const char *tname);\n\n関数の第 narg 引数が型 tname のユーザーデータであるかチェックする (luaL_newmetatable を参照)。\nluaL_error\n      int luaL_error (lua_State *L, const char *fmt, ...);\n\nエラーを発生させる。 エラーメッセージの書式は fmt と追加の引数で与えられる。 これは lua_pushfstring のと同じルールに従う。 また、メッセージの最初にエラーが発生したファイル名と行番号を、それらの情報が利用可能ならば、追加する。\nこの関数は決して戻らないが、 Cの関数で return luaL_error … のように使うのが慣例である。\nluaL_getmetafield\n      int luaL_getmetafield (lua_State *L, int obj, const char *e);\n\nインデックス obj のオブジェクトのメタテーブルのフィールド e をスタックに積む。 そのオブジェクトがメタテーブルを持っていないか、メタテーブルがそのフィールドを持っていなければ 0 を返して何も積まない。\nluaL_getmetatable\n      void luaL_getmetatable (lua_State *L, const char *tname);\n\nレジストリの名前 tname に関連付けられたメタテーブルをスタックに積む (luaL_newmetatable を参照)。\nluaL_gsub\n      const char *luaL_gsub (lua_State *L, const char *s,\n                             const char *p, const char *r);\n\n文字列 s 中の文字列 p をすべて文字列 r で置換したコピーを作る。 その結果の文字列をスタックに積み、それを返す。\nluaL_loadbuffer\n      int luaL_loadbuffer (lua_State *L, const char *buff,\n                           size_t sz, const char *name);\n\nLuaのチャンクとしてバッファをロードする。 この関数は lua_load を使って buff が指すサイズ sz のバッファに格納されているチャンクをロードする。\nこの関数は lua_load と同じ結果を返す。 name はデバッグ情報やエラーメッセージで使うチャンク名である。\nluaL_loadfile\n      int luaL_loadfile (lua_State *L, const char *filename);\n\nLuaのチャンクとしてファイルをロードする。 この関数は lua_load を使って名前 filename のファイルに格納されているチャンクをロードする。 filename が NULL の場合は標準入力から読み込む。 ファイルが # で始まっていたら、その最初の行を無視する。\nこの関数は lua_load と同じ結果を返すが、 追加のエラーコードとしてファイルを開けなかったり読めなかった場合は LUA_ERRFILE を返す。\nluaL_loadstring\n      int luaL_loadstring (lua_State *L, const char *s);\n\nLuaのチャンクとして文字列をロードする。 この関数は lua_load を使ってゼロ終端文字列 s に格納されているチャンクをロードする。\nこの関数は lua_load と同じ結果を返す。\nluaL_newmetatable\n      int luaL_newmetatable (lua_State *L, const char *tname);\n\nレジストリにキー tname がすでにあれば 0 を返す。 そうでなければ、ユーザーデータのメタテーブルとして使う新しいテーブルを作り、 それをレジストリにキー tname と共に追加して 1 を返す。\nどちらの場合もレジストリの tname に関連付けられた最終的な値をスタックに積む。\nluaL_newstate\n      lua_State *luaL_newstate (void);\n\n標準のCの realloc 関数をベースにしたアロケータ関数を使って lua_newstate を呼び、新しいLuaステートを作成する。 また、致命的エラーの場合に標準エラー出力にエラーメッセージを出力するパニック関数 (lua_atpanic を参照) を設定する。\n新しいステートを返す。 メモリ確保エラーの場合は NULL を返す。\nluaL_openlibs\n      void luaL_openlibs (lua_State *L);\n\n指定したステートにすべての標準Luaライブラリを開く。\nluaL_optint\n      int luaL_optint (lua_State *L, int narg, int d);\n\n関数の第 narg 引数が数値であれば、その数値を int にキャストして返す。 その引数が存在しないか nil であれば、d を返す。 さもなくばエラーを発生する。\nluaL_optinteger\n      lua_Integer luaL_optinteger (lua_State *L, int narg, lua_Integer d);\n\n関数の第 narg 引数が数値であれば、 その数値を lua_Integer にキャストして返す。 その引数が存在しないか nil であれば、d を返す。 さもなくばエラーを発生する。\nluaL_optlong\n      long luaL_optlong (lua_State *L, int narg, long d);\n\n関数の第 narg 引数が数値であれば、その数値を long にキャストして返す。 その引数が存在しないか nil であれば、d を返す。 さもなくばエラーを発生する。\nluaL_optlstring\n      const char *luaL_optlstring (lua_State *L, int narg,\n                                   const char *d, size_t *l);\n\n関数の第 narg 引数が文字列であれば、その文字列を返す。 引数が存在しないか nil であれば、d を返す。 さもなくばエラーを発生する。\nl が NULL でなければ、結果の長さを *l に格納する。\nluaL_optnumber\n      lua_Number luaL_optnumber (lua_State *L, int narg, lua_Number d);\n\n関数の第 narg 引数が数値であれば、その数値を返す。 その引数が存在しないか nil であれば、d を返す。 さもなくばエラーを発生する。\nluaL_optstring\n      const char *luaL_optstring (lua_State *L, int narg, const char *d);\n\n関数の第 narg 引数が文字列であれば、その文字列を返す。 その引数が存在しないか nil であれば、d を返す。 さもなくばエラーを発生する。\nluaL_prepbuffer\n      char *luaL_prepbuffer (luaL_Buffer *B);\n\nバッファ B に追加するための文字列を格納できる、 サイズ LUAL_BUFFERSIZE の領域のアドレスを返す (luaL_Buffer を参照)。 文字列をこの領域に格納したあと、文字列のサイズを渡して luaL_addsize を呼び、実際にバッファに追加しなければならない。\nluaL_pushresult\n      void luaL_pushresult (luaL_Buffer *B);\n\nスタックトップに最終的な文字列を残してバッファ B の使用を終える。\nluaL_ref\n      int luaL_ref (lua_State *L, int t);\n\nインデックス t のテーブルにスタックトップのオブジェクトに対する リファレンス を作成し、それを返す(そしてオブジェクトをスタックから取り除く)。\nリファレンスは一意な整数のキーである。 テーブル t に整数キーを手動で追加しなければ、 luaL_ref は返すキーの一意性を保証する。 lua_rawgeti(L, t, r) を呼ぶと、リファレンス r が参照するオブジェクトを取得できる。 luaL_unref はリファレンスとそれに関連付けられたオブジェクトを解放する。\nスタックトップのオブジェクトが nil の場合、 luaL_ref は定数 LUA_REFNIL を返す。 定数 LUA_NOREF は luaL_ref が返すいかなるリファレンスとも異なることが保証されている。\nluaL_Reg\n      typedef struct luaL_Reg &#123;\n        const char *name;\n        lua_CFunction func;\n      &#125; luaL_Reg;\n\nluaL_register が登録する関数の配列の型。 name は関数の名前で、func は関数へのポインタである。 luaL_Reg の配列は name と func が共に NULL である番兵エントリで終わらなければならない。\nluaL_register\n      void luaL_register (lua_State *L, const char *libname,\n                          const luaL_Reg *l);\n\nライブラリを開く。\nlibname に NULL を渡して呼ぶと、 単純にリスト l (luaL_Reg を参照) の関数をすべてスタックトップのテーブルに登録する。\nlibname がNULLでなければ、 新しいテーブル t を作成し、 それをグローバル変数 libname の値として設定し、 package.loaded[libname] の値として設定し、 そしてリスト l の関数をすべてそこに登録する。 もし package.loaded[libname] か変数 libname にテーブルが存在すれば、 新しいテーブルを作る代わりにそれを再利用する。\nいずれの場合も、この関数はスタックトップにそのテーブルを置く。\nluaL_typename\n      const char *luaL_typename (lua_State *L, int idx);\n\nインデックス idx の値の型の名前を返す。\nluaL_typerror\n      int luaL_typerror (lua_State *L, int narg, const char *tname);\n\n: bad argument  to  ( expected, got )のようなメッセージのエラーを生成する。 ただし  は luaL_where によって生成されたもので、  は現在の関数の名前、 and  は実引数の型名である。\nluaL_unref\n      void luaL_unref (lua_State *L, int t, int ref);\n\nインデックス t のテーブルからリファレンス ref を解放する (luaL_ref を参照)。 エントリがテーブルから取り除かれるので、参照されていたオブジェクトは回収され得る。 リファレンス ref も再利用するために解放される。\nref が LUA_NOREF または LUA_REFNIL の場合、 luaL_unref は何もしない。\nluaL_where\n      void luaL_where (lua_State *L, int lvl);\n\nコールスタックのレベル lvl の制御の現在位置を識別する文字列をスタックに積む。 典型的にこの文字列は :: のような書式になっている。 レベル0は実行中の関数、 レベル1は実行中の関数の呼び出し元の関数、 以下同様である。\nこの関数はエラーメッセージの接頭辞を構築するために使う。\n5 - 標準ライブラリ\nLua標準ライブラリは、CのAPIを使って直接実装された便利な関数を提供する。 いくつかは言語の本質的なサービスを提供するものであり (例えば type や getmetatable)、 残りは「外部の」サービスへのアクセスを提供するものである (例えば I/O)。 また、Lua自身で実装可能であるが、便利さやパフォーマンス要求のためにCで実装されたものもある (例えば sort)。\nすべてのライブラリは公開されているCのAPIを使って実装されており、独立したCのモジュールで提供されている。 現在、Luaには以下の標準ライブラリがある。\n基本ライブラリパッケージライブラリ文字列操作テーブル操作数学関数 (sin、logなど)入出力OS機能デバッグ機能基本ライブラリとパッケージライブラリ以外は、 それぞれのライブラリが、 グローバルテーブルのフィールドか、そのオブジェクトのメソッドとして、そのすべての関数を提供している。これらのライブラリを使うには、Cのホストプログラムで すべての標準ライブラリを開く luaL_openlibs を呼ばなければならない。 代わりに、 luaopen_base (基本ライブラリ用)、 luaopen_package (パッケージライブラリ用)、 luaopen_string (文字列ライブラリ用)、 luaopen_table (テーブルライブラリ用)、 luaopen_math (数学ライブラリ用)、 luaopen_io (I/OライブラリとOSライブラリ用)、 luaopen_debug (デバッグライブラリ用) を呼んで個別に開くこともできる。 これらは lualib.h に定義されているが、 直接呼ぶべきではなく、他のLuaのC関数と同様に —- 例えば lua_call を使って —- 呼ばなければならない。\n5.1 - 基本関数\n基本ライブラリはLuaへのコアな機能を提供する。 アプリケーションにこのライブラリを含めない場合は、その機能を提供する代わりの実装を用意する必要があるか慎重に調べるべきである。\nassert (v [, message])\n引数 v が偽 (すなわち nil または false) であればエラーを発生させる。 そうでなければ、そのすべての引数を返す。 message はエラーメッセージを指定する。 省略された場合は “assertion failed!” である。\ncollectgarbage (opt [, arg])\nこの関数はガベージコレクタへの汎用インタフェイスである。 最初の引数 opt によって異なる機能を実行する。\n“stop” — ガベージコレクタを停止する。“restart” — ガベージコレクタを再開する。“collect” — フルガベージコレクションサイクルを実行する。“count” — Luaが使っているメモリの合計を(キロバイトで)返す。“step” — ガベージコレクションステップひとつを実行する。 ステップの「サイズ」は arg で制御する。 大きな値は大きなステップを意味するが、具体的には定まっていない。 ステップサイズを制御したければ、 arg の値を実験的に調整しなければならない。 このステップでコレクションサイクルが終わった場合は true を返す。“steppause” — コレクタの停止値 (2.10 を参照) の新しい値を arg÷100に設定する。“setstepmul” — コレクタの ステップ係数 の新しい値を arg÷100に設定する (2.10 を参照)。\ndofile (filename)\nファイルを開き、その内容をLuaチャンクとして実行する。 引数が指定されなければ、標準入力 (stdin) から読み取って実行する。 dofileはチャンクから返されたすべての値をそのまま返す。 エラーが起きた場合は、呼び出し側に伝搬される (つまり dofile は保護モードで動くのではない)。\nerror (message [, level])\n最後に保護された関数呼び出しを終了し、message をエラーメッセージとして返す。 関数 error は戻らない。通常、error はメッセージの先頭にエラーの位置に関する何らかの情報を追加する。 level 引数は、エラーメッセージがエラー位置をどのように得るかを指定する。 レベル1では (デフォルト)、error 関数を呼んだ場所がエラー位置である。 レベル2は error を呼んだ関数を呼んだ位置を指す。 以下同様である。 レベル0を渡すとメッセージにエラー位置情報を追加しない。\n_G\nグローバル環境を保持するグローバル変数である (関数ではない)。 つまり、_G._G = _G である。 Lua自身はこの変数を使用しないので、この値を変更しても環境には何の影響もなく、逆もまた同じである (環境を変えるには setfenv を使う)。\ngetfenv (f)\n関数の現在の環境を返す。 f はLuaの関数か、関数のスタックレベルを示す数値である。 レベル1はgetfenvを呼んだ関数である。 もし与えられた関数がLuaの関数でなかったり、fが0の場合は、getfenv はグローバル環境を返す。 f のデフォルト値は1である。\ngetmetatable (object)\nもし object がメタテーブルを持っていなければ nil を返す。 もしobjectのメタテーブルが “__metatable” フィールドを持っていれば、その値を返す。 そうでなければobjectのメタテーブルを返す。\nipairs (t)\n3つの値、イテレータ関数、テーブル t、および0を返す。\n   for i,v in ipairs(t) do ... end\n\nは (1,t[1])、(2,t[2])、…のペアを、最初に値にnilが現れるまで繰り返す。巡回中にテーブルを変更する際の注意は next を参照。\nload (func [, chunkname])\nそのピースを取得する関数 func を使ってチャンクをロードする。 func は前回の戻り値と連結する文字列を返さなければならない。 nil を返す (または戻り値なし) とチャンクの終わりを知らせる。\nエラーがなければ、コンパイルされたチャンクが関数として返され、 そうでなければ nil とエラーメッセージが返される。 返された関数の環境はグローバル環境である。\nchunkname はエラーメッセージやデバッグ情報のためのチャンク名を指定する。\nloadfile ([filename])\nload と同じであるが、 ファイル filename からチャンクを読み込む。 ファイル名を与えなければ標準入力から読み込む。\nloadstring (string [, chunkname])\nload と同じであるが、 指定した文字列からチャンクを読み込む。\n与えられた文字列をロードして実行するには、以下の慣用句を使う。\n  assert(loadstring(s))()\n\nnext (table [, index])\nテーブルの全フィールドを巡回するための関数である。 最初の引数はテーブルを、二番目の引数はこのテーブルのインデックスを渡す。 next はテーブル内の次のインデックスと、その値を返す。 二番目の引数に nil を渡すと、初期インデックスとその値が返される。 最後のインデックスで呼び出すか、空のテーブルに対して nil で呼び出すと、 next は nil を返す。 二番目の引数が省略された場合は nil と解釈される。 特に、next(t) を使うとテーブルが空かどうか調べることができる。\nLuaにはフィールドの宣言がない。 テーブル内にフィールドが存在しないのと、nil 値が格納されたフィールドには、何の違いも無い。 ゆえに、next は nil でない値を持つフィールドのみを考慮する。 インデックスが列挙される順番は、数値のインデックスに対しても、不定である (数値順にテーブルを巡回するには、数値用の for 文や ipairs 関数を使う)。\nテーブルの巡回中に、もし存在していないフィールドに新たに値が割り当てられたら、next の動作は 未定義 である。 しかし既存のフィールドは変更してもよい。 特に、既存のフィールドを消去するのは構わない。\npairs (t)\n3つの値、next 関数、テーブル t、nil を返す。\n   for k,v in pairs(t) do ... end\n\nはテーブル t のすべてのキー・値ペアについて繰り返す。巡回中にテーブルを変更する際の注意は next を参照。 +\npcall (f, arg1, arg2, …)\n保護モードで、与えられた引数で f を呼び出す。 つまり f の内部で発生したエラーは伝搬されず、 代わりに pcall がエラーを捕らえ、ステータスコードを返す。 最初の引数はステータスコード (ブーリアン型) で、エラーなしに呼び出しが成功したときは真を返す。 その場合、f の戻り値もすべて、最初の戻り値に続いて返される。 エラーが起こった場合、pcall は false とエラーメッセージを返す。\nprint (e1, e2, …)\n引数をいくつでも取ることができ、それらの値を tostring で文字列に変換してから標準出力 (stdout) に表示する。 print は書式化出力を意図したものではなく、 典型的にはデバッグのために、値を表示する簡単な方法として用意されているだけである。 書式化出力には string.format を使う。\nrawequal (v1, v2)\nメタメソッドを呼ぶことなしに v1 と v2 が等しいかどうか調べる。 ブーリアンを返す。\nrawget (table, index)\nメタメソッドを呼ぶことなしに table[index] の本当の値を得る。 table はテーブルでなければならない。 index は nil 以外のどんな値でも良い。\nrawset (table, index, value)\nメタメソッドを呼ぶことなしに table[index] に value をセットする。 table はテーブルでなければならない。 index は nil 以外のどんな値でも良い。 value はどんなLuaの値でも良い。\nselect (index, …)\nindex が数値であれば、 index 番目以降の引数をすべて返す。 そうでなければ、index は文字列 “#” でなければならない。 この場合 select は受け取った余分の引数の合計数を返す。\nsetfenv (f, table)\n指定された関数で使われる環境を変更する。 f はLuaの関数か、関数のスタックレベルを指定する数値である。 レベル1は setfenv を呼び出した関数を示す。 setfenv は与えられた関数を返す。\n特殊なケースとして、fに0が与えられると、setfenv は走行中のスレッドの環境を変える。 この場合、setfenv は何も返さない。\nsetmetatable (table, metatable)\ntable のメタテーブルを変更する (Luaから他の型のメタテーブルを変更することはできない。Cからのみ可能である)。 もし metatable が nil であれば、table のメタテーブルは除去される。 元のメタテーブルが “__metatable” フィールドを持っていると、エラーを発する。\nこの関数は table を返す。\ntonumber (e [, base])\n引数を数値に変換しようとする。 もし引数がすでに数値だったり、数値に変換可能な文字列であれば、tonumber は数値を返す。 そうでなければ nil を返す。省略可能な引数は数値を解釈する際の基数を指定する。 基数は2から36の整数を指定できる。 10より大きい基数では、A´が10を表し、B´が11を表し、 以下同様に続き、`Z´が35を表す (大文字でも小文字でも良い)。 基数が10 (デフォルト) の場合 は、数値に小数部や指数部を付けることができる (2.1 を参照)。 他の基数では、符号なしの整数のみを受け付ける。\ntostring (e)\n任意の型の引数を受け取り、理解しやすい形式の文字列に変換する。 数値が変換される方法を完全にコントロールする場合は string.format を使う。もし e のメタテーブルが “__tostring” フィールドを持っていたら、 e を引数に、その関連付けられた値が呼び出され、その戻り値が結果として使われる。\ntype (v)\n値の型を文字列で返す。 この関数が返す値は以下のいずれかである。    “nil” (という文字列。nil 値ではなく。)    “number”    “string”    “boolean”    “table”    “function”    “thread”    “userdata”\nunpack (list [, i [, j]])\n与えられたテーブルの要素を返す。 この関数は、以下のコードには固定の要素数しか書けないことを除いて、以下のコードと等価である。  return list[i], list[i+1], …, list[j]デフォルトでは、i は1で j は長さ演算子 (2.5.5 を参照) 定義されているリストの長さである。\n_VERSION\n現在のインタプリタのバージョン文字列を保持しているグローバル変数 (関数ではない)。 この変数の現在の内容は “Lua 5.1” である。\nxpcall (f, err)\nこの関数は pcall に似ているが、エラーハンドラを指定できる点が異なる。\nxpcall は保護モードで f を呼び出し、 err をエラーハンドラとして使う。 f の内部で発生したエラーは伝搬されない。 代わりに、xpcall がエラーを捕らえ、エラーオブジェクトを引数に err を呼ぶ。 最初の戻り値はステータスコード (ブーリアン型) で、 エラーが起きなかった場合は true を返す。 その場合、最初の戻り値に続いて f の戻り値もすべて返される。 エラーが起きた場合、xpcall は false と err の戻り値を返す。\n5.2 - コルーチン操作\nコルーチン関連の操作は基本ライブラリのサブライブラリであり、テーブル coroutine 内に置かれている。 コルーチンに関する一般的な説明は 2.11 を参照。\ncoroutine.create (f)\nf を本体とする新しいコルーチンを作る。 f はLuaの関数でなければならない。 “thread” 型の新しいコルーチンオブジェクトを返す。\ncoroutine.resume (co [, val1, …, valn])\nコルーチン co の実行を開始/再開する。 コルーチンを最初にresumeしたとき、その本体の実行が開始される。 値 val1, … は本体の関数に引数として渡される。 コルーチンが中断されていた場合、resume はそれを再開し、 yield からの戻り値として val1, … が渡される。\nコルーチンがエラー無く実行されれば、 resume は true に加えて yield に渡された値 (コルーチンが中断された場合)、 もしくは本体の関数から返された値 (コルーチンが終了した場合) を返す。 エラーが起きたら、resume は false とエラーメッセージを返す。\ncoroutine.running ()\n走行中のコルーチンを返す。 メインスレッドで呼ばれた場合は nil を返す。\ncoroutine.status (co)\nコルーチン co の状態を文字列で返す。\n“running” … コルーチンは走行中。 “suspended” … コルーチンは yield の呼び出しで中断されているが、まだ実行中である。 “normal” … コルーチンはアクティブであるが走行中でない(つまり他のコルーチンをresumeしている)。 “dead” … コルーチンの本体の関数が終了したか、エラーで停止した。\ncoroutine.wrap (f)\nf を本体とする新しいコルーチンを作成する。 f はLuaの関数でなければならない。 coroutine.wrap は、呼ばれるたびにコルーチンを再開する関数を返す。 関数に渡された引数は resume に余分に渡される引数と同じ動作をし、 戻り値は resume から最初のブーリアンを除いた値と同じである。 もしエラーが起きた場合、エラーは伝搬する。\ncoroutine.yield ([val1, …, valn])\n呼ばれたコルーチンの実行を中断する。 コルーチンは、Cの関数やメタメソッド、イテレータを中断することはできない。 yield に渡された引数は resume から追加の戻り値として返される。\n5.3 - モジュール\nLuaでモジュールを構築したりロードしたりする基本的な機能を提供する。 2つの関数 require および module はグローバル環境に直接エクスポートされる。 それ以外はすべてテーブル package にエクスポートされる。\nmodule (name [, …])\nモジュールを作成する。 package.loaded[name] にテーブルがあれば、 このテーブルがモジュールである。 そうでなければ、指定した名前のグローバルなテーブル t があれば、 このテーブルがモジュールである。 そうでなければ、新しいテーブル t を作成し、 グローバル変数 name の値と package.loaded[name] の値にそれを設定する。 またこの関数は指定された名前で t._NAME を、 モジュール (t それ自身) で t._M を、 パッケージ名 (完全なモジュール名から最後の部分を除いたもの、下記参照) で t_PACKAGE を初期化する。 最後に、module は現在の関数の新しい環境および package.loaded[name] の新しい値として t を設定する。 従って require は t を返す。\nもし name が複合名 (つまり、ドットで各部が区切られたもの) であれば、 module はそれぞれの部分についてテーブルを作る (または、すでに存在すれば再利用する)。 例えば、name が a.b.c の場合、 module はグローバル変数 a のフィールド b のフィールド c にモジュールテーブルを格納する。\nこの関数はモジュール名の後に省略可能な オプション を渡すことができる。 この各オプションはモジュール全体に適用される関数である。\nrequire (modname)\n指定したモジュールをロードする。 この関数は modname がすでにロードされているかどうかを決定するために まずテーブル package.loaded を探す。 もしすでにロードされていれば、require は package.loaded[modname] に格納されている値を返す。 そうでなければ、モジュールの ローダ を探す。\nローダを探すために、 require はまず package.preload[modname] を問い合わせる。 もしそこに値があれば、この値 (関数であるべきである) がローダである。 そうでなければ、require は package.path に格納されているパスを使う Luaのローダを探す。 それも失敗したら、package.cpath に格納されているパスを使うCのローダを探す。 それもまた失敗したら、オールインワンローダ (下記参照) を試す。\nCのライブラリをロードする場合、 require はまずアプリケーションをそのライブラリとリンクするためのダイナミックリンク機能を使う。 次にこのライブラリ内からローダとして使うためのCの関数を探す。 このCの関数は “luaopen_” にモジュール名を付けた名前であるが、 ドットはアンダースコアに置換する。 さらに、モジュール名にハイフンが含まれていれば、 その最初のハイフンまでの接頭辞は (ハイフンも含めて) 取り除かれる。 例えば、モジュール名が a.v1-b.c の場合、関数名は luaopen_b_c となる。\nrequire がLuaのライブラリにもCのライブラリにもモジュールを見つけられなければ、 オールインワンローダ を呼ぶ。 このローダはCのパスを見て、指定したモジュールのルート名に対するライブラリを探す。 例えば a.b.c が要求された場合、a というCのライブラリを探す。 もし見つかれば、そのサブモジュールに対するオープン関数をその中から探す。 先の例でいうと、luaopen_a_b_c となる。 この機能により、いくつものCのサブモジュールをひとつのライブラリに納めることができる。 その場合でも各サブモジュールは、それぞれ独自のオープン関数を持つ。\nローダが見つかれば、 require は単一の引数 modname を渡してローダを呼ぶ。 ローダが何らかの値を返すと、 require はそれを package.loaded[modname] に格納する。 ローダが値を返さず、package.loaded[modname] に何の値も格納されていなければ、 require はこのエントリに true を格納する。 いずれにせよ、require は最終的な package.loaded[modname] の値を返す。\nモジュールのロードまたは実行でエラーがあったり、そのモジュールのローダが見つからなければ、 require はエラーを発生する。\npackage.cpath\nCのローダを探すために require が使うパス。\nLuaは環境変数 LUA_CPATH (に加えて、luaconf.h に定義されているもうひとつのデフォルトパス) を使って、 Luaのパス package.path と同じ方法で Cのパス package.cpath を初期化する。\npackage.loaded\nすでにロードされたモジュールを管理するために require が使うテーブル。 モジュール modname が要求され、 package.loaded[modname] が偽でなければ、 require は単に、そこに格納されている値を返す。\npackage.loadlib (libname, funcname)\nホストプログラムをCのライブラリ libname と動的リンクする。 このライブラリの中で関数 funcname を探し、その関数をCの関数として返す (従って、funcname は呼び出し規約 (lua_CFunction を参照) に従わなければならない)。\nこれは低レベルな関数であり、パッケージシステムやモジュールシステムを完全に迂回する。 require と異なり、 パス探索を行ったり拡張子を自動的に付加したりしない。 libname はCのライブラリの完全なファイル名でなければならず、 必要ならパスや拡張子も含めなければならない。 funcname はCのライブラリがエクスポートしている完全な名前でなければならない (使っているCコンパイラやリンカに依存するであろう)。\nこの関数はANSI Cのサポート範囲外である。 従って、これはいくつかのプラットフォーム (Windows, Linux, Mac OS X, Solaris, BSD, および dlfcn 標準をサポートする他のUnixシステム) でしか利用できない。\npackage.path\nLuaのローダを探すために require が使うパス。\n起動時にLuaは環境変数 LUA_PATH の値、 またはその環境変数が定義されていなければ luaconf.h で定義されているデフォルトパスで、この変数を初期化する。 環境変数の値に “;;” があれば、それをデフォルトパスで置換する。\nパスはセミコロンで区切られた一連の テンプレート である。 各テンプレートについて、 require は テンプレート内の疑問符 (interrogation mark) を ファイル名 に置換し、 結果のファイル名をロードしようと試みる。 このファイル名は、モジュール名のドットを 「ディレクトリ区切り文字」 (Unixの “/“ のような) で置き換えたものである。 例えば、Luaのパスが\n  “./?.lua;./?.lc;/usr/local/?/init.lua”であった場合、モジュール foo のLuaのローダの検索は、 ファイル ./foo.lua、./foo.lc、 /usr/local/foo/init.lua のロードをこの順序で試みる。\npackage.preload\n特定のモジュールのローダを格納するテーブル (require を参照)。\npackage.seeall (module)\n__index フィールドがグローバル環境を参照するメタテーブルを module にセットする。 従ってこのモジュールはグローバル環境から値を継承する。 関数 module へのオプションとして使われる。\n5.4 - 文字列操作\nこのライブラリは、検索や部分文字列の抽出、パターンマッチングといった、文字列操作のための一般的な機能を提供する。 Luaの文字列のインデックス付けは、最初の文字が1の位置である (Cのように0ではない)。 文字列の末尾から逆方向にマイナス値で指定することもできる。 つまり、最後の文字は -1 の位置で示される。\n文字列ライブラリはすべて、テーブル string 内の関数として提供される。 また、__index フィールドが自身を指す文字列用メタテーブルをセットする。 従って、文字列関数はオブジェクト指向スタイルで使うことができる。 例えば、string.bytes(s, i) は s:byte(i) と書くこともできる。\nstring.byte (s [, i [, j]])\n文字 s[i], s[i+1], …, s[j] の内部コードの数値を返す。 i のデフォルトは1、 j のデフォルトは i である。文字コードの数値は、プラットフォームを超えての可搬性がないことに注意。\nstring.char (i1, i2, …)\n0個以上の整数を指定できる。 各文字が与えられた引数と等しい内部コードを持ち、長さが引数の数に等しい、文字列を返す。文字コードの数値は、プラットフォームを超えての可搬性がないことに注意。\nstring.dump (function)\n指定された関数のバイナリ表現を保持する文字列を返す。 loadstring にこの文字列を渡すことで、関数のコピーを作ることができる。 function は上位値を持たないLua関数でなければならない。\nstring.find (s, pattern [, init [, plain]])\n文字列 s 内で pattern の最初のマッチを探す。 もしマッチが見つかれば、find は s 内でこのパターンがマッチした開始位置と終了位置のインデックスを返す。 そうでなければ nil を返す。 三番目の省略可能な引数 init は検索開始位置を指定し、デフォルト値は1で、負の値も使える。 四番目の省略可能な引数 plain に true が指定されると、 パターンマッチング機能はオフになり、 pattern 中の「魔法の」文字は無くなって、ただの「部分文字列を検索する」操作になる。 plain を与える場合は init も与えなければならないことに注意。もしパターン内にキャプチャが指定されていれば、 マッチ成功時にキャプチャされた文字列が2つのインデックスの後に返される。\nstring.format (formatstring, e1, e2, …)\n最初の引数 (文字列でなければならない) で指定された記述に従い、残りの可変個の引数を書式化して返す。 書式文字列は標準C関数のprintfファミリーと同じルールに従う。 ただし、 *、l、L、n、p、h はサポートされてなくて、追加の q がある点だけが異なる。 q オプションは、Luaインタプリタで安全に読み戻せる適切な形式の文字列に書式化する。 その文字列はダブルクォートの間に書かれ、 文字列中のダブルクォート、改行、埋め込まれたゼロ、バックスラッシュは正しくエスケープされる。 例えば、       string.format(‘%q’, ‘a string with “quotes” and \\n new line’)は次のような文字列を生成する。“a string with &quot;quotes&quot; and  new line”c、d、E、e、f, g、G、i、o、u, X、x はすべて数値の引数を期待し、 q と s は文字列を期待する。\nこの関数は埋め込まれたゼロを含む文字列を受け付けない。\nstring.gmatch (s, pattern)\n呼ばれるたびに文字列 s から pattern でキャプチャされた部分を次々と返すような、イテレータ関数を返す。\npattern にキャプチャが指定されていなければ、それぞれの呼び出しごとに、マッチした文字列全体を返す。\n例えば、以下のループでは\n  s = “hello world from Lua”  for w in string.gmatch(s, “%a+”) do    print(w)  end文字列 s のすべての単語について繰り返し、それぞれを別々の行に出力する。 次の例は、与えられた文字列から key=value のペアを集めてテーブルへ入れる。  t = {}  s = “from=world, to=Lua”  for k, v in string.gmatch(s, “(%w+)=(%w+)”) do    t[k] = v  end\nstring.gsub (s, pattern, repl [, n])\nパターン pattern をすべて repl によって指定された置換文字列に置き換えた s のコピーを返す。 repl は文字列、テーブル、または関数でもよい。 gsub は二番目の値として、置換が行われた回数も返す。repl が文字列であれば、その値が置換に使われる。 文字 % はエスケープ文字として機能する。 repl 内に現れる %n は (n は1から9)、 n 番目にキャプチャされた部分文字列を表す (以下を見よ)。 シーケンス %0 はマッチ全体を表す。 シーケンス %% は1個の % を表す。\nrepl がテーブルであれば、 そのテーブルは最初のキャプチャをキーとしてマッチのたびに問い合わせられる。 パターンにキャプチャがなければ、マッチ全体がキーとして使われる。\nrepl が関数であれば、マッチが現れるたびにこの関数が呼ばれる。 関数にはキャプチャされた部分文字列が順番にすべて渡される。 パターンにキャプチャが指定されていなければ、マッチした全体が唯一の引数として渡される。 テーブル問い合わせまたは関数呼び出しから返された値が文字列か数値であれば、 それが置換文字列として使われる。 そうでなくて false か nil であれば、置換は行われない (つまり、文字列中の元のマッチが維持される)。\n省略可能な最後の引数 n は置換が行われる最大回数を制限する。 例えば、n が1なら最初に現れる pattern だけが置換される。\nいくつか例を示す。\n   x = string.gsub(“hello world”, “(%w+)”, “%1 %1”)   –&gt; x=”hello hello world world”\n   x = string.gsub(“hello world”, “%w+”, “%0 %0”, 1)   –&gt; x=”hello hello world”\n   x = string.gsub(“hello world from Lua”, “(%w+)%s*(%w+)”, “%2 %1”)   –&gt; x=”world hello Lua from”\n   x = string.gsub(“home = $HOME, user = $USER”, “%$(%w+)”, os.getenv)   –&gt; x=”home = /home/roberto, user = roberto”\n   x = string.gsub(“4+5 = $return 4+5$”, “%$(.-)%$”, function (s)         return loadstring(s)()       end)   –&gt; x=”4+5 = 9”\n   local t = {name=”lua”, version=”5.1”}   x = string.gsub(“$name%-$version.tar.gz”, “%$(%w+)”, t)   –&gt; x=”lua-5.1.tar.gz”\nstring.len (s)\n文字列を受け取り、その長さを返す。 空文字列 “” の長さは0である。 文字列中のゼロも数えるので、”a\\000b\\000c” の長さは5である。\nstring.lower (s)\n文字列を受け取り、その中の大文字をすべて小文字に変えた文字列のコピーを返す。 それ以外の文字は変化しない。 何が大文字であるかは現在のロケールに依存する。\nstring.match (s, pattern [, init])\n文字列 s から pattern の最初の マッチ を探す。 見つかった場合、match はパターンのキャプチャを返し、 そうでなければ nil を返す。 pattern にキャプチャがなければ、マッチ全体が返される。 3つめの省略可能な数値の引数 init は検索を開始する位置を指定する。 デフォルト値は1で、負の値を指定してもよい。\nstring.rep (s, n)\n文字列 s のコピーを n 個連結した文字列を返す。\nstring.reverse (s)\n文字列 s を反転した文字列を返す。\nstring.sub (s, i [, j])\n文字列 s の、位置 i から位置 j までの部分文字列を返す。 i にも j にも、負の値を使える。 j が省略されたときは -1 とみなされる (つまり文字列の長さと同じ)。 特に、string.sub(s,1,j) は s の先頭から j 文字を取り出し、 string.sub(s, -i) は s の最後の i 文字を取り出す。\nstring.upper (s)\n文字列を受け取り、その中の小文字をすべて大文字に変えた文字列のコピーを返す。 それ以外の文字は変化しない。 何が小文字であるかは現在のロケールに依存する。\nPatterns\n文字クラス は文字の集合を表す。 以下の組み合わせを文字クラスの指定に使うことができる。\nx (x は 魔法の文字 ^$()%.[]*+-? 以外の文字) — 文字 x それ自身を表す。. — (ドット) すべての文字を表す。%a — すべてのletterを表す。%c — すべての制御文字を表す。%d — すべての数字を表す。%l — すべての小文字を表す。%p — すべての区切り記号を表す。%s — すべての空白文字を表す。%u — すべての大文字を表す。%w — すべての英数文字を表す。%x — すべての十六進数字を表す。%z — 0として表現される文字を表す。%x (x は英数文字以外) — 文字 x 自身を表す。 これは魔法の文字をエスケープする標準的な方法である。 いかなる区切り文字 (魔法の文字でなくても) は前に %´ を付けることでそれ自身を表すことができる。 [set] --- set 内のすべての文字の和からなるクラスを表す。 終わりの文字と -´ で繋げることで、文字の範囲を表す。 上で挙げた %x 形式のすべてのクラスも、set の中で使うことができる。 それ以外の set 内の文字は、それ自身を表す。 例えば、[%w_] (または [_%w]) は、すべての英数にアンダースコアを加えたものを表す。 [0-7] は八進数字を表し、 [0-7%l%-] は八進数字と小文字と `-´ を表す。範囲とクラスの相互作用は未定義である。 つまり、[%a-z] や [a-%%] のようなパターンは意味を持たない。\n[^set] — set の補集合を表す。 set の内容は上で説明したものと同じである。ひとつの文字で表現されるクラス (%a、%cなど) はすべて、対応する大文字は補集合を表す。 例えば %S は空白以外のすべての文字を表す。文字、空白、その他の文字のグループの定義については、現在のロケールに依存する。 特に、クラス [a-z] は %l と等価ではないかもしれない。\nパターンの要素 は以下のいずれかである。\n単一の文字クラス。そのクラス内の文字ひとつにマッチする。単一の文字クラスに *´ が続いたもの。 そのクラスの文字の0回以上の繰り返しにマッチする。 この繰り返し要素は、可能な限り長いシーケンスにマッチする。 単一の文字クラスに +´ が続いたもの。 そのクラスの文字の1回以上の繰り返しにマッチする。 この繰り返し要素は、可能な限り長いシーケンスにマッチする。単一の文字クラスに -´ が続いたもの。 そのクラスの文字の0回以上の繰り返しにマッチする。 *´ と異なり、この繰り返し要素は可能な限り 短い シーケンスにマッチする。単一の文字クラスに ?´ が続いたもの。 そのクラスの文字の0回または1回の出現にマッチする。 %n (n は1から9)。 これは、n 番目にキャプチャされた文字列にマッチするような要素である (下の説明を参照)。 %bxy (x と y は異なる文字)。 これは x で始まって y で終わる文字列にマッチするような要素である。 x と y は 対応が取れる。 つまり、文字列を左から右に読んでいって、 x が現れるたびにカウントを +1 し、y では -1 したとき、 最後の y はカウントが0になる最初の y である。 例えば、要素 %b() はカッコの対応が取れた式にマッチする。 pattern はパターン要素の列である。 パターンの最初に現れる ^´ は対象文字列の先頭にマッチを固定する。 パターンの最後に現れる $´ は対象文字列の最後にマッチを固定する。 他の位置では、^´ や `$´ は特別な意味を持たず、それ自身を表す。\nパターンはカッコで囲まれたサブパターンを持つことができ、それらは キャプチャ と呼ばれる。 マッチが成功したとき、対象文字列の中でキャプチャにマッチした部分が保存 (キャプチャ) され、後で使うことができる。 キャプチャはその左カッコによって番号付けされる。 例えば、パターン “(a*(.)%w(%s*))” では、 “a*(.)%w(%s*)” にマッチする部分が最初のキャプチャとして保存され (だから1番になる)、 “.” にマッチする文字が2番にキャプチャされ、 “%s*” にマッチする部分が3番になる。\n特殊なケースとして、空キャプチャ () は文字列の現在位置 (数値) をキャプチャする。 例えば、文字列 “flaaap” にパターン “()aa()” を適用すると、 2つのキャプチャ3と5を得られる。\nパターンには途中にゼロを含むことができない。代わりに %z を使う。\n5.5 - テーブル操作\nこのライブラリはテーブル操作のための一般的な機能を提供する。 テーブル table 内にすべての関数が提供される。 これらの関数でテーブルの「長さ」について言及するときは、 それは長さ演算子の結果を意味している。\ntable.concat (table [, sep [, i [, j]]])\ntable[i]..sep..table[i+1] … sep..table[j] を返す。 sep のデフォルト値は空文字列で、 i のデフォルト値は1、 j のデフォルト値はテーブルの長さである。 i が j よりも大きい場合は空文字列を返す。\ntable.insert (table, [pos,] value)\ntable の位置 pos に要素 value を挿入する。 空きスペースが必要なら、他の要素を上にずらす。 pos のデフォルト値は n+1 である。 n はテーブルの長さである (2.5.5 を参照)。 table.insert(t,x) の呼び出しは、テーブル t の最後に x を挿入する。\ntable.maxn (table)\n指定したテーブルの最大の正の数値インデックスを返す。 テーブルが正の数値インデックスを持たなければゼロを返す。 (結果を得るために、この関数はテーブル全体を線形に巡回する。)\ntable.remove (table [, pos])\ntable から位置 pos の要素を取り除き、 必要なら他の要素を下にずらして空白を埋める。 取り除かれた要素の値が返される。 pos のデフォルト値は n である。 n はテーブルの長さである。 table.remove(t) の呼び出しは、テーブル t の最後の要素を取り除く。\ntable.sort (table [, comp])\ntable[1] から table[n] までのテーブル要素を、指定された順序で その場で ソートする。 n はテーブルの長さである。 comp を与える場合、それは関数でなくてはならず、テーブルの要素を2つ受け取り、最初の要素が二番目よりも小さいときに真を返さなければならない (ソート後、not comp(a[i+1],a[i]) が真になる)。 comp が与えられなければ、標準のLuaの演算子 &lt; が代わりに使われる。ソートのアルゴリズムは安定でない。 つまり、指定された順序において等しいと考えられる要素は、ソートによってその相対位置が変わるかもしれない。\n5.6 - 数学関数\nこのライブラリは標準C数学ライブラリへのインタフェイスである。 math テーブルの中にすべての関数が提供される。 このライブラリは以下の関数を提供する:\n   math.abs     math.acos    math.asin    math.atan    math.atan2\n   math.ceil    math.cos     math.cosh    math.deg     math.exp\n   math.floor   math.fmod    math.frexp   math.ldexp   math.log\n   math.log10   math.max     math.min     math.modf    math.pow\n   math.rad     math.random  math.randomseed           math.sin\n   math.sinh    math.sqrt    math.tan     math.tanh\n\n加えて、変数 math.pi と、値 HUGE_VAL を持つ変数 math.huge も提供される。 これらのほとんどは、Cライブラリの対応する関数への単なるインタフェイスである。 すべての三角関数はラジアンを使う。 関数 math.deg と math.rad はラジアンと度を変換する。関数 math.max は引数の中の最大値を返す。 同様に math.min は最小値を求める。 共に1つ、2つ、あるいはもっとたくさんの引数を渡すことができる。\n関数 math.modf はCの関数 modf に対応する。 これは2つの値、引数の整数部と小数部を返す。 関数 math.frexp も2つの値、 引数の正規化した小数部と指数部を返す。\n関数 math.random と math.randomseed は ANSI C で提供される単純なランダム生成関数 rand と srand へのインタフェイスである (統計的な性質は保証されない)。 引数無しで呼ばれると、math.random は [0,1) の範囲の実数の疑似乱数を返す。 数値 n を渡すと、math.random は [1,n] の範囲の整数の疑似乱数を返す。 2つの引数 l と u を渡して呼んだときは、 math.random は [l,u] の範囲の整数の疑似乱数を返す。 math.randomseed 関数は疑似乱数発生器の「シード値」を設定する。 同じシード値からは同じ数列が生成される。\n5.7 - 入出力機能\nI/Oライブラリは2つの異なったスタイルのファイル操作を提供する。 ひとつめは暗黙のファイルディスクリプタを使うもので、 それらはデフォルト入力ファイルとデフォルト出力ファイルに対して作用し、 すべての入出力操作はデフォルトファイルを通して行われる。 ふたつめのスタイルでは明示的なファイルディスクリプタを用いる。\n暗黙のファイルディスクリプタを使う場合は、すべての操作はテーブル io で提供される。 明示的なファイルディスクリプタを使う場合は、 すべての操作は io.open が返すファイルディスクリプタのメソッドとして提供される。\nテーブル io は、 Cで使われる意味と同じの3つの定義済みファイルディスクリプタ io.stdin、io.stdout、io.stderr も提供する。\n例外なく、すべてのI/O関数は失敗時に nil (および二番目の戻り値としてエラーメッセージ) を返し、 成功時は nil 以外の何らかの値を返す。\nio.close ([file])\nfile:close() と等価である。 file が省略されると、デフォルト出力ファイルを閉じる。\nio.flush ()\nデフォルト出力ファイルに対する file:flush と等価である。\nio.input ([file])\nファイル名を与えて呼ぶと、その名前のファイルを (テキストモードで) 開き、 そのハンドルをデフォルト入力ファイルに設定する。 ファイルハンドルを与えて呼ぶと、単純にそのファイルハンドルがデフォルト入力ファイルに設定される。 引数無しで呼ぶと、現在のデフォルト入力ファイルを返す。\nエラーが起きた場合、この関数はエラーコードを返す変わりにエラーを発する。\nio.lines ([filename])\n指定されたファイル名を読み込みモードで開き、 呼ばれるたびにファイルから1行ずつ返すイテレータ関数を返す。 つまり、\n   for line in io.lines(filename) do ... end\n\nはファイルのすべての行について繰り返す。 イテレータ関数は、ファイルの終わりを検出すると nil を返し (ループを終えるため)、自動的にファイルを閉じる。io.lines() (ファイル名を渡さない) は io.input():lines() と等価である。 すなわち、デフォルト入力ファイルの各行について繰り返す。 この場合は、ループが終わってもファイルを閉じない。\nio.open (filename [, mode])\nこの関数は mode で指定されたモードでファイルを開く。 新しいファイルハンドルを返すか、エラーの場合は nil とエラーメッセージを返す。\nmode 文字列は以下のいずれかである。\n“r” — 読み込みモード (デフォルト)“w” — 書き込みモード“a” — 追記モード“r+” — 更新モード (以前のデータは消えない)“w+” — 更新モード (以前のデータはすべて消える)“a+” — 追記更新モード (以前のデータは消えない) ファイルの最後のだけ書き込みが許される。mode 文字列は最後に `b´ も付けることができ、 システムによってはバイナリモードでファイルを開くために必要である。 この文字列は標準Cの関数 fopen で使われるのと同じである。\nio.output ([file])\nio.input と同じであるが、デフォルト出力ファイルに対する操作である。\nio.popen ([prog [, mode]])\n分離されたプロセスの中でプログラム prog を開始し、 このプログラムからのデータを読み込む (デフォルトの、mode が “r” の場合) ためか、このプログラムにデータを書き込む (mode が “w” の場合) ためのファイルハンドルを返す。\nこの関数はシステム依存であり、すべてのプラットフォームで利用可能なわけではない。\nio.read (format1, …)\nio.input():read と等価である。\nio.tmpfile ()\nテンポラリファイルのハンドルを返す。 このファイルは更新モードでオープンされ、プログラムの終了時に自動的に削除される。\nio.type (obj)\nobj が有効なファイルハンドルかどうかチェックする。 obj がオープンされているファイルハンドルなら、文字列 “file” を返す。 obj がクローズされたファイルハンドルなら、文字列 “closed file” を返す。 obj がファイルハンドルでなければ nil を返す。\nio.write (value1, …)\nio.output():write と等価である。\nfile:close ()\nfile を閉じる。 ファイルハンドルがガベージコレクトされたときはそのファイルは自動的に閉じられるが、 それがいつ起きるかは予測不能であることに注意せよ。\nfile:flush ()\nfile に書き込まれたデータを保存する。\nfile:lines ()\n呼ばれるたびにファイルから新しい行を返すイテレータ関数を返す。 つまり、\n   for line in file:lines() do ... end\n\nはファイルのすべての行に対して繰り返す (io.lines と異なり、この関数はループの終わりでファイルを閉じない)。\nfile:read (format1, …)\n何を読むかを指定する書式に従って、ファイル file から読み込む。 各書式について、読み込んだ文字を文字列 (または数値) として返し、 指定された書式でデータを読めなければ nil を返す。 書式を指定せずに呼ばれた場合は、次の行全体を読むデフォルトの書式が使われる (以下を参照)。\n利用可能なフォーマットは次の通り。\n“*n” は数値を読み込む。 これは文字列の変わりに数値を読み込む唯一の書式である。“*a” は現在の位置から、残りのファイル全体を読み込む。 ファイルの終わりでは、空文字列を返す。“*l” は次の行を読み込む (行末文字は飛ばす)。 ファイルの終わりでは nil を返す。これはデフォルトの書式である。数値 はその文字数からなる文字列を読み込む。 ファイルの終わりでは空文字列を返す。 数値がゼロの場合は、何も読み込まず、空文字列を返す。 ファイルの終わりでは nil を返す。\nfile:seek ([whence] [, offset])\nファイルの先頭から計ったファイル位置を設定/取得する。 位置は文字列 whence で指定された基準位置に offset を加えた値で示す。 whence は以下のいずれかである。\n“set” — 基準位置は0 (ファイルの先頭)“cur” — 基準位置は現在の位置“end” — 基準位置はファイルの終わり成功すると、関数 seek はファイル先頭からのバイト数で最終的なファイル位置を返す。 この関数が失敗すると nil とエラー文字列を返す。whence のデフォルト値は “cur” で、 offset は0である。 つまり、file:seek() の呼び出しは、何も変化させずに、現在の位置を返す。 file:seek(“set”) はファイルの先頭に位置を変更する (そして0を返す)。 file:seek(“end”) はファイルの終わりに位置を変更し、ファイルの長さを返す。\nfile:setvbuf (mode [, size])\n出力ファイルのバッファリングモードを設定する。 設定可能なモードは3つある。\n“no” — バッファリングなし。出力操作の結果はすべて即座に現れる。“full” — 完全バッファリング。出力操作はバッファが満杯の場合 (または明示的にそのファイルを flush した場合 (5.7 を参照)) だけ行われる。“line” — 行バッファリング。出力は改行を出力するか、いくつかのスペシャルファイル (端末デバイスとか) から入力するまでバッファされる。下の2つの場合では、 sizes でバッファのサイズをバイト単位で指定できる。 デフォルトのサイズは適当である。\nfile:write (value1, …)\n引数のそれぞれの値を file に書き込む。 引数は文字列か数字でなければならない。 それ以外の値を書き込むには、 write の前に tostring か string.format を使う。\n5.8 - OS機能\nこのライブラリはテーブル os を通して提供される。\nos.clock ()\nプログラムが使ったCPU時間の概算値を秒で返す。\nos.date ([format [, time]])\n与えられた文字列 format に従って書式化した日付と時刻を含む文字列、またはテーブルを返す。\ntime 引数が存在すれば、それが書式化される時刻となる (この値の説明は os.time 関数を参照)。 そうでなければ、date は現在時刻を書式化する。\nformat が `!´ で始まっていたら、 日付は世界時 (Universal Time) で書式化される。 このオプション文字の後、 format が *t であれば、 date は以下のフィールドを持つテーブルを返す。\nyear (4桁の数値)month (1–12)day (1–31)hour (0–23)min (0–59)sec (0–61)wday (曜日、日曜日が1)yday (1月1日から数えた日数)isdst (夏時間を示すフラグ、ブーリアン)format が *t でなければ、 date は日付を文字列として返す。 Cの関数 strftime と同じルールに従って書式化される。\n引数なしで呼ばれた場合、 date はホストシステムと現在のロケールに依存する一般的な日付と時刻の表現を返す。 (つまり、os.date() は os.date(“%c”) と等価である)。\nos.difftime (t2, t1)\n時刻 t1 から時刻 t2 までの秒数を返す。 POSIX や Windows、その他のいくつかのシステムでは、 この値は t2-t1 に等しい。\nos.execute ([command])\nこの関数はCの関数 system と等価である。 command はOSのシェルによって実行されるコマンドを渡す。 システムに依存するステータスコードを返す。 command を省略すると、シェルが利用可能ならゼロ以外を返し、そうでなければゼロを返す。\nos.exit ([code])\n省略可能な code でCの関数 exit を呼んでホストプログラムを終了させる。 code のデフォルト値は成功を表すコードである。\nos.getenv (varname)\nプロセスの環境変数 varname の値を返す。 変数が未定義なら nil を返す。\nos.remove (filename)\n指定された名前のファイルまたはディレクトリを消す。 消すディレクトリは空でなければならない。 この関数が失敗した場合は nil とエラーメッセージを返す。\nos.rename (oldname, newname)\noldname という名前のファイルまたはディレクトリを newname にリネームする。 この関数が失敗した場合は nil とエラーメッセージを返す。\nos.setlocale (locale [, category])\nプログラムの現在のロケールを設定する。 locale はロケールを表す文字列である。 category は変更したいカテゴリを表す省略可能な文字列で、以下のいずれかである。 “all”, “collate”, “ctype”, “monetary”, “numeric”, or “time”。 デフォルトのカテゴリは “all” である。 この関数は新しいロケールの名前を返す。 あるいは要求が受け付けられなければ nil を返す。\nos.time ([table])\n引数無しで呼ばれたときは現在の時刻を返し、 引数がある場合は、与えられたテーブルで指定された日付と時刻を表す時刻を返す。 このテーブルはフィールド year, month, and day を持たなければならず、 省略可能だがフィールド hour, min, sec, and isdst があっても良い (これらのフィールドの説明は os.date 関数を参照).\n戻り値は数値であり、その意味はシステムに依存する。 POSIX や Windows、およびいくつかのシステムでは、 特定の開始時刻 (「エポック」)からの経過時間を秒で表している。 それ以外のシステムでは、その意味は不明であり、 time の戻り値は date と difftime の引数としてのみ使うことができる。\nos.tmpname ()\nテンポラリファイルとして使えるファイル名を返す。 このファイルは使う前に明示的にオープンする必要があり、 要らなくなったら明示的に削さなければならない。\n5.9 - デバッグライブラリ\nこのライブラリはLuaプログラムへのデバッグインタフェイスの機能を提供する。 このライブラリを使うときは注意すべきである。 ここで提供される関数はデバッグやそれに似たプロファイリングのようなタスクにのみ使うべきである。 普通のプログラミングツールとしてこれらを使う誘惑に抵抗するように。 これらは非常に遅い。 さらに言えば、いくつかの関数はLuaコードについてのいくつかの仮定 (関数のローカル変数は他の関数からアクセスできないとか、ユーザーデータのメタテーブルはLuaから変更できないとか) を侵害し、安全なコードを危うくする恐れがある。\nこのライブラリのすべての関数は debug テーブル内に提供される。\ndebug.debug ()\nユーザーとの対話モードに入り、ユーザーが入力した文字列を実行する。 単純なコマンドや他のデバッグ機能を使って、 ユーザーはグローバル変数やローカル変数を調べたり値を変更したり式を評価したりその他ができる。 ユーザーが cont だけの行を入力すると対話モードを終えて実行を継続する。\ndebug.debug で実行されるコマンドは、 どの関数のレキシカルスコープにも入っていないので、 ローカル変数へは直接アクセスできないことに注意。\ndebug.getfenv (o)\nオブジェクト o の環境を返す。\ndebug.gethook ()\n現在のフック関数、フックマスク、フックカウント (debug.sethook 関数で設定されたもの) を返す。\ndebug.getinfo (function [, what])\n関数に関する情報をテーブルに入れて返す。 関数を直接指定するか数値を指定することができる。 数値は、関数が走っているコールスタックのレベルを意味し、 レベル0は現在の関数 (getinfo 自身)、 レベル1は getinfo を呼び出した関数で、以下同様。 function がアクティブな関数の数よりも大きい数値であれば getinfo は nil を返す。\nwhat はどのフィールドを埋めるかを記述する文字列で、 戻り値のテーブルには lua_getinfo から返されるフィールドがすべて含まれている。 what のデフォルト値では有効なすべての情報を取得する。 もし存在すれば、`f´ オプションは func という名前のフィールドにその関数自身を入れる。\n例えば、式 debug.getinfo(1,”n”).name は現在の関数の名前を返す (もし適当な名前があれば)。 debug.getinfo(print) は print 関数に関するすべての利用可能な情報を持つテーブルを返す。\ndebug.getlocal (level, local)\nスタックレベル level の関数の、インデックス local のローカル変数の、名前と値を返す。 最初の引数かローカル変数がインデックス1で、以下同様に最後の有効なローカル変数まで続く。 もし指定されたインデックスのローカル変数がなければ nil を返し、 level が範囲外であればエラーを発する (debug.getinfo を使ってレベルが有効かどうかチェックできる)。\n`(´ (開き括弧) で始まる変数名は内部的な変数 (ループ制御変数、一時変数、Cの関数のローカルなど) を表している。\ndebug.getmetatable (object)\n指定した object のメタテーブルを返す。 メタテーブルを持っていなければ nil を返す。\ndebug.getregistry ()\nレジストリテーブル (3.5 を参照) を返す。\ndebug.getupvalue (func, up)\n関数 func の、インデックス up の上位値の、名前と値を返す。 指定されたインデックスの上位値が存在しなければ nil を返す。\ndebug.setfenv (object, table)\n指定した object の環境を指定した table にする。\ndebug.sethook (hook, mask [, count])\n指定された関数をフックに設定する。 文字列 mask と数値 count は、いつフックが呼ばれるかを記述する。 文字列maskは以下の文字からなる。\n“c” — フックはLuaが関数を呼ぶたびに呼ばれる。“r” — フックはLuaが関数から戻るたびに呼ばれる。“l” — フックはLuaがコードの新しい行に入るたびに呼ばれる。count がゼロでなければ、フックは count 命令が実行されるたびに、その直後に呼ばれる。引数なしで呼ぶとフックは無効になる。\nフックが呼ばれたとき、最初の引数はフックを起動したイベントを示す以下のいずれかの文字列である。 “call”, “return” “tail return”, “line”, “count”。 lineイベントの場合、フックは二番目の引数に新しい行番号が得られる。 “tail return” を除いて、 フックの内部でレベル2の getinfo を呼べば、実行中の関数に関する情報をもっと得られる (レベル0は getinfo 関数自身で、レベル1はフック関数である)。 “tail return” はLuaが復帰をシミュレートしているだけであり、 getinfo は正しくないデータを返すだろう。\ndebug.setlocal (level, local, value)\nスタックレベル level の関数の、インデックス local のローカル変数に、値 value を格納する。 指定されたインデックスのローカル変数が存在しなければ nil を返し、 level が範囲外であればエラーを発する (getinfo を使ってレベルが有効かどうかチェックできる)。 そうでなければ、ローカル変数の名前を返す。\ndebug.setmetatable (object, table)\n指定した object のメタテーブルを指定した table (nil でも良い) にする。\ndebug.setupvalue (func, up, value)\n関数 func の、インデックス up の上位値に、値 value を格納する。 指定されたインデックスの上位値が存在しなければ nil を返す。 そうでなければ、上位値の名前を返す。\ndebug.traceback ([message])\nコールスタックのトレースバックを出力した文字列を返す。 省略可能な message 文字列は、トレースバックの最初に付け加えられる。 この関数は典型的には、より良いエラーメッセージを生成するために xpcall と一緒に使われる。\n6 - スタンドアロンのLua\nLuaはCのホストプログラムに組み込まれる拡張言語としてデザインされたにも関わらず、 スタンドアロンの言語としてもよく使われる。 スタンドアロンの言語としてのLuaインタプリタは、単純に lua と呼ばれ、 標準のディストリビューションと共に提供されている。 スタンドアロンのインタプリタは、 デバッグライブラリを含むすべての標準ライブラリを持っている。 使い方は以下の通り。\n  lua [options] [script [args]]\n\nオプションは以下の通り。\n\nファイルの代わりに stdin から実行する。\ne stat 文字列 stat を実行する。\nl mod mod を “requires” する。\ni script を実行した後、対話モードに入る。\nv バージョン情報を出力する。\n\nオプションの処理を止める。\n\n\nオプションの処理を止め、stdin をファイルとして実行する。これらのオプションが処理されたあと、lua は指定された script に args を文字列として渡して実行する。 引数なしで呼ばれた場合、 stdin (標準入力) が端末であれば lua -v -i、 そうでなければ lua - として振る舞う。どの引数も適用される前に、 インタプリタは環境変数 LUA_INIT を調べる。 その書式が @filename であれば、そのファイルを実行する。 そうでなければ、その文字列自身を実行する。\n\n-i 以外のすべてのオプションは順番に処理される。 例えば、以下のようなコマンドは\n   $ lua -e&#39;a=1&#39; -e &#39;print(a)&#39; script.lua\n\nまず a に1を代入し、それから a の値 (つまり `1´) を表示し、最後にファイル script.lua を実行する (ここで、$ はシェルプロンプトである。キミのシェルプロンプトは違うかもしれない)。スクリプトを実行する前に、lua はコマンドライン引数を arg という名前のグローバルなテーブルに格納する。 スクリプト名がインデックス0に格納され、 最初のｈきすうがスクリプト名の後のインデックス1に格納され、以下同様である。 スクリプト名の前のすべての引数 (つまり、インタプリタの名前やオプション) は負のインデックスに割り当てられる。 つまり、次のような場合\n   $ lua -la b.lua t1 t2\n\nインタプリタはまずファイル a.lua を実行し、 次に以下のようなテーブルを作る。       arg = { [-2] = “lua”, [-1] = “-la”,               [0] = “b.lua”,               [1] = “t1”, [2] = “t2” }そして最後にファイル b.lua を実行する。 スクリプトは引数として arg[1], arg[2], … が渡されて呼ばれる。 可変引数式 `…´ を使って引数にアクセスすることもできる。対話モードでは、不完全な文を書いたときは、それが完全な文になるまで待つ。\nグローバル変数 _PROMPT が文字列を持っていれば、 その値がプロンプトに使われる。 同様に、グローバル変数 _PROMPT2 が文字列を持っていれば、 その値が第二プロンプトに使われる (不完全な文である間使われる)。 つまり、プロンプトはコマンドラインから直に変更できる。\n   $ lua -e&quot;_PROMPT=&#39;myprompt&gt; &#39;&quot; -i\n\n(外側のクォート対はシェルのための、内側はLuaのためのもの。) また、_PROMPT に代入することで、Luaのプログラムからも変更できる。 対話モードに入るには -i が要ることに注意。 そうでなければ、プログラムは _PROMPT に代入した直後に何も出力せず終わるであろう。UnixシステムでスクリプトインタプリタとしてLuaを使えるようにするために、 スタンドアロンインタプリタはチャンクが # で始まっていれば最初の行をスキップする。 従って、chmod +x と #! 形式を使って、 Luaスクリプトを実行可能なプログラムにすることができる。\n#!/usr/local/bin/lua(もちろん、キミのマシンではLuaインタプリタは違う場所にあるかもしれない。 もし PATH の通るところに lua があれば、#!/usr/bin/env luaがより移植性の高い解決法である)。\n前バージョンとの非互換\nプログラムをLua5.0からLua5.1に移行する際に見つかるかもしれない非互換の一覧を示す。 ほとんどの非互換は適切なオプションを使ってコンパイルすることで避けられる (ファイル luaconf.h を参照)。 しかしながら、これらの互換用オプションはすべて次のバージョンのLuaでは削除される予定である。\nバージョン5.0との非互換\n言語の変更\n可変引数システムは、余分の引数を持つテーブルの疑似引数 arg から 可変引数式に変更された。 (luaconf.h のオプション LUA_COMPAT_VARARG)for 文と repeat 文の暗黙の変数のスコープが微妙に変更された。長い文字列と長いコメントの構文 ([[…]]) はネストできなくなった。 この場合、新しい構文 ([=[…]=]) を使うことができる。 (luaconf.h のオプション LUA_COMPAT_LSTR)ライブラリの変更\n関数 string.gfind は string.gmatch に名前が変更された。 (オプション LUA_COMPAT_GFIND)string.gsub の3番目の引数に関数を渡した場合、 この関数が nil または false を返すと、 空文字列でなくマッチした文字列全体に置換するようになった。関数 table.setn は廃止された。 関数 table.getn は新しい長さ演算子 (#) が対応する。 関数の代わりに演算子を使う。 (オプション LUA_COMPAT_GETN)関数 loadlib は package.loadlib に名前が変更された。 (オプション LUA_COMPAT_LOADLIB)関数 math.mod は math.fmod に名前が変更された。 (オプション LUA_COMPAT_MOD)関数 table.foreach および table.foreachi は廃止された。 ループには代わりに pairs または ipairs を使う。新しいモジュールシステムを導入したため、 関数 require に大幅な変更が行われた。 しかしながら、新しい動作は以前とほぼ互換性がある。 ただし require は LUA_PATH の代わりに package.path からパスを取得する。関数 collectgarbage の引数が変更された。 関数 gcinfo は廃止された。 代わりに collectgarbage(“count”) を使う。APIの変更\nライブラリを開く luaopen_* 関数は通常のCの関数のようには直接は呼べなくなった。 これらはLuaの関数のようにLuaを通して呼ばなければならない。関数 lua_open は、ユーザ独自のメモリ確保関数を指定できる lua_newstate に置き換えられた。 標準のメモリ確保関数 (realloc をベースとする) を使ってステートを作るには、 標準ライブラリの luaL_newstate を使う。関数 luaL_getn および luaL_setn (補助ライブラリにあった) は廃止された。 luaL_getn の代わりに lua_objlen を使う。 luaL_setn の代わりは存在しない。関数 luaL_openlib は luaL_register に置き換えられた。Luaの完全な構文\nLuaの完全な構文を拡張BNF記法で示す。 これは演算子の優先順位や、 return および break 文がブロックの 最後の 文としてしか使えないといった いくつかの構文的制限は記述していない。\nchunk ::= &#123;stat [`;´]&#125; [laststat[`;´]]\n\nblock ::= chunk\n\nstat ::=  varlist1 `=´ explist1  | \n     functioncall  | \n     do block end  | \n     while exp do block end  | \n     repeat block until exp  | \n     if exp then block &#123;elseif exp then block&#125; [else block] end  | \n     for Name `=´ exp `,´ exp [`,´ exp] do block end  | \n     for namelist in explist1 do block end  | \n     function funcname funcbody  | \n     local function Name funcbody  | \n     local namelist [`=´ explist1] \n\nlaststat ::= return [explist1]  |  break\n\nfuncname ::= Name &#123;`.´ Name&#125; [`:´ Name]\n\nvarlist1 ::= var &#123;`,´ var&#125;\n\nvar ::=  Name  |  prefixexp `[´ exp `]´  |  prefixexp `.´ Name \n\nnamelist ::= Name &#123;`,´ Name&#125;\n\nexplist1 ::= &#123;exp `,´&#125; exp\n\nexp ::=  nil  |  false  |  true  |  Number  |  String  |  `...´  | \n     function  |  prefixexp  |  tableconstructor  |  exp binop exp  |  unop exp \n\nprefixexp ::= var  |  functioncall  |  `(´ exp `)´\n\nfunctioncall ::=  prefixexp args  |  prefixexp `:´ Name args \n\nargs ::=  `(´ [explist1] `)´  |  tableconstructor  |  String \n\nfunction ::= function funcbody\n\nfuncbody ::= `(´ [parlist1] `)´ block end\n\nparlist1 ::= namelist [`,´ `...´]  |  `...´\n\ntableconstructor ::= `&#123;´ [fieldlist] `&#125;´\n\nfieldlist ::= field &#123;fieldsep field&#125; [fieldsep]\n\nfield ::= `[´ exp `]´ `=´ exp  |  Name `=´ exp  |  exp\n\nfieldsep ::= `,´  |  `;´\n\nbinop ::= `+´  |  `-´  |  `*´  |  `/´  |  `^´  |  `%´  |  `..´  | \n     `&lt;´  |  `&lt;=´  |  `&gt;´  |  `&gt;=´  |  `==´  |  `~=´  | \n     and  |  or\n\nunop ::= `-´  |  not  |  `#´\n\n\n原文\n","slug":"old_topic/2016-09-17-349","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"193d30d1b1f932871a7703a692d3a8f9","title":"Lapis框架的常用处理方法","content":"作者：糖果\n在Lapis中处理GET、POST、PUT。1234567891011import respond_to from require &quot;lapis.application&quot;class App extends lapis.Application  @enable &quot;etlua&quot;  &quot;/login&quot;: respond_to &#123;    GET: =&gt;      return &quot;login get&quot;    POST: =&gt;      return &quot;login post&quot;    PUT: =&gt;      return &quot;login put&quot;  &#125;\n\nGET、POST、PUT的使用一目了然。\n在另一个路由中，调用GraylogSDK访问自己的/login方法，用PUT方法。12345678910111213141516171819202122232425headers_info = &#123;    &#x27;Authorization&#x27;: auth,     &#x27;Accept&#x27;: &#x27;*/*&#x27;,    &#x27;Content-Type&#x27;:&#x27;application/json&#x27;&#125;class RestyGraylog     @putRequest:(req_url, data) =&gt;        http = require &quot;resty.http&quot;        httpc = http.new()        metadata = &#123;          method:&quot;PUT&quot;,          body: data,          headers: self.headers_info        &#125;        res, err = httpc\\request_uri(req_url, metadata)          if not res          ngx.say(&quot;failed to request: &quot;, err)          return                  ngx.status = res.status          return res.body\n\n在这个版本的Graylog for MoonScript ，没用使用internal proxy的方式，使用的是RESTY-HTTP来完成这个工作，其达到的效果都是一样的。\n本文请不要用于商业目地，非商业转载请署名原作者与原文链接。https://www.moonscript.cn/lapis%E6%A1%86%E6%9E%B6/lapis-put-method/\n","slug":"old_topic/2016-09-17-351","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"35d8b592c5b982bc1f18037d6c818306","title":"Lapis框架的基本库模板","content":"作者：糖果\nMoonScript库模板代码：1234567891011121314local *configs = &#123;&#125;config = (env, fn) -&gt;  print(env, fn)  return 1setmetatable &#123;    :config&#125;, &#123;    __call:(...) =&gt; config ...\n\n\nLua库模板代码：12345678910111213local configs, configconfigs = &#123; &#125;config = function(env, fn)  return 1endreturn setmetatable(&#123;  config = config&#125;, &#123;  __call = function(self, ...)    return config(...)  end&#125;)\n\nMoonScript如何引用库123456789101112config = require &quot;lib&quot;print(type(config))for k,v in pairs(config)    print(k,v)config(&#x27;pa&#x27;, &#x27;pb&#x27;)config:config(&#x27;pa&#x27;, &#x27;pb&#x27;)config.config(&#x27;pa&#x27;, &#x27;pb&#x27;)config\\config(&#x27;pa&#x27;, &#x27;pb&#x27;)\n\nLua如何引用库1234567891011local config = require(&quot;lib&quot;)print(type(config))for k, v in pairs(config) do  print(k, v)endconfig(&#x27;pa&#x27;, &#x27;pb&#x27;)local _ = &#123;  config = config(&#x27;pa&#x27;, &#x27;pb&#x27;)&#125;config.config(&#x27;pa&#x27;, &#x27;pb&#x27;)return config:config(&#x27;pa&#x27;, &#x27;pb&#x27;)\n\n\n返回结果123456tableconfig  function: 0x11204b0pa      pbpa      pbpa      pbtable: 0x10005c0        pa\n\n注意一下“.”、“：”这两种调用的区别，“：”调用时会将自己作为第一个参数传给被调用函数第一个形参。\n上文提到的例子还是把函数作为元素包在table变量返回，而MoonScript本身是支持类的，所以直接用class形式声明的库。\nMoonScript类库模板代码：123class log    @output: =&gt;        print(&quot;log&quot;)\n\nLua类库模板代码：12345678910111213141516171819202122232425local logdo  local _class_0  local _base_0 = &#123;    output = function(self)      return print(&quot;log&quot;)    end  &#125;  _base_0.__index = _base_0  _class_0 = setmetatable(&#123;    __init = function() end,    __base = _base_0,    __name = &quot;log&quot;  &#125;, &#123;    __index = _base_0,    __call = function(cls, ...)      local _self_0 = setmetatable(&#123;&#125;, _base_0)      cls.__init(_self_0, ...)      return _self_0    end  &#125;)  _base_0.__class = _class_0  log = _class_0  return _class_0end\n\n调用库12345log = require &quot;1lib&quot;print(type(log))for k,v in pairs(log)     print(k,v)log\\output()\n\n\n调用结果123456table__name  log__init  function: 0x110a250output  function: 0x110a0a0__base  table: 0x10aa5b0log\n\n有了class关键字后，后发现require返回的变量依然是table，但多了几个变量，__name,__init初始化函数，__base基类表，自定义函数output。\n对于没有继承关系库用table方式封装库直接，需要类依赖的库用class相对方便一些，不过最终一切类都是table转化形式。\n本文请不要用于商业目地，非商业转载请署名原作者与原文链接。https://www.moonscript.cn/lapis%E6%A1%86%E6%9E%B6/lapis-lib/\n","slug":"old_topic/2016-09-17-352","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"bde2d986b961652c5b4dbeefb6342f0a","title":"MoonScript实现选择排序","content":"作者：糖果\nLUA代码：1234567891011121314list = &#123;1,5,3,2,9,3,6&#125;len=#listfor i=1,len   max = list[i]  for j=i+1, len do      if list[j]&gt;max then       tmp=list[j]       list[j]=max      list[i]=tmp      max=tmpfor item in *list  print(item)\n\n\nMoonScript代码12345678910111213141516171819202122232425local list = &#123;   1,    5,    3,    2,    9,    3,    6&#125;local len = #listfor i = 1, len do  local max = list[i]  for j = i + 1, len do    if list[j] &gt; max then      local tmp = list[j]      list[j] = max       list[i] = tmp       max = tmp     end   end endfor _index_0 = 1, #list do  local item = list[_index_0]  print(item)end","slug":"old_topic/2016-09-17-354","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"8df307659316a77ab2a33659c2147085","title":"MoonScript实现Map按值排序","content":"作者：糖果\nMoonScript代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051board = &#123;   [&#x27;0.0.0.1&#x27;]:1,  [&#x27;0.0.0.5&#x27;]:5,  [&#x27;0.0.0.3&#x27;]:3,  [&#x27;0.0.0.2&#x27;]:2,  [&#x27;0.0.0.9&#x27;]:9,  [&#x27;0.0.3.3&#x27;]:3,  [&#x27;0.0.0.6&#x27;]:6&#125;mapsort = (board)-&gt;  b_len = 0   for k,v in pairs(board)    b_len = b_len + 1     a1 = &#123;&#125;  a2 = &#123;&#125;  i = 0   for k,v in pairs(board)    i = i + 1     a1[i] = k     a2[i] = v   for i = 1, b_len     max = a2[i]     for j = i + 1, b_len        if a2[j] &gt; max          tmp = a2[j]         a2[j] = max         a2[i] = tmp         max = tmp         tmp1 = a1[j]         a1[j]  = a1[i]         a1[i] = tmp1  ret = &#123;&#125;  for k,v in ipairs(a1)     ret[k] = &#123;a1[k], a2[k]&#125;  return retprint(&quot;########&quot;)ret = mapsort boardfor k,v in ipairs(ret)   print(ret[k][1], ret[k][2])\n\nLUA代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354local board = &#123;   [&#x27;0.0.0.1&#x27;] = 1,  [&#x27;0.0.0.5&#x27;] = 5,  [&#x27;0.0.0.3&#x27;] = 3,  [&#x27;0.0.0.2&#x27;] = 2,  [&#x27;0.0.0.9&#x27;] = 9,  [&#x27;0.0.0.3&#x27;] = 3,  [&#x27;0.0.0.6&#x27;] = 6 &#125;local mapsortmapsort = function(board)  local b_len = 0   for k, v in pairs(board) do    b_len = b_len + 1   end   local a1 = &#123; &#125;   local a2 = &#123; &#125;   local i = 0   for k, v in pairs(board) do    i = i + 1     a1[i] = k     a2[i] = v   end   for i = 1, b_len do    local max = a2[i]    for j = i + 1, b_len do      if a2[j] &gt; max then        local tmp = a2[j]        a2[j] = max         a2[i] = tmp        max = tmp        local tmp1 = a1[j]        a1[j] = a1[i]        a1[i] = tmp1      end    end  end  local ret = &#123; &#125;  for k, v in ipairs(a1) do    ret[k] = &#123;      a1[k],      a2[k]    &#125;  end  return retendprint(&quot;########&quot;)local ret = mapsort(board)for k, v in ipairs(ret) do  print(ret[k][1], ret[k][2])end","slug":"old_topic/2016-09-17-353","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"a345db901c4262d0d7e3998d536c82d4","title":"关于Lua的LazyTable的实现","content":"作者：糖果\nLazyTable源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465local ngx_req = &#123;      headers = function()          return &quot;testcase&quot;      end,      method = function()          return &quot;GET&quot;      end,&#125;local lazy_tbllazy_tbl = function(tbl, index)  return setmetatable(tbl, &#123;    __index = function(self, key)      for k,v in pairs(index) do          print(k, v)      end      --print(key)      for k,v in pairs(self) do          print(k, v)      end      local fn = index[key]      if fn then        do          --此处fn(self)和fn()，传入self形参与否的效果是一样，table中的匿名函数          --定义是没有参数的，这个形参是moonscript翻译后加上去的。          local res = fn(self)          --local res = fn(self)                  local res = fn()          self[key] = res          --实际把return res去掉也不会影响这个程序的运行结果， 在此函数中          --从了这个return语句再也没有return调用了，而设定工作在self[key] = res这句就已经完成。          return res        end      end    end  &#125;)endlocal build_requestbuild_request = function(unlazy)  if unlazy == nil then    unlazy = false    --unlazy = true  end  do    local t = lazy_tbl(&#123; &#125;, ngx_req)    if unlazy then      for k in pairs(ngx_req) do        --这里遍历的ngx_req，但是调用的函数是t的。        local _ = t[k]      end    end    return t  endendreq = build_request(&quot;unlazy&quot;)for k,v in pairs(req) do    print(k, v)end\n\n\n重置setmetatable在一个匿名函数中，return setmetatable,通过对函数形参传入的table的变量的__index属性进行统一修改，而新设定的__index对应函数的形参self和key,分别对应新table的本身，和table对应的key。\n12__index = function(self, key) lazy_tbl(&#123; &#125;, ngx_req)\n self:是ngx_req的引用。 key:是ngx_req的key。\n 如果发现,ngx_req的元素类型是function就执行下，然后，把返回结果（字符串） 替换原value值。\n核心原理 lazy table实现的核心部分是，是在return setmetatable做table复制时，并统一的设定 新table的__index属性， 然后在遍历我们要批量设定的table时，得用table的__index对 应函数中的设置，修改要修改table的成员变量值，把table中，对应key的值是function 的元素，改成key的值等于，这个key对应匿名函数的返回值。 \n 修改table元素的是由setmetatable指定的__index方法来完成。而遍历循环执行table中的 所有匿名函数，由一次外层的循环来完成。\nmoonscript的lua翻译特征 do end 结构是为了让local型的局部变量，在 do end 结构外不可见。\n 1234do    local tmp = 1end print(tmp)\n结果是：nil 1234do    tmp = 1end print(tmp)\n结果是：1 下面的代码有明显的moonscript翻译成lua的特征：\n1234567891011local test test = function()    do          local tmp = &quot;do end&quot;        return tmp     end     return &quot;ret&quot;endret = test()print(ret)\n\n简化后的LazyTable代码123456789101112131415161718192021222324252627282930local ngx = &#123;     url = function()         return &quot;url&quot;    end,    method = function()        return &quot;method&quot;    end,&#125;local lazylazy = function(tbl, index)    return setmetatable (tbl, &#123;        __index = function(self, key)            print(key)        end     &#125;)  endlocal build_requestbuild_request = function(unlazy)        ret = lazy(&#123;&#125;, ngx)        for k in pairs(ngx) do             local _ = ret[k]        endendbuild_request(&quot;&quot;)\n\nlazy的核心是通过lazy函数，重新设置table的__index对应函数，在函数中调用元素值是function类型的函数，用函数返回结果修改当前元素的value值。\n通过LazyTable可把Table表的声明和元素值的动态设定在一个封装调用周期内完成。\n应用场景LazyTable在应用在Lapis的获取nginx变量的一个功能，我们把这个功能移到HiLua演示框架里，看LazyTable如何在实际应用场景应用的。\n1234567891011121314151617181920212223242526272829local ngx_request = &#123;  headers = function()    return ngx.req.get_headers()  end,  cmd_meth = function()    return ngx.var.request_method  end,  cmd_url = function()    return ngx.var.request_uri  end,&#125;local lazy_tbllazy_tbl = function(tbl, index)  return setmetatable(tbl, &#123;    __index = function(self, key)      local fn = index[key]      if fn then        do            local res = fn(self)          self[key] = res           return res         end       end     end   &#125;)  endreturn ngx_request\n\nMoonscript是有OO的类的组织结构，但是用Moonscript写的Lapis框架，有的一些文件并没有按类的形式组织，比如上面这个截取的代码，最后返回的就是一个ngx_request的table，通过引用table中的函数类型元素进行调用，即可返回你想要的数据，这个类似之前lapis ES的写法一个孙数的调用过程，可以整个组织成一个table声明的过程，在其过程中就完成了各种行为的调用，看起来很整洁，调用时序隐含在声明里，而不是传统的若干个函数过程顺序调用的方式。\n在一个数据结构中定义若干函数的调用，要是和路由器比较的话，路由器需要正则匹配判断而这个是顺序执行。\n在HiLua中的调用形式如下：\n12345local req = require &quot;nginx&quot;app:get(&quot;/hilua&quot;, function(request,id)    ngx.say(type(req.cmd_meth))end\n\nnginx中ngx_request取得HTTP请求阶段的各种变量,这个数据结构在HiLua进行路由匹配处理从这个数据结构中，取得相关变量。\n12345local req = require &quot;nginx&quot;function Route:run(router)        local url = req.cmd_url()        local method = req.cmd_meth()end\n\nLazyTable本身是一种设计实现的思路，可以用Moonscript实现，也可以用Lua实现，也可以C/CPP实现。\n","slug":"old_topic/2016-09-17-357","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"49340cb296849c990c24a5280443ee37","title":"LUA遍历所有Table变量元素与cjson.null的意义","content":"作者：糖果\nLapis使用JSON解析的代层库就是CJSON。\n遍历Table变量的所有元素。util.moon\n12345678910111213json_encodable = (obj, seen=&#123;&#125;) -&gt;  switch type obj    when &quot;table&quot;      unless seen[obj]        seen[obj] = true        &#123; k, json_encodable(v) for k,v in pairs(obj) when type(k) == &quot;string&quot; or type(k) == &quot;number&quot; &#125;    when &quot;function&quot;, &quot;userdata&quot;, &quot;thread&quot;      nil    else      objto_json = (obj) -&gt; json.encode json_encodable objfrom_json = (obj) -&gt; json.decode obj\n\n\njson_encodable递归调用检查形参，seen={} 在形参列表里的应用。检查出所有字符中含有的JSON数据，放入Table返回。\nutil.lua\n123456789101112131415161718192021222324252627282930json_encodable = function(obj, seen)  if seen == nil then    seen = &#123; &#125;  end  local _exp_0 = type(obj)  if &quot;table&quot; == _exp_0 then    if not (seen[obj]) then      seen[obj] = true      local _tbl_0 = &#123; &#125;      for k, v in pairs(obj) do        if type(k) == &quot;string&quot; or type(k) == &quot;number&quot; then          _tbl_0[k] = json_encodable(v)        end      end      return _tbl_0    end  elseif &quot;function&quot; == _exp_0 or &quot;userdata&quot; == _exp_0 or &quot;thread&quot; == _exp_0 then    return nil  else    return obj  endendto_json = function(obj)  return json.encode(json_encodable(obj))endfrom_json = function(obj)  return json.decode(obj)end\n\nLua版因为没有像MoonScript支持When语句，被翻译成了很多的if elseif end语句。\nLapis调用的JSON基础就是lua-cjson这个库，这个库同样有一个类似的递归调用就是：serialise_value。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384local function is_array(table)    local max = 0     local count = 0     for k, v in pairs(table) do        if type(k) == &quot;number&quot; then            if k &gt; max then max = k end             count = count + 1         else            return -1        end     end     if max &gt; count * 2 then        return -1    end     return max endlocal serialise_valuelocal function serialise_table(value, indent, depth)    local spacing, spacing2, indent2    if indent then        spacing = &quot;\\n&quot; .. indent        spacing2 = spacing .. &quot;  &quot;        indent2 = indent .. &quot;  &quot;    else        spacing, spacing2, indent2 = &quot; &quot;, &quot; &quot;, false    end     depth = depth + 1     if depth &gt; 50 then        return &quot;Cannot serialise any further: too many nested tables&quot;    end    local max = is_array(value)    local comma = false    local fragment = &#123; &quot;&#123;&quot; .. spacing2 &#125;    if max &gt; 0 then        -- Serialise array        for i = 1, max do            if comma then                table.insert(fragment, &quot;,&quot; .. spacing2)            end            table.insert(fragment, serialise_value(value[i], indent2, depth))            comma = true        end    elseif max &lt; 0 then        -- Serialise table        for k, v in pairs(value) do            if comma then                table.insert(fragment, &quot;,&quot; .. spacing2)            end            table.insert(fragment,                (&quot;[%s] = %s&quot;):format(serialise_value(k, indent2, depth),                                     serialise_value(v, indent2, depth)))            comma = true        end    end    table.insert(fragment, spacing .. &quot;&#125;&quot;)    return table.concat(fragment)endfunction serialise_value(value, indent, depth)    if indent == nil then indent = &quot;&quot; end    if depth == nil then depth = 0 end    if value == json.null then        return &quot;json.null&quot;    elseif type(value) == &quot;string&quot; then        return (&quot;%q&quot;):format(value)    elseif type(value) == &quot;nil&quot; or type(value) == &quot;number&quot; or           type(value) == &quot;boolean&quot; then        return tostring(value)    elseif type(value) == &quot;table&quot; then        return serialise_table(value, indent, depth)    else        return &quot;\\&quot;&lt;&quot; .. type(value) .. &quot;&gt;\\&quot;&quot;    endend\n\n调用序列化，如果table变量里的value还是table就递归的调用serialise_value函数自己。\n12345678910meta_info = &#123;     key = &quot;test key:&quot;,    values = &#123;         k = &quot;key&quot;,        v = &quot;value&quot;    &#125;,      testcase = &quot;null&quot;&#125;print(serialise_value(meta_info))\n\n以上函数是直接从CJSON中提取出来的，可以遍历任意的table，相关于pprint这种功能。\n打印结果如下：\n12345678&#123;  [&quot;testcase&quot;] = json.null,  [&quot;key&quot;] = &quot;test key:&quot;,  [&quot;values&quot;] = &#123;    [&quot;k&quot;] = &quot;key&quot;,    [&quot;v&quot;] = &quot;value&quot;  &#125;&#125;\n\n\n\ncjson.null与nil、NULL是否等价。下面是@hambut老师的测试代码：\n1234567local cjson = require &quot;cjson&quot;local s = [[&#123;&quot;key&quot;:null,&quot;key1&quot;:&quot;value&quot;&#125;]]local sd = cjson.decode(s)sd.key2 = &quot;value2&quot;ngx.say(cjson.encode(sd))\n\n\n打印结果如下：\n1&#123;&quot;key1&quot;:&quot;value&quot;,&quot;key&quot;:null,&quot;key2&quot;:&quot;value2&quot;&#125;\n\n\n再做一个实验， 我们直接写一个so库，同句函数cjson_new，只返回一个table结构数据。\n12345678910111213141516extern int cjson_new(lua_State* L); static luaL_Reg libtangguo[] = &#123;     &#123;&quot;cjson_new&quot;, cjson_new&#125;,    &#123;NULL, NULL&#125;&#125;;int cjson_new(lua_State* L) &#123;    lua_newtable(L);    /* Set cjson.null */    lua_pushlightuserdata(L, NULL);    lua_setfield(L, -2, &quot;null&quot;);    return 1;&#125;\n\n\ncjson.null 就是.so库返回的一个table变量，中的一个key名为 “null”, value是userdata(nil)的userdata类型的table元素，lightuserdata不归GC管理，就是一个的指针，一般就用于和其它的lightsuerdata比较， 而这个其它的lightuserdata变量，一般也都是C产生的，是产生lightuserdata之间比，不是C的lightuserdata和lua的lightuserdata比法。\nlightuserdata和userdata也不一样， lightuserdata是指针，userdata是buffer。\n12345678910111213141516171819202122232425local cjson_new = package.loadlib(&quot;libtangguo.so&quot;, &quot;cjson_new&quot;)local cjson = cjson_new()for k,v in pairs(cjson) do    print(k, v, type(v))endprint(cjson.null)tmp = cjson.nullprint(tmp, type(tmp))if cjson.null == nil then    print(&quot;OK&quot;)endif cjson.null == &quot;null&quot; then    print(&quot;OK&quot;)endif cjson.null == tmp then    print(&quot;OK&quot;)end\n\ncjson.null不是nil, 更不是”null”。数据在内存空间的存储形式是不一样的，但表示的现实意义是一样的，表示“啥也没有”。\n为了进一步说明是这样的，我们直接看一下pushlightusredata的C源码：\nlapi.c\n1234567891011121314151617181920/*** Union of all Lua values*/typedef union Value &#123;  GCObject *gc;    /* collectable objects */  void *p;         /* light userdata */  int b;           /* booleans */  lua_CFunction f; /* light C functions */  lua_Integer i;   /* integer numbers */  lua_Number n;    /* float numbers */&#125; Value;LUA_API void lua_pushlightuserdata (lua_State *L, void *p) &#123;  lua_lock(L);  setpvalue(L-&gt;top, p);  api_incr_top(L);  lua_unlock(L);&#125;\n\ncjson.so\n123lua_newtable(L);lua_pushlightuserdata(L, NULL);lua_setfield(L, -2, &quot;null&quot;);\n\n这样在实际调用时，  setpvalue(L-&gt;top, p);相当于 void *p = NULL，最后是被封装到table变量里返回的。\n","slug":"old_topic/2016-09-17-359","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f1a8029c8728847e5961c7e694008279","title":"MoonScript如何使用RESTY-HTTP","content":"作者：糖果\n在OpenResty中发起HTTP请求，一般情况下，有两种方式：1.通过内部Proxy。2.使用RESTY-HTTP库发起访问。\nLapis使用的是interal proxy,之前文章有提到，下面提到的是RESTY-HTTP的MoonScript调用实现。\nRESTY-HTTP安装实际RESTY-HTTP的主要实现就是两个lua文件， http_headers.lua和http.lua这两个文件。将文件复制到/usr/local/openresty/lualib/resty下即可使用，再引用http.lua时注意一下的是Lapis也有一个同名文件，需要注意一下冲突。\nMoonScript代码：1234567http = require &quot;resty.http&quot;httpc = http.new()res, err = httpc\\request_uri(&quot;http://www.baidu.com&quot;)if res.status == ngx.HTTP_OK   return res.bodyelse   return &quot;nil&quot;   \n\nLUA代码：123456789101112131415161718    [&quot;/testcase&quot;] = function(self)      local restyhttp = require(&quot;resty.http&quot;)      local httpc = restyhttp.new()      local res, err = httpc:request_uri(&quot;http://www.baidu.com&quot;)      if res.status == ngx.HTTP_OK then        return res.body      else        return &quot;nil&quot;      end    end```      MoonScript和LUA代码几乎没太大区别，因为request_uri请求中使用的是域名，所以需要修改conf文件。## nginx.conf配置\nlocation / &#123;\n        resolver 8.8.8.8;\n&#125;            \n\n12345678RESTY-HTTP与CJSON不同，并没有涉及到任何so库的生成，http_headers.lua和http.lua这两个文件也是在Makefile来实现的，使用的是install命令-d参数，相当于在cp过程中，如果目标位置没有相应的文件夹就创建一个文件夹。## Makefile\nOPENRESTY_PREFIX=/usr/local/openresty\nPREFIX ?=          /usr/localLUA_INCLUDE_DIR ?= $(PREFIX)/includeLUA_LIB_DIR ?=     $(PREFIX)/lib/lua/$(LUA_VERSION)INSTALL ?= installTEST_FILE ?= t\n.PHONY: all test install\nall: ;\ninstall: all        $(INSTALL) -d $(DESTDIR)/$(LUA_LIB_DIR)/resty        $(INSTALL) lib/resty/*.lua $(DESTDIR)/$(LUA_LIB_DIR)/resty/\n```\n","slug":"old_topic/2016-09-17-356","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"6621c44acdf5f08884e1627cc08cfbf8","title":"Django Guide","content":"给Django做一个索引。\nFormhttp://www.djangobook.com/en/2.0/chapter07.html\n打字少，功能实现快。\n开发备忘录\n1.创建空工程django-admin.py startproject djproject\n2.创建空应用python manage.py startapp jobs\n3.查看数据库表结构python manage.py sql jobs\n4.运行服务python manage.py runserver\n5.同步数据库变更python manage.py schemamigration youappname –initialpython manage.py syncdbpython manage.py convert_to_south youappnamepython manage.py schemamigration youappname –autopython manage.py migrate youappnam\n这个用到了south，一定程度解决修改表结构的痛苦，但是还有。\n6.运行本地服务\npython manage.py runserver 8086\n7.命令行方式的与Django交互。python manage.py shell\n8.ORM数据库python manage.py init 初始化数据库python manage.py sqlall [appname] 查看app的CREATE TABLE的语句，包括原始数据，创建索引等.\npython manage.py sqlreset [appname] 修改models，不保留以前数据，进行重置数据库，更新表。\npython manage.py validate 用来排错python manage.py syncdb 用来建表python manage.py sql databasename 用来查看已创建数据库表结构\nmyphpadminsudo apt-get install phpmyadminsudo ln -s /usr/share/phpmyadmin /var/www\nDjango Admin 录入中文错误解决办法ALTER TABLE auth_xxxxxx MODIFY COLUMN xxxxxx VARCHAR(255) CHARACTER SET utf8 COLLATE utf8_unicode_ci NOT NULL;\nALTER TABLE django_admin_log MODIFY COLUMN object_repr VARCHAR(255) CHARACTER SET utf8 COLLATE utf8_unicode_ci NOT NULL;\n","slug":"old_topic/2016-09-17-36","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"76c3bd62c0bfebefa8d37c47bf8fd902","title":"MoonScript调用LUA-CJSON","content":"作者：糖果\nLapis的util库有对cjson封装，而我们想更直接的调用CJSON的方法，而不想依赖的封装。\n我们首先实现一个MoonScript写文件的代码：\n写文件：12345678910write_data = (var, rule)-&gt;    path = &quot;/home/xxx&quot;      file = io.open(path,&quot;aw&quot;)    if file==nil then        return    ret = file\\write(rule)    file\\close()    return(t)\n\n访问接口：12345678restyhttp = require &quot;resty.http&quot;httpc = restyhttp.new()res, err = httpc\\request_uri(&quot;http://0.0.0.0/getjson&quot;)jsonbody = &quot;&quot;if res.status == ngx.HTTP_OK   jsonbody = res.bodyelse   jsonbody = nil \n\n对JSON数据DECODE:12345write_data(0, jsonbody)t = json.decode(jsonbody)tjson = json.decode(t[&#x27;message&#x27;])ngx.say(util.serialise_value(tjson))&quot;&quot;","slug":"old_topic/2016-09-17-355","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"5f974a115cefd23be7d8b6092b3445d0","title":"MoonScript与ElasticSearch客户端","content":"作者：糖果\n从Github上看，有一位叫做Dhaval Kapil老师完成了ElasticSearch for Lua的工作，另一位来自阿根廷的叫做Cristian Haunsen的老师，完成了ElasticSearch for Lapis的客户端程序写作工作,dhavalkapil还有一个博客可以访问：dhavalkapil.com\n这次实验的目标，是测试一下本地直接运行ES for Lua，然后在Lapis中访问ES，我们的日志在ES，可以用Lua，也可以用Python完成ES的访问工作， Python没有问题，Lua就看这个实验了。\n测试代码，如下：\n123456789101112131415161718192021local elasticsearch = require &quot;elasticsearch&quot;local client = elasticsearch.client&#123;    hosts = &#123;      &#123; -- Ignoring any of the following hosts parameters is allowed.        -- The default shall be set        protocol = &quot;http&quot;,        host = &quot;localhost&quot;,        port = 9200      &#125;    &#125;,    -- Optional parameters    params = &#123;      pingTimeout = 2    &#125;&#125;-- Will connect to default host/portlocal client = elasticsearch.client()local data, err = client:info()\n\n\nFull list of params（全参数列表）:\n\npingTimeout : The timeout of a connection for ping and sniff request. Default is 1.\nselector : The type of selection strategy to be used. Default is RoundRobinSelector.\nconnectionPool : The type of connection pool to be used. Default is StaticConnectionPool.\nconnectionPoolSettings : The connection pool settings,\nmaxRetryCount : The maximum times to retry if a particular connection fails.\nlogLevel : The level of logging to be done. Default is warning.\n\nGetting info of elasticsearch server（取得ES服务器信息）1local data, err = client:info()\n\n\nIndex a document（创建索引文档）Everything is represented as a lua table.(一切皆为Lua Table)\n12345678local data, err = client:index&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;,  body = &#123;    my_key = &quot;my_param&quot;  &#125;&#125;\n\nGet a document（取得文档）12345data, err = client:get&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;&#125;\n\nDelete a document（删除文档）12345data, err = client:delete&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;&#125;\n\nSearching a document （检索文档）You can search a document using either query string:（使有查询字符进行检索）\n12345data, err = client:search&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  q = &quot;my_key:my_param&quot;&#125;\n\nOr either a request body:(或是请求体)1234567891011data, err = client:search&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  body = &#123;    query = &#123;      match = &#123;        my_key = &quot;my_param&quot;      &#125;    &#125;  &#125;&#125;\n\nUpdate a document（更新文档）12345678910data, err = client:update&#123;  index = &quot;my_index&quot;,  type = &quot;my_type&quot;,  id = &quot;my_doc&quot;,  body = &#123;    doc = &#123;      my_key = &quot;new_param&quot;    &#125;  &#125;&#125;\n\n其实MoonScript for ElasticSearch的库是一个纯正的MoonScript实现，但从Readme中描述是没显明的看是用MoonScript实现，不防抽出的MoonScript核心实现，贴出来看一下：\n123456789101112131415161718192021222324252627282930client = elasticsearch.client &#123;    hosts: config.elasticsearch.hosts and parse_hosts_config(config.elasticsearch.hosts) or &#123;        &#123;            protocol: &quot;http&quot;            host: &quot;127.0.0.1&quot;            port: 9200        &#125;    &#125;,    params: &#123;        -- Should return a table with &#123; status, statusCode, body &#125;        preferred_engine: (method, uri, params, body, timeout) -&gt;            http = require &quot;resty.http&quot;            httpc = http.new!            args = &#123; :method, :body, headers: &#123; [&quot;Content-Type&quot;]: &quot;application/json&quot; &#125; &#125;            res, err = httpc\\request_uri(uri, args)            if not res                ngx.say(&quot;failed to request: &quot;, err)                return            response = &#123;&#125;            response.code = res.status            response.statusCode = res.status            response.body = res.body            return response    &#125;&#125;&#123;  :interpolate_query, :client&#125;\n\nAPI封装以外，用的还是”resty.http”调用，这里有一个疑问，resty.http和simple.http是不是同一个部件？\n原文\nlapis-elasticsearch\nPS：本文测式用代码都来自至官方ES-LUA的Github的Readme。\n","slug":"old_topic/2016-09-17-361","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"e42217fa2cd64fc77d86460421fbfaca","title":"HiLua框架与MoonScript库的交互过程","content":"作者：糖果\n上一篇是用.so作为框架的库，这是接上回，用MoonScript实现库。\n在HiLua工程中，创建/libs/moon目录，建立MoonScript库代码，如下：\nHiLog.moon\n1234class HiLog    @log: =&gt;        print(&quot;HiLog...&quot;)        return &quot;HiLog...&quot;\n\nHiLog.lua\n123456789101112131415161718192021222324252627local HiLogdo  local _class_0  local _base_0 = &#123; &#125;   _base_0.__index = _base_0  _class_0 = setmetatable(&#123;    __init = function() end,    __base = _base_0,    __name = &quot;HiLog&quot;  &#125;, &#123;    __index = _base_0,    __call = function(cls, ...)      local _self_0 = setmetatable(&#123;&#125;, _base_0)      cls.__init(_self_0, ...)      return _self_0    end   &#125;)    _base_0.__class = _class_0  local self = _class_0  self.log = function(self)    print(&quot;HiLog...&quot;)    return &quot;HiLog...&quot;  end   HiLog = _class_0  return _class_0end\n\n创建新工程与app:\n12hi project Test-HiLuahi app Test-HiLua\n\n修改一下app.lua\n123456789101112require &quot;log&quot;local HiLog = require &quot;HiLog&quot;local Application = require &quot;orc&quot;app = Application.new()app:get(&quot;/hilua&quot;, function(request,id)    ret = HiLog:log()       ngx.say(ret)    ngx.say(&#x27;hilua&#x27;) end)return app.run()\n\n\n\n库可以用C写生成SO共享库，也可以用MoonScript翻译成Lua，然后与框架路由结合起来，这种依赖就是纯调用依赖关联，尽量不产生数据关联。\n原文地址：\n源码地址：\n","slug":"old_topic/2016-09-17-360","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"05d6f9c12a393c22bb876b3b1fe14cf0","title":"MoonScript版的Ngx.Timer","content":"作者：糖果\n实际如果是直接调用ngx.timer的API，moonscript和lua的ngx.timer的函数写法差别不是很大。\ncandylab.moon\n123456789handler = (fill, params)-&gt;    ok, err = ngx.timer.at(1, handler, &quot;params-data&quot;)    ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok, &quot; err:&quot;, err)         ok, err = ngx.timer.at(6, handler, &quot;params-data&quot;)               if not ok then    ngx.log(ngx.ERR, &quot;err:&quot;, err)\n\ncandylab.lua\n12345678910111213local http = require(&quot;lapis.nginx.http&quot;)local handlerhandler = function(fill, params)  local ok, err = ngx.timer.at(1, handler, &quot;params-data&quot;)  return ngx.log(ngx.DEBUG, &quot;ok:&quot;, ok, &quot; err:&quot;, err)endlocal ok, err = ngx.timer.at(6, handler, &quot;params-data&quot;)if not ok then  return ngx.log(ngx.ERR, &quot;err:&quot;, err)end","slug":"old_topic/2016-09-17-364","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ec499223d38cc05a19e8571945944a4c","title":"MoonScript与Simple.HTTP","content":"作者：糖果\nMoonScript调用Lapis的Simple.http，其实调用的就是OpenResty的http的接口。\ncandylab.moon\n123456http = require &quot;lapis.nginx.http&quot;body, status_code, headers = http.simple &#123;    url: &#x27;http://moonscript.cn&#x27;     method: &quot;GET&quot;    headers: &#123;&#125; &#125;\n\ncandylab.lua\n123456local http = require(&quot;lapis.nginx.http&quot;)local body, status_code, headers = http.simple(&#123;    url = &#x27;http://moonscript.cn&#x27;,    method = &quot;GET&quot;,    headers = &#123; &#125;&#125;)","slug":"old_topic/2016-09-17-362","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"55c8ceefd620d530c7de11d61153ba84","title":"MoonScript与Redis客户端","content":"所谓的Redis LUA客户端有两种版本，一种就是本地可运行版本，还有一个版本是OpenResty的版本，下面介绍的这段Moonscript段代码是本地版的。\n作者：糖果\ncandylab.moon\n123456789redis = require &quot;redis&quot;client = redis.connect &#x27;127.0.0.1&#x27;, 6379auth_flg = client\\auth &quot;www.moonscript.cn&quot;if not auth_flg     print(&quot;Auth NG!!!&quot;)client\\publish &quot;chatroom&quot;, &quot;www.candylab.net&quot;\n\n\ncandylab.lua\n1234567local redis = require(&quot;redis&quot;)local client = redis.connect(&#x27;127.0.0.1&#x27;, 6379)local auth_flg = client:auth(&quot;www.moonscript.cn&quot;)if not auth_flg then  print(&quot;Auth NG!!!&quot;)endreturn client:publish(&quot;chatroom&quot;, &quot;www.candylab.net&quot;)","slug":"old_topic/2016-09-17-363","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"65fa3173cc522e3fb069063afc992231","title":"MoonScript与JSON","content":"作者：糖果\n12345678910111213lapis = require &quot;lapis&quot;                                                                                                                                                   import json_params from require &quot;lapis.application&quot;                                                                                                                                                                                                                                                                                                 class App extends lapis.Application                                                                                                                                         &quot;/&quot;: =&gt;                                                                                                                                                                     &#123;                                                                                                                                                                           json: &#123;                                                                                                                                                                     success: true                                                                                                                                                             message: &quot;hello world&quot;                                                                                                                                                  &#125;                                                                                                                                                                       &#125;                                                                                                                                                                       &quot;/json&quot;: json_params =&gt;                                                                                                                                                     @params.value    \n\n用curl进行测试：\n1curl -H &quot;Content-type: application/json&quot;  -d &#x27;&#123;&quot;value&quot;: &quot;hello&quot;&#125;&#x27;  0.0.0.0:8080/json","slug":"old_topic/2016-09-17-365","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"f17567ac35ebb144b8a5d3dffefc17d8","title":"MoonScript's Object","content":"作者：糖果\nCoffescript是一种中间的脚本，可以把这种脚本翻译成JavaScript。而MoonScript，是可以翻译成lua语言的中间脚本。\n本文简单的介绍的：\n\n如何在VIM中，实现MoonScript语法高亮。 \n如何简单的编译MoonScript脚本。\nMoonScript面向对象OO简介。\n\n1.安装MoonScript1sudo luarocks install moonscript\n\n2.创建.moon源文件app.moon\n1234lapis = require &quot;lapis&quot;   class extends lapis.Application     &quot;/&quot;: =&gt; &quot;Welcome to Lapis #&#123;require &quot;lapis.version&quot;&#125;!&quot; \n\n\n3.安装MoonScript语法高亮的插件。3-1.下载vim的bundle插件管理程序。\n1git clone https://github.com/gmarik/vundle.git ~/.vim/bundle/vundle\n\n\n3-2.创建.vimrc配置文件。\n1vim ~/.vimrc\n\n\n3-3. 编辑.vimrc文件内容。\n123456set nocompatible                                                                                                                      filetype off                                                                                                                          set rtp+=~/.vim/bundle/vundle/                                                                                                        call vundle#rc()                                                                                                                                      Bundle &#x27;leafo/moonscript-vim&#x27;                                                                                                         syntax enable \n\n\n3-4.进入VIM，安装bundle插件。\n1vim +BundleInstall\n\n\n3-5.翻译成lua脚本,并运行。\n12moonc app.moonlua app.lua\n\n\n\n按照如上步骤操作后:\n\n可以用moonc命令翻译.moon脚本到.lua脚步。\nvim支持moonscript的语法高亮检查。\n\nMoonscript与OO面向对象:\n讲MoonScript不能不提她对OO面向对像的支持，下面简单介绍一下MoonScirpt面像对像的特性。对向函数与变量的封装，MoonScirpt的函数定义有其独特的地方是。\n12345678910111213141516171819202122232425262728293031323334353637383940414243foo = -&gt;    print &quot;foo&quot;    foo()    --函数调用```    上面是无参数函数调用，没有形参，下面是加入形参的函数声明：```lua    foo(x, y) =&gt;   return x + yret = foo 1,5```       MoonScript的函数调用，可以不使用(),省着去括号。接下来，用类封装函数和成员表量，用一个单根继承两类做说明。```luaclass CandyLab     @metadata: &quot;Candy Lab&quot;class Candy extends CandyLab    @name: &quot;Candy&quot;        @value: &quot;From CandyLab&quot;        @func1: =&gt;        print @name        print @value + 6        print &quot;func1&quot;    @func2: (x, y) =&gt;        print x + y        return x + y    @func3: =&gt;        print &quot;ok&quot;        print &quot;#&#123;@metadata&#125;&quot;\n\nMoonScirpt的对象变量和函数可能直接在外部调用：\n123Candy\\func1!ret = Candy\\func2 1,5 Candy\\func3!\n\n在Candy类中的func3，直接引用的父类的变量metadata,另一个比较独特的地方是，用!表示调用无参函数。MoonScript的类继承关键还是与Java接近extends。\n下面是没有继承关系的两个类之间的函数调用与变量引用，而在引用的过程中有一个特别一点的表量类型声明，就是Table类型。\n123456789101112class CandyLab     endpoints: 1    tbl_url: &#123;             url_1:&quot;http://host.com/1&quot;,             url_2:&quot;http://host.com/2&quot;,             url_3:&quot;http://host.com/3&quot;         &#125;          class Candy    @func1: =&gt;        print(Common.endpoints)          print(type(Common.tbl_url[&quot;ur1_1&quot;]))\n\n\n上面的操作是直接在Candy类中调用CandyLab的变量，其实就是没有权限访问。MoonScript的OO特性比较常用如上，MoonScript这些特性，如果用来做Web开发，效率相对Lua来说还是高的，而目前用MoonScript实现的最大的一个项目就是Lua框架Lapis，接下来可以看看Lapis中是如何使用MoonScript的特性的。\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\nhttps://www.candylab.net\n","slug":"old_topic/2016-09-17-367","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"ea8283997977848c6827a1a83f28911d","title":"Moonscript与HTML模板","content":"作者：糖果\nMoonscript与HTML模板\nLapis框架可以用Moonscript直接编程，Moonscript可以将需要模板系统对于的网页输出，一揽子的都在Moonscript中用代码实现，可以看leaof.net/lapis下最典型的官方例子，其实DB的相关操作也可以在moonscript中都完成了，对于某种类型的操作来看，这是很酷的。\n我们先来看一下模板的例子：\n12345678910111213import Widget from require &quot;lapis.html&quot;class Index extends Widget  content: =&gt;    h1 class: &quot;header&quot;, &quot;Hello&quot;    @user_panel!    div class: &quot;body&quot;, -&gt;      text &quot;Welcome to my site!&quot;  user_panel: =&gt;    return unless @current_user    div class: &quot;user_panel&quot;, &quot;Welcome back &quot; .. @current_user.name\n\n\n这段mooncript代码会被翻译成下面的HTML\n1234567891011&lt;h1 class=&quot;header&quot;&gt;&lt;%= &quot;Hello&quot; %&gt;&lt;/h1&gt;&lt;% if current_user then %&gt;  &lt;div class=&quot;user_panel&quot;&gt;    Welcome back &lt;%= current_user.name %&gt;  &lt;/div&gt;&lt;% end %&gt;&lt;div class=&quot;body&quot;&gt;  Welcome to my site&lt;/div&gt;\n\n\n在实际leafo之前的应用代码中，利用的最明显的是下面这段：\n12345678910111213import Widget from require &quot;lapis.html&quot;class PostLayout extends Widget  content: =&gt;    @page.template_stack\\push &quot;web&quot;    div class: &quot;post&quot;, -&gt;      div class: &quot;sidebar&quot;, -&gt;        text @root      div class: &quot;main_column&quot;, -&gt;        raw @body\n\n下面这句话出现了问题：\n12div class: &quot;sidebar&quot;, -&gt;  text @root\n@root在某些情况下晃是一个”..“, 这个会造成左边栏的导航栏消失了。\n这里核心的库就是这个lapis.html\n1import Widget from require &quot;lapis.html&quot;\n\n代码太长，就贴个连接过来lapis.html.moon,Moonscript如果用来做个人项目还是挺酷的。如何用Moonscript生成Html看下面的连接：HTML Generation,Moonscript生成大量的前端可以维护起来可能有些难度，但做为生成模板描述，还是方便快速有优势。\n上面的模板定义代中，使用了一个助手函数raw：\n1raw @body\n\n还使用了另外的一个助手函数：\n1text @root\n\n\nraw(str)\n\n\n\n\n\n\n\n\n引用文本： — outputs the argument, a string, directly to the buffer without escaping.\nraw是直接将字符串写入到buffer，并且不经过转意。\ntext(args)\n\n\n\n\n\n\n\n\n引用文本： — outputs the argument to the buffer, escaping it if it’s a string. If it’s a function, it executes the function in HTML builder environment. If it’s a table, it writes each item in the table\n这个函数区别于raws，如果是字符串就转义。是函数就执行。如果是表，把每个元素都写入表。\n上面提到的@root是sitegen的内建变量。\n\n\n\n\n\n\n\n\n\n引用文本： $root — a relative path prefix that points back to the top level directory of your site. For example, if the current page is wwww/hello/world.html, the $root would be ../. This make it easy to built URLs to other pages without being concerned about where your page is being rendered to.\n一般的情况下,@root值就取”.”、”..” 比较常见。不过，此处这种输出会导致左导航栏消失。sitgen, jekyll,还有这个saepy-log，这三个系统，前二者是静态转换Markdown,saepy-log是从Mysql里，读取Markdown（最开始不是，改成了直接支持Markdown。）三个工具分别用三种语言实现。moonscript(lua), ruby, python(tornado)，设计风格也不一样。对SEO支持比较好的是SAEPY_LOG，最酷的还是sitegen。\n","slug":"old_topic/2016-09-17-366","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"99aa8520e0bab428f7fc88038d56c646","title":"MoonScript官方文档","content":"我本人写的中文版的MoonScript文档，直接看官方文档其实，还是会不得要领。后面的英文部分，就是官方的，前面是中文自己写的。\n国内用MoonScript的用户相对比较少，作者leafo创作了moonscript，另外还用moonscript创作的一个lua web框架：lapis。估计moonscript想在国内普及还需要一段路要走。\nCoffescript是一种中间的脚本，可以把这种脚本翻译成JavaScript。而MoonScript，是可以翻译成lua语言的中间脚本。本文简单的介绍的：\n\n如何在VIM中，实现MoonScript语法高亮。  \n如何简单的编译MoonScript脚本。\n\n1.安装MoonScript1sudo luarocks install moonscript\n\n2.创建.moon源文件 # app.moon1234lapis = require &quot;lapis&quot;   class extends lapis.Application     &quot;/&quot;: =&gt; &quot;Welcome to Lapis #&#123;require &quot;lapis.version&quot;&#125;!&quot; \n\n3.安装MoonScript语法高亮的插件。 # **3-1.下载vim的bundle插件管理程序。1git clone VundleVim/Vundle.vim ~/.vim/bundle/vundle\n\n3-2.创建.vimrc配置文件。\n1vim ~/.vimrc\n\n3-3. 编辑.vimrc文件内容。\n123456set nocompatible                                                                                                                      filetype off                                                                                                                          set rtp+=~/.vim/bundle/vundle/                                                                                                        call vundle#rc()                                                                                                                                      Bundle &#x27;leafo/moonscript-vim&#x27;                                                                                                         syntax enable \n3-4.进入VIM，安装bundle插件。\n1vim +BundleInstall\n3-5.翻译成lua脚本,并运行。\n12moonc app.moonlua app.lua\n\n按照如上步骤操作后:\n\n可以用moonc命令翻译.moon脚本到.lua脚步。 \n\nvim支持moonscript的语法高亮检查。\n\n\nMoonscript与OO面向对象:讲MoonScript不能不提她对OO面向对像的支持，下面简单介绍一下MoonScirpt面像对像的 特性。对向函数与变量的封装，MoonScirpt的函数定义有其独特的地方是。\n1234foo = -&gt;    print &quot;foo&quot;foo()    --函数调用\n\n上面是无参数函数调用，没有形参，下面是加入形参的函数声明：\n123foo(x, y) =&gt;   return x + yret = foo 1,5\n\nMoonScript的函数调用，可以不使用(),省着去括号。接下来，用类封装函数和成员表量，用一个单根继承两类做说明。\n123456789101112131415class CandyLab     @metadata: &quot;Candy Lab&quot;class Candy extends CandyLab  @name: &quot;Candy&quot;  @value: &quot;From CandyLab&quot;  @func1: =&gt;        print @name        print @value + 6        print &quot;func1&quot;  @func2: (x, y) =&gt;        print x + y        return x + y  @func3: =&gt;        print &quot;ok&quot;        print &quot;#&#123;@metadata&#125;&quot;\n\nMoonScirpt的对象变量和函数可能直接在外部调用：\n123Candy\\func1!ret = Candy\\func2 1,5 Candy\\func3!\n\n在Candy类中的func3，直接引用的父类的变量metadata,另一个比较独特的地方是，用!表 示调用无参函数。MoonScript的类继承关键还是与Java接近extends。下面是没有继承关系的两个类之间的函数调用与变量引用，而在引用的过程中有一个特别 一点的表量类型声明，就是Table类型。\n1234567891011class CandyLab     endpoints: 1    tbl_url: &#123;             url_1:&quot;http://host.com/1&quot;,             url_2:&quot;http://host.com/2&quot;,             url_3:&quot;http://host.com/3&quot;         &#125;class Candy    @func1: =&gt;        print(Common.endpoints)          print(type(Common.tbl_url[&quot;ur1_1&quot;]))\n\n上面的操作是直接在Candy类中调用CandyLab的变量，其实就是没有权限访问。MoonScript 的OO特性比较常用如上，MoonScript这些特性，如果用来做Web开发，效率相对Lua来说还是 高的，而目前用MoonScript实现的最大的一个项目就是Lua框架Lapis，接下来可以看看Lapis 中是如何使用MoonScript的特性的。\n作者：糖果PS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n{  target: “reference/standard_lib”  template: “reference”  title: “Standard Library”  short_name: “stdlib”}\nThe MoonScript installation comes with a small kernel of functions that can beused to perform various common things.\nThe entire library is currently contained in a single object. We can bring thismoon object into scope by requiring &quot;moon&quot;.\n123moon = require &quot;moon&quot;-- `moon.p` is the debug printermoon.p &#123; hello: &quot;world&quot; &#125;\n\nIf you prefer to just inject all of the functions into the current scope, youcan require &quot;moon.all&quot; instead. The following has the same effect as above:\n12require &quot;moon.all&quot;p &#123; hello: &quot;world&quot; &#125;\n\nAll of the functions are compatible with Lua in addition to MoonScript, butsome of them only make sense in the context of MoonScript.\nMoonScript Standard LibraryThis is an overview of all the included functions.All of the examples assume that the standard library has been included withrequire &quot;moon.all&quot;.\nPrinting Functionsp(arg)Prints a formatted version of an object. Excellent for inspecting the contentsof a table.\nTable Functionsrun_with_scope(fn, scope, [args...])Mutates the environment of function fn and runs the function with any extraarguments in args.... Returns the result of the function.\nThe environment of the function is set to a new table whose metatable will usescope to look up values. scope must be a table. If scope does not have anentry for a value, it will fall back on the original environment.\n123456789101112my_env = &#123;  secret_function: -&gt; print &quot;shhh this is secret&quot;  say_hi: -&gt; print &quot;hi there!&quot;&#125;say_hi = -&gt; print &quot;I am a closure&quot;fn = -&gt;  secret_function!  say_hi!run_with_scope fn, my_env\n\n\nNote that any closure values will always take precedence against global namelookups in the environment. In the example above, the say_hi in theenvironment has been shadowed by the local variable say_hi.\ndefaultbl([tbl,] fn)Sets the __index of table tbl to use the function fn to generate tablevalues when a missing key is looked up.\nextend(arg1, arg2, [rest...])Chains together a series of tables by their metatable’s __index property.Overwrites the metatable of all objects except for the last with a new tablewhose __index is set to the next table.\nReturns the first argument.\n123456a = &#123; hello: &quot;world&quot; &#125;b = &#123; okay: &quot;sure&quot; &#125;extend a, bprint a.okay\n\ncopy(tbl)Creates a shallow copy of a table, equivalent to:\n1copy = (arg) -&gt; &#123;k,v for k,v in pairs self&#125;\n\nClass/Object Functionsis_object(value)Returns true if value is an instance of a MoonScript class, false otherwise.\ntype(value)If value is an instance of a MoonScript class, then return it’s class object.Otherwise, return the result of calling Lua’s type method.\n12345class MyClass  nilx = MyClass!assert type(x) == MyClass\n\nbind_methods(obj)Takes an instance of an object, returns a proxy to the object whose methods canbe called without providing self as the first argument.\n1234567obj = SomeClass!bound_obj = bind_methods obj-- following have the same effectobj\\hello!bound_obj.hello!\n\nIt lazily creates and stores in the proxy table the bound methods when theyare first called.\nmixin(obj, class, [args...])Copies the methods of a class cls into the table obj, then calls theconstructor of the class with the obj as the receiver.\nIn this example we add the functionality of First to an instance of Secondwithout ever instancing First.\n12345678910class First  new: (@var) =&gt;  show_var: =&gt; print &quot;var is:&quot;, @varclass Second  new: =&gt;    mixin self, First, &quot;hi&quot;a = Second!a\\show_var!\n\nBe weary of name collisions when mixing in other classes, names will beoverwritten.\nmixin_object(obj, other_obj, method_names)Inserts into obj methods from other_obj whose names are listed inmethod_names. The inserted methods are bound methods that will run withother_obj as the receiver.\n1234567891011class List   add: (item) =&gt; print &quot;adding to&quot;, self  remove: (item) =&gt; print &quot;removing from&quot;, selfclass Encapsulation  new: =&gt;    @list = List!    mixin_object self, @list, &#123;&quot;add&quot;, &quot;remove&quot;&#125;e = Encapsulation!e.add &quot;something&quot;\n\nmixin_table(a, b, [names])Copies the elements of table b into table a. If names is provided, thenonly those names are copied.\nMisc Functionsfold(items, fn)Calls function fn repeatedly with the accumulated value and the current valueby iterating over items. The accumulated value is the result of the last callto fn, or, in the base case, the first value. The current value is the valuebeing iterated over starting with the second item.\nitems is a normal array table.\nFor example, to sum all numbers in a list:\n12numbers = &#123;4,3,5,6,7,2,3&#125;sum = fold numbers, (a,b) -&gt; a + b\n\nDebug Functionsdebug.upvalue(fn, key[, value])Gets or sets the value of an upvalue for a function by name.\n","slug":"old_topic/2016-09-17-369","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"bace4a0f855ab931a94c6323590dcc00","title":"MoonScript for GrayLog","content":"GrayLog REST API Wrapper for Moonscript\n此程序是Graylog REST对外提供的API的一个Moonscript的Wrapper封装，把REST接口提供的数据服务，变成通过函数调用的方式取得相应REST接口返回的数据。\n下面是一个实际的基于Lapis框架程序中调用此SDK的例子：\n123456789101112131415161718192021222324252627class App extends lapis.Application  &quot;/testcase&quot;: =&gt;    --准备对应REST的输入参数，如果相应该有的项目没有设定会输出NG原因。    param_data= &#123;        fields:&#x27;username&#x27;,        limit:3,        query:&#x27;*&#x27;,        from: &#x27;2017-01-05 00:00:00&#x27;,        to:&#x27;2017-01-06 00:00:00&#x27;,        filter:&#x27;streams&#x27;..&#x27;:&#x27;..&#x27;673b1666ca624a6231a460fa&#x27;    &#125;    --进行鉴权信息设定    url  = GMoonSDK\\auth &#x27;supervisor&#x27;, &#x27;password&#x27;, &#x27;127.0.0.1&#x27;, &#x27;12600&#x27;        --调用对应&#x27;TYPE&#x27;相对应的REST服务，返回结果。    ret = GMoonSDK\\dealStream &#x27;s_ua&#x27;, param_data    ret```    上文提到 ‘TYPE’， 其实就是对Endpoints的一种编号，基本上和GrayLog REST API是一对一关系。```lua    endpoints: &#123;        &#x27;s_uat&#x27;:&#123;&#x27;/search/universal/absolute/terms&#x27;:&#123;&#x27;field&#x27;, &#x27;query&#x27;, &#x27;from&#x27;, &#x27;to&#x27;, &#x27;limit&#x27;&#125; &#125;        &#x27;s_ua&#x27;:&#123;&#x27;/search/universal/absolute&#x27;:&#123;&#x27;fields&#x27;, &#x27;query&#x27;, &#x27;from&#x27;, &#x27;to&#x27;, &#x27;limit&#x27;&#125; &#125;        &#x27;s_urt&#x27;:&#123;&#x27;/search/universal/relative/terms&#x27;:&#123;&#x27;field&#x27;, &#x27;query&#x27;, &#x27;range&#x27;&#125; &#125;        &#x27;s_ut&#x27;:&#123;&#x27;/search/universal/relative&#x27;:&#123;&#x27;fields&#x27;, &#x27;query&#x27;, &#x27;range&#x27;&#125; &#125;    &#125;\n理论上说，可以个修改以上的数据结构，对应各种REST API的服封装(GET),只要知道对应URL与可接收的参数列表。\n","slug":"old_topic/2016-09-17-368","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"b886d3e0a930ce8de7df46cdd311c487","title":"Django超级简单的MVC实例","content":"【前言】写一遍django的入门例子，基于MVC设计模式，本程序有输入，处理，输出。开始用django搬运互联网上的数据。简单介绍一下什么是MVC模式。MVC就是把程序成分3部分职责。\n【MVC】V(View)：系统的界面，django中就是网页。UI部分，用于接受用户的数据，输出用户的数据。M(Model)： 处理用户输入的数据，对数据进行加工。django中就是py文件中的方法。C（Control）:处理用户的功能请求，分配给不同的模块进行处理。django中就url的分发。\n【功能概要】    提供一个表单，接受用户输入的数据（输入V），将用户的数据写出到数据库中（处理M），并将写入的结果显示在网页上(输出V)。这就是数据搬运的一个简单流程，在此最基本的模式上，会衍生出数据库的CRUD(增加，查询，更新，删除)操作。\n以上这些动作，基本都是熟能生巧的技术工作，某种角度来说，就是模式化重复的体力活，不同的是，django可以快速的完成这些任务，短小精干，并且快速。\n\n【HTTP】[code][08/Mar/2014 14:53:01] “GET /search/?name=%E9%83%9D%E5%BB%BA&amp;email=&#x73;&#x68;&#101;&#110;&#x67;&#x40;&#118;&#x65;&#x72;&#x75;&#x70;&#x2e;&#99;&#110; HTTP/1.1” 200 17[/code]\n这个是有两个输入项目表单提交的一条HTTP的get请求。【CGI】上面的那条Http的get请用，可以用各种类型的CGI程序去处理，比如说java,C,C++,PHP,ruby,python.可但是，功能最全打字越少，快速的处理HTTP请求，Get和Post的语言最好，先举出一个C语言写的CGI程序。\n[code]\n\n\n\n\n\n[/code]\n\n[code]#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;\nint main(int argc, char** argv){  char *data;  printf(“Content-type:text/html;charset=gb2312\\n\\n”);  data = getenv(“QUERY_STRING”);  return 0;}[/code]\n“Content-type:text/html;charset=gb2312\\n\\n”这个必须有，声明MIME类型。没有的话，结果网页无法正常显示，因为浏览器不知道程序输出的是什么。\n上面的变量data就是用户发送过来的字典数据，从“&amp;”符号分开的key pair数据，没一对数据的key和value在用“等号分割”\nGET /search/?name=sheng&amp;email=&#116;&#101;&#101;&#x31;&#54;&#56;&#64;&#113;&#x71;&#46;&#x63;&#111;&#109;name=sheng&amp;email=&#116;&#101;&#x65;&#49;&#x36;&#56;&#64;&#113;&#x71;&#x2e;&#x63;&#111;&#109;\n用户需要先对”&amp;”符号进行split,判断有多少组数据，然后在对每一组的数据进行“=”split，得到最后的数据，如下char* name=”sheng”;char* email=”&#116;&#101;&#101;&#49;&#54;&#x38;&#x40;&#x71;&#x71;&#x2e;&#x63;&#x6f;&#x6d;“;\n得到了key和value\n【视图实现(View)】本功能数据的源头就是用户从表单输入的输入，所以视图V一部分是HTML表单。另外一部分是对用户在网页上发出的http请求的响应处理，python的CGI程序。[code]\n\n\n        www.verup.cn\n\n\n        \n                \n                \n                \n        \n\n\n[/code]\n\n在接受到用户输入的数据后，会对用户的数据进行处理，[code]from hotwords.models import Author\ndef GetAuthorInfo(request):        return render_to_response(‘Author.html’)\ndef search(request):        if ‘key’ in request.GET:                message = request.GET[‘name’] + request.GET[‘email’]\n    name = request.GET[&#39;name&#39;]\n    email = request.GET[&#39;email&#39;]\n    #在创建Author的models后，就会有对应的Autor对象产生（参考【模型(M)】）\n    #引用Author的models,创建构造对象，调用一下save()方法，就完成了一条记录的插入，创造一个author对象，相当于表格的一条记录，用表单传入的数据，去构造对象，完成一条表记录的插入。\n    author = Author(1, name, email)\n    author.save()\n    return HttpResponse(message)\n\n[/code]\n对表输入的插入，删除，修改是常用的DB操作，map和list,这也都是主要的数据搬用动作，也是很没意思的部分。但是，你还得写。\n【CRUD】\n【模型(M)】使用django的ORM，通过定义数据对象类来创建数据库的table,几乎就不用再直接SQL打交道了。下面就。。。看！\n[code]from django.db import modelsfrom django.contrib import admin\nclass Author(models.Model):        name = models.CharField(max_length=50)        email = models.EmailField()\n    def __unicode__(self):\n            return self.name\n\n[/code]\n看到了没一共就两个字段，运行如下命令：\n[code]python manage.py syncdb[/code]\ndjango就会在数据库中创建名author表格。\n[code]+——-+————-+——+—–+———+—————-+| Field | Type        | Null | Key | Default | Extra          |+——-+————-+——+—–+———+—————-+| id    | int(11)     | NO   | PRI | NULL    | auto_increment || name  | varchar(50) | NO   |     | NULL    |                || email | varchar(75) | NO   |     | NULL    |                |+——-+————-+——+—–+———+—————-+[/code]\n作者：糖果\n","slug":"old_topic/2016-09-17-37","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"b4e10a2e9208e3bffc49bf639e841080","title":"MoonScript Command Line.","content":"{  target: “reference/command_line”  template: “reference”  title: “Command Line Tools”  short_name: “command_line”}\nCommand Line ToolsTwo tools are installed with MoonScript, moon and moonc.\nmoonc is for compiling MoonScript code to Lua.moon is for running MoonScript code directly.\nmoonmoon can be used to run MoonScript files directly from the command line,without needing a separate compile step. All MoonScript files are compiled inmemory as they are executed.\n1$ moon my_script.moon\n\nAny MoonScript files that are required will also be compiled on demand as theyare loaded.\nWhen an error occurs during runtime, the stack trace is rewritten to give linenumbers from the original .moon file.\nIf you want to disable error rewriting, you can pass the-d flag. A full list of flags can be seen by passing the -h or --helpflag.\nError RewritingRuntime errors are given special attention when running code using the mooncommand line tool. Because code is written in MoonScript but executed as Lua,errors that happen during runtime report Lua line numbers. This can makedebugging less than ideal.\nIn order to solve this problem MoonScript builds up a table of line numbermappings, allowing the runtime to calculate what line of MoonScript generatedthe line of Lua that triggered the error.\nConsider the following file with a bug (note the invalid z variable):\n12add_numbers = (x,y) -&gt; x + z  -- 1print add_numbers 10,0        -- 2\n\nThe following error is generated:\nmoon: scrap.moon:1(3): attempt to perform arithmetic on global &#39;z&#39; (a nil value)\nstack traceback:\n  scrap.moon:1(3): in function &#39;add_numbers&#39;\n  scrap.moon:2(5): in main chunk\n\nNotice how next to the file name there are two numbers. The first number is therewritten line number. The number in the parentheses is the original Lua linenumber.\nThe error in this example is being reported on line 1 of the moon file, whichcorresponds to line 3 of the generated Lua code. The entire stack trace is rewritten inaddition to the error message.\nCode Coveragemoon lets you run a MoonScript file while keeping track of which linesare executed with the -c flag.\nFor example, consider the following .moon file:\n12345678-- test.moonfirst = -&gt;  print &quot;hello&quot;second = -&gt;  print &quot;world&quot;first!\n\nWe can execute and get a glance of which lines ran:\n1$ moon -c test.moon\n\nThe following output is produced:\n------| @cool.moon\n     1| -- test.moon\n*    2| first = -&gt;\n*    3|   print &quot;hello&quot;\n     4|\n*    5| second = -&gt;\n     6|   print &quot;world&quot;\n     7|\n*    8| first!\n     9|\n\nThe star next to the line means that it was executed. Blank lines are notconsidered when running so by default they don’t get marked as executed.\nmooncmoonc is used for transforming MoonScript files into Lua files.It takes a list of files, compiles them all, and creates the associated .luafiles in the same directories.\n1$ moonc my_script1.moon my_script2.moon ...\n\nYou can control where the compiled files are put using the -t flag, followedby a directory.\nmoonc can also take a directory as an argument, and it will recursively scanfor all MoonScript files and compile them.\nmoonc can write to standard out by passing the -p flag.\nThe -w flag can be used to enable watch mode. moonc will stay running, andwatch for changes to the input files. If any of them change then they will becompiled automatically.\nA full list of flags can be seen by passing the -h or --help flag.\nLintermoonc contains a lint tool for statically detecting potential problemswith code. The linter has two tests: detects accessed global variables,detect unused declared variables. If the linter detects any issues with a file,the program will exit with a status of 1.\nYou can execute the linter with the -l flag. When the linting flag isprovided only linting takes place and no compiled code is generated.\nThe linter is compatible with the watch mode (see above) for automatic linting.\n1moonc -l file1.moon file2.moon\n\nLike when compiling, you can also pass a directory as a command line argumentto recursively process all the .moon files.\nGlobal Variable CheckingIt’s considered good practice to avoid using global variables and create localvariables for all the values referenced. A good case for not using globalvariables is that you can analyize the code ahead of time without the need toexecute it to find references to undeclared variables.\nMoonScript makes it difficult to declare global variables by forcing you to beexplicit with the export keyword, so it’s a good candidate for doing thiskind of linting.\nConsider the following program with a typo: (my_number is spelled wrong asmy_nmuber in the function)\n123456789-- lint_example.moonmy_number = 1234some_function = -&gt;  -- a contrived example with a small chance to pass  if math.random() &lt; 0.01    my_nmuber + 10some_function!\n\nAlthough there is a bug in this code, it rarely happens during execution. It’smore likely to be missed during development and cause problems in the future.\nRunning the linter immediately identifies the problem:\n1$ moonc -l lint_example.moon\n\nOutputs:\n./lint_example.moon\n\nline 7: accessing global `my_nmuber`\n==================================\n&gt;         my_nmuber + 10\n\nGlobal Variable WhitelistIn most circumstances it’s impossible to avoid using some global variables. Forexample, to access any of the built in modules or functions you typicallyaccess them globally.\nFor this reason a global variable whitelist is used. It’s a list of globalvariables that are allowed to be used. A default whitelist is provided thatcontains all of Lua’s built in functions and modules.\nYou can create your own entires in the whitelist as well. For example, thetesting framework Busted uses a collection ofglobal functions (like describe, before_each, setup) to make writingtests easy.\nIt would be nice if we could allow all of those global functions to be calledfor .moon files located in the spec/ directory. We can do that by creatinga lint_config file.\nlint_config is a regular MoonScript or Lua file that provides configurationfor the linter. One of those settings is whitelist_globals.\nTo create a configuration for Busted we might do something like this:\n123456789-- lint_config.moon&#123;  whitelist_globals: &#123;    [&quot;spec/&quot;]: &#123;      &quot;it&quot;, &quot;describe&quot;, &quot;setup&quot;, &quot;teardown&quot;,      &quot;before_each&quot;, &quot;after_each&quot;, &quot;pending&quot;    &#125;  &#125;&#125;\n\nCompile the file:\n1$ moonc lint_config.moon\n\nThen run the linter on your entire project:\n1$ moonc -l .\n\nThe whitelisted global references in spec/ will no longer raise notices.\nThe whitelist_globals property of the lint_config is a table where the keysare Lua patterns that match file names, and the values are an array of globalsthat are allowed.\nMultiple patterns in whitelist_globals can match a single file, the union ofthe allowed globals will be used when linting that file.\nUnused Variable AssignsSometimes when debugging, refactoring, or just developing, you might leavebehind stray assignments that aren’t actually necessary for the execution ofyour code. It’s good practice to clean them up to avoid any potential confusionthey might cause.\nThe unused assignment detector keeps track of any variables that are assigned,and if they aren’t accessed in within their available scope, they are reportedas an error.\nGiven the following code:\n12a, b = 1, 2print &quot;hello&quot;, a\n\nThe linter will identify the problem:\n./lint_example.moon\n\nline 1: assigned but unused `b`\n===============================\n&gt; a, b = 1, 2\n\nSometimes you need a name to assign to even though you know it will never beaccessed.  The linter will treat _ as a special name that’s allowed to bewritten to but never accessed:\nThe following code would not produce any lint errors:\n123item = &#123;123, &quot;shoe&quot;, &quot;brown&quot;, 123&#125;_, name, _, count = unpack itemprint name, count\n\n","slug":"old_topic/2016-09-17-370","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"80b2bfed22c13e124acdd5132be472fa","title":"善良比聪明重要---亚马逊 CEO 杰夫·贝佐斯（Jeff Bezos）在母校普林斯顿大学演讲","content":"2010 年，亚马逊 CEO 杰夫·贝佐斯（Jeff Bezos）在母校普林斯顿大学的毕业典礼上，勉励年轻人，善用自己的天赋，做出对的选择。因为，「人生到头来，我们的选择，决定了我们是什么样的人。」\n以下是 Bezos 演讲内容：\nAs a kid, I spent my summers with my grandparents on their ranch in Texas. I helped fix windmills, vaccinate cattle, and do other chores. We also watched soap operas every afternoon, especially “Days of our Lives.” My grandparents belonged to a Caravan Club, a group of Airstream trailer owners who travel together around the U.S. and Canada. And every few summers, we’d join the caravan. We’d hitch up the Airstream trailer to my grandfather’s car, and off we’d go, in a line with 300 other Airstream adventurers. I loved and worshipped my grandparents and I really looked forward to these trips. On one particular trip, I was about 10 years old. I was rolling around in the big bench seat in the back of the car. My grandfather was driving. And my grandmother had the passenger seat. She smoked throughout these trips, and I hated the smell.\n孩提时代，我总是在德州祖父母的农场中度过夏天。我帮忙修理风车，为牛接种疫苗，也做其他杂活。每天下午，我们也看肥皂剧，特别是《光辉岁月》。祖父母参加了一个房车俱乐部，一群人驾驶 Airstream 房车，结伴游历美国和加拿大。每隔几个夏天，我们会加入一次旅程。把房车挂在祖父的小汽车后面，融入 300 余名 Airstream 探险者的浩荡队伍中，就这样出发。我爱祖父母，心怀敬仰，很期盼这些旅程。在我大约 10 岁时，有一次很特殊的旅程。那次我胡乱坐在后座上，祖父开着车，祖母坐在他旁边。整个旅程祖母都吸着烟，我讨厌烟味。\nAt that age, I’d take any excuse to make estimates and do minor arithmetic. I’d calculate our gas mileage – figure out useless statistics on things like grocery spending. I’d been hearing an ad campaign about smoking. I can’t remember the details, but basically the ad said, every puff of a cigarette takes some number of minutes off of your life: I think it might have been two minutes per puff. At any rate, I decided to do the math for my grandmother. I estimated the number of cigarettes per days, estimated the number of puffs per cigarette and so on. When I was satisfied that I’d come up with a reasonable number, I poked my head into the front of the car, tapped my grandmother on the shoulder, and proudly proclaimed, “At two minutes per puff, you’ve taken nine years off your life!” I have a vivid memory of what happened, and it was not what I expected. I expected to be applauded for my cleverness and arithmetic skills. “Jeff, you’re so smart. You had to have made some tricky estimates, figure out the number of minutes in a year and do some division.” That’s not what happened. Instead, my grandmother burst into tears. I sat in the backseat and did not know what to do. While my grandmother sat crying, my grandfather, who had been driving in silence, pulled over onto the shoulder of the highway. He got out of the car and came around and opened my door and waited for me to follow. Was I in trouble? My grandfather was a highly intelligent, quiet man. He had never said a harsh word to me, and maybe this was to be the first time? Or maybe he would ask that I get back in the car and apologize to my grandmother. I had no experience in this realm with my grandparents and no way to gauge what the consequences might be. We stopped beside the trailer. My grandfather looked at me, and after a bit of silence, he gently and calmly said, “Jeff, one day you’ll understand that it’s harder to be kind than clever.”\n当年，我总是想尽办法去做估测或小算术。我会计算油耗还有杂货花销等鸡毛蒜皮的小事。我听过一个与吸烟相关的广告，但记不清细节了。广告大意是，每吸一口香烟会减少几分钟寿命，好像是两分钟。管它几分钟呢，我决定为祖母做个算术。我估测了祖母每天吸几支香烟，每支香烟吸几口等等，然后心满意足地得出了一个合理的数字。接着，我把头探入汽车前排，拍了拍祖母的肩膀，骄傲地宣称：「如果每吸一口烟少活两分钟的话，你的寿命已经少了九年！」我清晰地记得接下来发生的事，是我意料之外的。凭借聪明的大脑和算术技巧，我期待赢来夸赞：「杰夫，你真聪明。你应该做一些更需要技巧的算术，比如一年有多少分钟，以及做些除法。」我的期待并没有发生。相反，祖母突然哭泣起来，我坐在后座茫然无措。祖父一直在默默开车，听到祖母的哭声，把车停在高速路边。祖父走下车来，打开车门，等我跟他下车。我惹麻烦了吗？祖父是一个智慧而安静的人。他从来没有对我说过严厉的话，难道这会是第一次？还是他会让我回到车上给祖母道歉？我以前从未遇到过这种状况，无从知晓会有什么后果发生。我们在房车旁停下来，祖父注视着我，沉默片刻，然后轻轻地、平静地说： 「杰夫，有一天你会明白，善良比聪明更难。」\nWhat I want to talk to you about today is the difference between gifts and choices. Cleverness is a gift, kindness is a choice. Gifts are easy – they’re given after all. Choices can be hard. You can seduce yourself with your gifts if you’re not careful, and if you do, it’ll probably be to the detriment of your choices. This is a group with many gifts. I’m sure one of your gifts is the gift of a smart and capable brain. I’m confident that’s the case because admission is competitive and if there weren’t some signs that you’re clever, the dean of admission wouldn’t have let you in.\n今天我想对你们说的是，天赋和选择的不同。 聪明是一种天赋，而善良是一种选择。 天赋得来容易 —— 毕竟与生俱来。而选择颇为不易。一不小心，你可能会被天赋所诱惑，而这可能会损害到你的选择。 在座各位都拥有众多天赋。我确信你们的天赋之一就是拥有精明能干的头脑。之所以如此确信，是因为入学竞争如此激烈，如果你们不聪明，便不会有资格进入这所学校。\nYour smarts will come in handy because you will travel in a land of marvels. We humans — plodding as we are – will astonish ourselves. We’ll invent ways to generate clean energy and a lot of it. Atom by atom, we’ll assemble tiny machines that will enter cell walls and make repairs. This month comes the extraordinary but also inevitable news that we’ve synthesized life. In the coming years, we’ll not only synthesize it, but we’ll engineer it to specifications. I believe you’ll even see us understand the human brain. Jules Verne, Mark Twain, Galileo, Newton – all the curious from the ages would have wanted to be alive most of all right now. As a civilization, we will have so many gifts, just as you as individuals have so many individual gifts as you sit before me. How will you use these gifts? And will you take pride in your gifts or pride in your choices?\n你们将在一片充满奇迹的世界上前行，聪明才智必能派上用场。我们人类，尽管跬步前行，却终将令自己大吃一惊。我们能够想方设法制造清洁能源等等，也能够一个原子一个原子地组装微型机械，使之穿过细胞壁，去修复细胞。这个月，有一个非常激动人心却又不足为奇的消息 —— 人类终于合成了生命。在未来几年，我们不仅会合成生命，还能将之工程规范化。我相信你们甚至会看到人类大脑被彻底理解。儒勒·凡尔纳、马克·吐温、伽利略、牛顿 —— 所有那些充满好奇之心的人都希望能够活在现在。作为文明人，我们拥有如此多的天赋，就像是坐在我面前的你们，每一个生命个体都拥有众多独特的天赋。如何运用这些天赋？为自己的天赋感到骄傲，还是会为自己的选择感到骄傲？\nI got the idea to start Amazon 16 years ago. I came across the fact that Web usage was growing at 2,300 percent per year. I’d never seen or heard of anything that grew that fast, and the idea of building an online bookstore with millions of titles – something that simply couldn’t exist in the physical world – was very exciting to me. I had just turned 30 years old, and I’d been married for a year. I told my wife MacKenzie that I wanted to quit my job and go do this crazy thing that probably wouldn’t work since most startups don’t, and I wasn’t sure what would happen after that. MacKenzie (also a Princeton grad and sitting here in the second row) told me I should go for it. As a young boy, I’d been a garage inventor. I’d invented an automatic gate closer out of cement-filled tires, a solar cooker that didn’t work very well out of an umbrella and tinfoil, baking-pan alarms to entrap my siblings. I’d always wanted to be an inventor, and she wanted me to follow my passion.\n16 年前，我萌生了创办亚马逊的想法。当年，互联网使用量以每年 2300% 的速度增长，我从未看到或听说过任何东西增长如此快速。有个想法令我异常兴奋 —— 创建涵盖几百万种书籍的网上书店，这东西在物理世界根本无法存在。那时我刚满 30 岁，结婚才一年。我告诉妻子 MacKenzie 想辞去工作，然后去做这件疯狂的事，很可能会失败，因为大部分创业公司都如此，而且我不确定之后会发生什么。MacKenzie （也是普林斯顿毕业生，就坐在下面第二排）告诉我，我应该放手一搏。少年时期，我是一名车库发明家。我曾用水泥填充的轮胎制作自动关门器，用雨伞和锡箔制作太阳能炒锅（虽然不太好用），我还用煎锅做了一个警报器来吓唬邻居。我一直想做一个发明家，MacKenzie 支持我追随内心的热情。\nI was working at a financial firm in New York City with a bunch of very smart people, and I had a brilliant boss that I much admired. I went to my boss and told him I wanted to start a company selling books on the Internet. He took me on a long walk in Central Park, listened carefully to me, and finally said, “That sounds like a really good idea, but it would be an even better idea for someone who didn’t already have a good job.” That logic made some sense to me, and he convinced me to think about it for 48 hours before making a final decision. Seen in that light, it really was a difficult choice, but ultimately, I decided I had to give it a shot. I didn’t think I’d regret trying and failing. And I suspected I would always be haunted by a decision to not try at all. After much consideration, I took the less safe path to follow my passion, and I’m proud of that choice.\n我当时在纽约一家金融公司工作，同事是一群非常聪明的人，老板也很有智慧，我很敬佩他。我告诉老板我想开办一家公司，在网上卖书。老板带我在中央公园漫步良久，认真听我讲完，最后说：「听起来真是一个很好的主意。然而，对那些目前没有谋到一份好工作的人来说，这个主意会更好。」这一逻辑对我而言颇有道理，老板说服我做出最终决定之前再考虑 48 小时。那样想来，这个决定确实很艰难，但是最终，我决定拼一次。 我认为自己不会为尝试过后的失败而遗憾，倒是有所决定但完全不付诸行动会一直煎熬着我。 深思熟虑后，我选择了那条不安全的道路，去追随内心的热情。我为自己的决定感到骄傲。\nTomorrow, in a very real sense, your life – the life you author from scratch on your own – begins.How will you use your gifts? What choices will you make?Will inertia be your guide, or will you follow your passions?Will you follow dogma, or will you be original?Will you choose a life of ease, or a life of service and adventure?Will you wilt under criticism, or will you follow your convictions?Will you bluff it out when you’re wrong, or will you apologize?Will you guard your heart against rejection, or will you act when you fall in love?Will you play it safe, or will you be a little bit swashbuckling? When it’s tough, will you give up, or will you be relentless?Will you be a cynic, or will you be a builder?Will you be clever at the expense of others, or will you be kind?\n明天，非常现实地说，从零塑造自己人生的时代，即将开启。你会如何运用自己的天赋？又会做出怎样的抉择？你会随波逐流，还是追随内心的热情？你会顺从于教条，还是保持初心？你会选择安逸的生活，还是奉献与冒险的人生？你会屈于批评，还是会坚守信念？你会掩饰错误，还是会坦诚道歉？你会因害怕拒绝而掩饰真心，还是会在深爱中勇往直前？你想要波澜不惊，还是想搏击风浪？你会在严峻的现实之下选择放弃，还是会义无反顾前行？你要做愤世嫉俗者，还是踏实建设者？你要不计一切地展示聪明，还是选择善良？\nI will hazard a prediction. When you are 80 years old, and in a quiet moment of reflection narrating for only yourself the most personal version of your life story, the telling that will be most compact and meaningful will be the series of choices you have made. In the end, we are our choices. Build yourself a great story.\nThank you and good luck!\n我要做一个预测：在大家 80 岁追忆往昔的时刻，一个人静静对内心诉说人生故事时，其中最为充实、最有意义的那段故事，会是大家做出的一系列选择。最后， 是选择塑造了我们，为自己塑造一个伟大的故事吧。\n谢谢，祝福好运！\n（完）\n说明：初始译文来自网络，未找到原作者。细节有瑕疵，还有小部分漏译，我做了大量修正。\n原文链接\n","slug":"old_topic/2016-09-17-373","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"718dd50cb1bd8b8045cdc3956cf5b840","title":"MoonScript API","content":"{  target: “reference/api”  template: “reference”  title: “Compiler API”  short_name: “api”}\nMoonScript Compiler APIAutocompiling with the moonscript ModuleAfter installing MoonScript, you can include the moonscript module to makeany Lua script MoonScript aware.\n1require &quot;moonscript&quot;\n\nAfter moonscript is required, Lua’s package loader is updated to search for.moon files on any subsequent calls to require. The search path for .moonfiles is based on the current package.path value in Lua when moonscript isrequired. Any search paths in package.path ending in .lua are copied,rewritten to end in .moon, and then inserted in package.moonpath.\nThe moonloader is the function that is responsible for searchingpackage.moonpath for a file available to be included. It is inserted in thesecond position of the package.loaders table. This means that a matching .moon filewill be loaded over a matching .lua file that has the same base name.\nFor more information on Lua’s package.loaders see Lua Reference Manual&mdash;package.loaders\nThe moonloader, when finding a valid path to a .moon file, will parse andcompile the file in memory. The code is then turned into a function using thebuilt in load function, which is run as the module.\nIf you are executing MoonScript code with the included moon command line toolthen it is not required to include this module before including any otherMoonScript modules.\nmoonscript.base Module1moonscript = require &quot;moonscript.base&quot;\n\nThis module contains an assortment of functions for loading and compilingMoonScript code from within Lua.\nThe module provides load, loadfile, loadstring functions, which areanalogous to the similarly named Lua functions. The major difference is thatthey load MoonScript code instead of Lua code.\n1234moonscript = require &quot;moonscript.base&quot;fn = moonscript.loadstring &#x27;print &quot;hi!&quot;&#x27;fn!\n\nAll of these functions can take an optional last argument, a table of options.The only option right now is implicitly_return_root. Setting this to falsemakes it so the file does not implicitly return its last statement.\n1234567moonscript = require &quot;moonscript.base&quot;fn = moonscript.loadstring &quot;10&quot;print fn! -- prints &quot;10&quot;fn = moonscript.loadstring &quot;10&quot;, implicitly_return_root: falseprint fn! -- prints nothing\n\nOne more useful function is provided: to_lua. This function takes a string ofMoonScript code and returns the compiled Lua result along with the line mappingtable. If there are any errors then nil and the error message are returned.\n123456import to_lua from require &quot;moonscript.base&quot;lua_code, line_tabel = to_lua [[x = 124print &quot;hello world #&#123;x&#125;&quot;]]\n\nSimilar to the load* functions from above, to_lua can take an optionalfinal argument of a table of options.\nThe second return value of to_lua is useful if you want to perform linenumber reversal. It’s a table where the key is a Lua line number and the valueis a character offset from the original MoonScript source.\nProgrammatically CompilingIf you need finer grained control over the compilation process you can use theraw parse and compile modules.\nParsing converts a string of MoonScript into an abstract syntax tree. Compilingconverts an abstract syntax tree into a Lua code string.\nKnowledge of this API may be useful for creating tools to aid the generation ofLua code from MoonScript code. For example, you could build a macro system byanalyzing and manipulating the abstract syntax tree. Be warned though, theformat of the abstract syntax tree is undocumented and may change in thefuture.\nHere is a quick example of how you would compile a MoonScript string to a LuaString (This is effectively the same as the to_lua function described above):\n123456789101112131415parse = require &quot;moonscript.parse&quot;compile = require &quot;moonscript.compile&quot;moon_code = [[(-&gt; print &quot;hello world&quot;)!]]tree, err = parse.string moon_codeunless tree  error &quot;Parse error: &quot; .. errlua_code, err, pos = compile.tree treeunless lua_code  error compile.format_error err, pos, moon_code-- our code is readyprint lua_code","slug":"old_topic/2016-09-17-371","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"054f428f76705613481e9cfa45f6bed2","title":"Nginx+Lua返回JSON类型数据","content":"作者：糖果\nNginx返回JSON数据，一种是直接在配置文件里设置，一种是通过Lua代码封装完成，讲Nginx中执行Lua返回JSON的关键，一个用API函数ngx.say，同时配合json.encode对JSON格式的字符串进行编码，然后设定响应头信息的类型。\nNginx Conf中返回JSON的方式12345678location /json/ &#123;\t    default_type application/json;\t    add_header Content-Type &#x27;text/html; charset=utf-8&#x27;;\t    return 200 &#x27;&#123;&quot;about&quot;:&quot;糖果的Lua教程,&quot;sites&quot;:&quot;lua.ren&quot;&#125;&#x27;;&#125;\n\n\nNginx Lua返回JSON的方式三步操作：\n1.设置HTTP的响应头信息：1ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;\n2.json.encode(“Lua的Table型变量”)：12json = require &quot;cjson&quot; res_json_data = json.encode(ret)\n3.用say函数显示，经过encode的JSON数据。1ngx.say(res_json_data)\n\n用Lua实现以上3个步骤，就实同了JSON数据返回。\n完整代码片段，以下：123json = require &quot;cjson&quot;ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;ngx.say(json.encode(ret))\n\n\n下面的内容就是用Lua封装了几个函数，通过封装快实现了JSON数据的返回。\n一般的Python的WEB框架，都可以的指定返回JSON数据，基本的原理，还是通过指定返回JSON格式的字符串，并且设定HTTP返回时header的Content-Type属性为application/json，来实现返回JSON数据的目地。\n而在Openresty+Lua的框架模式下，不用同时指返回的header类，直接在路由对应的匿名函数中，指定返回一个table类型的即可， 在web框架部分区分判断，如果用户返回的是table类型的数据，直接就用cjson这种库，把table数据渲染成JSON返回。\n依Blues演示框架为例：\n12345678910111213app.run = function()        fun = Route:run(app.router)        if fun then            local ret = fun(app.req, app.id)            local rtype = type(ret)            if rtype == &quot;table&quot;  then                json = require &quot;cjson&quot;                ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;                ngx.say(json.encode(ret))            end         end end \n\n显然，这里只是对返回值的类型是“talbe”的做了处理，也可以对返回类型是“string”或是其它类型的数据做处理。\n1234567891011121314151617app.run = function()        fun = Route:run(app.router)        if fun then            local ret = fun(app.req, app.id)            local rtype = type(ret)            if rtype == &quot;table&quot;  then                json = require &quot;cjson&quot;                ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;                ngx.say(json.encode(ret))            end            if rtype == &quot;string&quot;  then                ngx.header[&#x27;Content-Type&#x27;] = &#x27;text/plain; charset=UTF-8&#x27;                ngx.say(ret)            end        end        le(&#x27;Application.app.run&#x27;)end\n\n没有把这种分类型处理，单独封装成一个方法，简单用这段代码说明问题。\n上面是框架中的代码实现，再来看看如何在测试项目中驱动这个功能。\n12345678910111213141516require &quot;log&quot;local HiLog = require &quot;HiLog&quot;local utils = require &quot;utils.utils&quot;local Application = require &quot;orc&quot;app = Application.new()app:get(&quot;/json&quot;, function(request,id)    return &#123;k=&#x27;key&#x27;, v=&#x27;value&#x27;&#125;    end)app:get(&quot;/string&quot;, function(request,id)    return &quot;Waterfall&quot;end)return app.run()\n这样以来，我们就可以快速的用Openresty + Lua构建超级微级的路由系统，管理渲染JSON数据，构建一个简单的JSON数据请求服务。\nBluesWaterfall\n","slug":"old_topic/2016-09-17-377","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"90f8068c136a1c725371f517843fe478","title":"Openresty OOM 臭虫","content":"Openresty OOM 臭虫最近我在线上改变了一个的 Nginx 配置，导致 OOM（Out of Memory） killer 在 Nginx 加载新配置的过程中 杀死了 Nginx 进程。这是添加到配置中的行：\nlua_ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;\n\n在这篇文章中，我将会阐述我是如何找出这个问题的根本原因、记录在这个过程中现学现用的工具。这篇文章内容细节非常琐碎。在进行深入阅读前，先列下使用的软件栈：\n\nOpenssl 1.0.2j\nOS:Ubuntu Trusty with Linux 3.19.0-80-generic\nNginx:Openresty bundle 1.11.2\nglibc:Ubuntu EGLIBC 2.19-0ubuntu6.9\n\n我们从 OOM Killer 开始。它是一个 Linux 内核函数，当内核不能分配更多的内存空间的时候它将会被触发。OOM Killer 的任务是探测哪一个进程是对系统危害最大（参考 https://linux-mm.org/OOM_Killer,获取更多关于坏评分是如何计算出来的信息），一旦检测出来，将会杀死进程、释放内存。也就是说我遇到的情况是 ，Nginx 是在申请越来越多的内存，最终内核申请内存失败并且触发OOM Killer，杀死 Nginx 进程。\n到此为止，现在让我们看看当 Nginx 重新加载配置的时候做了什么。可以使用 strace 进行跟踪。这是一个非常棒的工具，能在不用阅读源码的情况下查看程序正在做什么。\n在我这里，执行：\nsudo strace -p `cat /var/run/nginx.pid` -f\n\n接着\nsudo /etc/inid.t/nginx reload\n\n-f 选项告诉 strace 也要对子进程进行跟踪。 在http://jvns.ca/zines/#strace-zine.你能看到一个对strace非常好的评价。下面是一个非常有趣的片段，执行完strace后输出的：\n123456789101112131415161718192021[pid 31774] open(&quot;/etc/ssl/certs/ca-certificates.crt&quot;, O_RDONLY) = 5[pid 31774] fstat(5, &#123;st_mode=S_IFREG|0644, st_size=274340, ...&#125;) = 0[pid 31774] mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f6dc8266000[pid 31774] read(5, &quot;-----BEGIN CERTIFICATE-----\\nMIIH&quot;..., 4096) = 4096[pid 31774] read(5, &quot;WIm\\nfQwng4/F9tqgaHtPkl7qpHMyEVNE&quot;..., 4096) = 4096[pid 31774] read(5, &quot;Ktmyuy/uE5jF66CyCU3nuDuP/jVo23Ee&quot;..., 4096) = 4096...&lt;stripped for clarity&gt;...[pid 31774] read(5, &quot;MqAw\\nhi5odHRwOi8vd3d3Mi5wdWJsaWM&quot;..., 4096) = 4096[pid 31774] read(5, &quot;dc/BGZFjz+iokYi5Q1K7\\ngLFViYsx+tC&quot;..., 4096) = 4096[pid 31774] brk(0x26d3000)              = 0x26b2000[pid 31774] mmap(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f6c927c3000[pid 31774] read(5, &quot;/lmci3Zt1/GiSw0r/wty2p5g0I6QNcZ4&quot;..., 4096) = 4096[pid 31774] read(5, &quot;iv9kuXclVzDAGySj4dzp30d8tbQk\\nCAU&quot;..., 4096) = 4096...&lt;stripped for clarity&gt;...[pid 31774] read(5, &quot;ye8\\nFVdMpEbB4IMeDExNH08GGeL5qPQ6&quot;..., 4096) = 4096[pid 31774] read(5, &quot;VVNUIEVs\\nZWt0cm9uaWsgU2VydGlmaWt&quot;..., 4096) = 4004[pid 31774] read(5, &quot;&quot;, 4096)           = 0[pid 31774] close(5)                    = 0[pid 31774] munmap(0x7f6dc8266000, 4096) = 0\n\n\n\n这段重复了很多次！有两行非常有意思。\nopen(&quot;/etc/ssl/certs/ca-certificates.crt&quot;, O_RDONLY) = 5\n\n这行意味着是跟修改的配置（上面提到的修改）有关的操作，\nmmap(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f6c927c3000\n\n这行意味着在read过程中间请求内核分配 1M 内存空间。\n在 strace 的输出中，另一个有意思的细节是分配的内存从来没有执行munmap进行释放。注意在调用close后0x7f6dc8266000才被传入munmap。\n这些事实让我相信 ，当设置lua_ssl_trusted_certificate这条指令后，Nginx 发生了 内存泄露（尽管我对底层调试几乎没有任何经验）。什么？Nginx 发生了内存泄露，难道那还不让人兴奋？！不要这么兴奋。\n为了找出是Nginx 的哪个组件发生了内存泄露，我决定使用 gdb。如果编译程序的时候打开了调试符号选项，gdb将会非常有用。如上所述，我使用的是 Nginx Openresty 套件， 需要使用下面的命令开启调试符号选项重新编译：\n~/openresty-1.11.2.2 $ ./configure -j2 --with-debug --with-openssl=../openssl-1.0.2j/ --with-openssl-opt=&quot;-d no-asm -g3 -O0 -fno-omit-frame-pointer -fno-inline-functions&quot;\n\n--with-openssl-opt=&quot;-d no-asm -g3 -O0 -fno-omit-frame-pointer -fno-inline-functions&quot; 确保 OpenSSL 编译的时候也开启调试符号信息。现在已经在Openresty的可执行程序中带有了调试符号信息，能通过gdb启动运行、找到上面提到的触发mmap的具体的调用函数。\n首先我们需要启动gdb调试 Openresty 可执行程序：\nsudo gdb `which openresty`\n\n这个命令将打开gdb命令行，像下面这样：\n123456789101112131415161718GNU gdb (Ubuntu 7.7.1-0ubuntu5~14.04.2) 7.7.1Copyright (C) 2014 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.  Type &quot;show copying&quot;and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from /usr/local/openresty/bin/openresty...done.(gdb)\n\n接下来，设置程序的命令行参数\n(gdb) set args -p `pwd` -c nginx.conf\n\n这将使gdb在启动 Opneresty/Nginx 的时候把给出的命令行参数传递过去。接着配置断点，使其能够暂停程序到某一个文件的某一行或者是某一个函数。因为我想找出在open打开信任的验证文件后，那个令人奇怪的mmap的调用者，所以我首先添加了一个断点在\nopen(&quot;/etc/ssl/certs/ca-certificates.crt&quot;, O_RDONLY) = 5\n\n断点设置如下：\nbreak open if strcmp($rdi, &quot;/etc/ssl/certs/ca-certificates.crt&quot;) == 0\n\n如果你先前没有了解过gdb，gdb 是非常棒的工具，可以使用它添加一个自定义的条件来创建复杂的断点。这里我们告诉gdb暂停程序，如果open函数被调用并且rdi寄存器指向的数据是 /etc/ssl/certs/ca-certificates.crt 。我不知道是否还有更好的方式，我是在反复尝试后，发现open函数的第一个参数（文件路径）保存在了rdi寄存器，所以才会如此设置断点。现在告诉gdb运行程序：\n(gdb) run\n\n第一次出现open(&quot;/etc/ssl/certs/ca-certificates.crt&quot;, O_RDONLY)调用时，gdb将会暂停程序执行。现在我们可以使用其他的gdb辅助命令观察此刻程序的内部状态。下面是程序执行到断点的时候的内部状态：\n12345678910111213141516171819202122232425Breakpoint 1, open64 () at ../sysdeps/unix/syscall-template.S:8181  ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) bt#0  open64 () at ../sysdeps/unix/syscall-template.S:81#1  0x00007ffff6a3dec8 in _IO_file_open (is32not64=8, read_write=8, prot=438, posix_mode=&lt;optimized out&gt;, filename=0x7fffffffdb00 &quot;\\346\\f\\362\\367\\377\\177&quot;, fp=0x7ffff7f28a10) at fileops.c:228#2  _IO_new_file_fopen (fp=fp@entry=0x7ffff7f28a10, filename=filename@entry=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, mode=&lt;optimized out&gt;, mode@entry=0x6fb62d &quot;r&quot;, is32not64=is32not64@entry=1) at fileops.c:333#3  0x00007ffff6a323d4 in __fopen_internal (filename=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, mode=0x6fb62d &quot;r&quot;, is32=1) at iofopen.c:90#4  0x00000000005b3fd2 in file_fopen (filename=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, mode=0x6fb62d &quot;r&quot;) at bss_file.c:164#5  0x00000000005b3fff in BIO_new_file (filename=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, mode=0x6fb62d &quot;r&quot;) at bss_file.c:172#6  0x00000000005e8ad3 in X509_load_cert_crl_file (ctx=0x7ffff7f289e0, file=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, type=1) at by_file.c:251#7  0x00000000005e8626 in by_file_ctrl (ctx=0x7ffff7f289e0, cmd=1, argp=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, argl=1, ret=0x0) at by_file.c:115#8  0x00000000005e5747 in X509_LOOKUP_ctrl (ctx=0x7ffff7f289e0, cmd=1, argc=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, argl=1, ret=0x0) at x509_lu.c:120#9  0x00000000005dd5c1 in X509_STORE_load_locations (ctx=0x7ffff7f28750, file=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, path=0x0) at x509_d2.c:94#10 0x0000000000546e22 in SSL_CTX_load_verify_locations (ctx=0x7ffff7f27fd0, CAfile=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, CApath=0x0) at ssl_lib.c:3231#11 0x0000000000477d94 in ngx_ssl_trusted_certificate (cf=cf@entry=0x7fffffffe150, ssl=0x7ffff7f27a78, cert=cert@entry=0x7ffff7f22f20, depth=&lt;optimized out&gt;) at src/event/ngx_event_openssl.c:687#12 0x00000000004f0a1b in ngx_http_lua_set_ssl (llcf=0x7ffff7f22ef8, cf=0x7fffffffe150) at ../ngx_lua-0.10.7/src/ngx_http_lua_module.c:1240#13 ngx_http_lua_merge_loc_conf (cf=0x7fffffffe150, parent=0x7ffff7f15808, child=0x7ffff7f22ef8) at ../ngx_lua-0.10.7/src/ngx_http_lua_module.c:1158#14 0x000000000047e2b1 in ngx_http_merge_servers (cmcf=&lt;optimized out&gt;, cmcf=&lt;optimized out&gt;, ctx_index=&lt;optimized out&gt;, module=&lt;optimized out&gt;, cf=&lt;optimized out&gt;) at src/http/ngx_http.c:599#15 ngx_http_block (cf=0x7fffffffe150, cmd=0x0, conf=0x1b6) at src/http/ngx_http.c:269#16 0x0000000000460b5b in ngx_conf_handler (last=1, cf=0x7fffffffe150) at src/core/ngx_conf_file.c:427#17 ngx_conf_parse (cf=cf@entry=0x7fffffffe150, filename=filename@entry=0x7ffff7f0b9e8) at src/core/ngx_conf_file.c:283#18 0x000000000045e2f1 in ngx_init_cycle (old_cycle=old_cycle@entry=0x7fffffffe300) at src/core/ngx_cycle.c:274#19 0x000000000044cef4 in main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;) at src/core/nginx.c:276\n\n\n真令人兴奋，gdb向我们展示了完整的函数调用栈及参数！查看此刻寄存器中的数据，可以用 info registers命令。为了更好的理解调用栈，我查看了一下 Nginx的内部工作流程（我记得Openresty仅仅是组装了一些额外的模块的Nginx）。Nginx 内部所有的（除了Nginx 核心）都被实现为模块，这些模块注册 handlers 和 filters。Nginx 的配置文件主要有三个主要的块组成，分别是main、server、location。假设您的自定义Nginx模块引入了一个新的配置指令，那么您还需要注册一个处理程序（handler）来处理该指令的配置的值。因此整个过程如下 Nginx 解析配置文件，每一个配置部分解析后就会调用注册的相应处理程序。下面是lua-nginx-module（Openresty Nginx 组件的核心模块）的实现：\n12345678910111213141516171819202122ngx_http_module_t ngx_http_lua_module_ctx = &#123;#if (NGX_HTTP_LUA_HAVE_MMAP_SBRK)                                            \\    &amp;&amp; (NGX_LINUX)                                                           \\    &amp;&amp; !(NGX_HTTP_LUA_HAVE_CONSTRUCTOR)    ngx_http_lua_pre_config,          /*  preconfiguration */#else    NULL,                             /*  preconfiguration */#endif    ngx_http_lua_init,                /*  postconfiguration */    ngx_http_lua_create_main_conf,    /*  create main configuration */    ngx_http_lua_init_main_conf,      /*  init main configuration */    ngx_http_lua_create_srv_conf,     /*  create server configuration */    ngx_http_lua_merge_srv_conf,      /*  merge server configuration */    ngx_http_lua_create_loc_conf,     /*  create location configuration */    ngx_http_lua_merge_loc_conf       /*  merge location configuration */&#125;;\n\n\n这里是 Nginx 模块注册的处理程序。从注释中你也可以看到，Nginx 解析出来一个 location 配置 就会调用 ngx_http_lua_merge_loc_conf  将配置和 main 块合并。回到我们的上面的gdb输出,可以看到#13就是这个函数调用。默认情况下对于每一个 location 块配置这个函数将会被调用。通过源码我们可以看到这个函数直接去读去配置值、继承server中的配置条目、设置默认值。如果设置了lua_ssl_trusted_certificate 指令，可以看到其中调用了ngx_http_lua_set_ssl,在其内部又调用了Nginx SSL 模块的 ngx_ssl_trusted_certificate。ngx_ssl_trusted_certificate 是一个非常简单的函数，对于给定的配置块（一个location 块），设置SSL 环境(context)的验证深度，调用另外一个 OpenSSL API 加载验证文件（还有一些错误处理）。\n123456789101112131415161718192021222324252627282930313233340649 ngx_int_t0650 ngx_ssl_trusted_certificate(ngx_conf_t *cf, ngx_ssl_t *ssl, ngx_str_t *cert,0651     ngx_int_t depth)0652 &#123;0653     SSL_CTX_set_verify_depth(ssl-&gt;ctx, depth);0654 0655     if (cert-&gt;len == 0) &#123;0656         return NGX_OK;0657     &#125;0658 0659     if (ngx_conf_full_name(cf-&gt;cycle, cert, 1) != NGX_OK) &#123;0660         return NGX_ERROR;0661     &#125;0662 0663     if (SSL_CTX_load_verify_locations(ssl-&gt;ctx, (char *) cert-&gt;data, NULL)0664         == 0)0665     &#123;0666         ngx_ssl_error(NGX_LOG_EMERG, ssl-&gt;log, 0,0667                       &quot;SSL_CTX_load_verify_locations(\\&quot;%s\\&quot;) failed&quot;,0668                       cert-&gt;data);0669         return NGX_ERROR;0670     &#125;0671 0672     /*0673      * SSL_CTX_load_verify_locations() may leave errors in the error queue0674      * while returning success0675      */0676 0677     ERR_clear_error();0678 0679     return NGX_OK;0680 &#125;\n\nNginx SSL 模块的完整代码在这里能找到。\n现在我们已经走到调用栈的一半了，并且走出了 Nginx的世界。下一个函数调用是SSL_CTX_load_verify_locations，来自于 OpenSSL。程序在这里程序打开了信任的验证文件，并且暂停。接下来将会读取文件（根据上面的strace输出）。\n由于我最初的目的就是找出是谁调用了令人奇怪的mmap 调用，很自然的下一个断点就是:\n(gdb) b mmap\n\nb是break的简写。(gdb) c将会继续程序的执行。程序暂停在了下一个断点：\n1234567891011121314151617181920212223Breakpoint 3, mmap64 () at ../sysdeps/unix/syscall-template.S:8181  ../sysdeps/unix/syscall-template.S: No such file or directory.(gdb) bt#0  mmap64 () at ../sysdeps/unix/syscall-template.S:81#1  0x00007ffff6a44ad2 in sysmalloc (av=0x7ffff6d82760 &lt;main_arena&gt;, nb=48) at malloc.c:2495#2  _int_malloc (av=0x7ffff6d82760 &lt;main_arena&gt;, bytes=40) at malloc.c:3800#3  0x00007ffff6a466c0 in __GI___libc_malloc (bytes=40) at malloc.c:2891#4  0x000000000057d829 in default_malloc_ex (num=40, file=0x6f630f &quot;a_object.c&quot;, line=350) at mem.c:79#5  0x000000000057deb9 in CRYPTO_malloc (num=40, file=0x6f630f &quot;a_object.c&quot;, line=350) at mem.c:346&lt;internal OpenSSL function calls stripped for clarity&gt;#30 0x000000000065e2f7 in PEM_X509_INFO_read_bio (bp=0x7ffff7f28c50, sk=0x0, cb=0x0, u=0x0) at pem_info.c:248#31 0x00000000005e8b22 in X509_load_cert_crl_file (ctx=0x7ffff7f289e0, file=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, type=1) at by_file.c:256#32 0x00000000005e8626 in by_file_ctrl (ctx=0x7ffff7f289e0, cmd=1, argp=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, argl=1, ret=0x0) at by_file.c:115#33 0x00000000005e5747 in X509_LOOKUP_ctrl (ctx=0x7ffff7f289e0, cmd=1, argc=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, argl=1, ret=0x0) at x509_lu.c:120#34 0x00000000005dd5c1 in X509_STORE_load_locations (ctx=0x7ffff7f28750, file=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, path=0x0) at x509_d2.c:94#35 0x0000000000546e22 in SSL_CTX_load_verify_locations (ctx=0x7ffff7f27fd0, CAfile=0x7ffff7f20ce6 &quot;/etc/ssl/certs/ca-certificates.crt&quot;, CApath=0x0) at ssl_lib.c:3231#36 0x0000000000477d94 in ngx_ssl_trusted_certificate (cf=cf@entry=0x7fffffffe150, ssl=0x7ffff7f27a78, cert=cert@entry=0x7ffff7f22f20, depth=&lt;optimized out&gt;) at src/event/ngx_event_openssl.c:687#37 0x00000000004f0a1b in ngx_http_lua_set_ssl (llcf=0x7ffff7f22ef8, cf=0x7fffffffe150) at ../ngx_lua-0.10.7/src/ngx_http_lua_module.c:1240#38 ngx_http_lua_merge_loc_conf (cf=0x7fffffffe150, parent=0x7ffff7f15808, child=0x7ffff7f22ef8) at ../ngx_lua-0.10.7/src/ngx_http_lua_module.c:1158#39 0x000000000047e2b1 in ngx_http_merge_servers (cmcf=&lt;optimized out&gt;, cmcf=&lt;optimized out&gt;, ctx_index=&lt;optimized out&gt;, module=&lt;optimized out&gt;, cf=&lt;optimized out&gt;) at src/http/ngx_http.c:599&lt;Nginx function calls stripped for clarity&gt;\n\n此刻我异常兴奋。我“发现”了一个OpenSSL内存泄露！带着异常兴奋的情绪，我开始阅读理解 上个世纪90年代就开发的 OpenSSL 的代码。如此高兴，接下来的几天几夜去理解这写函数并且试图找到我非常确定的函数中的内存泄露。看了许多给 OpenSSL 的内存泄露bug（尤其是和上面这个函数相关的）后，我信心大增，因此我有花了几天几夜去捉这个臭虫！\n基本上这些函数做的事情是 首先打开受信任的证书文件，分配缓冲（4096字节），从文件中读取 4KB 内容到缓冲区，解密数据，转换成 OpenSSL 的内部表示，保存到给定的SSL context的证书存储区（这个属于一个 location 块上下文环境）。因此以后无论何时，在这个location块中，当Nginx需要验证SSL 客户端证书的时候，都将会调用OpneSSL 中的SSL_get_verify_result传递开始保存保存的 SSL context。接着那个函数将会使用已经加载的和内部初始化的受信任证书验证客户端。\n这就是日日夜夜学习的那些所有的事情如何在一起工作的收获，但是没有发现一个bug。\n也了解到mmap是被在CRYPTO_malloc 触发的malloc调用的，CRYPTO_malloc是另一个OpenSSL 函数，用来扩展证书存储大小，使其可以适应解密和内部初始化的证书数据。现在我已经知道究竟发生了什么，其不会释放所分配的内存，因为OpenSSL在这个进程生命周期中的后面可能会使用。\n但是这个主要的问题 ，当lua_ssl_trusted_certificate  指令配置后，为什 么 Nginx 消耗的内存增长如此之快，还是一个谜。 \n从我手中掌握的已有数据来看是每个 location 块中的 mmap导致了这个问题。现在我决定提出 Openresty/Nginx 中的相关代码，用相同的 OpenSSL API 写一个独立C程序加载配置文件。\n反复调用模拟多个 location 块（我这里是5000个）:\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdint.h&gt;#include &lt;sys/mman.h&gt;#include &lt;openssl/ssl.h&gt;#include &lt;malloc.h&gt;#include &lt;unistd.h&gt;void read_cert() &#123;        const char ca_bundlestr[] = &quot;/etc/ssl/certs/ca-certificates.crt&quot;;        BIO               *outbio = NULL;        int ret;        SSL_CTX *ctx;        outbio  = BIO_new_fp(stdout, BIO_NOCLOSE);        SSL_library_init();        SSL_load_error_strings();        OpenSSL_add_all_algorithms();        ctx = SSL_CTX_new(SSLv23_method());        SSL_CTX_set_mode(ctx, SSL_MODE_RELEASE_BUFFERS);        SSL_CTX_set_mode(ctx, SSL_MODE_NO_AUTO_CHAIN);        SSL_CTX_set_read_ahead(ctx, 1);        ret = SSL_CTX_load_verify_locations(ctx, ca_bundlestr, NULL);        if (ret == 0)                BIO_printf(outbio, &quot;SSL_CTX_load_verify_locations failed&quot;);        BIO_free_all(outbio);        SSL_CTX_free(ctx);&#125;int main() &#123;        int i = 0;        for (i = 0; i &lt; 5000; i++) &#123;                read_cert();                //malloc_trim(0);        &#125;        malloc_stats();&#125;\n\n如果我能解决这里的问题，我就能解决 Openresty/Nginx 中的问题，由于这是等价于原问题的。但是猜猜发生了什么，strace 的输出跟我预期的不同！\n12345678910111213141516171819202122...read(3, &quot;fqaEQn6/Ip3Xep1fvj1KcExJW4C+FEaG&quot;..., 4096) = 4096read(3, &quot;IYWxvemF0Yml6dG9u\\nc2FnaSBLZnQuMR&quot;..., 4096) = 4096read(3, &quot;nVz\\naXR2YW55a2lhZG8xHjAcBgkqhkiG&quot;..., 4096) = 4096read(3, &quot;A\\nMIIBCgKCAQEAy0+zAJs9Nt350Ulqax&quot;..., 4096) = 4096read(3, &quot;MRAwDgYDVQQHEwdDYXJhY2FzMRkwFwYD&quot;..., 4096) = 4096read(3, &quot;OR1YqI0JDs3G3eicJlcZaLDQP9nL9bFq&quot;..., 4096) = 4096read(3, &quot;E7zelaTfi5m+rJsziO+1ga8bxiJTyPbH&quot;..., 4096) = 4096read(3, &quot;Xtdj182d6UajtLF8HVj71lODqV0D1VNk&quot;..., 4096) = 4096read(3, &quot;AAOCAQ8AMIIBCgKCAQEAt49VcdKA3Xtp&quot;..., 4096) = 4096brk(0x1cfb000)                          = 0x1cfb000read(3, &quot;396gwpEWoGQRS0S8Hvbn+mPeZqx2pHGj&quot;..., 4096) = 4096read(3, &quot;QYwDwYDVR0T\\nAQH/BAUwAwEB/zANBgkq&quot;..., 4096) = 4096read(3, &quot;ETzsemQUHS\\nv4ilf0X8rLiltTMMgsT7B&quot;..., 4096) = 4096read(3, &quot;wVU3RhYXQgZGVyIE5lZGVybGFuZGVuMS&quot;..., 4096) = 4096read(3, &quot;N/uLicFZ8WJ/X7NfZTD4p7dN\\ndloedl4&quot;..., 4096) = 4096read(3, &quot;fzDtgUx3M2FIk5xt/JxXrAaxrqTi3iSS&quot;..., 4096) = 4096read(3, &quot;sO+wmETRIjfaAKxojAuuK\\nHDp2KntWFh&quot;..., 4096) = 4096read(3, &quot;8z+uJGaYRo2aWNkkijzb2GShROfyQcsi&quot;..., 4096) = 4096read(3, &quot;CydAXFJy3SuCvkychVSa1ZC+N\\n8f+mQA&quot;..., 4096) = 4096...\n\nbrk 调用后面没有 mmap 调用，内存消耗也没有按照超出预期的增长！\n好吧，我现在非常恼火也想放弃。但是我我的好奇心没让我放弃。我决定了解更多的关于内存分配如何工作的。\n通常来说当程序中申请更多的内存的时候会调用glibc中的malloc(或者改版)。对于用户空间的程序，glibc抽象了很多内存管理的工作、提供了一个使用虚拟内存的 API 。\n默认情况下，当一个程序调用malloc的申请更多的堆上内存时候，将会使用brk申请需要的内存空间。如果堆上有洞，brk将不能正常工作。\n现在假设你有1G的堆上内存空闲空间。在上面直接创建一个洞，可以使用mmap指定具体地址A 这种方式，指定内存空间大小。这样mmap就会从堆上的内存地址A开始，申请指定大小的内存空间。\n但是因为程序中断点还在堆开始的地方,这时如果使用sbrk函数申请的B &gt; A 字节大小的内存空间，此次请求将会失败，因为brk尝试申请的一部分内存区域已经被分配（洞）。这时候malloc会使用mmap代替申请内存空间。\n因为mmap调用代价非常高，为了降低其调用次数，malloc 申请 1M内存即使申请分配的内存不足1M。https://code.woboq.org/userspace/glibc/malloc/malloc.c.html#406 注释文档中也有记载。你会发现上面的输出日志中，令人奇怪的mmap调用申请1048576字节内存，正好是1M–当brk失败后，malloc使用此默认值去调用mmap。\n高潮来了！！！把这些线索放一起。一个明显的猜想是 brk 调用后面是mmap调用在Openresty 上下文环境中，但是在独立的c中却不是，因为 Openresty 在配置文件加载之前 在某个地方创建了一个洞。 \n这不难验证，使用grep 命令在PRs,issus和lua-nginx-module源码中查找。最后发现Luajit 需要工作在低地址空间获得更高的效率，这是为什么lua-nginx-module那群家伙决定在程序开始执行之前执行下面这段代码：\n1234if (sbrk(0) &lt; (void *) 0x40000000LL) &#123;    mmap(ngx_align_ptr(sbrk(0), getpagesize()), 1, PROT_READ,         MAP_FIXED|MAP_PRIVATE|MAP_ANON, -1, 0);&#125;\n\n\n完整代码可以在仓库中找到。现在我还没太弄明白这段代码是如何让luajit拥有低地址空间的（如果有人能在评论里面解释清楚，我将非常感激），但是这确实是导致这个问题的代码。\n为了证明，我拷贝出来这段代码到我的 独立 C 程序中：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;stdint.h&gt;#include &lt;sys/mman.h&gt;#include &lt;openssl/ssl.h&gt;#include &lt;malloc.h&gt;#include &lt;unistd.h&gt;#define ngx_align_ptr(p, a) \\        (u_char *) (((uintptr_t) (p) + ((uintptr_t) a - 1)) &amp; ~((uintptr_t) a - 1))ngx_http_lua_limit_data_segment(void) &#123;        if (sbrk(0) &lt; (void *) 0x40000000LL) &#123;                mmap(ngx_align_ptr(sbrk(0), getpagesize()), 1, PROT_READ,                                MAP_FIXED|MAP_PRIVATE|MAP_ANON, -1, 0);        &#125;&#125;void read_cert() &#123;        const char ca_bundlestr[] = &quot;/etc/ssl/certs/ca-certificates.crt&quot;;        BIO               *outbio = NULL;        int ret;        SSL_CTX *ctx;        outbio  = BIO_new_fp(stdout, BIO_NOCLOSE);        SSL_library_init();        SSL_load_error_strings();        OpenSSL_add_all_algorithms();        ctx = SSL_CTX_new(SSLv23_method());        SSL_CTX_set_mode(ctx, SSL_MODE_RELEASE_BUFFERS);        SSL_CTX_set_mode(ctx, SSL_MODE_NO_AUTO_CHAIN);        SSL_CTX_set_read_ahead(ctx, 1);        ret = SSL_CTX_load_verify_locations(ctx, ca_bundlestr, NULL);        if (ret == 0)                BIO_printf(outbio, &quot;SSL_CTX_load_verify_locations failed&quot;);        BIO_free_all(outbio);        SSL_CTX_free(ctx);&#125;int main() &#123;        ngx_http_lua_limit_data_segment();        int i = 0;        for (i = 0; i &lt; 5000; i++) &#123;                read_cert();                //malloc_trim(0);        &#125;        malloc_stats();        usleep(1000 * 60);&#125;\n\n\n当我编译运行这段程序的时候，通过strace我能看到和Openresty环境中相同的行为。为了更进一步的确认，我编辑Opneresty的源码、注释掉ngx_http_lua_limit_data_segment、重新编译运行，内存增长的现象没有发生。\n搞定！！！\n上面就是我这次的收获。根据这次结果，我提交了一个issue。当你有很多的location 块的时候，这真的会成为一个问题。例如加入你有一个很大的 Nginx 配置文件，里面有超过4k 个location 块，然后你加入了lua_ssl_trusted_certificate指令到 mian 配置块，然后当你 reload/restart/start Nginx 的时候，内存消耗将会增长到~4G(4k * 1MB)并且不会释放。\n原文\n原文链接\n在lua-nginx-module 中，一个内存相关的黑魔法导致冗余的大内存分配。\n","slug":"old_topic/2016-09-17-376","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"5eeea6ebd87d9454a6342cbab6e0f1fc","title":"Blues框架如何取得请求者的Rquest信息","content":"Blues框架如何取得请求者的Rquest信息\n在request.lua下引用nginx.lua这个lazytable库。\n123456789101112131415161718192021local params = require &quot;nginx&quot;function Request:getInstance()        local name = &quot;request&quot;        local instance = &#123;                         url=&quot;/request&quot;,                        getName = function()                                lp(&quot;CRequest!&quot;)                        end                         &#125;           instance.uri = &quot;candy lab&quot;        instance.params = params        setmetatable(instance, &#123; __index = self,                                 __call = function()                                                lp(&quot;Initial Instance&quot;)                                        end                                  &#125;)          return instanceend\n\n\napp.lua\n123456app:get(&quot;/blues&quot;, function(request,id)    for k,v in pairs(request.params) do        ngx.say(k)    end     return &#123;k=&#x27;key&#x27;, v=&#x27;value&#x27;&#125;end)","slug":"old_topic/2016-09-17-378","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"9a08798d6ed47e5066c21c10dcfbe72f","title":"反扫描可视化","content":"威胁情报可视化，一直以来对安全人员分析安全事件起着有益的作用， 可视化是对分析的结果一种图形化的映射，是威胁行为的一种图形具象化。\n针对蜜罐日志分析的流程来讲，溯源和展示攻击行为本身也是很重要的。\n一般比较传统的日志分析方式是：\n\n蜜罐向类似mysql这种库中写入被访问的IP地址和Port，启动定时任务读取数据库，取出数据库当条目总数，与之前本地保存的最大数进行比较 发现，数据库中的日志记录变多了，就将这些数据取出，进行分析和报警。 \n\n另一种方式是依赖ips,ids这种设备，对网段内的所有蜜罐的流量进行监控，发现有任何触发蜜罐的访问就进行数据的报警分析，不好的地方是，除了要依赖这些设备 ，ids和ids本身对蜜罐被访问策略控制比较单一,另外如果想进一步的想取得访问的payload也需要与ids，ips再次交互取，不同产商的设备特点不统一。 \n\n\n\n还有一种方案是，除了构建蜜网之外，再构建一个日志中心（ES集群+Openresty）一方面可以通过在设备上加agent把数据传回日志中心,另一方面日志中心本身也是一个REST网关，接受多种 形志的日志推送，这个方案是有构建成本的，但是一旦构建好，策略处理就比较灵活，push和poll模式下都可以，接受push数据过来，进行实性分析和显示更直观。\n\n\n图a-1一个典型的用例，poll模式下对日志中心的REST服务的使用，可以像最传统方式一样，起动定时任务，按时间段范围，对当前指定时间内，所有（用户ID，或DeviceID，或IP）访问日志数量大的访问（IP）进行降排（数据源可以来自蜜罐，或是其它设备），并对被访问IP的PORT进行联合枚举分析，如果某个IP访问量大，访问PORT范围大，或是访问 非常规Port，可以进入新的报警与分析阶段。 关于非常规的Port数据，可以对网内常规的PORT进行数据汇聚，常规以外的就是不常规的，汇聚可在对机器进行扫描时，把网内IP的常开PORT进行序列化，生成数据指纹，与之后 的蜜网数据进行联合分析。 \n上图a-1，既是对一次用户抄描形为的图形展现。\n供参考。\n","slug":"old_topic/2016-09-17-372","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"805020bcfe4a2b05d104deeb78f27106","title":"如何读取request的body数据","content":"作者：糖果\n我们通过curl向openresty服务器端请求rest，采用GET请求方式，提交一个json,然后路由到对应的匿名函数，通过request.params.body直接取得json数据主体，解析成table变量，放回渲染。下面：\n1curl -X GET  http://0.0.0.0/blues -d  &#x27;&#123;&quot;key&quot;:&quot;value&quot;&#125;&#x27;\n\n\n12345678app:get(&quot;/blues&quot;, function(request,id)    local ret = request.params.body    local json = require &quot;cjson&quot;    local util = require &quot;cjson.util&quot;    local t = json.decode(ret)    ngx.say(util.serialise_value(t))    return retend)\n\n\n结果：\n1234&#123;  [&quot;key&quot;] = &quot;value&quot;&#125;&#123;&quot;key&quot;:&quot;value&quot;&#125;\n\n\n\n123456app:get(&quot;/blues&quot;, function(request,id)    local ret = request.params.body    local json = require &quot;cjson&quot;    local t = json.decode(ret)    return tend)\n\n结果：\n1&#123;&quot;key&quot;:&quot;value&quot;&#125;","slug":"old_topic/2016-09-17-379","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"babc875b7e0a7de20c19f4de9786a53d","title":"xml-sitemaps.com自动生成网站sitemap","content":"xml-sitemaps.com自动生成网站sitemap,之前这网站是，根据数库后台数生成sitemap.xml和sitemap.html. 这种方式很自动化，但有没有一种工具，可以不通过自己写的代码，直接在前台输入网站地址就会生成相应的文件呢，有就是www.xml-sitemaps.com，可以看一下http://lua.ren/sitemap.html\n","slug":"old_topic/2016-09-17-374","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"6f22cd23969a4d12ca816a42b73ce9e8","title":"如何在Openresty中实现一个REST服务","content":"作者：糖果\n使用Blues框架在Openresty中实现一个REST服务解析和返回JSON数据，并通过curl向openresty服务器端请求rest，采用GET请求方式，提交一个json,然后路由到对应的匿名函数，通过request.params.body直接取得json数据主体，解析成table变量，放回渲染。下面：\n1-1.接口测试通过CURL调用我们将要实现的REST接口:\n1curl -X GET  http://0.0.0.0/blues -d  &#x27;&#123;&quot;key&quot;:&quot;value&quot;&#125;&#x27;\n\n在app.lua加入如下函数:\n1-2.接口实现（案A）app.lua \n123456789101112131415161718app:get(&quot;/blues&quot;, function(request,id)    --读取用户请求中的body数据    local ret = request.params.body        --调用cjso库    local json = require &quot;cjson&quot;    local util = require &quot;cjson.util&quot;        --对用户请求的数据进入JSON编码， 转成Table变量。    local t = json.decode(ret)        --递归显示JSON结构中的所有数据。    ngx.say(util.serialise_value(t))        --返回一个JSON数据结构    return retend)\n\n1-3.返回结果调用结果，如下：\n1234&#123;  [&quot;key&quot;] = &quot;value&quot;&#125;&#123;&quot;key&quot;:&quot;value&quot;&#125;\n\n\n2-1.接口实现（案B）下面我们去掉多余的JSON遍历部分，直接将用户请求中的JSON数据转成LUA的Table变量，然后再把个Table变量，返回为一个JSON进行渲染。\napp.lua\n123456app:get(&quot;/blues&quot;, function(request,id)    local ret = request.params.body    local json = require &quot;cjson&quot;    local t = json.decode(ret)    return tend)\n\n2-2.返回结果调用结果，如下：\n1&#123;&quot;key&quot;:&quot;value&quot;&#125;\n\n\n\n3-1.接口实现（案c）12345app:get(&quot;/blues&quot;, function(request,id)    ngx.say(&quot;==============&quot;)    local t = utils:to_json(request)    return t end)\n\n3-2.返回结果12==============&#123;&quot;key&quot;:&quot;value&quot;&#125;\n\n\nC方案就是我们将之前的cjson做的json编码工作进行了封装，封装成了一个叫to_json函数来完成这个工作。\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n糖果实验室\nhttp://www.candylab.net\n","slug":"old_topic/2016-09-17-380","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"6565f98206b7c6f49f5b3e935831f11b","title":"Moonscript的Map声明差异","content":"Moonscript的Map声明差异\n在Moonscript中，第一种table map的声明，对变量的赋值使用的是：“=”，，而第二种使用的方式是：“：”，可以通过下面moonc生成的代码，看出差异在那里：\n使用：“=”\n12345678910stats= &#123;    buffer_size_limit: t[&#x27;journal_size_limit&#x27;],    buffer_size: t[&#x27;journal_size&#x27;],&#125;  local stats = &#123;    buffer_size_limit = t[&#x27;journal_size_limit&#x27;],    buffer_size = t[&#x27;journal_size&#x27;]  &#125;\n\n\n使用：“：”\n1234567891011stats: &#123;    buffer_size_limit: t[&#x27;journal_size_limit&#x27;],    buffer_size: t[&#x27;journal_size&#x27;],&#125;  local _ = &#123;    stats = &#123;      buffer_size_limit = t[&#x27;journal_size_limit&#x27;],      buffer_size = t[&#x27;journal_size&#x27;]    &#125;  &#125;\n\n而上述这种差异，会在什么地方起作用呢？\n123456789101112json = require &quot;cjson&quot;util = require &quot;cjson.util&quot;stats= &#123;    buffer_size_limit: t[&#x27;journal_size_limit&#x27;],    buffer_size: t[&#x27;journal_size&#x27;],&#125;json: &#123;   success: true   message: json.encode(stats)&#125;     \n在Cjson的encode时，如果选用的表变量是”:”声明，基本是无法编码成json出来的，不出意外，返回的就是一个’null’。\n","slug":"old_topic/2016-09-17-375","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"3e4806ea54f2e91c20a1148ca6b83f31","title":"函数返回的结果是函数的返回的结果不是函数","content":"函数返回的结果是函数的返回的结果不是函数\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758function read(self)    print(&quot;key:&quot;..self.key)endenable = function(func)      self = &#123;key=&#x27;value&#x27;&#125;      local fn = func       if type(fn) == &quot;function&quot; then        return fn(self)      end endenable(read)function test()    print(&quot;test&quot;)    return true endparams = function(func)    if func == false then        return function() print(&#x27;params error&#x27;) end     end     return function(request, id)         print(&quot;request&quot;)    end endret = params(test())ret()function json(func)    if type(func) == &quot;function&quot; then         print(&#x27;json&#x27;)        return func    end endfunction get(request, id)         print(&#x27;get&#x27;)end ret = json(get)ret()function pprint(self, ...)    print(self)    print(...)endpprint(&quot;test pprint&quot;, 1, 2, 3)","slug":"old_topic/2016-09-17-381","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"68ecc63ec79c9905410118253d04884f","title":"Lua的Table的成员函数声明中的形参self","content":"作者：糖果\nLua函数声明中的形参self\nLua中有两种对Table结构的成员函数声明方式：”:”和”.”。而对table的函数成员表量的调用也是这两种方试。\n允许的：第一种:用”.”声明函数，用”:”调用用函数。函数调用时lua会把table变量本身做为第一个参数，传给这个被调用的函数。\n第二种:用”.”声明函数，用”.”调用用函数。再用”.”执行table的函数，函数默认不会为这个函数，第一个实参传入self参数。 这里的self不一定要叫self,可以声明为任何的变量名。\n1234567891011121314151617181920212223242526272829303132333435363738local tbl = &#123;a=1&#125;function tbl.test(self)    print(&quot;tbl.test&quot;)    print(type(self))    for k,v in pairs(self) do        print(k,v)    end endtbl:test()function tbl.test1(params)    print(&quot;tbl.test1&quot;)    print(type(params))    for k,v in pairs(params)do        print(k,v)    end endtbl:test1()```    上面的代码说明了这个问题：```lualocal tbl = &#123;a=1&#125;function tbl.test1(params)    print(&quot;tbl.test1&quot;)    print(type(params))    for k,v in pairs(params)do        print(k,v)    end endtbl.test1()\n上面这段代码，如何用”.”声明，”.”调用，在函数内部遍历params参数时，就会出错，提示params为空。\n第三种:用”:”声明函数，用”:”和”.” 两种方式调用函数。 这种情况，无论如何lua也不会把table表量本身作为”self”量传入。\n所以，什么时候有”self”存在呢？就是在用”.”声明，再后用”:”调用。\n下面是一个显示程序,总体说明上面提到的问题：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748local tbl = &#123;a=1&#125;function tbl.test(self)    print(&quot;tbl.test&quot;)    print(type(self))    for k,v in pairs(self) do        print(k,v)    end endtbl:test()function tbl.test1(params)    print(&quot;tbl.test1&quot;)    print(type(params))    for k,v in pairs(params)do        print(k,v)    end endtbl:test1()--tbl.test()print(&quot;======================&quot;)for k,v in pairs(tbl) do    print(k,v)endprint(&quot;======================&quot;)local values = &#123;b=1&#125;function values:test(self)    print(&quot;value:test&quot;)    print(type(self))endvalues:test()values.test()print(&quot;======================&quot;)for k,v in pairs(values) do    print(k,v)endprint(&quot;======================&quot;)\n\nself这个参数是隐式传入的，参考下面的代码:\n1234567891011121314151617181920local tbl = &#123;a=1&#125;function tbl.testMultiParams(params, key)    print(&quot;------------------------&quot;)    print(&quot;tbl.testMultiParams&quot;)    print(key)    print(&quot;------------------------&quot;)    for k,v in pairs(params)do        print(k,v)    end endtbl:testMultiParams(&quot;tstKey&quot;)print(&quot;======================&quot;)for k,v in pairs(tbl) do    print(k,v)endprint(&quot;======================&quot;)\n\n这就是典型的”.”声明,”:”调用。\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n糖果实验室\nhttp://www.candylab.net\n","slug":"old_topic/2016-09-17-382","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"12c80aa2a75d231f673b151b589c54e9","title":"使用Openresty编写WAF插件","content":"对于有的站点来说，除了一些上传文件的场景，基本上都是GET操作比较多，针对一些GET请求中存在的异常数据，可以在pipeline写一个小的WAF插件来拦截。\n直接使用了X-WAF的规则文件：\n1234567891011121314151617181920212223[&#123;&quot;Id&quot;:26,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;\\\\.\\\\./&quot;&#125;,&#123;&quot;Id&quot;:27,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;\\\\:\\\\$&quot;&#125;,&#123;&quot;Id&quot;:28,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;\\\\$\\\\&#123;&quot;&#125;,&#123;&quot;Id&quot;:29,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;select.+(from|limit)&quot;&#125;,&#123;&quot;Id&quot;:30,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;(?:(union(.*?)select))&quot;&#125;,&#123;&quot;Id&quot;:31,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;having|rongjitest&quot;&#125;,&#123;&quot;Id&quot;:32,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;sleep\\\\((\\\\s*)(\\\\d*)(\\\\s*)\\\\)&quot;&#125;,&#123;&quot;Id&quot;:33,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;benchmark\\\\((.*)\\\\,(.*)\\\\)&quot;&#125;,&#123;&quot;Id&quot;:34,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;base64_decode\\\\(&quot;&#125;,&#123;&quot;Id&quot;:35,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;(?:from\\\\W+information_schema\\\\W)&quot;&#125;,&#123;&quot;Id&quot;:36,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;(?:(?:current_)user|database|schema|connection_id)\\\\s*\\\\(&quot;&#125;,&#123;&quot;Id&quot;:37,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;(?:etc\\\\/\\\\W*passwd)&quot;&#125;,&#123;&quot;Id&quot;:38,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;into(\\\\s+)+(?:dump|out)file\\\\s*&quot;&#125;,&#123;&quot;Id&quot;:39,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;group\\\\s+by.+\\\\(&quot;&#125;,&#123;&quot;Id&quot;:40,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;xwork.MethodAccessor&quot;&#125;,&#123;&quot;Id&quot;:41,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;(?:define|eval|file_get_contents|include|require|require_once|shell_exec|phpinfo|system|passthru|preg_\\\\w+|execute|echo|print|print_r|var_dump|(fp)open|alert|showmodaldialog)\\\\(&quot;&#125;,&#123;&quot;Id&quot;:42,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;xwork\\\\.MethodAccessor&quot;&#125;,&#123;&quot;Id&quot;:43,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;(gopher|doc|php|glob|file|phar|zlib|ftp|ldap|dict|ogg|data)\\\\:\\\\/&quot;&#125;,&#123;&quot;Id&quot;:44,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;java\\\\.lang&quot;&#125;,&#123;&quot;Id&quot;:45,&quot;RuleType&quot;:&quot;cookie&quot;,&quot;RuleItem&quot;:&quot;\\\\$_(GET|post|cookie|files|session|env|phplib|GLOBALS|SERVER)\\\\[&quot;&#125;]\n\n代码如下：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556local buffer = require &quot;buffer&quot;local bjson = require &quot;utils.bjson&quot;local waf_plugin = &#123;&#125;local src = &#123;   args=&quot;route args&quot;&#125;local sink = &#123;    name = &quot;route_plugin&quot;,    ver = &quot;0.1&quot;&#125;function waf_plugin.output(self, list, flg)    if flg == 0 then return end    for k,v in pairs(list) do print(k,v) endendfunction waf_plugin.push(self, stream)    for k,v in pairs(stream.metadata) do        self.source[k]=v    end endfunction waf_plugin.init(self)    self.source = src     self.sink = sinkendfunction waf_plugin.action(self, stream)     local rules = bjson.loadf(&quot;./data/json/waf_plugin_rule.rule&quot;, env)     local meta = bjson.decode(rules)    for k,v in pairs(meta) do        local rulematch = ngx.re.find        if rulematch(stream.request.url, v[&#x27;RuleItem&#x27;], &quot;jo&quot;) then            local tpl = require &quot;render&quot;            ngx.header[&#x27;Content-Type&#x27;] = &#x27;text/html; charset=UTF-8&#x27;            ngx.say(tpl.render(&quot;./views/waf.html&quot;, &#123;timestamp=ngx.localtime()&#125;))        end     end     return self.source,  self.sink  endfunction waf_plugin.match(self, param)    self.sink[&#x27;found_flg&#x27;]=false    for k,v in pairs(self.source) do         self.sink[k] = v    end    self:action(self.sink)    return self.source, self.sinkendreturn waf_plugin\n\n\n在pipeline上加入这个插件：\n123456789local pipeline = require &quot;wario.pipeline&quot;local status = pipeline:new &#123;    require&quot;wario.plugin.content.httpsrc_plugin&quot;,    require&quot;wario.plugin.content.blockip_plugin&quot;,    require&quot;wario.plugin.content.rewrite_plugin&quot;,    require&quot;wario.plugin.content.route_plugin&quot;,    require&quot;wario.plugin.content.waf_plugin&quot;,&#125;return pipeline\n\n\n\n\n作者：糖果\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n糖果实验室\nhttp://www.candylab.net\n","slug":"old_topic/2016-09-17-387","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"d63383a09ac480bfeab8c376afa1f147","title":"lua的table复制copy","content":"源代码实现，来至于RESTY-HTTP\n代码如下：\n1234567891011121314151617-- Returns a new table, recursively copied from the one given.---- @param   table   table to be copied-- @return  tablelocal function tbl_copy(orig)    local orig_type = type(orig)    local copy    if orig_type == &quot;table&quot; then        copy = &#123;&#125;        for orig_key, orig_value in next, orig, nil do            copy[tbl_copy(orig_key)] = tbl_copy(orig_value)        end    else -- number, string, boolean, etc        copy = orig    end    return copyend","slug":"old_topic/2016-09-17-385","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"2eb9778cfe15235d511c05b2278c1e5d","title":"使用windump监控流量","content":"windump相关于linux和mac上的tcpdump，有些场景在windows平台上使用windump要比wireshark方便一些,wireshark是GUI形式的，还支持lua插件，有机会我们介绍wireshark的lua插件，windump是一个分析tcp/udp/icmp等协议监控的一个好工具，简单介绍一下使用，后期我们就是使用windump.exe这个命令行工具，分要我们应用服务器，分析我们的服务器承受压力的极限。\n1.显示出所以的网卡设备。-D可以列出本机所有的网卡设备，包括VPN或是虚拟机建立的虚拟网卡。\nwindump.exe  -D\n\n监听指定网卡。-i 后面紧跟数字序号，表示本地网卡对应的序号，用 -D显示出来的序号。\n\nwindump.exe -i 1\n-i 的后面跟的数字，就是本机网卡的序号名。\n\n监听指定协议数据。udp的字样是我们指定监控udp协议的流量。\n\nwindump.exe -i 1 udp\n\n监听指定端口数据。指定端口后就只监听流过这个端口的流量数据。\n\nwindump.exe -i 1 udp port 1234\n\n监听指定主机的数据。指定IP只监听本机上和这个IP有关的数据包。\n\nwindump.exe -i 1 udp port 1234 and host 192.168.0.1\n6.写流量记录到文件中。我们把监听的数据包存起来，便于以后分析。\nwindump.exe  -w cap.txt -i 1 udp port 1234 and host 192.168.0.1\n7.读取文本件的流量信息。-w存起来的数据不是明文的，需要用-F显示出正常的ACSII码，让人能看懂。\nwindump -F cap.txt\n官方文档介绍的是最全的：\nhttps://www.winpcap.org/windump/docs/manual.htm\n","slug":"old_topic/2016-09-17-389","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"88310665d32cdba1d5ff1f6f71acda67","title":"graylog的sidercar与nxlog部署","content":"graylog的sidercar与nxlog部署\n1.去github上下载sidercar.\n2.配置sidercar的配置文件。\n1234567891011121314151617server_url: http://192.168.0.3:9100/api update_interval: 10tls_skip_verify: falsesend_status: truelist_log_files:node_id: graylog-collector-sidecarcollector_id: file:C:\\Program Files\\graylog\\collector-sidecar\\collector-idcache_path: C:\\Program Files\\graylog\\collector-sidecar\\cachelog_path: C:\\Program Files\\graylog\\collector-sidecar\\logslog_rotation_time: 86400log_max_age: 604800tags: [windows, iis]backends:    - name: nxlog      enabled: false      binary_path: C:\\Program Files (x86)\\nxlog\\nxlog.exe      configuration_path: C:\\Program Files\\graylog\\collector-sidecar\\generated\\nxlog.conf\n\n\n3.安装后，设置服务并启动。\n12$ &quot;C:\\Program Files\\graylog\\collector-sidecar\\graylog-collector-sidecar.exe&quot; -service install$ &quot;C:\\Program Files\\graylog\\collector-sidecar\\graylog-collector-sidecar.exe&quot; -service start\n\n\n4.安装nxlog。\n5.配置nxlog.conf文件。\nnxlog的配置文件存在一种配对关系，定义Input节、Output节、Route节，下面的配置文件只定义了一个Input,Output的路由对应关系，nxlog是模块化的设计，我们在in这个Input节中，用了im_file这个模块，告诉nxlog去那里读取本地日志文件，我们这定义日志文件放到c:\\rlog\\下的所有.log文件。\n123456789101112131415161718192021&lt;Extension _syslog&gt;    Module      xm_syslog&lt;/Extension&gt;&lt;Input in&gt;    Module    im_file     file    &#x27;C:\\\\rlog\\\\*.log&#x27;    SavePos    TRUE&lt;/Input&gt;&lt;Output out&gt;    Module      om_udp    Host        192.168.1.3    Port        521    Exec parse_syslog(); &lt;/Output&gt;&lt;Route 1&gt;    Path        in =&gt; out&lt;/Route&gt;\n名out的Output节定义的是输出才用什么协议，并解析成什么形式，使用om_udp模块，将本的日志文件以udp传输协议，输出成syslog形式，到指定的服务器,syslog服务器或是graylog的数据接收端口。\n安装服务\n1nxlog -i\n\n停止一下nxlog，如果启动了。\n1nxlog -s\n\n在后端启动nxlog监听服务\n1nxlog -f\n\n\n看一下默认的位置nxlog的启动log。\n文件位置：C:\\Program Files (x86)\\nxlog\\data\n正常启动nxlog会显示下面的字样：\n12017-08-16 17:02:15 INFO nxlog-ce-2.9.1716 started\n\n如果出现这样的字段就OK了，如有其它警告和提示，可能是配置文件写错了。\n","slug":"old_topic/2016-09-17-390","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"65ce57f5fdb9c6ca938fd44776fc3ed9","title":"TMUX最常用操作命令","content":"作者：糖果\n一般情况下，当你用SSH链接VPS，然后关掉terminal的操作窗口时，所有的当前操作都结束了。而如果用TMUX,当前正在运行的非后台操作会话还会存在，下面是TMUX最常用的操作了。\n1.创建新会话tmux new -s  candylab\n2.选择新会话tmux attach -t  candylab\n3.显示会话列表tmux ls\n4.翻页Ctrl + b + (PageUp PageDown)\n5.退出当前tmux会话Ctrl + b + d是退出当前会话，但是用tmux ls盾，这个会话，还是会存在的，如果exit命令,当前的tmux会话就彻底结束了，tmux ls中也少了当前的会话。\n6.上下分屏Ctrl + b + %\n7.左右分屏Ctrl + b + “\n8.重命名当前会话Ctrl + b + $ 重命名session\n糖果实验室\n","slug":"old_topic/2016-09-17-386","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"bf9123379f1a4de9653db6fc2b33716c","title":"快速安装MySQL与为Lapis修改mysql字符集","content":"快速安装MySQL下载安装Yum源\n1wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm\n安装的MySQL与服务器端\n12yum -y install mysql57-community-release-el7-10.noarch.rpmyum -y install mysql-community-server\n\n启动关闭 MySQL服务\n12systemctl start  mysqld.servicesystemctl status mysqld.service\n\n修改root密码\n12ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;new password&#x27;;grant all on *.* to root@&#x27;%&#x27; identified by &#x27;password&#x27;;\n\n\n修改mysql字符集第一种方式：\n1234show variables like &#x27;%char%&#x27;;  set character_set_connection=gbk;set character_set_client=gbk;set character_set_results=gbk;\n\n这种情况，在Mysql重新起动之后，值还会恢复到原先值。\n第二种方式：my.ini\n12345678[mysqld]#default-character-set = utf8init-connect=&#x27;SET NAMES utf8&#x27;character-set-server = utf8[mysql]default-character-set = utf8\n\n1SET NAMES utf8\n\n它相当于下面的三句指令：\n123SET character_set_client = utf8;SET character_set_results = utf8;SET character_set_connection = utf8;\n\n\n\n这种方式在Mysql得起之后，会安装my.ini中的设置重新设定。特别是Lapis框架，要从中文数据库中取数据，必须设置中文字符集。\n","slug":"old_topic/2016-09-17-39-mysql-install","date":"2016-09-17T14:50:18.000Z","categories_index":"topic,mysql","tags_index":"mysql,lapis","author_index":"安全书"},{"id":"1da6405cfff3883466e411939e823d07","title":"libpcap监听网络端口数据","content":"下面的代码是监听本机源80地址流出的数据， 并以字符的形式打印出来。\n代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;pcap.h&gt;  #include &lt;time.h&gt;  #include &lt;stdlib.h&gt;  #include &lt;stdio.h&gt;    void getPacket(u_char * arg, const struct pcap_pkthdr * pkthdr, const u_char * packet)  &#123;    int * id = (int *)arg;        printf(&quot;id: %d\\n&quot;, ++(*id));    printf(&quot;Packet length: %d\\n&quot;, pkthdr-&gt;len);    printf(&quot;Number of bytes: %d\\n&quot;, pkthdr-&gt;caplen);    printf(&quot;Recieved time: %s&quot;, ctime((const time_t *)&amp;pkthdr-&gt;ts.tv_sec));         int i;    for(i=0; i&lt;pkthdr-&gt;len; ++i)    &#123;       //printf(&quot; %02x&quot;, packet[i]);      printf(&quot; %c&quot;, packet[i]);      if( (i + 1) % 16 == 0 )       &#123;           //printf(&quot;\\n&quot;);      &#125;     &#125;       //printf(&quot;%s\\n&quot;, packet);  printf(&quot;\\n\\n&quot;);  &#125;  int main()  &#123;    char errBuf[PCAP_ERRBUF_SIZE], * devStr;        /* get a device */    //devStr = pcap_lookupdev(errBuf);    devStr = &quot;eth1&quot;;      if(devStr)    &#123;       printf(&quot;success: device: %s\\n&quot;, devStr);    &#125;     else    &#123;       printf(&quot;error: %s\\n&quot;, errBuf);      exit(1);    &#125;         /* open a device, wait until a packet arrives */    pcap_t * device = pcap_open_live(devStr, 65535, 1, 0, errBuf);        if(!device)    &#123;       printf(&quot;error: pcap_open_live(): %s\\n&quot;, errBuf);      exit(1);    &#125;         /* construct a filter */    struct bpf_program filter;    pcap_compile(device, &amp;filter, &quot;src port 80&quot;, 1, 0);    //pcap_compile(device, &amp;filter, &quot;dst port 80&quot;, 1, 0);    pcap_setfilter(device, &amp;filter);  /* wait loop forever */  int id = 0;  pcap_loop(device, -1, getPacket, (u_char*)&amp;id);  pcap_close(device);  return 0;&#125;\n\n\n编译：\n1gcc test.c -o test -lpcap","slug":"old_topic/2016-09-17-392","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"a97a619732554d0e595f9f947fc0b0aa","title":"windump与graylog","content":"抓取流量最流行的工具就是Wireshark,在Windows上Wireshark的GUI界面很酷，但对于在linux和mac用惯了tcpdump用户来说，用命令行的tcpdump更直接便捷。Windows上有没有类似tcpdump的抓包工具呢？答案是有的，就是windump，底层是基于winpcap库的命令行工具。\n大体的背景是这样的，有一台Windows服务器运行了一个较定制化的闭源的radius服务，因为这是一个很老的服务，并没以完备的日志输出机制，我们无法从现有的日志统计出用户流量数据，在服务压力大到什么程度会出现问题，我们现掌握的数据中无法更好的识别民常，统计出流量分布，估算出预警的峰值，也无法可视化当前服务的状态。本身认证服务，随着外部的关联服务变的压力不段加大。\n根据目前的现状整个出几个需求：\n1.可在不入侵代码的前题下，量化监听流量。2.可将流量日志数据传到大数据平台，进行非实时的统计，找出预警的阀值。3.用基于winpcap自主开发的监听工具代替windump，做实时的数据分析，阀值预警、可视化负载状态。\n本文侧生点是用windump和大数据graylog配合，做到前2点，第3点后继做介绍。\n所以，下面开始我们要接触几个软件，但不会触及到太多代码问题，软件分别是windump,sidercar,nxlog,而graylog的安装使用不做具体介绍。\n安装这些工具后，我们就可以来监控流量了，并在graylog端做简单的可视化分析。\n1.运行windump，监听指定IP的测试流量。\nwindump.exe -i 1 udp port 1812 and 192.168.0.6\n2.将windump输出的日志文件，重定向到指定文件目录。\n3.启运流量分析脚本。\n4.停制监控，查看graylog日志结果，做分析。\n关于graylog的部分，pcap库的定制使用后在后期出。\n","slug":"old_topic/2016-09-17-391","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"3dbf10926df36a20b5bcd08982cc5ba0","title":"进程调试工具","content":"查看TCP链接状态\n123456netstat -n | awk &#x27;/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;&#x27;ps -A -o stat,ppid,pid,cmd | grep -e &#x27;^[Zz]&#x27; | awk &#x27;&#123;print $2&#125;&#x27; |ps -A -o stat,ppid,pid,cmd | grep -e &#x27;^[Zz]&#x27; | awk &#x27;&#123;print $2&#125;&#x27; | xargs kill -9\n\n\n查看假死进程\n1ps -A -o stat,ppid,pid,cmd | grep -e &#x27;^[Zz]&#x27;\n\n\n还有两个工具 \npstack\nstrace\n","slug":"old_topic/2016-09-17-388","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"865669acba81f78ac004d912a3c001a5","title":"基于PyQt的微博客户端（一）","content":"【概要】用PyQt作为Windows下的GUI客户端开发工具，结合廖雪峰老师的weibo python SDK，实现一个windows与Linux平台通用的微博客户端应用。过程中使用新浪云上架设的RPC服务，与客户端交换数据。\n【环境准备】\nI.Windows平台 \n1.Python安装:\nhttp://www.python.org/\n去官网下载，注意下载2.6-2.7的版本，weibo python sdk是基于此版本的。\n\n2.QT安装:http://qt-project.org/去官网下载适用于你操作系统的SDK，选MinGW,版本的，里面带有gcc编译和连接器。\n3.PyQt安装:http://www.riverbankcomputing.co.uk/software/pyqt/download/去RBC下载PyQt的二进制版本。\n4.Weibo SDK安装：直接参考github上的说明。如果有什么注意的话就是：A.Windows上安装后，在系统path下添加Python的路径。B.python setup.py install 用这句话安装windows版本的weibo SDK.\n5.Python编辑器安装:\n方案A： \n如果你实在不想安装Java和eclipse一堆东西，而且让系统变慢，就用eric,参看文章尾部的链接。eric和PyQt有很好的结合，如果做PyQt开发，eric是首选。\n\nhttp://eric-ide.python-projects.org/eric-download.html\n一个题外话，你可以分别在百度搜索和360搜索里，输入”eric下载”，体验一下有哪些不同。\n方案B： \n无所谓，考虑到输入效率，使用eclipse + PyDev插件。\nA.安装JDK or JRE：\n必须是Java7不然PyDev在eclipse的新建工程中显示不出来,如果不做Java开发，下载一个25多的JRE7就OK。\nhttp://www.oracle.com/technetwork/java/javasebusiness/downloads/java-archive-downloads-javase6-419409.html#jdk-6u21-oth-JPR\nhttp://www.oracle.com/technetwork/java/javase/downloads/index.html\n\nB.下载Eclipse （KEPLER版）除了kepler，很多版本都可以。3.x能比4.x速度快，如果只是python开发。http://www.eclipse.org/downloads/http://www.eclipse.org/downloads/download.php?file=/eclipse/downloads/drops/R-3.7.1-201109091335/eclipse-SDK-3.7.1-win32.zip\nC.下载安装PyDevhttp://www.pydev.org/http://sourceforge.net/projects/pydev/files/http://marketplace.eclipse.org/content/pydev-python-ide-eclipse#.UyHX_j-Sw_8\nhttp://sourceforge.net/projects/eric-ide/files/eric4/stable/4.5.20/eric4-4.5.20.zip/download\nII.Linux平台 \n如果用ubuntu,基本上可以sudo apt-get install XXX和pip install XXX这两个强大的自动安装工具解决安装和环境问题，步骤先略。\n\nIII.IPC \n在新浪云上基于python的RPC部署，略。\n\n\n【结束语】部署环境机是如此，把链接资源整理出来，以便之后不时之需。\n【参考资料】http://michaelliao.github.io/sinaweibopy/Python: 发送新浪微博（使用oauth2）http://blog.csdn.net/dyx1024/article/details/8470983http://blog.csdn.net/huyoo/article/details/11952603http://blog.csdn.net/dongtingzhizi/article/details/9098527Eclipse+PyDev 安装和配置http://www.itokit.com/2012/0317/73351.htmlpython+PyQT+Eric安装配置http://www.cnblogs.com/lhj588/archive/2011/10/03/2198472.htmlEric4在Windows下的安装http://hi.baidu.com/runningon/item/1b07680e3453478a03ce1be4python编辑器对比和推荐http://blog.csdn.net/cserchen/article/details/7036435\n","slug":"old_topic/2016-09-17-41","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"4a5cc773e0399b5ad7bd2f2bfa7a3e83","title":"C调用LUA","content":"通过一个简单的例子，看C是如何调用LUA的，这样将原有C处理数据的逻辑用LUA来做，省去了编译C的过程。\n代码，如下：\n12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;lua.h&gt;#include &lt;lauxlib.h&gt;#include &lt;lualib.h&gt;lua_State* L = NULL;int main()&#123;    L = lua_open();    luaL_openlibs(L);    if (luaL_loadfile(L, &quot;test.lua&quot;) || lua_pcall(L, 0,0,0))        error(L, &quot;cannot run configuration file:%s&quot;, lua_tostring(L, -1));     double x = 1.0;     double y = 5.0;     double z;         lua_getglobal(L, &quot;f&quot;);     lua_pushnumber(L, x);      lua_pushnumber(L, y);          lua_pcall(L, 2,1,0);//    printf(&quot;%f\\n&quot;, f(1.0, 2.0));        return 0;&#125;\n\n编译参数：\n1gcc   a6.c -I/usr/include/lua5.1 -ldl -lm -llua5.1","slug":"old_topic/2016-09-17-393","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"f0e002a5a85356fc1129dc9430639179","title":"Ragel for Ruby","content":"发现Ragel的语言支持列表里没有列出Python,在已经列出的语言选一个，就选了Ruby.\nlinux上本身自带，又装了一个windows版本。http://rubyforge.org/frs/?group_id=167&amp;release_id=28426\n比较靠谱的Ruby环境构建文章：http://www.cnblogs.com/zhuque/archive/2012/11/24/2785609.html\n下载Ruby开发插件（RDT）地址：http://jaist.dl.sourceforge.net/sourceforge/rubyeclipse/org.rubypeople.rdt-0.7.0.601192300PRD.zip\nruby在windows环境下下载安装devkithttp://gaitian00.blog.163.com/blog/static/186234180201311612545501/\nRuby的基本语法http://www.blogjava.net/xxllnnn/archive/2009/01/18/251762.html\n每天一条Ruby小道之高级数据结构http://hideto.iteye.com/blog/112528\nRuby程序快速入门之数据结构http://dev.yesky.com/467/2381967.shtml\n差不多，python和ruby的list和map定义都差不多。\nragelhttp://www.complang.org/ragel/\nrails forumhttp://archive.railsforum.com/viewtopic.php?id=22303\n","slug":"old_topic/2016-09-17-45","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"ef96aa94ccb50b3e2aed57d40319c515","title":"基于PyQt的微博客户端（二）","content":"云服务器搭建【概要】客户端的数据交互：一部分来至新浪微博。另一部分数据来至新浪云，比如本地的用户验证时放到SAE上。\n【环境】服务器端使用的python django, SAE上本身的环境是配置好的，本地环境需要安装。Linux上的python django MySQL很好安装，还是apt-get和pip，主要是Windows版本也安装一份，更便于本地调试。\n值得介绍的一点就是RPC，都是跳着写的…\nDjango安装：未来和SAE同步，使用的是Django 1.5https://pypi.python.org/pypi/Django/1.5.1\n【参考】Windows下安装Djangohttp://www.th7.cn/Program/Python/201305/136301.shtmlwindows下安装Djangohttp://jingyan.baidu.com/article/466506580e7d29f549e5f8b6.html\n","slug":"old_topic/2016-09-17-42","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"0cb9b7f667542d54e27810e7e909c462","title":"Python和C++混合使用QML开发GUI","content":"作者：糖果\npyqt和qml结合的中文资很少，在baidu上搜索，基本上就是浪费时间。在国外的blog上，有零星的几篇，但是介绍好的少。在stackoverflow上看到一篇关于pyside，发现pyside，发现pyside果然给力，那就开始我们的pyside游戏之旅吧。\n【编辑器】目前的编辑环境是，Eclipse+PyDev, Erics, QtCreator这三个工具一起使用。用前两者进PY代码编辑，用QtCreator进行QML编辑和设计。\n【概要】用PyQt,C++,QML实现一个简单但的文本输入框值得取得和设置。从编码角度来看，我们需要在Python中调用QML的function方法，并通过参数传递把python中设定的变量值给QML.需要在QML中调用Python定义的函数方法，并把QML中InputText的Text值传递给Python.无论控件和业务逻辑多复杂都是如此。\nPython代码 \n\n\n12345678910import sysfrom PySide import QtCore, QtDeclarative,  QtGuiclass QtInterface(QtCore.QObject):    signaller_in_txt = QtCore.Signal(str)    signaller_out_txt = QtCore.Signal()         def __init__(self):        QtCore.QObject.__init__(self)        self.in_txt = &quot;test&quot;\n\n #@的这种声明方式，会在后面的部分介绍，并且参考链接中，有一篇文也介绍的很清晰。\n\n #这是一个不带参数的Slot函数。                \n\n123@QtCore.Slot()def getInputText(self):    print self.in_txt        \n #这个一个带参数的Slot函数，我们就是利用这个参数，在QML中，调用这个函数，并把InputText的text值发送过来，并且在函数中，打印出这个传递值。\n\n123@QtCore.Slot(str)def setInputText(self, text):    print text\n #在updateValues函数中，通过信号发射，调用QML中的function函数，并将对控件的设置值，传递过去。信号变量声明，在类中，和与对应的QML函数简历毁掉联系，是在main函数中完成的。\n\n123    def updateValues(self):#        self.signaller_in_txt.emit(str(self.in_txt))        self.signaller_out_txt.emit()\n\nMainView是主要View视图，继承了基类，QDeclarativeView，继承了最大化，最小话和关闭窗体的机能。\n12345678910class MainView(QtDeclarative.QDeclarativeView):    def __init__(self,  parent=None):          #构造父类        super( MainView,  self).__init__(parent)          #设定窗体Title内容        self.setWindowTitle(&quot;Counter&quot;)          #设定与本地QML关联        self.setSource( QtCore.QUrl.fromLocalFile(&#x27;abc.qml&#x27;))          #设定窗体尺寸变化的模式，继承了父类的模式        self.setResizeMode( QtDeclarative.QDeclarativeView.SizeRootObjectToView)\n\n创建一个QtGui的应用实例\n123456789101112131415161718192021qApplication = QtGui.QApplication(sys.argv)#主视图创建window = MainView()#显示主视图window.show()#取得用于解析QML的类实例qcontext = window.rootContext()interface = QtInterface()#将用户自己的QtObject子类和窗体类建立连接qcontext.setContextProperty(&quot;qInterface&quot;,  interface)#将信号和QML函数建立映射关联。interface.signaller_score_a.connect(window.rootObject().updateScoreA)interface.signaller_in_txt.connect(window.rootObject().updateInText)interface.signaller_out_txt.connect(window.rootObject().getInTxt)#退出应用sys.exit(qApplication.exec_())\n\n\nQML代码 \n\nQML语言基本UI元素的描述信息和功能函数，QML本身可以通过自己的函数定义执行来完成一定程度上功能，完全和背后的语言（C++,Python）脱离关系。而且在很多的平台上使用，甚至包括移动平台，可以和我的WEB服务器很好的链接，传递数据。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134import QtQuick 1.1Rectangle &#123;    id: rectangle1    width: 480    height: 272    gradient: Gradient &#123;        GradientStop &#123;            id: gradientStop1            position: 0            color: &quot;#ffffff&quot;        &#125;        GradientStop &#123;            position: 1            color: &quot;#abc09f&quot;        &#125;    &#125;    //UML中的函数，要通过emit发射信号调用。    function updateInText(string) &#123;        in_txt.text = string    &#125;    function updateIn() &#123;        in_txt.text = &quot;ozzy&quot;    &#125;    //在Python中，通过emit调用getInTxt函数    function getInTxt() &#123;         //console.log基本就是JavaScript的用法。        console.log(&quot;debug&quot;)        return (in_txt.text)    &#125;    Text &#123;        id: score_a        x: 150        y: 74        width: 131        height: 48        text: qsTr(&quot;Text&quot;)        verticalAlignment: Text.AlignVCenter        font.pixelSize: 12    &#125;    MouseArea &#123;        id: a_scored        x: 303        y: 200    &#125;    Rectangle &#123;        id: team_a        x: 150        y: 148        width: 127        height: 46        color: &quot;#4e3a3a&quot;        radius: 10        TextInput &#123;            id: team_a_txt            x: 24            y: 13            width: 80            height: 20            text: qsTr(&quot;A&quot;)            selectionColor: &quot;#316cc4&quot;            horizontalAlignment: TextInput.AlignHCenter            font.pixelSize: 12        &#125;        MouseArea &#123;            id: team_a_score_ma            x: 1            y: 0            width: 126            height: 46            onClicked: &#123;                qInterface.aScored()            &#125;        &#125;    &#125;    TextInput &#123;        id: in_txt        x: 345        y: 67        width: 80        height: 20        text: qsTr(&quot;InputText&quot;)        selectionColor: &quot;#316cc4&quot;        font.pixelSize: 12        MouseArea &#123;            id: in_txt_ma            x: -17            y: 77            width: 115            height: 57            z: 2          //直接在MouseArea中添加对应的事件处理            onClicked: &#123;               //qInterface是在Python中建立的映射关系，通过这个对象实例，就可以直接调用Python中的函数方法，并且可以传递参数                               qInterface.setInputText(in_txt.text)     //下面的这个函数被注释掉了，因为getText()是一个C++写的方法     //console.log(qInterface.getText())            &#125;        &#125;    &#125;    Rectangle &#123;        id: get_in_text        x: 322        y: 148        width: 127        height: 46        color: &quot;#4e3a3a&quot;        radius: 10        Text &#123;            id: text1            x: 38            y: 15            width: 40            height: 16            text: qsTr(&quot;Enter&quot;)            font.pixelSize: 12        &#125;    &#125;&#125;\n\nC++代码 \n12345678910111213141516171819202122232425262728293031323334353637383940#ifndef LOGIN_H#define LOGIN_H#include &lt;QObject&gt;class Login: public QObject&#123;    Q_OBJECTpublic:     //Q_INVOKABLE关键字，可以让QML直接调用C++方法。相当于 濮阳天python中的@QtCore.Slot()     Q_INVOKABLE QString getText(void) const;    Login(QObject *parent = 0);    virtual ~Login();signals:    void setInputText(const QString &amp;s);public slots:     void setText(const QString &amp;s);&#125;;#endif // LOGIN_H#include &quot;login.h&quot;Login::Login(QObject *parent)      :QObject(parent)  &#123;    QObject::connect(this, SIGNAL(setInputText(QString)), this, SLOT(setText(QString)));  &#125;    Login::~Login() &#123;    &#125;  QString LS::getText(void) const  &#123;      return &quot;from C++ Code&quot;;  &#125;  void LS::setText(const QString &amp;s) &#123;      qDebug(&quot;this is string.&quot;);      qDebug(&quot;%s&quot;, s.toLocal8Bit().data());  &#125;\n【后记】\n\n上面的代码可以看到，PyQt和C++公用一个QML代码，QML几乎不变（不是几乎，就是一样的）。PyQT(PySide)更适应快速开发。用C++实现性能要求比较高的共同部分，则更有优势。\nPython中QML调用Python函数，只要把python的函数声明为@QtCore.SlotPython调用QML函数，需要定义信号和connect QML的函数。C++是，UML调用C++函数，只要把C++函数声明过为Q_INVOKABLE。C++调用QML函数，需要声明Signal和Connect Slot函数。这点Python和C++的流程保持一致。\n【参考】\n\nPytSide\n\n在QML中使用JavaScript和Sqlite\n\n关于QML中调用qt类中的信号，槽，成员函数,属性做记录\n\nConnecting Qt signal to QML function\n\n@符号在python中的作用\n\nFilling and reading QML UI forms from python.\n\n\n","slug":"old_topic/2016-09-17-46","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"21c5fcf79f3b2d72db7be480f2522eaa","title":"DIV+CSS","content":"【概要】选择Python做全栈解决方案，但是希望前段简单一些，可以向QML一样被重复的利用。选择用DIV+CSS控制页面的元素，一步步的构建社区。将JQuery融入进来。本篇太简单，其他内容之后带入。\n[code]\n\n\n\n\n\n\n#div1 {\n    font-style: italic;\n    text-align: center;\n    width: 200px;\n    height:200px;\n    line-height:120px;\n    border:1px \n    solid #000000;\n    left:66px;\n    top:38px;\n    position: absolute;\n    }\n\n#div2 {\n    font-style: italic;\n    text-align: center;\n    width: 200px;\n    height:200px;\n    line-height:120px;\n    border:1px \n    solid #000000;\n    left:272px;\n    top:38px;\n    position: absolute;\n    }\n    \n#div3 {\n    font-style: italic;\n    text-align: center;\n    width: 200px;\n    height:200px;\n    line-height:120px;\n    border:1px \n    solid #000000;\n    left:477px;\n    top:38px;\n    position: absolute;\n    }    \n#div4 {\n    font-style: italic;\n    text-align: center;\n    width: 200px;\n    height:200px;\n    line-height:120px;\n    border:1px \n    solid #000000;\n    left:67px;\n    top:245px;\n    position: absolute;\n    }    \n#div5 {\n    font-style: italic;\n    text-align: center;\n    width: 200px;\n    height:200px;\n    line-height:120px;\n    border:1px \n    solid #000000;\n    left:272px;\n    top:245px;\n    position: absolute;\n    }    \n#div6 {\n    font-style: italic;\n    text-align: center;\n    width: 200px;\n    height:200px;\n    line-height:120px;\n    border:1px \n    solid #000000;\n    left:478px;\n    top:245px;\n    position: absolute;\n    }                \n     \n\n\nVerup\n\n\n Part A \n Part B \n Part C \n Part D \n Part E \n Part F \n\n\n\n[/code]\n","slug":"old_topic/2016-09-17-47","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"bc51e73d376d390e21ec280bce3ba4f7","title":"通过进程信息，检查内存泄露。","content":"作者：糖果\n【问题】寻找内存泄露，有时是一件困难的事情。代码的内存申请和释放动作不配对，或是在并发环境下，时序变换的异常，都会引起的内存泄露，即使从core dump回溯调用栈，也未必能找到快速内存的泄露点。\n某些嵌入式系统，对制造方式有特殊的限制，不允许使用智能指针或是STL库。编码的错误引起的内存泄露机率等问题，可以提前通过第三方软件静态检查，输出错误报告，从而找到问题的代码。\n对稍微复杂的嵌入式系统而言，在UI层，中间件层，驱动层，都可能发生泄露。特别是在并发环境下的时序异常，引起的泄露就比较难找，可以用GDB attach 断点，或是输出系统Log，进行问题的切分。\n如何解决？Linux也提供了一种，不需要debug或是改代码的情况下，进行内从泄露检查的机制。在linux的proc目录下，有与系统进程同名的文件目录，进入目录后可以查看此进程的各种相关信息。\n例如，要查看系统中一个叫做candy的进程的内存使用情况，就可以按如下步骤进行。\n1）取得“candy”进程的PID号。\n1ps -elf | grep candy\n2）查看进程使用内存的信息,假设candy的PID号是1688。\n1cat /proc/1688/status\n在屏幕上输出的项目中有一项“VmData: xxxK”这一项就是进程使用堆的情况。\n3)打印时间戳和内存占用情况(时间间隔3秒)。\n1clear;date;cat /proc/1688/status | grep VmData;sleep 3;echo &quot;######&quot;;date;echo &quot;######&quot;;cat /proc/1688/status | grep VmData\n如果想查看系统UI进程是否有异常，就可以在UI进程启动后，通过运行类似于上面这种脚本，查看系统内存变化，进入某页面，然后不触发UI界面上的任何操作，分别在观察开始结束两个时间点，观察系统占用情况，如果伴随时间的变化，VmData的值变化明显，越来越大，基本可以切分出，这个页面内存泄露的可能性很大，然后在进行系统log代码级别的问题切分。\n有些时候，我们希望有一个声音提醒，可以在脚本结尾，加一句gst-launch播放音乐的命令，在等待一定时间后，通过播放音乐，进行提醒，另外也可以把结果直接通过管道输入到文件里。\n如何查看进程使用了那些文件句柄？\n有些功能需要频繁的打开关闭文件，如果程序执行的某个时间点，忽略了文件关闭的动作，特别是写实时log到文件里的功能，某一处没关闭该关的文件，造成log内容逻辑错乱。{问题：在复杂的时序条件下，很难判断是哪个文件没关上。}\n1ls -anl /proc/1688/fd\n通过这行命令就可以看到，当前的进程都使用了那些文件，其中也包括socket句柄。\n如何有兴趣，可以看看nginx进程的这个数据。\n注释：个人劳动成果，使用请注明，本文作者及出处链接，谢谢合作！\n测试\n","slug":"old_topic/2016-09-17-5","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"588827ea99547898fdc61cb9e0f76523","title":"SWIFT之旅","content":"对于一个新语言的第一个程序来说，比较传统的搞法是，在屏幕上，打印一行”hello,word” 。看看swift吧，一行语句就能搞定。\nprintln(“Hello, world”)如果你之前玩过C或是Objective-C, Swift的这种语法你可能眼熟。这一行代码就完成了这个程序，你都不用提前引用那些像输入输出控制或是字符串那些乱七八糟的库。程序的代码的全局范围有效的，所以，你都不需要像main函数的那种东西，你甚至也不需要在每个语句的后面加上一个分号。\n这篇小文会提供给你足够的信息，给你秀一下，如何完成一个编程任务。如果有一些东西你暂时搞不懂，不用担心。几乎所有的细节介绍都会在本书的其他部分出现。\n提示：\n最好的经验就是，在Xcode中，打开本篇涉及到的例子代码，那样就允许你编辑代码，还可以立马的看到运行效果。\n简单的变量值使用let关键字定义一个常量，使用var关键字定义一个变量。这个常量值不需要再编译的时候知道。但你必须进行一次赋值。就是说，你可以使用一个常量命名一个值，再很多的地方使用。\nvar myVariable = 42myVariable = 50let myConstant = 42\n无论是常量还是变量，都必须和你给他赋的值，保持相同的类型。可但是，你不需要总是显式的这么做。在创建常量或是变量的时候赋一个值，然后让编译器去推测类型。在上面的这个例子，编译器推测myVariable 是一个整形，因为她的初始化值是一个整数。\n如果初始化值，没有提供一个足够的信息（或是压根就没有初始化值），特殊的类型，使用引号在变量的后面进行标注。\nlet implicitInteger = 70let implicitDouble = 70.0let explicitDouble: Double = 70\n实践显式的创建一个浮点类型的常量，并赋值4。\n变量时不能隐式的转换成其他类型的。 如果你需要转换一个值到不同的类型。显式的生成一个想要类型的实例。\nlet label = “The width is “let width = 94let widthLabel = label + String(width)实践把最后一行的String去掉，你猜你会得到一个什么错误？有一个简单的方法包含一个字符串变量： 把值写到一对括号里，然后在双括号的前面写一个反斜杠，如下：\nlet apples = 3let oranges = 5let appleSummary = “I have (apples) apples.”let fruitSummary = “I have (apples + oranges) pieces of fruit.”实践使用()在字符串中包含一个浮点值和包含一个特定的名字。\n使用括号和中括号创建数组和字典。在中括号中写索引值或是键来访问他们的元素。\nvar shoppingList = [“catfish”, “water”, “tulips”, “blue paint”]shoppingList[1] = “bottle of water”var occupations = [“Malcolm”: “Captain”,“Kaylee”: “Mechanic”,]occupations[“Jayne”] = “Public Relations”下面是创建一个空数组和空字典的语法。\nlet emptyArray = Stringlet emptyDictionary = Dictionary&lt;String, Float&gt;()\n如果类型信息可以被推测出来，你可以写一个像[]的空数组和一个像[:]的空字典的例子。如果你想为一个函数设定形参变量。\nshoppingList = [] // Went shopping and bought everything.控制流\n使用if和switch去创建条件判断语句，使用for-in,for,while和do-while去创建循环。括号周围都是条件或是循环变量选项，并且周围需要有大括号。\nlet individualScores = [75, 43, 103, 87, 12]var teamScore = 0for score in individualScores {if score &gt; 50 {teamScore += 3} else {teamScore += 1}}teamScore在if判断语句中，条件必须是布尔型表达式，也就是说想if score {} 这种表达是错误的，不能隐式的和零进行比较。\nvar optionalString: String? = “Hello”optionalString == nilvar optionalName: String? = “John Appleseed”var greeting = “Hello!”if let name = optionalName {greeting = “Hello, (name)”}你可以一起使用if和let语句，值的选项表达式。选项值要么包含一个值，要么包含nil去指向一个值。问好表达式是用值的类型区标记一个值得选项。\n实践把optionName指向nil空，greeting的值会是多少？如果optionName指向了nil空，加上一个else分支，去设定不同的greeting值。\n如果条件值是空，条件表达式的结果是false假，并且会跳出大括号。其他情况，其他的条件值是被展开的，并且是用let赋值的常量，让展开的值在代码块之内。\nswitchs 支持各种类型的语句和广泛的变量比较操作，而且不局限于整数和等值测试。\nlet vegetable = “red pepper”switch vegetable {case “celery”:let vegetableComment = “Add some raisins and make ants on a log.”case “cucumber”, “watercress”:let vegetableComment = “That would make a good tea sandwich.”case let x where x.hasSuffix(“pepper”):let vegetableComment = “Is it a spicy (x)?”default:let vegetableComment = “Everything tastes good in soup.”}\n实践如果把default分支去掉，你会得到一个什么错误那？\n如果在switch case 段内，匹配执行了相应的代码，不会继续执行其他分子段的代码。所以这个不需要在每个switch分子段内，显式的声明break语句。\n你会使用for-in语句去迭代字典数据结构， 只要提供key-value简直值所对应的主键。\nlet interestingNumbers = [“Prime”: [2, 3, 5, 7, 11, 13],“Fibonacci”: [1, 1, 2, 3, 5, 8],“Square”: [1, 4, 9, 16, 25],]var largest = 0for (kind, numbers) in interestingNumbers {for number in numbers {if number &gt; largest {largest = number}}}largest\n实践\n添加一个变量去跟踪最大值，并且得到那个最大值。\n使用while语句去重复的执行代码，直到循环条件发生了变更。循环条件的判断也可以再结尾出现，但可以确定的是，这种情况下，循环至少要执行一次。\nvar n = 2while n &lt; 100 {n = n * 2}nvar m = 2do {m = m * 2} while m &lt; 100m你仍然可以使用数字索引的说话呢方式，给出一个索引的范围值去显式的初始化，还有循环条件和递增的步长， 下面的两个循环异曲同工。\nvar firstForLoop = 0for i in 0..3 {firstForLoop += i}firstForLoopvar secondForLoop = 0for var i = 0; i &lt; 3; ++i {secondForLoop += 1}secondForLoop使用..指定上限值范围，使用…指定一个区间的值。\n函数与闭包\n使用func进行函数声明，调用函数使用下面的名字，使用括号内参数列表。使用-&gt;符号来去本函数的返回类型。\nfunc greet(name: String, day: String) -&gt; String {return “Hello (name), today is (day).”}greet(“Bob”, “Tuesday”)实践\n消除参数day, 添加一个包含今天午餐的特别需求在函数 中。\n使用一个复数的元组作为函数返回值。\nfunc getGasPrices() -&gt; (Double, Double, Double) {return (3.59, 3.69, 3.79)}getGasPrices()函数也可以使用可变长参数， 作为一个数组集合传入值。\nfunc sumOf(numbers: Int…) -&gt; Int {var sum = 0for number in numbers {sum += number}return sum}sumOf()sumOf(42, 597, 12)实践\n写一个函数，计算函数参数的平均值。\n在swift中，函数式可以嵌套的， 被嵌套函数可以使用嵌套函数中的变量。你可以使用嵌套函数组织一个长的或是复杂的代码块。\nfunc returnFifteen() -&gt; Int {var y = 10func add() {y += 5}add()return y}returnFifteen()嵌套函数都是首类类型， 就是说嵌套函数可以使用被嵌套函数的结果作为函数返回值。\nfunc makeIncrementer() -&gt; (Int -&gt; Int) {func addOne(number: Int) -&gt; Int {return 1 + number}return addOne}var increment = makeIncrementer()increment(7)函数可以作为函数的参数。并共享形参。\nfunc hasAnyMatches(list: Int[], condition: Int -&gt; Bool) -&gt; Bool {for item in list {if condition(item) {return true}}return false}func lessThanTen(number: Int) -&gt; Bool {return number &lt; 10}var numbers = [20, 19, 7, 12]hasAnyMatches(numbers, lessThanTen)函数其实是一种特殊的函数分支， 你可以写一个没有名字的分子语句块，并用大括号括起来， 使用in关键字来区别函数块的参数和返回值。\nnumbers.map({(number: Int) -&gt; Int inlet result = 3 * numberreturn result})实践\n重写这段closure封闭代码为所有的奇数返回零。\n你有一些列的选项让封闭块写的更简洁。如果一个封闭代码块的类型已知，比如一个回调授权，你可以省略参数的类型，他是一个返回类型，或是两个，单体封闭段代码隐式的返回他们自己的段。\nnumbers.map({ number in 3 * number } 你而引用参数名称代替数字，在短的闭包段中，这种办法很灵。\n把闭包作为最后一个参数传给函数，可以在后面的大括号立即出现。\nsort([1, 5, 3, 12, 2]) { $0 &gt; $1 }对象和类\n使用class关键字创建一个新类。只要在同类的上下文中，类属性的声明的方式和一个变量或是常量是相同的。函数方法同理。\nclass Shape {var numberOfSides = 0func simpleDescription() -&gt; String {return “A shape with (numberOfSides) sides.”}}实践\n创建一个常量属性，在类中添加一个有参数的方法。\n通过在类名的后面紧跟一个括号来生成类的实例。使用点语法规则去访问类的属性方法。\nvar shape = Shape()shape.numberOfSides = 7var shapeDescription = shape.simpleDescription()这个版本的Shape类貌似少了写东西，引用一个初始化方法去设定类，当类的实例创建的时候，使用init方法完成初始化设定工作。\nclass NamedShape {var numberOfSides: Int = 0var name: Stringinit(name: String) {self.name = name}func simpleDescription() -&gt; String {return “A shape with (numberOfSides) sides.”}}注意self如果初始化name参数。在类的实例创建的时候去执行初始化方法。每个属性都需要赋值，要么在类中直接声明赋值（例如: 变量numberOfSide）要么通过初始化方法初始化。（例如：变量name）\n如果想在类销毁的时候，去做一些终了清理动作,那就使用deinit方法去实现。\n子类的名称放到父类名称的前面，用分号隔开。子类不一定有父类，其实你也可以省略父类。\n子类方法覆盖父类方法实现，使用override方法，没有ovverride，编译器会检测一个错误，编译器也检测子类是否覆盖了父类。\nclass Square: NamedShape {var sideLength: Doubleinit(sideLength: Double, name: String) {self.sideLength = sideLengthsuper.init(name: name)numberOfSides = 4}func area() -&gt; Double {return sideLength * sideLength}override func simpleDescription() -&gt; String {return “A square with sides of length (sideLength).”}}let test = Square(sideLength: 5.2, name: “my test square”)test.area()test.simpleDescription()创建一个NamedShape的子类Circle,使用初始化器初始化radius属性，在Circle类中实现area和describe方法。\n使用脚手架方法设定和读取属性值。\nclass EquilateralTriangle: NamedShape {var sideLength: Double = 0.0init(sideLength: Double, name: String) {self.sideLength = sideLengthsuper.init(name: name)numberOfSides = 3}var perimeter: Double {get {return 3.0 * sideLength}set {sideLength = newValue / 3.0}}override func simpleDescription() -&gt; String {return “An equilateral triagle with sides of length (sideLength).”}}var triangle = EquilateralTriangle(sideLength: 3.1, name: “a triangle”)triangle.perimetertriangle.perimeter = 9.9triangle.sideLengthperimeter设定，有一个显式的名称 newValue.  你可以提供隐式名字在set代码段的括号范围内。\n注意，初始化EquilateralTriange类分3步：\n\n声明子类，设定属性值。\n\n2.调用父类的初始化函数。\n3.改变父类的属性值，额外的设置工作使用，getters 和 setters方法。\n如果你不需要计算，但是仍然需要在set新变量之前或之后执行代码，使用willSet和didSet.例如， 例如， 计算三角的边长和计算矩形的边长相同。\n类的方法和函数有一个很重的区别。函数的参数名只在函数中使用， 方法在调用的时候可以使用缺省值，在方法的调用过程中，函数有相同的参数名称，你可以再方法内指定别名。\nclass Counter {var count: Int = 0func incrementBy(amount: Int, numberOfTimes times: Int) {count += amount * times}}var counter = Counter()counter.incrementBy(2, numberOfTimes: 7)形参是否可写？之前的操作想一个方法，属性和下标。如果之前的值是nil, 每个变量后都有一个？ 无视并且整个表达式的的值都是nil, 其他情况，选项值是展开的，每个后面都？作用于整个展开值。在两种情况，整个表达式的值都是选项值。\nlet optionalSquare: Square? = Square(sideLength: 2.5, name: “optional square”)let sideLength = optionalSquare?.sideLength枚举和结构体\n使用eum去创建一个枚举。像类和其他名称类型， 枚举有一个方法和她关联。\nenum Rank: Int {case Ace = 1case Two, Three, Four, Five, Six, Seven, Eight, Nine, Tencase Jack, Queen, Kingfunc simpleDescription() -&gt; String {switch self {case .Ace:return “ace”case .Jack:return “jack”case .Queen:return “queen”case .King:return “king”default:return String(self.toRaw())}}}let ace = Rank.Acelet aceRawValue = ace.toRaw()实践\n写个函数，使用他们的RAW值 比较两个rank值。\n以上的例子，raw值类型是一个整形枚举值，你可以只指定第一个RAW值，raw值得赋值是哟顺序的，你也可以使用字符串和浮点数枚举值。\n使用toRaw和fromRaw函数去在raw值和枚举值间进行转换。\nif let convertedRank = Rank.fromRaw(3) {let threeDescription = convertedRank.simpleDescription()}枚举的成员变量是一个实际的数值，写raw值得方式，不仅仅是一种，事实上，没有意义的raw值得这种情况，你不能只提供一个。\nenum Suit {case Spades, Hearts, Diamonds, Clubsfunc simpleDescription() -&gt; String {switch self {case .Spades:return “spades”case .Hearts:return “hearts”case .Diamonds:return “diamonds”case .Clubs:return “clubs”}}}let hearts = Suit.Heartslet heartsDescription = hearts.simpleDescription()实践\n添加一个color方法到Suit中，返回一个黑桃和黑梅花，返回一个红心和红方片。\n注意，两种方法应用上面的红桃成员，当给hearts赋一个常量，枚举成员Suit, Hearts是原名引用，因为常量没有显式指定类型。在switch分支判断内，枚举使用简写形式，Hearts因为slef的值是已知的，如果类型已知，你尅在任何的时候使用简写形式。\n使用struct关键之创建结构体。结构体是支持许多相同类型的类，包括方法和初始值化器。类和结构体之间最大的的区别是结构体在你的代码中是传值得，而类是传引用的。\nstruct Card {var rank: Rankvar suit: Suitfunc simpleDescription() -&gt; String {return “The (rank.simpleDescription()) of (suit.simpleDescription())”}}let threeOfSpades = Card(rank: .Three, suit: .Spades)let threeOfSpadesDescription = threeOfSpades.simpleDescription()实践\n添加一个创建一个完成扑克牌方法，一个卡时候各种组合情况。\n一个枚举成员可以给一个枚举实例赋值，相同的枚举成员可以赋予不同的值。你创建一个实例的时候，提供一个赋值。管理安置和rawv值是不同的，一个枚举的raw值可以赋予所有的实例，你定义一个枚举然后赋一个raw值。\n例如，考虑从服务器上请求日出日落时间需求，服务器要么返回一个有效信息，要么返回一个错误信息。\nenum ServerResponse {case Result(String, String)case Error(String)}let success = ServerResponse.Result(“6:00 am”, “8:09 pm”)let failure = ServerResponse.Error(“Out of cheese.”)switch success {case let .Result(sunrise, sunset):let serverResponse = “Sunrise is at (sunrise) and sunset is at (sunset).”case let .Error(error):let serverResponse = “Failure… (error)”}实践添加第三个服务器相应分支。注意如何从ServerResponse截取日出和日落的日期，如另一个想匹配的分支。协议与扩展使用protocol关键字声明一个协议。protocol ExampleProtocol {var simpleDescription: String { get }mutating func adjust()}类，枚举，结构体都可以采用协议。\nclass SimpleClass: ExampleProtocol {var simpleDescription: String = “A very simple class.”var anotherProperty: Int = 69105func adjust() {simpleDescription += “ Now 100% adjusted.”}}var a = SimpleClass()a.adjust()let aDescription = a.simpleDescriptionstruct SimpleStructure: ExampleProtocol {var simpleDescription: String = “A simple structure”mutating func adjust() {simpleDescription += “ (adjusted)”}}var b = SimpleStructure()b.adjust()let bDescription = b.simpleDescription\nclass SimpleClass: ExampleProtocol {var simpleDescription: String = “A very simple class.”var anotherProperty: Int = 69105func adjust() {simpleDescription += “ Now 100% adjusted.”}}var a = SimpleClass()a.adjust()let aDescription = a.simpleDescriptionstruct SimpleStructure: ExampleProtocol {var simpleDescription: String = “A simple structure”mutating func adjust() {simpleDescription += “ (adjusted)”}}var b = SimpleStructure()b.adjust()let bDescription = b.simpleDescription实践写一个枚举来遵循一个协议。提示：使用mutating关键字声明SimpleStructure去标示一个可以修改结构体的方法。SimpleClass不需要任何的方法mutating标示，因为类的方法总是可以改变类的属性。使用extension添加一个已存在的类型，就一个新的方法可以计算属性，你可以使用一个扩展添加一个协议来适应一个新类型，在任何的地方声明，甚至从框架中引入一个类型。extension Int: ExampleProtocol {var simpleDescription: String {return “The number (self)”}mutating func adjust() {self += 42}}7.simpleDescription实践\n写一个double的扩展类型，添加absoluteValue绝对值属性。\n你可以使用协议名称想任何其他的名字类型，例如， 创建一个有不同类型但是遵循一个单独协议的对象集合。当你的工作变量时一个协议类型，方法外的协议定义是不可变的。\nlet protocolValue: ExampleProtocol = aprotocolValue.simpleDescription// protocolValue.anotherProperty // Uncomment to see the error虽然protocolValue是SimpleClass的实时类型，编译器协商一个ExampleProtocol类型，就是说你不能偶然的访问实现了一个辅助协议的类的方法和属性。\n泛型\n在尖括号内写名字来创建泛型函数或类型。\nfunc repeat(item: ItemType, times: Int) -&gt; ItemType[] {var result = ItemTypefor i in 0..times {result += item}return result}repeat(“knock”, 4)你可以创泛型方法，泛型函数， 如类，枚举，结构体。\n// Reimplement the Swift standard library’s optional typeenum OptionalValue {case Nonecase Some(T)}var possibleInteger: OptionalValue = .NonepossibleInteger = .Some(100)使用where关键字在类型名称的后面，指定一个列表需求，例如， 需要一个实现协议类型， 需要实现两个相同的类型，或是需要一个类有特定的父类。\nfunc anyCommonElements &lt;T, U where T: Sequence, U: Sequence, T.GeneratorType.Element: Equatable, T.GeneratorType.Element == U.GeneratorType.Element&gt; (lhs: T, rhs: U) -&gt; Bool {for lhsItem in lhs {for rhsItem in rhs {if lhsItem == rhsItem {return true}}}return false}anyCommonElements([1, 2, 3], [3])实践\n修改anyCommonElments函数，让函数返回一个有任意两个序列的数组。\n这种简单的情况，你可以省略where关键字，在引号的后面简单的写一个协议或是类名。的写法，等同于。\n","slug":"old_topic/2016-09-17-53","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"0702cc2eb251ca9e1ae5634e3650489b","title":"圣诞的三个思考","content":"关于脚本语言。\n最近写了一段时间的LUA脚本，LUA使用好了，非常的强大，使用不好，给自己埋坑。通过使用LUA，对解释性的脚本语言的看法和以前有些变化。之前一直以来，尽量避免使用特殊的脚本语言开发，更倾向于使用Python做脚本开发，如果是从C++转向Python开发可以说很顺手。再使用LUA之后，就发现任何语言都有自己的优缺点。从面向解决问题的角度来说，尝试使用其他的脚本语言些程序也是很有意思的事，选择好的开发脚本语言。有着事半功倍的效果。\n\n至此，发现现在如果开发点PHP和JAVA也未尝不可。有些功能用PHP到时很方便，因为是在服务器端运行，谁也不大关心具体用的技术，保证并发处理质量就和健壮性就可以。现在有的互联网公司，比的不是稳定，是速度。比的不是技术，是体力。\n\n\n\n关于Linux开发环境。\n\n今天群里有一个大哥说他，就是不喜欢Ubuntu，宁可选用freebsd也不愿意使用Ubuntu，问他为什么，他说他就是不喜欢。就是这么的任性。\n\n使用开源语言工具开发系统，在Linux环境下，部署运行环境和开发环境都比较便利。个人比较YUM和apt-get 之间，更喜欢Ubuntu的apt-get,因为更少会遇到依赖不对的问题。这相对以前用centOS的体验要好的多，也可能是对centos的用法有问题，但是yum是python写的，有时的却会很容易被弄坏。\n\n其实，某些环境部署不是很复杂的情况下，使用Windows下部署也挺好的，比如Python的Django的开发环境部署在Windows环境，只需要一个eclipse+PyDev+SVN插件+Django的源码包就OK。依赖不多，安装的问题也不多，最多也就是eclipse和JDK版本过来的问题，但是用新的版本基本都可以解决。\n\n所以，现在不太纠结什么都需要在纯Linux环境下开发，某些简单部署的项目，Windows下部署开源软件就OK。\n\n\n\n关于技术书和源代码\n\n这方面，国内的确也没什么太成气候的社区，等技术文档都翻译成中文，有可能都跟不上技术发展升级的速度。最好还是直接看英文的文档比较好。如果是用开源的技术作为解决方案，有很多的源代码，直接可以去Github上下载，学习文档，GitHub真是一个好东西。因为使用开源的解决方案，现在也经很少的去收集一节老的软件。只要有随时随地的都可以在网站找到，而保留在自己的老软件，或许因为版本过来，运行起来会有问题。另一方面，有些特殊的开源软件，发展一定时期就停滞了，比如有的在200X年代码就不更新了，但是基本的服务现在拿来现在还是可以使用的，前提这代码是开放独立的，没有过多的依赖问题。\n\n估计有错别字，但是不想改了。\n\n","slug":"old_topic/2016-09-17-57","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"503704190843bf2a46548f05306fa34f","title":"开源一览","content":"Hy’shttps://hy.readthedocs.org/en/latest/\nmemcachedhttp://memcached.org/\nlibeventhttp://libevent.org/\nlibevent for pythonhttps://github.com/fancycode/python-libevent\nwebsocket for pythonhttps://github.com/Lawouach/WebSocket-for-Python\nsinacloud for pythonhttps://github.com/sinacloud/sae-python-dev-guide\n","slug":"old_topic/2016-09-17-58","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"5e89e52cbdad9a5b6688281047c5f734","title":"C和PYTHON的SOCKET通信","content":"作者：糖果\n[问题] C和python的Socket通信\nSocket是linux提供的基础服务,用于实现计算机间的tcp/ip协议通信。python是强大的高级解释行语言，功能抽象程度高，语法简洁功能强大。网络上有很多socket入门例子程序，都是用C语言写的，传统的CS服务器客户端演示程序。\n本文提供的同样是最简单的CS结构通信程序，区别是，Server用Python编写，Client用C语言编写。\n基础的Socket API 使用是模式化的,没有算法过程，只有配置过程。而pyhon被誉为是可以运行的伪语言，可以更好的说明Socket API的模式化使用步骤。\n[解决案]首先列出Server端程序的Python代码，除了import和print,几乎其中的每一句都是socket API使用步骤中，不可或缺的部分。\nC语言使用Socket的套路几乎和python的一样，区别是，C语言本身还要考虑buf空间的申请和释放，判断socket各个步骤成功异常。还要准备hostent结构体和sockaddr结构体，进行更详细定义过程。\nserver.py\n1234567891011121314151617181920212223import socket#取得一个socket对象句柄s = socket.socket()                 #取得主机名host = socket.gethostname()                  #定义端口号port = 1236                  #将socket对象句柄，与指定的IP和Port号绑定。s.bind((host, port))                  #服务其开始监听数据s.listen(5)                  #大循环，开始堵塞式的数据读取while True:                      #接受外部链接请求“c”其他客户机与本机链接产生的，新的通信socket句柄，“addr”表示client记得IP地址。    c, addr = s.accept()                      #接受1024大的数据    data = c.recv(1024)                      print data    print &#x27;Got connection from:&#x27;, addr, data    #相应链接，把一条英文信息返回给client    c.send(&#x27;Thank you for connecting:&#x27;)                     #关闭socket链接    c.close()                 \n\n运行服务器端程序：\n1python server.py\n\n“坑”提示：代码“c, addr = s.accept()”中，c和addr之间的符号是”, “逗号，输入时请注意！\n\n\nclient.c下面是一段c语言的客户端程序。一般来说，需要对“hostent”和“sockaddr_in”进行解释，还有对socket, recv, connect,send等API接口参数含义的介绍。就不介绍了，直接在系统里man一下API吧，或是发挥一下自己想象力，然后代码实践，再看文档求证一下吧！因为API不用背，需要动态的理解。\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/socket.h&gt;#define PORT 1236#define BUFFER_SIZE 1024int main(int argc, char** argv)&#123;  int sock_fd, recvbytes;  char buf[BUFFER_SIZE];  struct hostent *host;  struct sockaddr_in serv_addr;  if (argc &lt; 2) &#123;    fprintf(stderr, &quot;Please enter the server&#x27;s hostname!\\n&quot;);    exit(1);  &#125;  if ((host=gethostbyname(argv[1]))== NULL) &#123;    herror(&quot;get host b name error!&quot;);  &#125;  if ((sock_fd = socket(AF_INET, SOCK_STREAM, 0)) == -1) &#123;    perror(&quot;Create socket error!&quot;);    exit(1);  &#125;  serv_addr.sin_family = AF_INET;  serv_addr.sin_port = htons(PORT);  serv_addr.sin_addr = *((struct in_addr*)host-&gt;h_addr);  printf(&quot;hostname:%s&quot;, host-&gt;h_addr);  bzero(&amp;(serv_addr.sin_zero), 8);  if (connect(sock_fd, (struct sockaddr* )&amp;serv_addr, sizeof(struct sockaddr)) == -1) &#123;    perror(&quot;connect error&quot;);  &#125;  if (send(sock_fd, &quot;spring&quot;, 8,0) == -1) &#123;    perror(&quot;send error!&quot;);  &#125;  if ((recvbytes = recv(sock_fd, buf, BUFFER_SIZE, 0)) == -1) &#123;    perror(&quot;recv error!&quot;);    exit(1);  &#125;    buf[recvbytes] = &#x27;\\0&#x27;;  printf(&quot;Received:%s&quot;, buf);  close(sock_fd);  return 0;&#125;\n\n\n编译客户端程序：[code]gcc -o client client.c[/code]运行客户端程序：[code]./client 127.0.0.1[/code]\n“坑”提示:C语言程序中的“if ((recvbytes = recv(sock_fd, buf, BUFFER_SIZE, 0)) == -1) ”这句，不要写成：“if (recvbytes = recv(sock_fd, buf, BUFFER_SIZE, 0) == -1)” \n\n\n以上的C语言client程序，几乎等同于如下python的client代码。结合上面的python服务器端的程序注释，下面的client端程序几乎不需要解释。\n12345678import sockets = socket.socket()host = socket.gethostname()port = 1236s.connect((host, port))s.send(bytes(&quot;python&quot;))print s.recv(1024)s.close()\n\n[尾声]socket的API使用相对很简单，于Linux下的打开关闭读写文件类似。而socket API的使用，是建立在对TCP/IP基本概念了解的基础上，至少要了解主机和端口号的概念。项目中几乎不会用这么简单的代码，下一篇介绍select基础，基础原理哥附身。\n谨以此文，献给大姐！献给想不起API的青春,再见青春，再见的永远的故乡！峰哥护体。\n[赠送内容] \n下面是python之间进行UDP通信：\n123456789101112131415import socket    address = (&#x27;127.0.0.1&#x27;, 1812)  s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  s.bind(address)    while True:      data, addr = s.recvfrom(2048)      if not data:          print &quot;client has exist&quot;          break      print &quot;received:&quot;, data, &quot;from&quot;, addr    s.close()  \n\n123456789101112import socket    address = (&#x27;127.0.0.1&#x27;, 1812)  s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)    while True:      msg = raw_input()      if not msg:          break      s.sendto(msg, address)    s.close()  \n\n\n下面是python之间进行TCP通信：\n123456789101112131415def tcpServer():       srvsock = socket.socket( socket.AF_INET, socket.SOCK_STREAM)       srvsock.bind((&#x27;&#x27;, 1812))       srvsock.listen(5)         while True:           clisock, (remoteHost, remotePort) = srvsock.accept()           print &quot;[%s:%s] connected&quot; % (remoteHost, remotePort)           #do something on the clisock           clisock.close()       if __name__ == &quot;__main__&quot;:       tcpServer()   \n\n\n1234567891011def tcpClient():       clisock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)       clisock.connect((&#x27;localhost&#x27;, 1812))       #I/O on this clisock       #clisock.send(&quot;&quot;)       #dat = clisock.recv(len)              print dat          if __name__ == &quot;__main__&quot;:       tcpClient()  \n\n\n\n\n\n注释：个人劳动成果，转载使用请注明本文作者及出处链接，谢谢合作！\n","slug":"old_topic/2016-09-17-6","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"6705e8206cf0cbe8dfed2f6418924ac7","title":"十部国外经典算法著作","content":"1、《Fundamentals of Data Structures》（Horowitz and Sartaj Sahni著）——中文译名《数据结构基础》2、《Practical Data Structures in C++ 》（Bryan Flamig著）——中文译名（数据结构实践-用C++描述）3、《Reliable Data Structures in C》（Thomas Plum著）——中文名不太清楚4、《Data Structures and Algorithms》（Alfred V. Aho, Bell Laboratories, Murray Hill, New JerseyJohn E. Hopcroft, Cornell University, Ithaca, New YorkJeffrey D. Ullman, Stanford University, Stanford, California）——作者可全都是大腕啊！5、《Data Structures, Algorithms and Program Style Using C》6、《Data Structures and Algorithm Analysis in C》7、《Data Structures: From Arrays to Priority Queues》8、《Information Retrieval: Data Structures &amp; Algorithms》9、《Introduction to Algorithms》（Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest著）——算法导论10、《DDJ Algorithms and Data Structures Articles》\n","slug":"old_topic/2016-09-17-56","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"1b32c1036ca4d3e5df2f07764518d56f","title":"2014年书目","content":"这些书很多都是可以用来查的：\n12345678910111213141516171819202122232425C陷阱与缺陷C专家编程C和指针C HeadFirs：征服C指针Essential C++C++对象模型C++ PrimerC++ GUI QT4STL源码刨析大话设计模式Python HeadFirstPython自然语言处理Python编程初学者指南TCP/IP详解Unix环境高级编程Unix网络编程Linux编程设计Linux内核设计与实现Linux鸟哥私房菜深入理解Linux内核Hadoop权威指南Swift权威指南数学之美统计思维(程序员数学之概率统计)","slug":"old_topic/2016-09-17-60","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"8d4d4a31b8348f77d3557b100128fdb4","title":"PySide Tutorials with QtQuick and QML","content":"qt-project.org/wiki/Category:LanguageBindings::PySide\n","slug":"old_topic/2016-09-17-81","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"045828a93c4cf8c815bcc3479b927f80","title":"《QT---SDK自动生成代码解析》","content":"一般情况，任何一个SDK开工具，在创建一个工程后，都会自动的生成一些自动代码，而之后的工作，就是在这一套自动生成的东西上，完成我们的后续工作，很好的理解SDK自动生成的东西，更便于我们后续的开发工作，可以起到事半功倍的效果，可以类推扩展出很多外延的知识，更便于之后对整个工具的快速学习理解。\n传统的一些教程都是step by step的方式，这种方式对有没有基础概念的人来说，可以很好的达成他们想做出东西的目标，问题是在不了解框架机制的前提下跟着做，只能是照猫画虎，不能举一反三。\n\n   网上是不是，有很多的蛇精病教程让你苦恼那？那好吧，我们来写一个。   首先，QT在创建一个工程之后，她的目录结构是这样的。\n   主要的文件类型有：.pro .h .cpp .ui   .pro 文件： 简单说，这个就是整个C++工程的makefile文件，遵循的是QMakefile的语法规则，好普通的makefile语法类似。\n   .cpp 文件： SDK一共会生成两个.cpp 文件，main.cpp和mainwindow.cp, main.cpp是整个工程主函数的文件， mainwindow.cpp 就是用户自定义的窗体类。\n   .UI 文件： 此文件是一个描述UI控件信息的XML文件，QT Designer就是把用户绘制的窗体控件的信息，保存到这个XML文件中。在工程编译之后，就会把XML形式的窗体信息，转换成C++语法内容的.h 文件。\n   整个工程中以MainWindow这个类为中心，开始设计用户的UI程序，下面是MainWindowl.cpp代码。\n[code]#ifndef MAINWINDOW_H#define MAINWINDOW_H\n#include \nnamespace Ui {class MainWindow;}\nclass MainWindow : public QMainWindow{    Q_OBJECT\npublic:    explicit MainWindow(QWidget *parent = 0);    ~MainWindow();signals:    void refresh();public slots:    void update();    void clicked();private:    Ui::MainWindow *ui;};\n#endif // MAINWINDOW_H\n[/code]\n","slug":"old_topic/2016-09-17-52","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"f64657093bb73966c8848e346d510189","title":"Flask文档汇总","content":"Flash用户指南 \nFlask WTF \n文档翻译计划 \nFlask用户手册(PDF)下载\nFlask用户手册(Kindle 尺寸PDF)下载\nGitHub翻译项目\n利用SAE Storage+Flask搭建图片托管站\n","slug":"old_topic/2016-09-17-59","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"d49fd4ef7fef560290ae6ae45970e981","title":"Django Backstage","content":"Django Backstage    使用virtualevn,uWSGI, nginx在网站上部署Django工程。早期的Django，运行应用很多都是和特定的网站相关的。为了确保应用和页面在站点上可重用，站点框架继承到Django中。\n站在历史的角度上讲，Apache-modwsgi上下问环境的异议在于，从独立的web域名中，把Django应用独立出来。\n\n回到从前，新兴的标准推荐是uwsgi + nginx. 这开创一个新纪元，你的Django Apps 可以提供RESTful 服务，WebSockets和任何其他各种各样的的服务，另外还有传统的Html/CSS/JS的内容。\n\n感谢uWsgi，就想你期望的那样就，你可以把很多不同的服务运行在不同的端口（或是套接字）幸福的一起运行而不需要附加的web服务器（再见apache）。直到后来(如果真的发生)，当我绑定了一个开心的小uWsgi服务在服务器上。\n\n（喂 nginx-后面详细说明）我们从逻辑上谈网站域名和网站框架。一些大型服务的构建，并不在公共命名空间保留。所以，参照这些的站点上下文是没有清晰的意义的。\n\n我们需要一个新的方式来讨论和管理这些服务。因此，我们介绍Django Backstage项目和使用（可能会滥用 ）使用、一个爵士乐的比喻表示他的结构和功能组件。\n\nClass Act:“”Act类本质上是一个可运行的Django应用。（可以运行，没必要运行）这是类比了一个表演。（演奏者，和声，合唱团，等）迈尔斯.戴维斯隐藏自己的名誉，戴维斯此期间的演出结束了，但是保留了这个音乐表演。的确存在，他们没有演，但确实是纯在一种音乐演出（音乐家是这样的）。类似你的应用，事实上没有运行，但也被类比定义成演出。（Act）””“”””自然而然，一个团体必须有一个经理(演出经理)。想象：鲁本 金凯德。（鹧鸪家庭合唱团）, 帕科上校(埃尔维斯)。\nClass Stage:“”Stage是你运行Act的一个环境。就像一个音乐舞台，可以演奏音乐的物理空间，在这，我们会使用Virtualevn来构建和使用一个舞台，uWsgi和Nginx, 尽管我们可以使用更流行的舞台，用gunicorn/superviso 或是其他什么的。\nClass Manager:“”””我们的Stage Manager(舞台经理)和uWsgi Emperor协作控制，开始/停止/添加/移除/修改 会话。内部，意味着 和应用uwsgi.ini文件协作。外部，意味StageManager需要调高系统级别权限去“增加/消除”连接到/etc/uwsgi-emperor/vassals.正确的uwsgi.ini文件/连接，设计命名的方案。在运行的Backstage实例之间，将冲突机会最小化。Class Set:“”””A Stage Set(舞台布景)集合了安装完了的应用（乐器），样式，脚本（光线和道具等）”””\nClass Sess:“”””Sess，是一个团体在舞台上演出。是Django App运行在uWsgi.在本机暴漏端口/或是套接字。就像车库表演。你确定在演奏音乐，但（邻居很生气）是外面世界的没人听或是知道他。（我们使用’Sess’的缩写代替‘Session’避免和Django的Sessions冲突。）“”“”Class Venue:“”””A Venu(案发现场)是DNS的命名空间，例如example.com 或者类似的。案发现场是可意会不可言传的，如果你想，他可以显示小猫的图片，他可以显示一个纸杯蛋糕食谱,他也许不包含内容,在音乐世界，Venue是一个（公开或是私有）人们可以去听音乐的地方。根据演出，星期五演奏爵士，星期六演奏hipHop, 星期日什么也没有。Class Gig“”A Gig是一个现实运行的网站，是一个演出，预定了在演出地点的音乐会的舞台上演奏。她是现场音乐会。””\nClass Production:“”A production 是单个的Backstage实例，而是是她内容的超集。“”Class Manager:“”””The Production Manger(产品经理类)控制全部的产品，显然，是协调演出活动的， 舞台和 预约经理。一个演出不代表随便的拥挤小演唱会， 而是在有演出地点一个独立的演出。除非产品经理说的。\nClass Producer(PowerDNS)  企业范围产品经理 我的DNS选项/目前还没有实现。\n","slug":"old_topic/2016-09-17-89","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"c7af08cb0e1504eafb75f03c0e63769a","title":"在安装nodeJS过程中，遇到的问题。","content":"作者：糖果\n1\n1234sudo apt-get install python-software-propertiessudo add-apt-repository ppa:chris-lea/node.jssudo apt-get updatesudo apt-get install nodejs\n\n2\n12sudo apt-get install nodejs npm在安装nodejs的时候，就需要安装npm。\n\n3\n123express找不到依赖的解决办法。npm install express -gdnpm install -d (选项D是安装所有相关的依赖)\n\n\n4\n找不到express命令的解决办法express命令行和express分成独立两个部分，使用命令行，安装下面的内容。\n12sudo npm install -g express-generator@3（第三版）sudo npm install -g express-generator（第四版）\n\n5找不到express模块的解决方法\n12export PATH=”$HOME/node/bin:$PATH”export NODE_PATH=”$HOME/node/lib/node_modules”\n\n6用express创建的例子工程，不灵用curl监听不到，所以在Stackoverflow上找了一个简单的helloword的node.js例子，然后运行\n12node test.jscurl localhost:1337\n\n测试通过，测试代码如下：\n12345678var http = require(&#x27;http&#x27;);http.createServer(function (req, res) &#123;    res.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/plain&#x27;&#125;);    res.end(&#x27;Hello World\\n&#x27;);&#125;).listen(1337);console.log(&#x27;Server running at http://localhost:1337/&#x27;);","slug":"old_topic/2016-09-17-90","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"3139e571c8dedb1f42632f1a0237b0bb","title":"测试图片系统","content":"测试\n","slug":"old_topic/2016-09-17-91","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"58d2296c453074b589ed10ee2476f21a","title":"比Table灵活的DIV标签。","content":"网页制作的过程中，难免要对网页中的元素进行排版布局。最开始的时候，流行的方法是用Table标签进行网页布局。因为，众所周知的原因：“速度”。表格标签在嵌套过多的时候，网页在显示的时候会变慢。人们就开始使用Div标签进行布局。\n表格是现实生活中最常见的二维表示形式，很好理解。从个人角度来看，表格表示一行一行的明细信息的时候，很方便。但在，纵向首先描述“列”的时候，Div标签更合适，更灵活一些。\n\n下面列出，类似表格行明细的Div实现代码。\n\nCSS样式：\n12345678910111213141516&lt;style&gt;    .afooter &#123;        float : none;        alignment-adjust: center;        &#125;       .afooter-list &#123;        float : left;        alignment-adjust: center;        &#125;        .afooter-list-bottom &#123;        float : none;        alignment-adjust: center;        &#125;&lt;/style&gt;\n\nHTML代码：（演示1）\n1234567891011121314&lt;div class=&quot;afooter&quot;&gt;    &lt;div class=&quot;afooter-list&quot;&gt;a&lt;/div&gt;    &lt;div class=&quot;afooter-list&quot;&gt;b&lt;/div&gt;    &lt;div class=&quot;afooter-list&quot;&gt;c&lt;/div&gt;    &lt;div class=&quot;afooter-list&quot;&gt;d&lt;/div&gt;    &lt;div class=&quot;afooter-list-bottom&quot;&gt;e&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;afooter&quot;&gt;    &lt;div class=&quot;afooter-list&quot;&gt;e&lt;/div&gt;    &lt;div class=&quot;afooter-list&quot;&gt;f&lt;/div&gt;    &lt;div class=&quot;afooter-list&quot;&gt;g&lt;/div&gt;    &lt;div class=&quot;afooter-list&quot;&gt;h&lt;/div&gt;    &lt;div class=&quot;afooter-list-bottom&quot;&gt;i&lt;/div&gt;&lt;/div&gt;   \n\n\n上面这段代码，用Table标签写，如下：（演示3）\n1234567891011121314151617&lt;table&gt;    &lt;tr&gt;        &lt;td&gt;a&lt;/td&gt;        &lt;td&gt;b&lt;/td&gt;        &lt;td&gt;c&lt;/td&gt;        &lt;td&gt;d&lt;/td&gt;        &lt;td&gt;e&lt;/td&gt;             &lt;/tr&gt;    &lt;tr&gt;        &lt;td&gt;h&lt;/td&gt;        &lt;td&gt;i&lt;/td&gt;        &lt;td&gt;j&lt;/td&gt;        &lt;td&gt;h&lt;/td&gt;         &lt;td&gt;i&lt;/td&gt;            &lt;/tr&gt;&lt;/table&gt;\n\n其实，所谓的灵活，是指代码从机制给你提供了灵活操作的可能，在这个基础上来讲，运用的灵活不灵活，取决于人编码者。\nCSS样式：\n1234567891011121314151617181920212223242526272829303132333435&lt;style&gt;    .cfooter &#123;        float : left;        alignment-adjust: center;                   &#125;                .cfooter-list &#123;        float : none;        alignment-adjust: center;                   &#125;            .cfooter-list-bottom &#123;        float : none;        alignment-adjust: center;                   &#125;               .dfooter &#123;        float : none;        alignment-adjust: center;                   &#125;                .dfooter-list &#123;        float : none;        alignment-adjust: center;                   &#125;            .dfooter-list-bottom &#123;        float : none;        alignment-adjust: center;                   &#125;          &lt;/style&gt;\n\nHTML代码：（演示2）[code]\n1234567891011121314    &lt;div class=&quot;cfooter&quot;&gt;        &lt;div class=&quot;cfooter-list&quot;&gt;1&lt;/div&gt;        &lt;div class=&quot;cfooter-list&quot;&gt;2&lt;/div&gt;        &lt;div class=&quot;cfooter-list&quot;&gt;3&lt;/div&gt;        &lt;div class=&quot;cfooter-list&quot;&gt;4&lt;/div&gt;        &lt;/div&gt;    &lt;div class=&quot;dfooter&quot;&gt;        &lt;div class=&quot;dfooter-list&quot;&gt;5&lt;/div&gt;        &lt;div class=&quot;dfooter-list&quot;&gt;6&lt;/div&gt;        &lt;div class=&quot;dfooter-list&quot;&gt;7&lt;/div&gt;        &lt;div class=&quot;dfooter-list&quot;&gt;8&lt;/div&gt;        &lt;/div&gt;&lt;/div&gt;  \n\n这里可能需要多说的是，每个Div层次，在默认的时候，每个Div元素都是需要换行的。每个Div元素都不在一行，但是这个可以情况可以通过改变CSS样式来改变，如上面代码中的“float : none;”属性设置。在这篇代码里，float的left表示，后面的div元素，紧接着其后不换行，而none属性表示，先一个div层开始，div元素就换行了，不在一行了。\nDiv比较灵活，至于怎么运用，取决于编码者。可以用Div表示类似于表格的明细信息，也可以应用于比较复杂的图片布局。\n实际的运行效果，可以看下面的连接：运行效果演示\n","slug":"old_topic/2016-09-17-93","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"d843ced03f40ac612213952de4b63ad2","title":"二分查找","content":"12345678910111213141516171819202122232425262728293031323334353637383940#include&lt;stdio.h&gt;int bseek(int key) &#123;        int array[10] = &#123;1,2,3,4,5,6,7,8,9,10&#125;;        int low = 0;        int high = (sizeof(array) / 4) - 1;        int mid = 0;        int ret = -1;        while(low &lt;= high) &#123;                mid = (low + high) / 2;                if (key == array[mid]) &#123;                        ret = mid;                        break;                &#125; else if (key &lt; array[mid]) &#123;                        high = mid - 1;                &#125; else if (key &gt; array[mid]) &#123;                        low = mid + 1;                &#125;        &#125;        return ret;&#125;void main(int argc, char* argv[])&#123;        printf(&quot;key[0]:%d\\n&quot;, bseek(0));        printf(&quot;key[1]:%d\\n&quot;, bseek(1));        printf(&quot;key[2]:%d\\n&quot;, bseek(2));        printf(&quot;key[3]:%d\\n&quot;, bseek(3));        printf(&quot;key[4]:%d\\n&quot;, bseek(4));        printf(&quot;key[5]:%d\\n&quot;, bseek(5));        printf(&quot;key[6]:%d\\n&quot;, bseek(6));        printf(&quot;key[7]:%d\\n&quot;, bseek(7));        printf(&quot;key[8]:%d\\n&quot;, bseek(8));        printf(&quot;key[9]:%d\\n&quot;, bseek(9));        printf(&quot;key[10]:%d\\n&quot;, bseek(10));        printf(&quot;key[11]:%d\\n&quot;, bseek(11));&#125;\n\n\nlist  = [1,2,3,4,5,6,7,8,9,10]\nlow = 0\nhigh = len(list) - 1\nidx = 0\n\ndef bseek(key):\n        global low\n        global high\n        global idx\n        while(low &lt;= high):\n                mid = (low + high) / 2\n                if (key == list[mid]):\n                        idx = mid\n                        break\n                elif(key &lt; list[mid]):\n                        high = mid - 1\n                elif(key &gt; list[mid]):\n                        low = mid + 1\n\nbseek(6)\nprint idx\n           \n\n","slug":"old_topic/2016-09-17-49","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua,折半查找,二分查找,lua二分查找,c","author_index":"安全书"},{"id":"e383b4e22fb82668d69a82a24de61560","title":"div中嵌套div的网页布局","content":"作者：糖果\n因为这个个人网站的前端，没有过于复杂的元素 ，所以，想使用纯Div+css+js的方式实现，这个可以对很细微的元素进行调整。\n这次主要是说，网页中Div嵌套的布局处理方式。而应用的场合是，网站的登录框。下面，就分别给出了，网站元素的样式和Html标签代码。\nCSS样式代码,如下：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 &lt;style&gt;.outside&#123;    float: left;    padding: 0;    margin: 1px 0 0 1px;\twidth: 230px;\theight:320px;\tborder:1px solid #F00;\tbackground-image:url(/static/yqfy/img/login_background.png)&#125;.inside &#123;    float: left;    padding: 0;    margin: 30px 0px 0px 40px;\twidth:150px;\theight:130px;\tborder:1px solid #F00;&#125;.login_username &#123;    float: right;    padding: 0;    margin: 0 0 0 1px;    background : none ;    font-size: .8em;    text-align:center;    background-color: black;         border-spacing: 1px;    border: 1px;    border-radius: 1px;    color:cornsilk&#125;    .login_password &#123;    float: right;    padding: 0;    margin: 1px 0 0 1px;    background : none ;    font-size: .8em;    text-align:center;    background-color: black;         border-spacing: 1px;    border: 1px;    border-radius: 1px;    color:cornsilk&#125; &lt;/style&gt;\n\nHtml代码如下：\n1234567891011121314151617181920212223&lt;div class=&quot;outside&quot;&gt;\toutside\t&lt;div class=&quot;inside&quot;&gt;\t\tinside       &lt;form action=&quot;&quot; method=&#x27;post&#x27; &gt;           &lt;div class=&quot;login_box&quot;&gt;           \t&lt;div class=&quot;div_input&quot;&gt;               \t&lt;img src=&quot;/static/yqfy/img/login.jpg&quot; alt=&quot;login&quot; /&gt;               &lt;/div&gt;                                          &lt;div class=&quot;div_input&quot;&gt;               \t&lt;input class=&quot;login_username&quot; name=&#x27;username&#x27; type=&quot;text&quot;  width=&quot;75px&quot; height=&quot;50px&quot; placeholder=&quot;用户名&quot; &gt;                         &lt;/div&gt;               &lt;div class=&quot;div_input&quot;&gt;               \t&lt;input class=&quot;login_password&quot; name=&#x27;password&#x27; type=&quot;password&quot;  width=&quot;75px&quot; height=&quot;50px&quot; placeholder=&quot;密码&quot; &gt;               &lt;/div&gt;\t\t           &lt;/div&gt;                                   \t&lt;div class=&quot;div_input&quot;&gt;           \t&lt;button class=&quot;login_btn&quot; type=&quot;submit&quot;&gt;登录&lt;/button&gt;        \t&lt;/div&gt;        &lt;/form&gt;&lt;/div&gt;&lt;/div&gt;\n\n实际效果，如下：点击查看效果 \n总结：css+html标签，本质上还是“设定”，这种设定主要集中在，样式颜色，位置，等。而以上的例子，关键的属性设定是margin属性。div中设定div好理解，关键点在于，如何设定嵌套在一起啊的div彼此位置关系的设定，所以，div的css的关键是：margin。\n","slug":"old_topic/2016-09-17-95","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"f779aebeb656b0c73cae40e6a7b49f03","title":"立即调用函数表达式(IIFE)","content":"可能你没注意，对于一些术语我还是有点小固执。因此，会被之后听起来流行的东西误导。JavaScript术语“自运行匿名函数”\n","slug":"old_topic/2016-09-17-94","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"a26e6182024b9cb41b1b957f9eda51b7","title":"Tenjin1.1.1(基于嵌入Python的快速全机能模版引擎)","content":"介绍pyTenjin是一个非常快速的全机能模版引擎。可以嵌入到python模版文件中的语句和表达式里面。pyTenjin会把它转化成Python脚本并且评估它。\n！！友情提示！！pyTenjin足够稳定 ，但是还是基于beta版本发布的。这就意味着未来API的式样在未来会修改。\n机能特点 \n非常快速 \n     比Django快10倍，比Cheetah快4倍，比Mako快2倍。\n     另外tenjin.py加载的很快轻量（对CGI程序很重要）\n\n全机能 \n     可组装的布局模版\n     可拆分（局部变量）缓存\n     捕获\n     预处理\n\n学习简单 \n     你不需要学习特别的模版语言。\n\n支持GAE \n     \n用户手册和变更细节请看连接。\n安装\n1.使用easy_ install安装。\n$ sudo easy_install Tenjin\n2.用源代码安装。$ tar xzf Tenjin-X.X.X.tar.gz$ cd Tenjin-X.X.X$ sudo python setup.py install\n更简单的办法是，直接将’lib/tenjin.py’和’bin/pytenjin’这两个文件复制到要使用的那个目录。\n（可选项目）安装PyYAML\n例子example.pyhtml\n12345678910&lt;?py # -*- coding: utf-8 -*- ?&gt;&lt;?py #@ARGS items ?&gt;&lt;table&gt;&lt;?py cycle = new_cycle(&#x27;odd&#x27;, &#x27;even&#x27;) ?&gt;&lt;?py for item in items: ?&gt;  &lt;tr class=&quot;#&#123;cycle()&#125;&quot;&gt;    &lt;td&gt;$&#123;item&#125;&lt;/td&gt;  &lt;/tr&gt;&lt;?py #endfor ?&gt;&lt;/table&gt;\n\nexample.py:\n123456789import tenjin#tenjin.set_template_encoding(&#x27;utf-8&#x27;)  # optional (defualt &#x27;utf-8&#x27;)from tenjin.helpers import *from tenjin.html import *#import tenjin.gae; tenjin.gae.init()   # for Google App Engineengine = tenjin.Engine()context = &#123; &#x27;items&#x27;: [&#x27;&lt;AAA&gt;&#x27;, &#x27;B&amp;B&#x27;, &#x27;&quot;CCC&quot;&#x27;] &#125;html = engine.render(&#x27;example.pyhtml&#x27;, context)print(html)\n\n\nOutput:\n123456789101112$ python example.py&lt;table&gt;  &lt;tr class=&quot;odd&quot;&gt;    &lt;td&gt;&lt;AAA&gt;&lt;/td&gt;  &lt;/tr&gt;  &lt;tr class=&quot;even&quot;&gt;    &lt;td&gt;B&amp;B&lt;/td&gt;  &lt;/tr&gt;  &lt;tr class=&quot;odd&quot;&gt;    &lt;td&gt;&quot;CCC&quot;&lt;/td&gt;  &lt;/tr&gt;&lt;/table&gt;","slug":"old_topic/2016-09-17-92","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"fe64fe43a5794c7d2cd2d7aeb68fd561","title":"新版网站的PS效果图。","content":"没有对细节渲染的太多，只想用纯的CSS,HTML进行网页布局，不在使用bootstrap的现成部件。\n","slug":"old_topic/2016-09-17-96","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"3e76fe6981c345fa30829545d52dbd82","title":"VIM的插件与自动补全","content":"插件下载地址。\n\nctags\n\n\n\nneocomplcache  \n\n\ntaglist\n\n\n\npathogen \n\n\n\n\nvim-colors-solarized \n","slug":"old_topic/2016-09-17-98","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"e51e31b662fde535ca5d2fe195614f82","title":"视频推荐APP：“开眼”。","content":"在繁复网络世界中，寻找优质的内容，就像在沙漠中寻找绿洲中的甘泉，在网上，看上去很美的一些东西，其实往往都是海市蜃楼般的内容。\n而今天，给小伙伴们，介绍一款新鲜的应用，这款应用还处于内侧阶段 ,名字叫“开眼”。开眼是一款视频的推荐APP，把精选的视频内容传送给你，可以想刷新闻一样去刷有趣的短视频，另外，像人们说的那样，“开眼“蕴含着让你大开眼界的意思。\n特点“开眼”APP的使用简单明了，开始就会有一个简洁的使用向导。重点介绍了位于，屏幕右上角的“眼睛“图标，负责整个应用的导航，回到其他级别的菜单主要靠她。从大的功能来看，有以下几大功能：\n\n每日精选\n\n“开眼”每天都会呈上新鲜有趣的视频。\n \n\n\n开眼的“每日精选”视频推荐的内容，明显更有品质，给人们挑选的视觉盛宴，是视觉饕餮者的美餐。你可以像刷新闻一样，刷新视频。\n\n往期分类如果你是对某些类别的视频，情有独钟，可以直接选择“往期分类”。 \n“往期分类”里，把过去发布的视频，进行了分类安排。你可以快速根据视频类型，定位你的兴趣所在。\n\n3.视频解说每一个视频都有一段介绍独白。介绍可以快速帮你判断，是否继续看下去，而且文字有着其自身独特的魅力。\n4.收藏分享你可以把自己喜欢的视频，收藏起来，以备不时之需，温故知新，还可以分享给小伙伴们，分享到各种社交媒体。当你闲暇的时候可以继续回味你的珍藏，有的快乐可以重复温习。分享吧，用快乐的视频感染别人。\n5.视频播放选中你喜欢的视频，猛戳进去。视频的画质很不错，不会怠慢你的眼睛，代入感很强。对视频播放的操作也很简单，缩放快进。过程中，没有广告打断你的观看。\n6.意见反馈因为是内侧版本，“开眼”还提供了一个反馈的页面，认为不错的点个赞，有建议的也可以提出来。 \n总结：对“开眼”这个软件还是很喜欢的，她真的是可以大开你的眼界，提供优质的内容。慢慢的积累把自己喜欢的视频收集起来，现在可以欣赏，未来可以回忆。将很多有趣的联想与乐趣串联起来。\n虽然是内侧版本，像一如既往的豌豆荚应用，每一次都能带给我们新鲜的空气养料。希望在未来的版本中，可以加入更丰富的内容，比如视频被观看次数和被收藏分享的次数，还有如果可以在视频的下面，看到小伙伴精妙的评论回复，就更有互动性了，哪怕是有人在问视频的背景音乐叫什么名字也好，这样至少让我们感觉，我们不是一个人战斗，一个人看视频。有更多来至网友小伙伴们哪里来的，视频“画外音”，让这一切变得更丰富多彩，有滋有味了。\n个人建议：1  可以开放视频的评论，除了谩骂，其实有些视频评论本身也是对视频的一种信息补充。2   视频介绍页面显示，视频被收藏和分享的量化数据，这种热度信息能反应出，视频的受欢迎程度。3  毕竟受众都是中国人，现在视频B格很高，本土化的文化气息比较少，除非要做成精英的小众软件。4  播放页面的设置提示可以多一些，比如基本的音量提示和亮度提示，在播放页面也可以快速分享。     如果通过右上角的图标，一级一级的退回到视频分享页面，会操作很多次，而且会打断观看。5   关于个人收藏功能，一方面应该考虑账号同步问题，另外就是以后自己的收藏的内容多了，自己怎么索引自己的收藏，一页页的翻阅，还是提供分类，或是检索框。6 希望加入每日精选的推送功能，对当天的精选推送有一个预报。7  开眼的图标如果在黑白的基础加入一些，高识别度的颜色是否会更好一些。8 右上角的回退图标使用的频率很高，可以否考虑右一个顶级的子页面导航，快速导航到想要到页面，减少页面间的跳转。9 在播放的时候，缩放按钮可以自动隐藏，全屏只有影片信息，再次触碰屏幕时候，在显示出来。10 加入最受到欢迎的 top10－100视频排行榜。11 个人设置种加入，更多的设置项目，微博，QQ登录和账号管理，云同步，WI-FI环境下观看，批量视频缓冲。12 加入收藏分类，收藏管理，收藏集合分享给好友，共享收藏夹，藏友私信。13  加入收藏达人，分享达人，最活跃用户显示。14 加入投票功能，选出群众最欢迎视频。15 加入用户推荐视频，取之于民，用之于民。开眼海报\n","slug":"old_topic/2016-09-17-97","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"4e932e195ef501e41ad67f12814a88d1","title":"有意思的脚本moonscript","content":"想看看lua到底有什么web框架，为了找到和openresty有点关系的框架，就找到了lapis，lapis是可以在openresty上跑的，更有意思的是，lapis可以使用moonscript,moonscript是一位叫做leafo的人写的。\n","slug":"old_topic/2016-09-17-99","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"054f428f76705613481e9cfa45f6bed2","title":"Nginx+Lua返回JSON类型数据","content":"作者：糖果\nNginx返回JSON数据，一种是直接在配置文件里设置，一种是通过Lua代码封装完成，讲Nginx中执行Lua返回JSON的关键，一个用API函数ngx.say，同时配合json.encode对JSON格式的字符串进行编码，然后设定响应头信息的类型。\nNginx Conf中返回JSON的方式12345678location /json/ &#123;\t    default_type application/json;\t    add_header Content-Type &#x27;text/html; charset=utf-8&#x27;;\t    return 200 &#x27;&#123;&quot;about&quot;:&quot;糖果的Lua教程,&quot;sites&quot;:&quot;lua.ren&quot;&#125;&#x27;;&#125;\n\n\nNginx Lua返回JSON的方式三步操作：\n1.设置HTTP的响应头信息：1ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;\n2.json.encode(“Lua的Table型变量”)：12json = require &quot;cjson&quot; res_json_data = json.encode(ret)\n3.用say函数显示，经过encode的JSON数据。1ngx.say(res_json_data)\n\n用Lua实现以上3个步骤，就实同了JSON数据返回。\n完整代码片段，以下：123json = require &quot;cjson&quot;ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;ngx.say(json.encode(ret))\n\n\n下面的内容就是用Lua封装了几个函数，通过封装快实现了JSON数据的返回。\n一般的Python的WEB框架，都可以的指定返回JSON数据，基本的原理，还是通过指定返回JSON格式的字符串，并且设定HTTP返回时header的Content-Type属性为application/json，来实现返回JSON数据的目地。\n而在Openresty+Lua的框架模式下，不用同时指返回的header类，直接在路由对应的匿名函数中，指定返回一个table类型的即可， 在web框架部分区分判断，如果用户返回的是table类型的数据，直接就用cjson这种库，把table数据渲染成JSON返回。\n依Blues演示框架为例：\n12345678910111213app.run = function()        fun = Route:run(app.router)        if fun then            local ret = fun(app.req, app.id)            local rtype = type(ret)            if rtype == &quot;table&quot;  then                json = require &quot;cjson&quot;                ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;                ngx.say(json.encode(ret))            end         end end \n\n显然，这里只是对返回值的类型是“talbe”的做了处理，也可以对返回类型是“string”或是其它类型的数据做处理。\n1234567891011121314151617app.run = function()        fun = Route:run(app.router)        if fun then            local ret = fun(app.req, app.id)            local rtype = type(ret)            if rtype == &quot;table&quot;  then                json = require &quot;cjson&quot;                ngx.header[&#x27;Content-Type&#x27;] = &#x27;application/json; charset=utf-8&#x27;                ngx.say(json.encode(ret))            end            if rtype == &quot;string&quot;  then                ngx.header[&#x27;Content-Type&#x27;] = &#x27;text/plain; charset=UTF-8&#x27;                ngx.say(ret)            end        end        le(&#x27;Application.app.run&#x27;)end\n\n没有把这种分类型处理，单独封装成一个方法，简单用这段代码说明问题。\n上面是框架中的代码实现，再来看看如何在测试项目中驱动这个功能。\n12345678910111213141516require &quot;log&quot;local HiLog = require &quot;HiLog&quot;local utils = require &quot;utils.utils&quot;local Application = require &quot;orc&quot;app = Application.new()app:get(&quot;/json&quot;, function(request,id)    return &#123;k=&#x27;key&#x27;, v=&#x27;value&#x27;&#125;    end)app:get(&quot;/string&quot;, function(request,id)    return &quot;Waterfall&quot;end)return app.run()\n这样以来，我们就可以快速的用Openresty + Lua构建超级微级的路由系统，管理渲染JSON数据，构建一个简单的JSON数据请求服务。\nBluesWaterfall\n","slug":"old_topic/2016-09-17-Nginx+Lua返回JSON类型数据","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"f8bbe799e3bbd9198fe4b47a5760cfc6","title":"Lua的MD5库","content":"作者：糖果\ncrypto.evp也支持md5,因环境问题，我们采用md5。\n第一：安装。\n1sudo luarocks install md5\n\n\n第二：测试\ntest.lua\n123md5=require&quot;md5&quot;val = md5.sumhexa(&quot;test string&quot;)print(val)\n\n目前来看，这个md5库比较稳定，可以优先选择。\n第三：注意的地方\n如何在解释器(在命令行中，直接输入lua)\n1md5=require&quot;md5&quot;\n\n在引用的时候，不要写成 local md5=require”md5”。\n因为lua local变量的作用域，生存周期的问题，这样声明，在下一 行 “&gt;print(md)”\n得到的结果是nil，显而易见的是，如果nil，后面的调用都没法进行了。\n没有local修饰 md5：md5=require”md5”\nmd5打印出来，才是一个table类型的值，之后的sumhexa才可成功调用。\n底层调用的如下：\n1/usr/local/lib/lua/5.1/md5/core.so\n\n在centos上，安装core.so、des56.so的位置是\n1/usr/lib/lua/5.1/md5\n\nmd5.lua\n1/usr/local/share/lua/5.1\n\ncentos比较麻烦，推荐使用ubuntu\n最后如果遇到复杂的环境问题，就将md5.lua des56.so core.so 复制到当前目录（luarocks install md5产生，也有可能luarocks安装后不生md5.lua，这种就luarocks在centos上的bug,因为.lua是源主件，直接从别的机器制过来…）\nPS:转载到其它平台请注明作者姓名及原文链接，请勿用于商业用途。\n","slug":"old_topic/2016-09-17-Lua的MD5库","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua","author_index":"安全书"},{"id":"713e977b7d1b8fcae8cb4a255a6ea756","title":"Lua判断空表的正确姿势","content":"作者:ms2008\n编辑:糖果\n1if t == &#123;&#125; then\n\n这样的结果就是 t == {} 永远返回 false，是一个逻辑错误。因为这里比较的是 table t 和一个匿名 table 的内存地址。\n1if table.maxn(t) == 0 then\n\n\n这样做也不保险，除非 table 的 key 都是数字，而没有 hash 部分。\n1if next(t) == nil then\n\n\nnext 其实就是 pairs 遍历 table 时用来取下一个内容的函数。在项目的 module 中最好封装一下，免得 module 本地也有 next 函数。封装后判断的 lua table 是否为空的函数如下：\n123function table_is_empty(t)     return _G.next(t) == nil end\n\n\n糖果实验室编辑整理\n","slug":"old_topic/2016-09-17-Lua判断空表的正确姿势","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"","author_index":"安全书"},{"id":"d843ced03f40ac612213952de4b63ad2","title":"二分查找","content":"12345678910111213141516171819202122232425262728293031323334353637383940#include&lt;stdio.h&gt;int bseek(int key) &#123;        int array[10] = &#123;1,2,3,4,5,6,7,8,9,10&#125;;        int low = 0;        int high = (sizeof(array) / 4) - 1;        int mid = 0;        int ret = -1;        while(low &lt;= high) &#123;                mid = (low + high) / 2;                if (key == array[mid]) &#123;                        ret = mid;                        break;                &#125; else if (key &lt; array[mid]) &#123;                        high = mid - 1;                &#125; else if (key &gt; array[mid]) &#123;                        low = mid + 1;                &#125;        &#125;        return ret;&#125;void main(int argc, char* argv[])&#123;        printf(&quot;key[0]:%d\\n&quot;, bseek(0));        printf(&quot;key[1]:%d\\n&quot;, bseek(1));        printf(&quot;key[2]:%d\\n&quot;, bseek(2));        printf(&quot;key[3]:%d\\n&quot;, bseek(3));        printf(&quot;key[4]:%d\\n&quot;, bseek(4));        printf(&quot;key[5]:%d\\n&quot;, bseek(5));        printf(&quot;key[6]:%d\\n&quot;, bseek(6));        printf(&quot;key[7]:%d\\n&quot;, bseek(7));        printf(&quot;key[8]:%d\\n&quot;, bseek(8));        printf(&quot;key[9]:%d\\n&quot;, bseek(9));        printf(&quot;key[10]:%d\\n&quot;, bseek(10));        printf(&quot;key[11]:%d\\n&quot;, bseek(11));&#125;\n\n\nlist  = [1,2,3,4,5,6,7,8,9,10]\nlow = 0\nhigh = len(list) - 1\nidx = 0\n\ndef bseek(key):\n        global low\n        global high\n        global idx\n        while(low &lt;= high):\n                mid = (low + high) / 2\n                if (key == list[mid]):\n                        idx = mid\n                        break\n                elif(key &lt; list[mid]):\n                        high = mid - 1\n                elif(key &gt; list[mid]):\n                        low = mid + 1\n\nbseek(6)\nprint idx\n           \n\n","slug":"old_topic/2016-17-Lua二分查找算法实现","date":"2016-09-17T14:50:18.000Z","categories_index":"topic","tags_index":"lua,折半查找,二分查找,lua二分查找,c","author_index":"安全书"}]