{"title":"Kafka cluaster partitions replicas group","uid":"6de49941c0e06cf59df272961068cd7b","slug":"zl/2016-01-01-510_Kafka cluaster partitions replicas group","date":"2024-04-03T03:47:35.788Z","updated":"2024-04-03T03:47:35.788Z","comments":true,"path":"api/articles/zl/2016-01-01-510_Kafka cluaster partitions replicas group.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","content":"<h2 id=\"partition--replicas\">Partition &amp; Replicas</h2>\n<h3 id=\"kafka-集群默认自动分配解析\">Kafka 集群默认自动分配解析</h3>\n<ul>\n  <li>下面以一个Kafka集群中4个Broker举例，创建1个topic包含4个Partition，2 Replication；数据Producer流动如图所示：</li>\n</ul>\n<table>\n  <thead>\n    <tr>\n      <th style=\"text-align: center\">Broker1</th>\n      <th style=\"text-align: center\">Broker2</th>\n      <th style=\"text-align: center\">Broker3</th>\n      <th style=\"text-align: center\">Broker4</th>\n      <th style=\"text-align: center\">BrokerX</th>\n      <th style=\"text-align: center\">BrokerX</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"text-align: center\">P0</td>\n      <td style=\"text-align: center\">P1</td>\n      <td style=\"text-align: center\">P2</td>\n      <td style=\"text-align: center\">P3</td>\n      <td style=\"text-align: center\">N/A</td>\n      <td style=\"text-align: center\">N/A</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: center\">P3</td>\n      <td style=\"text-align: center\">P0</td>\n      <td style=\"text-align: center\">P1</td>\n      <td style=\"text-align: center\">P2</td>\n      <td style=\"text-align: center\">N/A</td>\n      <td style=\"text-align: center\">N/A</td>\n    </tr>\n  </tbody>\n</table>\n<ul>\n  <li>当集群中新增2节点，Partition增加到6个时分布情况如下：</li>\n</ul>\n<table>\n  <thead>\n    <tr>\n      <th style=\"text-align: center\">Broker1</th>\n      <th style=\"text-align: center\">Broker2</th>\n      <th style=\"text-align: center\">Broker3</th>\n      <th style=\"text-align: center\">Broker4</th>\n      <th style=\"text-align: center\">Broker5</th>\n      <th style=\"text-align: center\">Broker6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"text-align: center\">P0</td>\n      <td style=\"text-align: center\">P1</td>\n      <td style=\"text-align: center\">P2</td>\n      <td style=\"text-align: center\">P3</td>\n      <td style=\"text-align: center\">P4</td>\n      <td style=\"text-align: center\">P5</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: center\">P3</td>\n      <td style=\"text-align: center\">P0</td>\n      <td style=\"text-align: center\">P1</td>\n      <td style=\"text-align: center\">P2</td>\n      <td style=\"text-align: center\"> </td>\n      <td style=\"text-align: center\">P4</td>\n    </tr>\n    <tr>\n      <td style=\"text-align: center\">P5</td>\n      <td style=\"text-align: center\"> </td>\n      <td style=\"text-align: center\"> </td>\n      <td style=\"text-align: center\"> </td>\n      <td style=\"text-align: center\"> </td>\n      <td style=\"text-align: center\"> </td>\n    </tr>\n  </tbody>\n</table>\n<h3 id=\"副本分配逻辑规则如下\">副本分配逻辑规则如下：</h3>\n<ul>\n  <li>在Kafka集群中，每个Broker都有均等分配Partition的Leader机会。</li>\n  <li>上述图Broker Partition中，箭头指向为副本，以Partition-0为例:broker1中parition-0为Leader，Broker2中Partition-0为副本。</li>\n  <li>上述图种每个Broker(按照BrokerId有序)依次分配主Partition,下一个Broker为副本，如此循环迭代分配，多副本都遵循此规则。</li>\n</ul>\n<h3 id=\"副本分配算法如下\">副本分配算法如下：</h3>\n<ul>\n  <li>将所有N Broker和待分配的i个Partition排序.</li>\n  <li>将第i个Partition分配到第(i mod n)个Broker上.</li>\n  <li>将第i个Partition的第j个副本分配到第((i + j) mod n)个Broker上.</li>\n</ul>\n<h2 id=\"group-on-consumers\">Group on Consumers</h2>\n<h3 id=\"kafka-partition--group\">Kafka Partition &amp; Group</h3>\n<ul>\n  <li>原理图</li>\n  <li>原理描述</li>\n</ul>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>一个topic 可以配置几个partition，produce发送的消息分发到不同的partition中，consumer接受数据的时候是按照group来接受，kafka确保每个partition只能同一个group中的同一个consumer消费，如果想要重复消费，那么需要其他的组来消费。Zookeerper中保存这每个topic下的每个partition在每个group中消费的offset  \n新版kafka把这个offsert保存到了一个__consumer_offsert的topic下  \n这个__consumer_offsert 有50个分区，通过将group的id哈希值%50的值来确定要保存到那一个分区.  这样也是为了考虑到zookeeper不擅长大量读写的原因。  \n所以，如果要一个group用几个consumer来同时读取的话，需要多线程来读取，一个线程相当于一个consumer实例。当consumer的数量大于分区的数量的时候，有的consumer线程会读取不到数据。   \n假设一个topic test 被groupA消费了，现在启动另外一个新的groupB来消费test，默认test-groupB的offset不是0，而是没有新建立，除非当test有数据的时候，groupB会收到该数据，该条数据也是第一条数据，groupB的offset也是刚初始化的ofsert, 除非用显式的用–from-beginnging 来获取从0开始数据   \n</code></pre></div></div>\n<ul>\n  <li>查看topic-group的offsert</li>\n</ul>\n<div class=\"highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>位置：zookeeper \n路径：[zk: localhost:2181(CONNECTED) 3] ls /brokers/topics/__consumer_offsets/partitions \n在zookeeper的topic中有一个特殊的topic __consumer_offserts \n计算方法：（放入哪个partitions）\n<p>int hashCode = Math.abs(&quot;ttt&quot;.hashCode());<br />\nint partition = hashCode % 50;<br />\n先计算group的hashCode，再除以分区数(50),可以得到partition的值<br />\n使用命令查看： <a href=\"http://kafka-simple-consumer-shell.sh\">kafka-simple-consumer-shell.sh</a> --topic __consumer_offsets --partition 11 --broker-list localhost:9092,localhost:9093,localhost:9094 --formatter &quot;kafka.coordinator.GroupMetadataManager$OffsetsMessageFormatter&quot;<br />\n</code></pre></div></div></p>\n<ul>\n  <li>\n    <p>参数<br/>\nauto.offset.reset:默认值为largest，代表最新的消息，smallest代表从最早的消息开始读取，当consumer刚开始创建的时候没有offset这种情况，如果设置了largest，则为当收到最新的一条消息的时候开始记录offsert,若设置为smalert，那么会从头开始读partition</p>\n  </li>\n  <li>\n    <p>Consumer Group \n使用Consumer high level API时，同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。<br/>\n这是Kafka用来实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。如果需要实现广播，只要每个Consumer有一个独立的Group就可以了。要实现单播只要所有的Consumer在同一个Group里。用Consumer Group还可以将Consumer进行自由的分组而不需要多次发送消息到不同的Topic。<br/>\n实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的Consumer属于不同的Consumer Group即可。<br/>\n下面这个例子更清晰地展示了Kafka Consumer Group的特性。首先创建一个Topic (名为topic1，包含3个Partition)，然后创建一个属于group1的Consumer实例，并创建三个属于group2的Consumer实例，最后通过Producer向topic1发送key分别为1，2，3的消息。结果发现属于group1的Consumer收到了所有的这三条消息，同时group2中的3个Consumer分别收到了key为1，2，3的消息。</p>\n  </li>\n</ul>","text":"Partition &amp; Replicas Kafka 集群默认自动分配解析 下面以一个Kafka集群中4个Broker举例，创建1个topic包含4个Partition，2 Replication；数据Producer流动如图所示： Broker1 Broker2 Bro...","link":"","photos":[],"count_time":{"symbolsCount":"3.2k","symbolsTime":"3 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#partition--replicas\"><span class=\"toc-text\">Partition &amp; Replicas</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#kafka-%E9%9B%86%E7%BE%A4%E9%BB%98%E8%AE%A4%E8%87%AA%E5%8A%A8%E5%88%86%E9%85%8D%E8%A7%A3%E6%9E%90\"><span class=\"toc-text\">Kafka 集群默认自动分配解析</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%89%AF%E6%9C%AC%E5%88%86%E9%85%8D%E9%80%BB%E8%BE%91%E8%A7%84%E5%88%99%E5%A6%82%E4%B8%8B\"><span class=\"toc-text\">副本分配逻辑规则如下：</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%89%AF%E6%9C%AC%E5%88%86%E9%85%8D%E7%AE%97%E6%B3%95%E5%A6%82%E4%B8%8B\"><span class=\"toc-text\">副本分配算法如下：</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#group-on-consumers\"><span class=\"toc-text\">Group on Consumers</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#kafka-partition--group\"><span class=\"toc-text\">Kafka Partition &amp; Group</span></a></li></ol></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Lua语句段 · 花生肉泥","uid":"82d70b1b5facde5290424415786eeaf4","slug":"zl/2016-01-01-514_Lua语句段 · 花生肉泥","date":"2024-04-03T03:47:35.789Z","updated":"2024-04-03T03:47:35.789Z","comments":true,"path":"api/articles/zl/2016-01-01-514_Lua语句段 · 花生肉泥.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":"chunk语句组chunk是一系列语句，lua执行的每一块语句，比如一个文件或者交互模式下的每一行都是一个chunk 语句块显式的语句块对于控制变量的作用范围很有用，有时候，显式的语句块被用来在另一个语句块中插入retuen或是break 赋值语句lua允许多重赋值，因此，赋值的...","link":"","photos":[],"count_time":{"symbolsCount":"2.5k","symbolsTime":"2 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"LuaInterface简介","uid":"47c2a3b8557d1f5b890b5bb9ea97b552","slug":"zl/2016-01-01-511_LuaInterface简介","date":"2024-04-03T03:47:35.788Z","updated":"2024-04-03T03:47:35.788Z","comments":true,"path":"api/articles/zl/2016-01-01-511_LuaInterface简介.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":"LuaInterface https://www.cnblogs.com/sifenkesi/p/3901831.html 二 使用1.C#中调用Lua下载LuaInterface。下载地址 里面有两个文件：lua51.dll，LuaInterface.dll 新建c#控制台，添...","link":"","photos":[],"count_time":{"symbolsCount":"4.3k","symbolsTime":"4 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}