{"title":"evaluate(input_sentence)","uid":"a7684d8db99f4a04b496679622ad1b05","slug":"zl/2016-01-01-986_evaluate(input_sentence)","date":"2024-04-03T03:47:36.239Z","updated":"2024-04-03T03:47:36.239Z","comments":true,"path":"api/articles/zl/2016-01-01-986_evaluate(input_sentence).json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","content":"<p>详细的记录 evaluate函数的实现。<br/>解决报错</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br/><span class=\"line\">2</span><br/><span class=\"line\">3</span><br/><span class=\"line\">4</span><br/><span class=\"line\">5</span><br/><span class=\"line\">6</span><br/><span class=\"line\">7</span><br/><span class=\"line\">8</span><br/><span class=\"line\">9</span><br/><span class=\"line\">10</span><br/><span class=\"line\">11</span><br/><span class=\"line\">12</span><br/><span class=\"line\">13</span><br/><span class=\"line\">14</span><br/><span class=\"line\">15</span><br/><span class=\"line\">16</span><br/><span class=\"line\">17</span><br/><span class=\"line\">18</span><br/><span class=\"line\">19</span><br/></pre></td><td class=\"code\"><pre><span class=\"line\">ValueError                                Traceback (most recent call last)</span><br/><span class=\"line\">&lt;ipython-input-44-2ec1176683f0&gt; <span class=\"keyword\">in</span> &lt;module&gt;</span><br/><span class=\"line\">----&gt; 1 translate(u<span class=\"string\">&#39;Estoy trabajando.&#39;</span>)</span><br/><span class=\"line\"></span><br/><span class=\"line\">&lt;ipython-input-43-4364cc5c7981&gt; <span class=\"keyword\">in</span> translate(input_sentence)</span><br/><span class=\"line\">     49 </span><br/><span class=\"line\">     50 def translate(input_sentence):</span><br/><span class=\"line\">---&gt; 51     results, input_sentence, attention_matrix = evaluate(input_sentence)</span><br/><span class=\"line\">     52 </span><br/><span class=\"line\">     53     <span class=\"built_in\">print</span>(<span class=\"string\">&#34;Input: %s&#34;</span> % (input_sentence))</span><br/><span class=\"line\"></span><br/><span class=\"line\">&lt;ipython-input-43-4364cc5c7981&gt; <span class=\"keyword\">in</span> evaluate(input_sentence)</span><br/><span class=\"line\">     20     decoding_input = tf.expand_dims([out_tokenizer.word_index[<span class=\"string\">&#39;&lt;start&gt;&#39;</span>]], 0)</span><br/><span class=\"line\">     21     <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(max_length_output):</span><br/><span class=\"line\">---&gt; 22         predictions. decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)</span><br/><span class=\"line\">     23         attention_weights = tf.reshape(attention_weights, (-1,))</span><br/><span class=\"line\">     24         attention_matrix[t] = attention_weights.numpy()</span><br/><span class=\"line\"></span><br/><span class=\"line\">ValueError: too many values to unpack (expected 2)</span><br/></pre></td></tr></tbody></table></figure>\n<h3 id=\"注意看predictions-后面的标点符号\"><a href=\"#注意看predictions-后面的标点符号\" class=\"headerlink\" title=\"注意看predictions 后面的标点符号\"></a>注意看predictions 后面的标点符号</h3><p>接收的是一个文本的输入，首先就要转换成适合模型的数据类型。</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br/><span class=\"line\">2</span><br/><span class=\"line\">3</span><br/><span class=\"line\">4</span><br/><span class=\"line\">5</span><br/><span class=\"line\">6</span><br/><span class=\"line\">7</span><br/><span class=\"line\">8</span><br/><span class=\"line\">9</span><br/><span class=\"line\">10</span><br/><span class=\"line\">11</span><br/><span class=\"line\">12</span><br/><span class=\"line\">13</span><br/><span class=\"line\">14</span><br/><span class=\"line\">15</span><br/><span class=\"line\">16</span><br/><span class=\"line\">17</span><br/><span class=\"line\">18</span><br/><span class=\"line\">19</span><br/><span class=\"line\">20</span><br/><span class=\"line\">21</span><br/><span class=\"line\">22</span><br/><span class=\"line\">23</span><br/><span class=\"line\">24</span><br/><span class=\"line\">25</span><br/><span class=\"line\">26</span><br/><span class=\"line\">27</span><br/><span class=\"line\">28</span><br/><span class=\"line\">29</span><br/><span class=\"line\">30</span><br/><span class=\"line\">31</span><br/><span class=\"line\">32</span><br/><span class=\"line\">33</span><br/><span class=\"line\">34</span><br/><span class=\"line\">35</span><br/><span class=\"line\">36</span><br/><span class=\"line\">37</span><br/><span class=\"line\">38</span><br/><span class=\"line\">39</span><br/><span class=\"line\">40</span><br/><span class=\"line\">41</span><br/><span class=\"line\">42</span><br/><span class=\"line\">43</span><br/><span class=\"line\">44</span><br/><span class=\"line\">45</span><br/><span class=\"line\">46</span><br/><span class=\"line\">47</span><br/><span class=\"line\">48</span><br/><span class=\"line\">49</span><br/><span class=\"line\">50</span><br/><span class=\"line\">51</span><br/><span class=\"line\">52</span><br/><span class=\"line\">53</span><br/><span class=\"line\">54</span><br/><span class=\"line\">55</span><br/><span class=\"line\">56</span><br/><span class=\"line\">57</span><br/></pre></td><td class=\"code\"><pre><span class=\"line\">def evaluate(input_sentence):</span><br/><span class=\"line\">    attention_matrix = np.zeros((max_length_output, max_length_input)) </span><br/><span class=\"line\">    input_sentence = preprocess_sentence(input_sentence) <span class=\"comment\"># 输入的句子进行预处理。就是分割标点符号/</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    inputs = [input_tokenizer.word_index[token] <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> input_sentence.split(<span class=\"string\">&#39; &#39;</span>)] <span class=\"comment\"># text---&gt;id 把句子转换成id</span></span><br/><span class=\"line\">    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen = max_length_input, padding= <span class=\"string\">&#39;post&#39;</span>) <span class=\"comment\"># 把转换成id的向量，进行padding</span></span><br/><span class=\"line\">    inputs = tf.convert_to_tensor(inputs) <span class=\"comment\">#把向量转换为tensor</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    results = <span class=\"string\">&#39;&#39;</span> <span class=\"comment\"># 定义str, 保存translate的结果</span></span><br/><span class=\"line\"></span><br/><span class=\"line\"><span class=\"comment\">#     encoding_hidden = encoder.initialize_hidden_state()</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    encoding_hidden = tf.zeros((1, units)) <span class=\"comment\">#初始化encoding_hidden层</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden) <span class=\"comment\"># 这一步得到的encoding_hidden就是decoding_hidden 的第一个值</span></span><br/><span class=\"line\">    decoding_hidden = encoding_hidden</span><br/><span class=\"line\"></span><br/><span class=\"line\"></span><br/><span class=\"line\">    decoding_input = tf.expand_dims([out_tokenizer.word_index[<span class=\"string\">&#39;&lt;start&gt;&#39;</span>]], 0) <span class=\"comment\"># 找到开始的第一个输入的id</span></span><br/><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(max_length_output):</span><br/><span class=\"line\">        predictions, decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)</span><br/><span class=\"line\">        attention_weights = tf.reshape(attention_weights, (-1,))</span><br/><span class=\"line\">        attention_matrix[t] = attention_weights.numpy()</span><br/><span class=\"line\"></span><br/><span class=\"line\">        predicted_id = tf.argmax(predictions[0]).numpy()</span><br/><span class=\"line\"></span><br/><span class=\"line\">        results += out_tokenizer.index_word[predicted_id] + <span class=\"string\">&#39; &#39;</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">        <span class=\"keyword\">if</span> out_tokenizer.index_word[predicted_id] == <span class=\"string\">&#39;&lt;end&gt;&#39;</span>:</span><br/><span class=\"line\">            <span class=\"built_in\">return</span> results, input_sentence, attention_matrix</span><br/><span class=\"line\"></span><br/><span class=\"line\">        decoding_input = tf.expand_dims([predicted_id], 0)</span><br/><span class=\"line\">    <span class=\"built_in\">return</span> results, input_sentence, attention_matrix</span><br/><span class=\"line\"></span><br/><span class=\"line\">def plot_attention(attention_matrix, input_sentence, predicted_sentence):</span><br/><span class=\"line\">    fig = plt.figure(figsize=(10,10))</span><br/><span class=\"line\">    ax = fig.add_subplot(1, 1, 1)</span><br/><span class=\"line\"></span><br/><span class=\"line\">    ax.matshow(attention_matrix, cmap=<span class=\"string\">&#39;viridis&#39;</span>)</span><br/><span class=\"line\"></span><br/><span class=\"line\">    font_dict = {<span class=\"string\">&#39;fontsize&#39;</span>: 14}</span><br/><span class=\"line\"></span><br/><span class=\"line\">    ax.set_xticklabels([<span class=\"string\">&#39;&#39;</span>] + input_sentence,</span><br/><span class=\"line\">                              fontdict = font_dict, rotation = 90)</span><br/><span class=\"line\">    ax.sey_yticklables([<span class=\"string\">&#39;&#39;</span>] + predicted_sentence,</span><br/><span class=\"line\">                              fontdict = font_dict,)</span><br/><span class=\"line\">    plt.show()</span><br/><span class=\"line\"></span><br/><span class=\"line\">def translate(input_sentence):</span><br/><span class=\"line\">    results, input_sentence, attention_matrix = evaluate(input_sentence)</span><br/><span class=\"line\"></span><br/><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#34;Input: %s&#34;</span> % (input_sentence))</span><br/><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#34;Predicted translation: %s&#34;</span> % (results))</span><br/><span class=\"line\"></span><br/><span class=\"line\">    attention_matrix = attention_matrix[:len(results.split(<span class=\"string\">&#39; &#39;</span>)),</span><br/><span class=\"line\">                                                       :len(input_sentence.split(<span class=\"string\">&#39; &#39;</span>))]</span><br/><span class=\"line\">    plot_attention(attention_matrix, input_sentence.split(<span class=\"string\">&#39; &#39;</span>), results.split(<span class=\"string\">&#39; &#39;</span>))</span><br/></pre></td></tr></tbody></table></figure>","text":"详细的记录 evaluate函数的实现。解决报错 12345678910111213141516171819ValueError Traceback (most recent call last)&lt;ipython-input-44-2ec1176683f0&gt; in &...","link":"","photos":[],"count_time":{"symbolsCount":"3.7k","symbolsTime":"3 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B3%A8%E6%84%8F%E7%9C%8Bpredictions-%E5%90%8E%E9%9D%A2%E7%9A%84%E6%A0%87%E7%82%B9%E7%AC%A6%E5%8F%B7\"><span class=\"toc-text\">注意看predictions 后面的标点符号</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"给 Tengine 加上 lua 拓展","uid":"6224a2d92b8e1402c742058a9d03bd16","slug":"zl/2016-01-01-990_给 Tengine 加上 lua 拓展","date":"2024-04-03T03:47:36.240Z","updated":"2024-04-03T03:47:36.241Z","comments":true,"path":"api/articles/zl/2016-01-01-990_给 Tengine 加上 lua 拓展.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":"Tengine 能动态加载第三方模块，成为我们青睐的选择，我们可以编译动态链接文件，而不需要重新安装 Nginx, 这对在线增强 webservice 很有帮助.感谢 agentzh, lua-nginx-module, 可以让我们使用 lua 增强nginx的功能, 不言而喻，...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"lua gc分析","uid":"907fabdd67222b9ee3c6f8c656f559b7","slug":"zl/2016-01-01-983_lua gc分析","date":"2024-04-03T03:47:36.238Z","updated":"2024-04-03T03:47:36.238Z","comments":true,"path":"api/articles/zl/2016-01-01-983_lua gc分析.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":"说明分析lua使用的gc算法，如何做到分步gc，以及测试结论 gc算法分析lua gc采用的是标记-清除算法，即一次gc分两步： 从根节点开始遍历gc对象，如果可达，则标记 遍历所有的gc对象，清除没有被标记的对象 二色标记法lua 5.1之前采用的算法，二色回收法是最简单的标记...","link":"","photos":[],"count_time":{"symbolsCount":"6.5k","symbolsTime":"6 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}