{"title":"evaluate(input_sentence)","uid":"a7684d8db99f4a04b496679622ad1b05","slug":"zl/2016-01-01-807_evaluate(input_sentence)","date":"2024-04-03T03:47:36.052Z","updated":"2024-04-03T03:47:36.052Z","comments":true,"path":"api/articles/zl/2016-01-01-807_evaluate(input_sentence).json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","content":"<p>详细的记录 evaluate函数的实现。<br/>解决报错</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br/><span class=\"line\">2</span><br/><span class=\"line\">3</span><br/><span class=\"line\">4</span><br/><span class=\"line\">5</span><br/><span class=\"line\">6</span><br/><span class=\"line\">7</span><br/><span class=\"line\">8</span><br/><span class=\"line\">9</span><br/><span class=\"line\">10</span><br/><span class=\"line\">11</span><br/><span class=\"line\">12</span><br/><span class=\"line\">13</span><br/><span class=\"line\">14</span><br/><span class=\"line\">15</span><br/><span class=\"line\">16</span><br/><span class=\"line\">17</span><br/><span class=\"line\">18</span><br/><span class=\"line\">19</span><br/></pre></td><td class=\"code\"><pre><span class=\"line\">ValueError                                Traceback (most recent call last)</span><br/><span class=\"line\">&lt;ipython-input-44-2ec1176683f0&gt; <span class=\"keyword\">in</span> &lt;module&gt;</span><br/><span class=\"line\">----&gt; 1 translate(u<span class=\"string\">&#39;Estoy trabajando.&#39;</span>)</span><br/><span class=\"line\"></span><br/><span class=\"line\">&lt;ipython-input-43-4364cc5c7981&gt; <span class=\"keyword\">in</span> translate(input_sentence)</span><br/><span class=\"line\">     49 </span><br/><span class=\"line\">     50 def translate(input_sentence):</span><br/><span class=\"line\">---&gt; 51     results, input_sentence, attention_matrix = evaluate(input_sentence)</span><br/><span class=\"line\">     52 </span><br/><span class=\"line\">     53     <span class=\"built_in\">print</span>(<span class=\"string\">&#34;Input: %s&#34;</span> % (input_sentence))</span><br/><span class=\"line\"></span><br/><span class=\"line\">&lt;ipython-input-43-4364cc5c7981&gt; <span class=\"keyword\">in</span> evaluate(input_sentence)</span><br/><span class=\"line\">     20     decoding_input = tf.expand_dims([out_tokenizer.word_index[<span class=\"string\">&#39;&lt;start&gt;&#39;</span>]], 0)</span><br/><span class=\"line\">     21     <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(max_length_output):</span><br/><span class=\"line\">---&gt; 22         predictions. decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)</span><br/><span class=\"line\">     23         attention_weights = tf.reshape(attention_weights, (-1,))</span><br/><span class=\"line\">     24         attention_matrix[t] = attention_weights.numpy()</span><br/><span class=\"line\"></span><br/><span class=\"line\">ValueError: too many values to unpack (expected 2)</span><br/></pre></td></tr></tbody></table></figure>\n<h3 id=\"注意看predictions-后面的标点符号\"><a href=\"#注意看predictions-后面的标点符号\" class=\"headerlink\" title=\"注意看predictions 后面的标点符号\"></a>注意看predictions 后面的标点符号</h3><p>接收的是一个文本的输入，首先就要转换成适合模型的数据类型。</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br/><span class=\"line\">2</span><br/><span class=\"line\">3</span><br/><span class=\"line\">4</span><br/><span class=\"line\">5</span><br/><span class=\"line\">6</span><br/><span class=\"line\">7</span><br/><span class=\"line\">8</span><br/><span class=\"line\">9</span><br/><span class=\"line\">10</span><br/><span class=\"line\">11</span><br/><span class=\"line\">12</span><br/><span class=\"line\">13</span><br/><span class=\"line\">14</span><br/><span class=\"line\">15</span><br/><span class=\"line\">16</span><br/><span class=\"line\">17</span><br/><span class=\"line\">18</span><br/><span class=\"line\">19</span><br/><span class=\"line\">20</span><br/><span class=\"line\">21</span><br/><span class=\"line\">22</span><br/><span class=\"line\">23</span><br/><span class=\"line\">24</span><br/><span class=\"line\">25</span><br/><span class=\"line\">26</span><br/><span class=\"line\">27</span><br/><span class=\"line\">28</span><br/><span class=\"line\">29</span><br/><span class=\"line\">30</span><br/><span class=\"line\">31</span><br/><span class=\"line\">32</span><br/><span class=\"line\">33</span><br/><span class=\"line\">34</span><br/><span class=\"line\">35</span><br/><span class=\"line\">36</span><br/><span class=\"line\">37</span><br/><span class=\"line\">38</span><br/><span class=\"line\">39</span><br/><span class=\"line\">40</span><br/><span class=\"line\">41</span><br/><span class=\"line\">42</span><br/><span class=\"line\">43</span><br/><span class=\"line\">44</span><br/><span class=\"line\">45</span><br/><span class=\"line\">46</span><br/><span class=\"line\">47</span><br/><span class=\"line\">48</span><br/><span class=\"line\">49</span><br/><span class=\"line\">50</span><br/><span class=\"line\">51</span><br/><span class=\"line\">52</span><br/><span class=\"line\">53</span><br/><span class=\"line\">54</span><br/><span class=\"line\">55</span><br/><span class=\"line\">56</span><br/><span class=\"line\">57</span><br/></pre></td><td class=\"code\"><pre><span class=\"line\">def evaluate(input_sentence):</span><br/><span class=\"line\">    attention_matrix = np.zeros((max_length_output, max_length_input)) </span><br/><span class=\"line\">    input_sentence = preprocess_sentence(input_sentence) <span class=\"comment\"># 输入的句子进行预处理。就是分割标点符号/</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    inputs = [input_tokenizer.word_index[token] <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> input_sentence.split(<span class=\"string\">&#39; &#39;</span>)] <span class=\"comment\"># text---&gt;id 把句子转换成id</span></span><br/><span class=\"line\">    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen = max_length_input, padding= <span class=\"string\">&#39;post&#39;</span>) <span class=\"comment\"># 把转换成id的向量，进行padding</span></span><br/><span class=\"line\">    inputs = tf.convert_to_tensor(inputs) <span class=\"comment\">#把向量转换为tensor</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    results = <span class=\"string\">&#39;&#39;</span> <span class=\"comment\"># 定义str, 保存translate的结果</span></span><br/><span class=\"line\"></span><br/><span class=\"line\"><span class=\"comment\">#     encoding_hidden = encoder.initialize_hidden_state()</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    encoding_hidden = tf.zeros((1, units)) <span class=\"comment\">#初始化encoding_hidden层</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">    encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden) <span class=\"comment\"># 这一步得到的encoding_hidden就是decoding_hidden 的第一个值</span></span><br/><span class=\"line\">    decoding_hidden = encoding_hidden</span><br/><span class=\"line\"></span><br/><span class=\"line\"></span><br/><span class=\"line\">    decoding_input = tf.expand_dims([out_tokenizer.word_index[<span class=\"string\">&#39;&lt;start&gt;&#39;</span>]], 0) <span class=\"comment\"># 找到开始的第一个输入的id</span></span><br/><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(max_length_output):</span><br/><span class=\"line\">        predictions, decoding_hidden, attention_weights = decoder(decoding_input, decoding_hidden, encoding_outputs)</span><br/><span class=\"line\">        attention_weights = tf.reshape(attention_weights, (-1,))</span><br/><span class=\"line\">        attention_matrix[t] = attention_weights.numpy()</span><br/><span class=\"line\"></span><br/><span class=\"line\">        predicted_id = tf.argmax(predictions[0]).numpy()</span><br/><span class=\"line\"></span><br/><span class=\"line\">        results += out_tokenizer.index_word[predicted_id] + <span class=\"string\">&#39; &#39;</span></span><br/><span class=\"line\"></span><br/><span class=\"line\">        <span class=\"keyword\">if</span> out_tokenizer.index_word[predicted_id] == <span class=\"string\">&#39;&lt;end&gt;&#39;</span>:</span><br/><span class=\"line\">            <span class=\"built_in\">return</span> results, input_sentence, attention_matrix</span><br/><span class=\"line\"></span><br/><span class=\"line\">        decoding_input = tf.expand_dims([predicted_id], 0)</span><br/><span class=\"line\">    <span class=\"built_in\">return</span> results, input_sentence, attention_matrix</span><br/><span class=\"line\"></span><br/><span class=\"line\">def plot_attention(attention_matrix, input_sentence, predicted_sentence):</span><br/><span class=\"line\">    fig = plt.figure(figsize=(10,10))</span><br/><span class=\"line\">    ax = fig.add_subplot(1, 1, 1)</span><br/><span class=\"line\"></span><br/><span class=\"line\">    ax.matshow(attention_matrix, cmap=<span class=\"string\">&#39;viridis&#39;</span>)</span><br/><span class=\"line\"></span><br/><span class=\"line\">    font_dict = {<span class=\"string\">&#39;fontsize&#39;</span>: 14}</span><br/><span class=\"line\"></span><br/><span class=\"line\">    ax.set_xticklabels([<span class=\"string\">&#39;&#39;</span>] + input_sentence,</span><br/><span class=\"line\">                              fontdict = font_dict, rotation = 90)</span><br/><span class=\"line\">    ax.sey_yticklables([<span class=\"string\">&#39;&#39;</span>] + predicted_sentence,</span><br/><span class=\"line\">                              fontdict = font_dict,)</span><br/><span class=\"line\">    plt.show()</span><br/><span class=\"line\"></span><br/><span class=\"line\">def translate(input_sentence):</span><br/><span class=\"line\">    results, input_sentence, attention_matrix = evaluate(input_sentence)</span><br/><span class=\"line\"></span><br/><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#34;Input: %s&#34;</span> % (input_sentence))</span><br/><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#34;Predicted translation: %s&#34;</span> % (results))</span><br/><span class=\"line\"></span><br/><span class=\"line\">    attention_matrix = attention_matrix[:len(results.split(<span class=\"string\">&#39; &#39;</span>)),</span><br/><span class=\"line\">                                                       :len(input_sentence.split(<span class=\"string\">&#39; &#39;</span>))]</span><br/><span class=\"line\">    plot_attention(attention_matrix, input_sentence.split(<span class=\"string\">&#39; &#39;</span>), results.split(<span class=\"string\">&#39; &#39;</span>))</span><br/></pre></td></tr></tbody></table></figure>","text":"详细的记录 evaluate函数的实现。解决报错 12345678910111213141516171819ValueError Traceback (most recent call last)&lt;ipython-input-44-2ec1176683f0&gt; in &...","link":"","photos":[],"count_time":{"symbolsCount":"3.7k","symbolsTime":"3 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B3%A8%E6%84%8F%E7%9C%8Bpredictions-%E5%90%8E%E9%9D%A2%E7%9A%84%E6%A0%87%E7%82%B9%E7%AC%A6%E5%8F%B7\"><span class=\"toc-text\">注意看predictions 后面的标点符号</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Lua的win和linux环境搭建","uid":"7fe1dad0ab07c1159a9c6ba848add36c","slug":"zl/2016-01-01-809_Lua的win和linux环境搭建","date":"2024-04-03T03:47:36.055Z","updated":"2024-04-03T03:47:36.056Z","comments":true,"path":"api/articles/zl/2016-01-01-809_Lua的win和linux环境搭建.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" &lt;a href=&quot;/2015/11/03/Linux常用命令笔记整理之tcpdump/&quot; rel=&quot;next&quot; title=&quot;Linux常用命令笔记整理之tcpdump&quot;&gt; &lt;i class=&quo...","link":"","photos":[],"count_time":{"symbolsCount":"3k","symbolsTime":"3 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Lua 中的随机数","uid":"73feeba3e1d1ac59d590841c2286442d","slug":"zl/2016-01-01-808_Lua 中的随机数 ","date":"2024-04-03T03:47:36.052Z","updated":"2024-04-03T03:47:36.055Z","comments":true,"path":"api/articles/zl/2016-01-01-808_Lua 中的随机数 .json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":"Lua 随机数算法用的是 libc 中的 rand, 也就是 LCG。然而这个算法的随机性一般。尤其是在一些平台上，当随机种子变化非常小的时候，产生的随机数变化也非常小。这样再经过 Lua 的精度取舍之后，产生的随机序列仍然很相似（伪随机的结果变成可预知性）。 lua-l 上也讨...","link":"","photos":[],"count_time":{"symbolsCount":"2.2k","symbolsTime":"2 mins."},"categories":[{"name":"topic","slug":"topic","count":1441,"path":"api/categories/topic.json"}],"tags":[{"name":"lua文章","slug":"lua文章","count":1133,"path":"api/tags/lua文章.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}