{"title":"SonicVisionLM视频生成音效","uid":"dde64d8630e6c5550acf06dbe60b7085","slug":"opensource/sound/SonicVisionLM视频生成音效","date":"2024-03-14T06:15:59.760Z","updated":"2024-03-14T06:15:59.760Z","comments":true,"path":"api/articles/opensource/sound/SonicVisionLM视频生成音效.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h1 id=\"SonicVisionLM视频生成音效\"><a href=\"#SonicVisionLM视频生成音效\" class=\"headerlink\" title=\"SonicVisionLM视频生成音效\"></a>SonicVisionLM视频生成音效</h1><p>SonicVisionLM 可以为视频生成音效。它使用视觉语言模型 (VLM) 来识别视频中的事件并生成与视频内容匹配的声音。  </p>\n<p>戳视频听听音效↓  </p>\n<p>项目：yusiissy.github.io/SonicVisionLM.github.io  </p>\n<p>SonicVisionLM: Playing Sound with Vision Language Models（用视觉语言模型播放声音）  </p>\n<p>论文摘要：<br>人们对为无声视频生成声音的任务越来越感兴趣，主要是因为它在简化视频后期制作方面的实用性。然而，现有的视频声音生成方法试图直接从视觉表示创建声音，由于难以将视觉表示与音频表示对齐，这可能具有挑战性。  </p>\n<p>在本文中，我们提出了SonicVisionLM，这是一种新颖的框架，旨在通过利用视觉语言模型生成各种声音效果。我们没有直接从视频生成音频，而是使用强大的视觉语言模型 (VLM) 的功能。  </p>\n<p>当提供无声视频时，我们的方法首先使用 VLM 识别视频中的事件，以建议与视频内容匹配的可能声音。这种方法的转变将图像和音频对齐的挑战性任务转变为通过流行的扩散模型对齐图像到文本和文本到音频的更深入研究的子问题。  </p>\n<p>为了提高LLM的音频推荐质量，我们收集了一个广泛的数据集，将文本描述映射到特定的声音效果，并开发了时间控制的音频适配器。  </p>\n<p>我们的方法超越了当前将视频转换为音频的最先进方法，从而增强了与视觉效果的同步并改善了音频和视频组件之间的对齐。</p>\n","text":"SonicVisionLM视频生成音效SonicVisionLM 可以为视频生成音效。它使用视觉语言模型 (VLM) 来识别视频中的事件并生成与视频内容匹配的声音。 戳视频听听音效↓ 项目：yusiissy.github.io/SonicVisionLM.github.io So...","link":"","photos":[],"count_time":{"symbolsCount":645,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"SonicVisionLM","slug":"AIGC/SonicVisionLM","count":1,"path":"api/categories/AIGC/SonicVisionLM.json"}],"tags":[{"name":"SonicVisionLM","slug":"SonicVisionLM","count":1,"path":"api/tags/SonicVisionLM.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#SonicVisionLM%E8%A7%86%E9%A2%91%E7%94%9F%E6%88%90%E9%9F%B3%E6%95%88\"><span class=\"toc-text\">SonicVisionLM视频生成音效</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"AnimateAnyone","uid":"eb7ff1a1c10025a2663883c2cd4d7e49","slug":"opensource/video/AnimateAnyone","date":"2024-03-14T06:15:59.760Z","updated":"2024-03-14T06:15:59.760Z","comments":true,"path":"api/articles/opensource/video/AnimateAnyone.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":"AnimateAnyone刚发现摩尔线程前几天复原了阿里的单图跳舞项目并且已经开源训练代码，你可以训练自己的AnimateAnyone模型。有个基于摩尔线程开源的版本制作了 ComfyUI 节点，并且提供了基础的工作流。现在可以在ComfyUI中非常简单的让单图跳舞了。 http...","link":"","photos":[],"count_time":{"symbolsCount":192,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"AnimateAnyone","slug":"AIGC/AnimateAnyone","count":1,"path":"api/categories/AIGC/AnimateAnyone.json"}],"tags":[{"name":"AnimateAnyone","slug":"AnimateAnyone","count":1,"path":"api/tags/AnimateAnyone.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"WhisperFusion","uid":"b47d7593669fa330c65584f3449adde6","slug":"opensource/sound/WhisperFusion","date":"2024-03-14T06:15:59.760Z","updated":"2024-03-14T06:15:59.760Z","comments":true,"path":"api/articles/opensource/sound/WhisperFusion.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://s2.loli.net/2024/02/07/RXn9COQmp7iqwH1.png","text":"WhisperFusion通过语音与AI进行对话https://github.com/collabora/WhisperFusion/blob/main/README.md ","link":"","photos":[],"count_time":{"symbolsCount":87,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"}],"tags":[{"name":"WhisperFusion","slug":"WhisperFusion","count":1,"path":"api/tags/WhisperFusion.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}