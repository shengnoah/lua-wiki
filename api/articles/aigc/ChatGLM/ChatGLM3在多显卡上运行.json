{"title":"ChaGLM3在多显卡上运行","uid":"c8a161f78cff976f698872281578706e","slug":"aigc/ChatGLM/ChatGLM3在多显卡上运行","date":"2024-03-14T06:15:59.708Z","updated":"2024-03-14T06:15:59.708Z","comments":true,"path":"api/articles/aigc/ChatGLM/ChatGLM3在多显卡上运行.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h1 id=\"ChaGLM3在多显卡上运行\"><a href=\"#ChaGLM3在多显卡上运行\" class=\"headerlink\" title=\"ChaGLM3在多显卡上运行\"></a>ChaGLM3在多显卡上运行</h1><p>在明确是16位量化的时候，用ChatGLM项目中的utils文件的load_model_on_gpus方法，进行对model的配置， num_gpus=4,意思是说在4块显卡上运行。<br>from utils import load_model_on_gpus</p>\n<p>model = load_model_on_gpus(model_name, num_gpus=4)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> quantize == <span class=\"number\">16</span>:</span><br><span class=\"line\">model = load_model_on_gpus(model_name, num_gpus=<span class=\"number\">4</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">model = AutoModel.from_pretrained(model_name, device_map=<span class=\"string\">&quot;auto&quot;</span>,trust_remote_code=<span class=\"literal\">True</span>).half().quantize(quantize).cuda()</span><br></pre></td></tr></table></figure>\n\n\n\n<p>运行的时候，用命令参数 -d，指定所在运行的显卡。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">parser.add_argument(<span class=\"string\">&#x27;--device&#x27;</span>, <span class=\"string\">&#x27;-d&#x27;</span>, <span class=\"built_in\">help</span>=<span class=\"string\">&#x27;device， -1 means cpu, other means gpu ids&#x27;</span>, default=<span class=\"string\">&#x27;0&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python fastapiGPU.py -d 0,1,2,3</span><br></pre></td></tr></table></figure>\n\n<p>相当于SD的 CUDA_VISIBLE_DEVICES。</p>\n<p>webui-user.sh中加入export参数。</p>\n<p>export CUDA_VISIBLE_DEVICES=0,1,2,3</p>\n<p>./stable-diffusion-webui/webui.sh –listen –device-id 1<br>这样运行，SD可以同时使用显卡0和显卡1.</p>\n<p>CUDA_VISIBLE_DEVICES=0,1,2,3 python launch.py  –share</p>\n<p>CUDA_VISIBLE_DEVICES=1 python launch.py  –share</p>\n<p>cmd_args.py    –device-id </p>\n<p>device-id参数是在cmd_args.py文件中出现的。 </p>\n","text":"ChaGLM3在多显卡上运行在明确是16位量化的时候，用ChatGLM项目中的utils文件的load_model_on_gpus方法，进行对model的配置， num_gpus=4,意思是说在4块显卡上运行。from utils import load_model_on_gpu...","link":"","photos":[],"count_time":{"symbolsCount":937,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"chatglm3","slug":"AIGC/chatglm3","count":1,"path":"api/categories/AIGC/chatglm3.json"}],"tags":[{"name":"chatglm3","slug":"chatglm3","count":1,"path":"api/tags/chatglm3.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#ChaGLM3%E5%9C%A8%E5%A4%9A%E6%98%BE%E5%8D%A1%E4%B8%8A%E8%BF%90%E8%A1%8C\"><span class=\"toc-text\">ChaGLM3在多显卡上运行</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"gpt4all","uid":"bc3e68a199458a681f2c7fe3b421bbd6","slug":"aigc/langchain/GPT4all Embeddings","date":"2024-03-14T06:15:59.708Z","updated":"2024-03-14T06:15:59.709Z","comments":true,"path":"api/articles/aigc/langchain/GPT4all Embeddings.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"gpt4all1pip install gpt4all Embeddings翻译成中文为“嵌入”，是指将一个数据集或模型的特征值映射到一个更小的向量空间内的过程。在计算机自然语言处理领域中，Embeddings 通常被用来表示文本、图像或其他数据类型的特征，并使得模型能够更好地理...","link":"","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/categories/gpt4all.json"}],"tags":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/tags/gpt4all.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"git在命令行模式下不支持中文显示乱码","uid":"406b641de940a6e95a960364da29d8e1","slug":"zhihu/git在命令行模式下不支持中文显示乱码","date":"2023-03-15T04:39:31.000Z","updated":"2024-03-14T06:15:59.771Z","comments":true,"path":"api/articles/zhihu/git在命令行模式下不支持中文显示乱码.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"1git config --global core.quotepath false ","link":"","photos":[],"count_time":{"symbolsCount":43,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}