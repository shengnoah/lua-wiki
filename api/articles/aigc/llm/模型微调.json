{"title":"模型微调","uid":"80343fe751072d14380c6c808291386e","slug":"aigc/llm/模型微调","date":"2024-03-14T07:45:09.022Z","updated":"2024-03-14T07:45:09.022Z","comments":true,"path":"api/articles/aigc/llm/模型微调.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","content":"<h1 id=\"模型微调\"><a class=\"markdownIt-Anchor\" href=\"#模型微调\"></a> 模型微调</h1>\n<p>模型微调和增加检索的区别是什么， 什么场景适用模型进行微调，什么场景更适合适用增加检索RAG进行处理？</p>\n<p>模型微调和增加检索的区别在于它们的目标和方法。</p>\n<p>模型微调是指在一个预训练的模型基础上，使用特定的数据集进行再训练，以适应特定的任务或领域。通过微调模型，可以使其更好地适应目标任务，并提升性能。模型微调适用于以下场景：</p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当已有的预训练模型与目标任务或领域相关性较高时，可以通过微调来提升性能。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当可用于微调的数据集较大时，可以更充分地利用这些数据来优化模型。</p>\n</li>\n</ul>\n<p>增加检索（retrieval-augmented generation, RAG）是一种结合检索和生成的方法，在生成文本时利用检索到的信息进行辅助。RAG 模型首先使用一个预训练的编码器将输入文本编码成向量表示，并使用这个向量进行检索。然后，在生成阶段，根据检索到的相关信息来引导生成过程。增加检索适用于以下场景：</p>\n<ul class=\"lvl-0\">\n<li class=\"lvl-2\">\n<p>当需要根据一些特定问题或主题来生成文本时，可以使用增加检索来获取相关信息并引导生成。</p>\n</li>\n<li class=\"lvl-2\">\n<p>当需要在生成过程中引入外部知识或约束条件时，可以利用增加检索来实现。</p>\n</li>\n</ul>\n<p>总之，在选择模型微调还是增加检索时应考虑任务的特点和需求。模型微调更适用于直接优化模型性能的场景，而增加检索更适用于需要引入外部信息来辅助生成的场景。</p>\n","text":" 模型微调 模型微调和增加检索的区别是什么， 什么场景适用模型进行微调，什么场景更适合适用增加检索RAG进行处理？ 模型微调和增加检索的区别在于它们的目标和方法。 模型微调是指在一个预训练的模型基础上，使用特定的数据集进行再训练，以适应特定的任务或领域。通过微调模型，可以使其更好...","link":"","photos":[],"count_time":{"symbolsCount":561,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"}],"tags":[{"name":"llama","slug":"llama","count":1,"path":"api/tags/llama.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83\"><span class=\"toc-text\"> 模型微调</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Mixtral-8x7B中文","uid":"9a40a6a39b959d0093a5b06c499bf410","slug":"aigc/llm/ollama/Mixtral-8x7B中文","date":"2024-03-14T07:45:09.023Z","updated":"2024-03-14T07:45:09.023Z","comments":true,"path":"api/articles/aigc/llm/ollama/Mixtral-8x7B中文.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" Mixtral-8x7B中文 Chinese-Mixtral-8x7B：中文Mixtral-8x7B，基于Mistral发布的模型Mixtral-8x7B进行了中文扩词表增量预训练】‘Chinese-Mixtral-8x7B’ GitHub: github.com/HIT-SC...","link":"","photos":[],"count_time":{"symbolsCount":165,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"Mixtral-8x7B","slug":"AIGC/Mixtral-8x7B","count":1,"path":"api/categories/AIGC/Mixtral-8x7B.json"}],"tags":[{"name":"Mixtral-8x7B","slug":"Mixtral-8x7B","count":1,"path":"api/tags/Mixtral-8x7B.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"ChatGLM运行在多块显卡上","uid":"cfb4d1b86fdb40bad53c9ad03918951d","slug":"aigc/llm/chatglm/ChatGLM运行在多块显卡上","date":"2024-03-14T07:45:09.022Z","updated":"2024-03-14T07:45:09.022Z","comments":true,"path":"api/articles/aigc/llm/chatglm/ChatGLM运行在多块显卡上.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" ChatGLM运行在多块显卡上 ChatGLM如何运行在多块显卡上 ChatGLM是一个基于GPT-3的模型，由于GPT-3模型本身的特性，它无法直接在多块显卡上运行。GPT-3是一个非常大的模型，需要大量的计算资源和内存来训练和运行。 然而，可以使用分布式训练和推理技术来在多...","link":"","photos":[],"count_time":{"symbolsCount":489,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"ChatGLM","slug":"AIGC/ChatGLM","count":1,"path":"api/categories/AIGC/ChatGLM.json"}],"tags":[{"name":"ChatGLM","slug":"ChatGLM","count":1,"path":"api/tags/ChatGLM.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}