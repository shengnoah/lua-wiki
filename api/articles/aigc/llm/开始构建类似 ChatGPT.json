{"title":"开始构建类似 ChatGPT","uid":"cf3ae125b94c92a05016e1e5aae14eba","slug":"aigc/llm/开始构建类似 ChatGPT","date":"2024-03-14T07:45:09.023Z","updated":"2024-03-14T07:45:09.023Z","comments":true,"path":"api/articles/aigc/llm/开始构建类似 ChatGPT.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","content":"<h1 id=\"开始构建类似-chatgpt\"><a class=\"markdownIt-Anchor\" href=\"#开始构建类似-chatgpt\"></a> 开始构建类似 ChatGPT</h1>\n<p>教你从零开始构建类似 ChatGPT 的大语言模型。</p>\n<p>在 GitHub 上发现一本《Build a Large Language Model (From Scratch)》书籍。</p>\n<p>作者将带你从头开始构建一个类似 GPT 语言模型，这过程让你了解如何创建、训练和微调大型语言模型 (LLMs)！</p>\n<p>在线阅读：<a href=\"http://livebook.manning.com/book/build-a-large-language-model-from-scratch/welcome/v-3/\">livebook.manning.com/book/build-a-large-language-model-from-scratch/welcome/v-3/</a><br />\n涉及源码：<a href=\"http://github.com/rasbt/LLMs-from-scratch\">github.com/rasbt/LLMs-from-scratch</a></p>\n<p>书籍主要分为 8 大章节，如下：</p>\n<p>第 1 章：了解大语言模型（LLM）解析<br />\n第 2 章：介绍文本数据处理技巧<br />\n第 3 章：通过编程实现注意力机制（Attention Mechanisms）<br />\n第 4 章：从零开始实现类似 GPT 模型<br />\n第 5 章：对未标注数据进行预训练<br />\n第 6 章：针对文本分类的模型微调<br />\n第 7 章：结合人类反馈进行模型微调<br />\n第 8 章：在实践中使用大语言模型</p>\n","text":" 开始构建类似 ChatGPT 教你从零开始构建类似 ChatGPT 的大语言模型。 在 GitHub 上发现一本《Build a Large Language Model (From Scratch)》书籍。 作者将带你从头开始构建一个类似 GPT 语言模型，这过程让你了解如何...","link":"","photos":[],"count_time":{"symbolsCount":479,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"}],"tags":[{"name":"book","slug":"book","count":1,"path":"api/tags/book.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%BC%80%E5%A7%8B%E6%9E%84%E5%BB%BA%E7%B1%BB%E4%BC%BC-chatgpt\"><span class=\"toc-text\"> 开始构建类似 ChatGPT</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Sora 和之前 Runway 那些在架构上有啥区别呢","uid":"d513b66cf42e1723c2bda6d425c5b9ed","slug":"aigc/sora/Sora 和之前 Runway 那些在架构上有啥区别呢","date":"2024-03-14T07:45:09.024Z","updated":"2024-03-14T07:45:09.024Z","comments":true,"path":"api/articles/aigc/sora/Sora 和之前 Runway 那些在架构上有啥区别呢.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" Sora 和之前 Runway 那些在架构上有啥区别呢 Sora是基于Diffusion Transformer模型的生成式模型，融合了扩散模型和Transformer架构，能有效处理含噪点的图像输入并逐步预测出更清晰的图像版本。与传统Token预测不同，Sora预测序列中的下...","link":"","photos":[],"count_time":{"symbolsCount":"2.3k","symbolsTime":"2 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"sora","slug":"AIGC/sora","count":1,"path":"api/categories/AIGC/sora.json"}],"tags":[{"name":"sora","slug":"sora","count":3,"path":"api/tags/sora.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"书生・浦语 2.0（InternLM2）大语言模型正式开源","uid":"ba1b40adefccb80b7453716eb9f031b1","slug":"aigc/llm/书生・浦语 2.0（InternLM2）大语言模型正式开源","date":"2024-03-14T07:45:09.023Z","updated":"2024-03-14T07:45:09.023Z","comments":true,"path":"api/articles/aigc/llm/书生・浦语 2.0（InternLM2）大语言模型正式开源.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 书生・浦语 2.0（InternLM2）大语言模型正式开源 Github：[https://github.com/InternLM/InternLM] HuggingFace：[https://huggingface.co/internlm] ModelScope：[https...","link":"","photos":[],"count_time":{"symbolsCount":194,"symbolsTime":"1 mins."},"categories":[{"name":"InternLM2","slug":"InternLM2","count":1,"path":"api/categories/InternLM2.json"}],"tags":[{"name":"InternLM2","slug":"InternLM2","count":1,"path":"api/tags/InternLM2.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}