{"title":"gpt4all","uid":"bc3e68a199458a681f2c7fe3b421bbd6","slug":"aigc/langchain/GPT4all Embeddings","date":"2024-03-14T07:45:09.025Z","updated":"2024-03-14T07:45:09.025Z","comments":true,"path":"api/articles/aigc/langchain/GPT4all Embeddings.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","content":"<h1 id=\"gpt4all\"><a class=\"markdownIt-Anchor\" href=\"#gpt4all\"></a> gpt4all</h1>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">pip <span class=\"token function\">install</span> gpt4all<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<h3 id=\"embeddings\"><a class=\"markdownIt-Anchor\" href=\"#embeddings\"></a> Embeddings</h3>\n<p>翻译成中文为“嵌入”，是指将一个数据集或模型的特征值映射到一个更小的向量空间内的过程。在计算机自然语言处理领域中，Embeddings 通常被用来表示文本、图像或其他数据类型的特征，并使得模型能够更好地理解这些特征。️Embeddings翻译成中文，翻译成计算机自言语言处理的专业词汇️</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> gpt4all <span class=\"token keyword\">import</span> GPT4All<span class=\"token punctuation\">,</span> Embed4All\ntext <span class=\"token operator\">=</span> <span class=\"token string\">'The quick brown fox jumps over the lazy dog'</span>\nembedder <span class=\"token operator\">=</span> Embed4All<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noutput <span class=\"token operator\">=</span> embedder<span class=\"token punctuation\">.</span>embed<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p><a href=\"https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All.__init__\">https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All.__init__</a></p>\n<p>~/.username/.cache/gpt4all/ggml-all-MiniLM-L6-v2-f16.bin</p>\n<p>git clone <a href=\"https://github.com/nomic-ai/gpt4all\">https://github.com/nomic-ai/gpt4all</a></p>\n<p><a href=\"https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf\">https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf</a></p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">pip install -U langchain\n\npip install gpt4all<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>embeddings <span class=\"token keyword\">import</span> GPT4AllEmbeddings\n\n gpt4all_embd <span class=\"token operator\">=</span> GPT4AllEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n query_result <span class=\"token operator\">=</span> gpt4all_embd<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span><span class=\"token string\">\"This is test doc\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>query_result<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">pip install langchain sentence_transformers<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>embeddings <span class=\"token keyword\">import</span> HuggingFaceEmbeddings\n\nembeddings <span class=\"token operator\">=</span> HuggingFaceEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"This is a test document.\"</span>\nquery_result <span class=\"token operator\">=</span> embeddings<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>query_result <span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">3</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">embeddings <span class=\"token operator\">=</span> HuggingFaceEmbeddings<span class=\"token punctuation\">(</span>model_name<span class=\"token operator\">=</span><span class=\"token string\">\"sentence-transformers/all-MiniLM-L6-v2\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>sentence-transformers/all-MiniLM-L6-v2</p>\n<p>sentence_bert_config.json</p>\n<p>modules.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [00:00&lt;00:00, 836kB/s]<br />\nconfig_sentence_transformers.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00&lt;00:00, 254kB/s]<br />\n<a href=\"http://README.md\">README.md</a>: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10.6k/10.6k [00:00&lt;00:00, 12.6MB/s]<br />\nsentence_bert_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00&lt;00:00, 130kB/s]<br />\nconfig.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571/571 [00:00&lt;00:00, 703kB/s]<br />\npytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 438M/438M [06:21&lt;00:00, 1.15MB/s]<br />\n/home/parallels/miniconda3/envs/rag/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()</p>\n<p>#<a href=\"https://abetlen.github.io/llama-cpp-python/\">https://abetlen.github.io/llama-cpp-python/</a></p>\n<p>#%pip uninstall -y llama-cpp-python<br />\n#%pip install --upgrade llama-cpp-python</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>embeddings <span class=\"token keyword\">import</span> LlamaCppEmbeddings\nllama <span class=\"token operator\">=</span> LlamaCppEmbeddings<span class=\"token punctuation\">(</span>model_path<span class=\"token operator\">=</span>GPT4ALL_MODEL_PATH<span class=\"token punctuation\">)</span>\n\n<span class=\"token operator\">%</span><span class=\"token operator\">%</span>time\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"This is a test document.\"</span>​\nquery_result <span class=\"token operator\">=</span> llama<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\nCPU times<span class=\"token punctuation\">:</span> user <span class=\"token number\">12.9</span> s<span class=\"token punctuation\">,</span> sys<span class=\"token punctuation\">:</span> <span class=\"token number\">1.57</span> s<span class=\"token punctuation\">,</span> total<span class=\"token punctuation\">:</span> <span class=\"token number\">14.5</span> s\nWall time<span class=\"token punctuation\">:</span> <span class=\"token number\">2.13</span> s\n<span class=\"token operator\">%</span><span class=\"token operator\">%</span>time\ndoc_result <span class=\"token operator\">=</span> llama<span class=\"token punctuation\">.</span>embed_documents<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>text<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nCPU times<span class=\"token punctuation\">:</span> user <span class=\"token number\">10.4</span> s<span class=\"token punctuation\">,</span> sys<span class=\"token punctuation\">:</span> <span class=\"token number\">59.7</span> ms<span class=\"token punctuation\">,</span> total<span class=\"token punctuation\">:</span> <span class=\"token number\">10.4</span> s\nWall time<span class=\"token punctuation\">:</span> <span class=\"token number\">1.47</span> s<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>nc监听端口，如何可以指定IP</p>\n<p>要指定IP地址来监听端口，可以使用以下命令：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">nc -l &lt;IP地址&gt; &lt;端口号&gt;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>例如，要在IP地址为192.168.1.100上监听端口8888，可以运行以下命令：</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">nc -l 192.168.1.100 8888<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>这将使nc程序在指定的IP地址和端口上启动监听。</p>\n","text":" gpt4all pip install gpt4all Embeddings 翻译成中文为“嵌入”，是指将一个数据集或模型的特征值映射到一个更小的向量空间内的过程。在计算机自然语言处理领域中，Embeddings 通常被用来表示文本、图像或其他数据类型的特征，并使得模型能够更好...","link":"","photos":[],"count_time":{"symbolsCount":"3.3k","symbolsTime":"3 mins."},"categories":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/categories/gpt4all.json"}],"tags":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/tags/gpt4all.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#gpt4all\"><span class=\"toc-text\"> gpt4all</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#embeddings\"><span class=\"toc-text\"> Embeddings</span></a></li></ol></li></ol></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"长文本能力会不会杀死RAG","uid":"124bb865c7cb77ee9606b987c0e9b277","slug":"aigc/长文本能力会不会杀死RAG","date":"2024-03-14T07:45:09.026Z","updated":"2024-03-14T07:45:09.026Z","comments":true,"path":"api/articles/aigc/长文本能力会不会杀死RAG.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" 长文本能力会不会杀死RAG 随着 Gemini 超100万上下文的推出，推特上关于长文本能力会不会杀死RAG的讨论还是挺多的。围绕 RAG vs 长文本的成本的讨论还比较多，例如图1，但也有说法认为，长文本的成本会慢慢下降。 看到一个还不错的长推特评论，来自 Snorkel A...","link":"","photos":[],"count_time":{"symbolsCount":544,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"rag","slug":"AIGC/rag","count":1,"path":"api/categories/AIGC/rag.json"}],"tags":[{"name":"RAG","slug":"RAG","count":2,"path":"api/tags/RAG.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Langchain与RAG","uid":"3821cbe723791c750780b1a12e2a0049","slug":"aigc/langchain/Langchain与RAG","date":"2024-03-14T07:45:09.025Z","updated":"2024-03-14T07:45:09.025Z","comments":true,"path":"api/articles/aigc/langchain/Langchain与RAG.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":"https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg","text":" Langchain与RAG https://tnblog.net/hb/article/details/8200#LangChain调用 ","link":"","photos":[],"count_time":{"symbolsCount":70,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":117,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}