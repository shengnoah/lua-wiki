{"title":"gpt4all","uid":"bc3e68a199458a681f2c7fe3b421bbd6","slug":"aigc/langchain/GPT4all Embeddings","date":"2024-03-14T07:45:09.025Z","updated":"2024-03-14T07:45:09.025Z","comments":true,"path":"api/articles/aigc/langchain/GPT4all Embeddings.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h1>gpt4all</h1>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install gpt4all</span><br></pre></td></tr></table></figure>\n<h3 id=\"Embeddings\">Embeddings</h3>\n<p>翻译成中文为“嵌入”，是指将一个数据集或模型的特征值映射到一个更小的向量空间内的过程。在计算机自然语言处理领域中，Embeddings 通常被用来表示文本、图像或其他数据类型的特征，并使得模型能够更好地理解这些特征。️Embeddings翻译成中文，翻译成计算机自言语言处理的专业词汇️</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> gpt4all <span class=\"keyword\">import</span> GPT4All, Embed4All</span><br><span class=\"line\">text = <span class=\"string\">&#x27;The quick brown fox jumps over the lazy dog&#x27;</span></span><br><span class=\"line\">embedder = Embed4All()</span><br><span class=\"line\">output = embedder.embed(text)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output)</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All.__init__\">https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All.__init__</a></p>\n<p>~/.username/.cache/gpt4all/ggml-all-MiniLM-L6-v2-f16.bin</p>\n<p>git clone <a href=\"https://github.com/nomic-ai/gpt4all\">https://github.com/nomic-ai/gpt4all</a></p>\n<p><a href=\"https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf\">https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -U langchain</span><br><span class=\"line\"></span><br><span class=\"line\">pip install gpt4all</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langchain.embeddings <span class=\"keyword\">import</span> GPT4AllEmbeddings</span><br><span class=\"line\"></span><br><span class=\"line\"> gpt4all_embd = GPT4AllEmbeddings()</span><br><span class=\"line\"> query_result = gpt4all_embd.embed_query(<span class=\"string\">&quot;This is test doc&quot;</span>)</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(query_result)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install langchain sentence_transformers</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> langchain.embeddings <span class=\"keyword\">import</span> HuggingFaceEmbeddings</span><br><span class=\"line\"></span><br><span class=\"line\">embeddings = HuggingFaceEmbeddings()</span><br><span class=\"line\">text = <span class=\"string\">&quot;This is a test document.&quot;</span></span><br><span class=\"line\">query_result = embeddings.embed_query(text)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(query_result [:<span class=\"number\">3</span>])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">embeddings = HuggingFaceEmbeddings(model_name=<span class=\"string\">&quot;sentence-transformers/all-MiniLM-L6-v2&quot;</span>)</span><br></pre></td></tr></table></figure>\n<p>sentence-transformers/all-MiniLM-L6-v2</p>\n<p>sentence_bert_config.json</p>\n<p>modules.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 349/349 [00:00&lt;00:00, 836kB/s]<br>\nconfig_sentence_transformers.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00&lt;00:00, 254kB/s]<br>\n<a href=\"http://README.md\">README.md</a>: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10.6k/10.6k [00:00&lt;00:00, 12.6MB/s]<br>\nsentence_bert_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00&lt;00:00, 130kB/s]<br>\nconfig.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 571/571 [00:00&lt;00:00, 703kB/s]<br>\npytorch_model.bin: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 438M/438M [06:21&lt;00:00, 1.15MB/s]<br>\n/home/parallels/miniconda3/envs/rag/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()</p>\n<p>#<a href=\"https://abetlen.github.io/llama-cpp-python/\">https://abetlen.github.io/llama-cpp-python/</a></p>\n<p>#%pip uninstall -y llama-cpp-python<br>\n#%pip install --upgrade llama-cpp-python</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> langchain.embeddings <span class=\"keyword\">import</span> LlamaCppEmbeddings</span><br><span class=\"line\">llama = LlamaCppEmbeddings(model_path=GPT4ALL_MODEL_PATH)</span><br><span class=\"line\"></span><br><span class=\"line\">%%time</span><br><span class=\"line\">text = <span class=\"string\">&quot;This is a test document.&quot;</span>​</span><br><span class=\"line\">query_result = llama.embed_query(text)</span><br><span class=\"line\">CPU times: user <span class=\"number\">12.9</span> s, sys: <span class=\"number\">1.57</span> s, total: <span class=\"number\">14.5</span> s</span><br><span class=\"line\">Wall time: <span class=\"number\">2.13</span> s</span><br><span class=\"line\">%%time</span><br><span class=\"line\">doc_result = llama.embed_documents([text])</span><br><span class=\"line\">CPU times: user <span class=\"number\">10.4</span> s, sys: <span class=\"number\">59.7</span> ms, total: <span class=\"number\">10.4</span> s</span><br><span class=\"line\">Wall time: <span class=\"number\">1.47</span> s</span><br></pre></td></tr></table></figure>\n<p>nc监听端口，如何可以指定IP</p>\n<p>要指定IP地址来监听端口，可以使用以下命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nc -l &lt;IP地址&gt; &lt;端口号&gt;</span><br></pre></td></tr></table></figure>\n<p>例如，要在IP地址为192.168.1.100上监听端口8888，可以运行以下命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">nc -l 192.168.1.100 8888</span><br></pre></td></tr></table></figure>\n<p>这将使nc程序在指定的IP地址和端口上启动监听。</p>\n","text":"gpt4all 1pip install gpt4all Embeddings 翻译成中文为“嵌入”，是指将一个数据集或模型的特征值映射到一个更小的向量空间内的过程。在计算机自然语言处理领域中，Embeddings 通常被用来表示文本、图像或其他数据类型的特征，并使得模型能够更好...","link":"","photos":[],"count_time":{"symbolsCount":"3.4k","symbolsTime":"3 mins."},"categories":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/categories/gpt4all.json"}],"tags":[{"name":"gpt4all","slug":"gpt4all","count":1,"path":"api/tags/gpt4all.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\"><span class=\"toc-text\">gpt4all</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Embeddings\"><span class=\"toc-text\">Embeddings</span></a></li></ol></li></ol></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"长文本能力会不会杀死RAG","uid":"124bb865c7cb77ee9606b987c0e9b277","slug":"aigc/长文本能力会不会杀死RAG","date":"2024-03-14T07:45:09.026Z","updated":"2024-03-14T07:45:09.026Z","comments":true,"path":"api/articles/aigc/长文本能力会不会杀死RAG.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"长文本能力会不会杀死RAG 随着 Gemini 超100万上下文的推出，推特上关于长文本能力会不会杀死RAG的讨论还是挺多的。围绕 RAG vs 长文本的成本的讨论还比较多，例如图1，但也有说法认为，长文本的成本会慢慢下降。 看到一个还不错的长推特评论，来自 Snorkel AI...","link":"","photos":[],"count_time":{"symbolsCount":543,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"rag","slug":"AIGC/rag","count":1,"path":"api/categories/AIGC/rag.json"}],"tags":[{"name":"RAG","slug":"RAG","count":2,"path":"api/tags/RAG.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Langchain与RAG","uid":"3821cbe723791c750780b1a12e2a0049","slug":"aigc/langchain/Langchain与RAG","date":"2024-03-14T07:45:09.025Z","updated":"2024-03-14T07:45:09.025Z","comments":true,"path":"api/articles/aigc/langchain/Langchain与RAG.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"Langchain与RAG https://tnblog.net/hb/article/details/8200#LangChain调用 ","link":"","photos":[],"count_time":{"symbolsCount":69,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}