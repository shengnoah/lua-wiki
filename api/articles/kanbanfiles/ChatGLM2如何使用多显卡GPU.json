{"title":"ChatGLM2如何使用多显卡GPU","uid":"db337d0c1275ad3ba82eaea7216e78e0","slug":"kanbanfiles/ChatGLM2如何使用多显卡GPU","date":"2024-03-14T06:15:59.717Z","updated":"2024-03-14T06:15:59.717Z","comments":true,"path":"api/articles/kanbanfiles/ChatGLM2如何使用多显卡GPU.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h2 id=\"ChatGLM2的train-sh的NUM-GPUS如何设置配置双显卡？\"><a href=\"#ChatGLM2的train-sh的NUM-GPUS如何设置配置双显卡？\" class=\"headerlink\" title=\"ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？\"></a>ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？</h2><p>ChatGLM和ChatGLM2，对GPU配置的传参数样式不太一样，一代的时候，“0,1”这么用双显卡，二代的时候直接输入NUM_GPUS=2.</p>\n<p>要配置双显卡进行训练，可以将NUM_GPUS设置为2，以表示使用两个GPU。以下是一个示例的train.sh文件的内容：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> NUM_GPUS=2</span><br><span class=\"line\"></span><br><span class=\"line\">python train.py \\</span><br><span class=\"line\">  --data_dir=data \\</span><br><span class=\"line\">  --model_dir=model \\</span><br><span class=\"line\">  --num_gpus=<span class=\"variable\">$NUM_GPUS</span> \\</span><br><span class=\"line\">  --batch_size=64 \\</span><br><span class=\"line\">  --learning_rate=0.001</span><br></pre></td></tr></table></figure>\n\n<p>在这个示例中，将NUM_GPUS设置为2，并传递给train.py脚本的–num_gpus参数。根据你的需求，你可以调整其他参数，例如数据目录、模型目录、批量大小和学习率等。</p>\n<p>请注意，具体的命令可能会根据ChatGLM2的实际代码库有所不同，请根据你使用的代码库和框架进行相应调整。</p>\n<h2 id=\"ChatGLM2如何使用多显卡GPU\"><a href=\"#ChatGLM2如何使用多显卡GPU\" class=\"headerlink\" title=\"ChatGLM2如何使用多显卡GPU\"></a>ChatGLM2如何使用多显卡GPU</h2><p>要在ChatGLM2中使用多个显卡GPU，你需要使用分布式训练的方法。以下是一个使用多个显卡GPU进行ChatGLM2训练的示例：</p>\n<ol>\n<li><p>确保你的计算机上有多个显卡GPU，并安装了相应的驱动程序。</p>\n</li>\n<li><p>使用<code>transformers</code>库加载ChatGLM2模型和tokenizer：</p>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> ChatGPT</span><br><span class=\"line\"></span><br><span class=\"line\">model = ChatGPT.from_pretrained(<span class=\"string\">&quot;microsoft/DialoGPT-medium&quot;</span>)</span><br><span class=\"line\">tokenizer = AutoTokenizer.from_pretrained(<span class=\"string\">&quot;microsoft/DialoGPT-medium&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li>使用<code>torch.nn.DataParallel</code>将模型包装在多个GPU上：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\">model = nn.DataParallel(model)</span><br><span class=\"line\">model.to(device)</span><br></pre></td></tr></table></figure>\n\n<ol start=\"4\">\n<li>在训练循环中，确保将输入数据和目标标签移动到正确的设备上：</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input_ids = input_ids.to(device)</span><br><span class=\"line\">attention_mask = attention_mask.to(device)</span><br><span class=\"line\">labels = labels.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)</span><br></pre></td></tr></table></figure>\n\n<p>这样，模型就会自动在多个显卡GPU上并行计算，并共享梯度更新。</p>\n<p>请注意，使用多个显卡GPU进行训练可能需要更大的批次大小和更长的训练时间。此外，还可以通过设置CUDA_VISIBLE_DEVICES环境变量来选择要使用的特定GPU设备。</p>\n","text":"ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？ChatGLM和ChatGLM2，对GPU配置的传参数样式不太一样，一代的时候，“0,1”这么用双显卡，二代的时候直接输入NUM_GPUS=2. 要配置双显卡进行训练，可以将NUM_GPUS设置为2，以表示使...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"ChatGLM","slug":"ChatGLM","count":1,"path":"api/categories/ChatGLM.json"}],"tags":[{"name":"ChatGLM2","slug":"ChatGLM2","count":1,"path":"api/tags/ChatGLM2.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ChatGLM2%E7%9A%84train-sh%E7%9A%84NUM-GPUS%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%E9%85%8D%E7%BD%AE%E5%8F%8C%E6%98%BE%E5%8D%A1%EF%BC%9F\"><span class=\"toc-text\">ChatGLM2的train.sh的NUM_GPUS如何设置配置双显卡？</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#ChatGLM2%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E5%A4%9A%E6%98%BE%E5%8D%A1GPU\"><span class=\"toc-text\">ChatGLM2如何使用多显卡GPU</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Graylog3的Python调用库","uid":"17128178a8a90f40f15298b35f6dcb19","slug":"kanbanfiles/Graylog库引用","date":"2024-03-14T06:15:59.717Z","updated":"2024-03-14T06:15:59.717Z","comments":true,"path":"api/articles/kanbanfiles/Graylog库引用.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":"早期的Graylog2时期 ，Python Graylog的库也是Python版本的。到了Graylog3时期，使用了Python3版本，这时候Python的库就不能在Python中使用的， 需要将原有Pygralog2变成支持Python3的版本。 ","link":"","photos":[],"count_time":{"symbolsCount":128,"symbolsTime":"1 mins."},"categories":[{"name":"Sec","slug":"Sec","count":5,"path":"api/categories/Sec.json"},{"name":"Graylog","slug":"Sec/Graylog","count":3,"path":"api/categories/Sec/Graylog.json"}],"tags":[{"name":"Graylog","slug":"Graylog","count":3,"path":"api/tags/Graylog.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Hexo使用Gitee+PicGO图墙图片不显示","uid":"70ccad85c177ffedfa95e18f77517e68","slug":"kanbanfiles/Hexo使用Gitee+PicGO图墙图片不显示","date":"2024-03-14T06:15:59.717Z","updated":"2024-03-14T06:15:59.718Z","comments":true,"path":"api/articles/kanbanfiles/Hexo使用Gitee+PicGO图墙图片不显示.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":" 如何只对网页中的img标签进行no-referrer限制。 要对网页中的img标签进行no-referrer限制，您可以使用以下方法： 使用JavaScript：在网页中插入以下JavaScript代码，它将遍历所有的img标签，并为每个img标签设置rel属性为”norefe...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"obsidian","slug":"obsidian","count":8,"path":"api/categories/obsidian.json"},{"name":"hexo","slug":"obsidian/hexo","count":3,"path":"api/categories/obsidian/hexo.json"}],"tags":[{"name":"obsidian","slug":"obsidian","count":3,"path":"api/tags/obsidian.json"},{"name":"hexo","slug":"hexo","count":1,"path":"api/tags/hexo.json"},{"name":"picgo","slug":"picgo","count":1,"path":"api/tags/picgo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}