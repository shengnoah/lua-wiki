{"title":"Scrapy快速写爬虫","uid":"a0f1485d8813f2781144a51b0a71a712","slug":"old_topic/2016-09-17-342","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-14T07:45:09.225Z","comments":true,"path":"api/articles/old_topic/2016-09-17-342.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<p>看到别人的教程，学着测了一下，不错。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy startproject ren</span><br></pre></td></tr></table></figure>\n<p>直接保存到文件中</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LuarenSpider</span>(scrapy.Spider):</span><br><span class=\"line\">    name = <span class=\"string\">&quot;luaren&quot;</span> </span><br><span class=\"line\">    allowed_domains = [<span class=\"string\">&quot;lua.ren&quot;</span>]</span><br><span class=\"line\">    start_urls = [</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/topic/342/&#x27;</span></span><br><span class=\"line\">    ]        </span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">parse</span>(<span class=\"params\">self, response</span>):</span><br><span class=\"line\">        filename = response.url.split(<span class=\"string\">&quot;/&quot;</span>)[-<span class=\"number\">2</span>] </span><br><span class=\"line\">        <span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(filename, <span class=\"string\">&#x27;wb&#x27;</span>) <span class=\"keyword\">as</span> f: </span><br><span class=\"line\">            f.write(response.body)</span><br></pre></td></tr></table></figure>\n<p>保存到ORM中</p>\n<p>ORM定义</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">RenItem</span>(scrapy.Item):</span><br><span class=\"line\">    title = scrapy.Field()</span><br><span class=\"line\">    link = scrapy.Field()</span><br><span class=\"line\">    desc = scrapy.Field()</span><br></pre></td></tr></table></figure>\n<p>爬虫</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: utf-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> scrapy</span><br><span class=\"line\"><span class=\"keyword\">from</span> ren.items <span class=\"keyword\">import</span> RenItem</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LuarenSpider</span>(scrapy.Spider):</span><br><span class=\"line\">    name = <span class=\"string\">&quot;luaren&quot;</span> </span><br><span class=\"line\">    allowed_domains = [<span class=\"string\">&quot;lua.ren&quot;</span>]</span><br><span class=\"line\">    start_urls = [</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/&#x27;</span>,</span><br><span class=\"line\">        <span class=\"string\">&#x27;http://lua.ren/topic/342/&#x27;</span></span><br><span class=\"line\">    ]        </span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">parse</span>(<span class=\"params\">self, response</span>):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> sel <span class=\"keyword\">in</span> response.xpath(<span class=\"string\">&#x27;//ul/li&#x27;</span>):</span><br><span class=\"line\">            item = RenItem() </span><br><span class=\"line\">            item[<span class=\"string\">&#x27;title&#x27;</span>] = sel.xpath(<span class=\"string\">&#x27;a/text()&#x27;</span>).extract()</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;link&#x27;</span>] = sel.xpath(<span class=\"string\">&#x27;a/@href&#x27;</span>).extract()</span><br><span class=\"line\">            item[<span class=\"string\">&#x27;desc&#x27;</span>] = sel.xpath(<span class=\"string\">&#x27;text()&#x27;</span>).extract()</span><br><span class=\"line\">            <span class=\"keyword\">yield</span> item</span><br></pre></td></tr></table></figure>\n<p>先生成一堆的代码， 添加代码，按url进行依次访问，然的把body reponse通过回调返回给用用户处理，用户在cb中写自己的代码， xpath解析返回的数据，整个机制不是很复杂，不多说了。</p>\n<p>运行与保存结果为JSON数据。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy crawl luaren</span><br><span class=\"line\">scrapy crawl luaren -o items.json</span><br></pre></td></tr></table></figure>","text":"看到别人的教程，学着测了一下，不错。 1scrapy startproject ren 直接保存到文件中 123456789101112131415# -*- coding: utf-8 -*-import scrapyclass LuarenSpider(scrapy.Spid...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"toc":"","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"OpenResty向graylog推送数据","uid":"dbc3ab64f8a793e30ff0dafc0aa1a042","slug":"old_topic/2016-09-17-339","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-14T07:45:09.203Z","comments":true,"path":"api/articles/old_topic/2016-09-17-339.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"编辑作者：糖果 access_log syslog:server=0.0.0.0:55555 graylog2_format; error_log syslog:server=0.0.0.0:55555; ","link":"","photos":[],"count_time":{"symbolsCount":104,"symbolsTime":"1 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"MoonScript与Simple.http","uid":"df2fd49163891cc3e511275bc9921624","slug":"old_topic/2016-09-17-343","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-14T07:45:09.218Z","comments":true,"path":"api/articles/old_topic/2016-09-17-343.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"MoonScript调用Lapis的Simple.http，其实调用的就是OpenResty的http的接口。 candylab.moon 123456http = require &quot;lapis.nginx.http&quot;body, status_code, he...","link":"","photos":[],"count_time":{"symbolsCount":496,"symbolsTime":"1 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}