{"title":"爬虫小工具BeautifulSoup","uid":"916d00d5ac3386eee42a586e5f38ef7d","slug":"old_topic/2016-09-17-264","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-14T06:15:59.744Z","comments":true,"path":"api/articles/old_topic/2016-09-17-264.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<p>BeautifulSoup是一种用于分析网页HTML内容元素的工具，还有类似的Request也可完成相关工作。</p>\n<p>下面是一小段程序，翻出来：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> urllib2 <span class=\"keyword\">import</span> urlopen, URLError</span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">fetch</span>():</span><br><span class=\"line\">        baseUrl = <span class=\"string\">&#x27;http://house.focus.cn/msglist/7906/&#x27;</span></span><br><span class=\"line\">        hd = urlopen(baseUrl, timeout = <span class=\"number\">6</span>)</span><br><span class=\"line\">        content = hd.read()</span><br><span class=\"line\">        content = content.decode(<span class=\"string\">&#x27;gb2312&#x27;</span>, <span class=\"string\">&#x27;ignore&#x27;</span>)</span><br><span class=\"line\">        soup = BeautifulSoup(content)</span><br><span class=\"line\">        p = soup.findAll(<span class=\"string\">&#x27;a&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> item <span class=\"keyword\">in</span> p:</span><br><span class=\"line\">                val = <span class=\"built_in\">str</span>(item)</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (val.find(<span class=\"string\">&#x27;title&#x27;</span>) &gt; <span class=\"number\">0</span>) <span class=\"keyword\">and</span> (val.find(<span class=\"string\">&#x27;href&#x27;</span>) &gt; <span class=\"number\">0</span>) <span class=\"keyword\">and</span> (val.find(<span class=\"string\">&#x27;font&#x27;</span>) &gt; <span class=\"number\">0</span>):</span><br><span class=\"line\">                        <span class=\"built_in\">print</span> item.text</span><br><span class=\"line\">                        tmpurl =  <span class=\"string\">&#x27;http://house.focus.cn&#x27;</span> + <span class=\"built_in\">str</span>(item[<span class=\"string\">&#x27;href&#x27;</span>])</span><br><span class=\"line\">                        <span class=\"built_in\">print</span> tmpurl</span><br><span class=\"line\"></span><br><span class=\"line\">fetch()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n<p>Beautiful最本质完成一个作内容，是把HTML的元素标签”对像:化，item化。如果不喜欢那种，直接通过正则表达式在HTML内容中匹配数据，或是不是所有的都用正则，Beautiful是一个不错的选择。</p>\n<p>scrapy生成爬虫生成，更工程化，至少会自动生成一个目录构成，自动生成脚本脚架代码。没有非常大的爬取量，这些python工具可以完成任务的。</p>\n","text":"BeautifulSoup是一种用于分析网页HTML内容元素的工具，还有类似的Request也可完成相关工作。 下面是一小段程序，翻出来： 123456789101112131415161718192021from urllib2 import urlopen, URLError...","link":"","photos":[],"count_time":{"symbolsCount":"1k","symbolsTime":"1 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"toc":"","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"PIL与Pylibmc","uid":"7a3c5a1d23bfd5b9726de20fd52ae700","slug":"old_topic/2016-09-17-262","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-14T06:15:59.744Z","comments":true,"path":"api/articles/old_topic/2016-09-17-262.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"作者：糖果 要用一个小系统，需要装PIL和Pylibmc。 PIL就不用pip装了，直接用apt-get装： 1sudo apt-get install python-imaging Pylibmc需要安装下面的依赖库： Ubuntu 123sudo apt-get instal...","link":"","photos":[],"count_time":{"symbolsCount":334,"symbolsTime":"1 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Lapis快速分页查询","uid":"e7519b56d8be6d962f5762cfa924baa8","slug":"old_topic/2016-09-17-265","date":"2016-09-17T14:50:18.000Z","updated":"2024-03-14T06:15:59.744Z","comments":true,"path":"api/articles/old_topic/2016-09-17-265.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"作者：糖果 Lapis分页查询和一般的Django分页查询有明显的分别： lapis分页器对象的创建和查询条件的指定是同时的。 1234567891011121314151617181920local lapis = require &quot;lapis&quot;local ...","link":"","photos":[],"count_time":{"symbolsCount":"1.9k","symbolsTime":"2 mins."},"categories":[{"name":"topic","slug":"topic","count":308,"path":"api/categories/topic.json"}],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}