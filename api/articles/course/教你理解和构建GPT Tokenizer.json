{"title":"教你理解和构建GPT Tokenizer","uid":"3f78d971eabe4d648c246dd6ba6afdb2","slug":"course/教你理解和构建GPT Tokenizer","date":"2024-03-14T06:15:59.714Z","updated":"2024-03-14T06:15:59.714Z","comments":true,"path":"api/articles/course/教你理解和构建GPT Tokenizer.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"content":"<h1 id=\"教你理解和构建GPT-Tokenizer\"><a href=\"#教你理解和构建GPT-Tokenizer\" class=\"headerlink\" title=\"教你理解和构建GPT Tokenizer\"></a>教你理解和构建GPT Tokenizer</h1><p>Open AI传奇研究员Andrej Karpathy的新课，教你理解和构建GPT Tokenizer。</p>\n<p>他可以把相当复杂的LLM概念用非常好理解的方式讲出来。希望了解LLM的强烈建议听一下他的课，包括一些历史课程。  </p>\n<p>用GPT-4翻译了一下这节课，感兴趣可以听一下。字幕文件下载和历史课程会放最后。  </p>\n<p>补充一下视频介绍：  </p>\n<p>分词器是大语言模型（LLM）处理流程中一个独立且关键的环节。它们有专属的训练数据集、采用特定的训练算法——字节对编码（Byte Pair Encoding），训练完成后，分词器能够执行两个核心功能：encode() 函数将普通文本字符串转换为词元，而 decode() 函数则能将词元还原为原始文本字符串。在这场讲座中，我们将一步步揭开 OpenAI GPT 系列分词器的构建过程。  </p>\n<p>我们将发现，许多大语言模型(LLM)表现出的异常行为和问题，其实都源于标记化(tokenization)这一环节。我们会针对这些问题进行详细讨论，探究标记化为何成为问题的关键所在，以及为什么最理想的情况是有人能够找到办法，完全去除这一处理阶段。</p>\n<p>00:00:00 intro: Tokenization, GPT-2 paper, tokenization-related issues<br>00:05:50 tokenization by example in a Web UI (tiktokenizer)<br>00:14:56 strings in Python, Unicode code points<br>00:18:15 Unicode byte encodings, ASCII, UTF-8, UTF-16, UTF-32<br>00:22:47 daydreaming: deleting tokenization<br>00:23:50 Byte Pair Encoding (BPE) algorithm walkthrough<br>00:27:02 starting the implementation<br>00:28:35 counting consecutive pairs, finding most common pair<br>00:30:36 merging the most common pair<br>00:34:58 training the tokenizer: adding the while loop, compression ratio<br>00:39:20 tokenizer/LLM diagram: it is a completely separate stage<br>00:42:47 decoding tokens to strings<br>00:48:21 encoding strings to tokens<br>00:57:36 regex patterns to force splits across categories<br>01:11:38 tiktoken library intro, differences between GPT-2/GPT-4 regex<br>01:14:59 GPT-2 encoder.py released by OpenAI walkthrough<br>01:18:26 special tokens, tiktoken handling of, GPT-2/GPT-4 differences<br>01:25:28 minbpe exercise time! write your own GPT-4 tokenizer<br>01:28:42 sentencepiece library intro, used to train Llama 2 vocabulary<br>01:43:27 how to set vocabulary set? revisiting gpt.py transformer<br>01:48:11 training new tokens, example of prompt compression<br>01:49:58 multimodal [image, video, audio] tokenization with vector quantization<br>01:51:41 revisiting and explaining the quirks of LLM tokenization<br>02:10:20 final recommendations</p>\n<p><a href=\"https://pan.quark.cn/s/60d51adb8ecc#/list/share\">https://pan.quark.cn/s/60d51adb8ecc#/list/share</a></p>\n<p><img src=\"https://gitee.com/shengnoah/picture/raw/master/20240221124153.png\" alt=\"image.png\"></p>\n","text":"教你理解和构建GPT TokenizerOpen AI传奇研究员Andrej Karpathy的新课，教你理解和构建GPT Tokenizer。 他可以把相当复杂的LLM概念用非常好理解的方式讲出来。希望了解LLM的强烈建议听一下他的课，包括一些历史课程。 用GPT-4翻译了一下...","link":"","photos":[],"count_time":{"symbolsCount":"1.9k","symbolsTime":"2 mins."},"categories":[{"name":"课程","slug":"课程","count":1,"path":"api/categories/课程.json"}],"tags":[{"name":"GPT","slug":"GPT","count":1,"path":"api/tags/GPT.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%95%99%E4%BD%A0%E7%90%86%E8%A7%A3%E5%92%8C%E6%9E%84%E5%BB%BAGPT-Tokenizer\"><span class=\"toc-text\">教你理解和构建GPT Tokenizer</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"HFish蜜罐与SOC安全运营中心","uid":"3e5e0ad875e008f2f5596d741d0ac42f","slug":"candylab/soc","date":"2024-03-14T06:15:59.714Z","updated":"2024-03-14T06:15:59.714Z","comments":true,"path":"api/articles/candylab/soc.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":"HFish蜜罐与SOC安全运营中心 Excerpt作者：糖果 0x01 传统蜜罐传统蜜罐在安全运营当中，起到防御与威胁发现的作用。蜜罐系统提供Web（WordPress等）服务模拟、及各种主机服务模拟，比如：ElasticSearch、FTP、Telnet、Redis等。 类似F...","link":"","photos":[],"count_time":{"symbolsCount":"2.6k","symbolsTime":"2 mins."},"categories":[{"name":"文章","slug":"文章","count":22,"path":"api/categories/文章.json"}],"tags":[],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"ElasticSearch数据库","uid":"d4d3965730bda512a6efdd0a5e371f72","slug":"database/ElasticSearch数据库","date":"2024-03-14T06:15:59.714Z","updated":"2024-03-14T06:15:59.714Z","comments":true,"path":"api/articles/database/ElasticSearch数据库.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"ElasticSearch是一个开源的分布式搜索和分析引擎，它是基于Apache Lucene构建的。它具有高可用性、可扩展性和实时性等特点。ElasticSearch被广泛应用于构建实时的、可扩展的全文搜索和分析系统。 首先，ElasticSearch采用了分布式架构，可以将数...","link":"","photos":[],"count_time":{"symbolsCount":"1.3k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}