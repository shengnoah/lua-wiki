{"title":"距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","uid":"7e39ea8bf1e59b18cfe1f80ce00c3293","slug":"weibo/距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间","date":"2024-03-14T06:15:59.771Z","updated":"2024-03-14T06:15:59.771Z","comments":true,"path":"api/articles/weibo/距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"content":"<h1 id=\"距离机器人-AI-的-ChatGPT-时刻大约还有-3-年时间\"><a href=\"#距离机器人-AI-的-ChatGPT-时刻大约还有-3-年时间\" class=\"headerlink\" title=\"距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间\"></a>距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</h1><p>距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</p>\n<p>英伟达 AI 科学家 Jim Fan 预言：距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间  </p>\n<p>以下为其推文转译：  </p>\n<p>除了大语言模型（LLM）之外，2024年最重大的领域无疑是机器人学。我们距离实体 AI 智能体实现 ChatGPT 式的突破仅有大约三年的时间。长期以来，我们一直受到莫拉维克悖论（Moravec’s paradox）的困扰，这一直觉反常的现象表明：“人类觉得简单的任务，对 AI 来说却异常困难，反之亦然”。  </p>\n<p>2024年将成为 AI 领域首次大规模反抗这种困境的一年。虽然我们不会立刻取得胜利，但我们已经在通往成功的道路上迈出了坚实的步伐。  </p>\n<p>回顾2023年，我们已经初步见识到了未来机器人的基础模型和平台：  </p>\n<ul>\n<li>多模态大型语言模型与机器人手臂作为物理输入输出接口：VIMA、PerAct、RvT（NVIDIA）、RT-1、RT-2、PaLM-E（Google）、RoboCat（DeepMind）、Octo（伯克利、斯坦福、卡内基梅隆大学）等。  </li>\n<li>连接高级推理（大型语言模型）与低级控制的算法：Eureka（NVIDIA）、Code as Policies（Google）等。  </li>\n<li>在坚固硬件方面取得巨大进步：Tesla Optimus <a href=\"https://weibo.com/n/elonmusk\">@elonmusk</a>、Figure <a href=\"https://weibo.com/n/adcock_brett\">@adcock_brett</a>、1X <a href=\"https://weibo.com/n/ericjang11\">@ericjang11</a>、Apptronik、Sanctuary、Agility+Amazon、Unitree 等。  </li>\n<li>数据长期以来一直是机器人学发展的弱点。研究社区正致力于创造下一个“影像网”（ImageNet），如 Open X-Embodiment (RT-X) 数据集。尽管这些数据集的多样性尚未达到理想状态，但即使是微小的进步也意味着重大的飞跃。  </li>\n<li>在解决机器人灵活性甚至整个计算机视觉领域中，仿真和合成数据将扮演关键角色。<br>(1) NVIDIA Isaac 能以比现实时间快1000倍的速度进行仿真，其产生的数据量会随着计算能力的提升而增长。<br>(2) 通过硬件加速的光线追踪技术实现逼真效果，这种逼真的渲染还自带地面真值标注，比如分割、深度、3D 姿态等。<br>(3) 仿真器甚至能够扩展现实世界的数据，形成更大的数据集，从而大大减少昂贵的人类示范工作的需要。NVIDIA 的 MimicGen 就是一个很好的例子。  </li>\n</ul>\n<p>我个人全力投入这一领域。最精彩的部分还在后面。</p>\n","text":"距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 英伟达 AI 科学家 Jim Fan 预言：距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间 以下为其推文转译： 除了大语言模型（LLM）之...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"},{"name":"weibo","slug":"AIGC/weibo","count":59,"path":"api/categories/AIGC/weibo.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%B7%9D%E7%A6%BB%E6%9C%BA%E5%99%A8%E4%BA%BA-AI-%E7%9A%84-ChatGPT-%E6%97%B6%E5%88%BB%E5%A4%A7%E7%BA%A6%E8%BF%98%E6%9C%89-3-%E5%B9%B4%E6%97%B6%E9%97%B4\"><span class=\"toc-text\">距离机器人 AI 的 ChatGPT 时刻大约还有 3 年时间</span></a></li></ol>","author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"最优秀的员工专注于内容而非流程","uid":"14892301d84b563bc4bbcba4dcec4bc6","slug":"weibo/最优秀的员工专注于内容而非流程","date":"2024-03-14T06:15:59.771Z","updated":"2024-03-14T06:15:59.771Z","comments":true,"path":"api/articles/weibo/最优秀的员工专注于内容而非流程.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":null,"text":"最优秀的员工专注于内容而非流程27 年前，史蒂夫·乔布斯曾经说过：最优秀的员工专注于内容而非流程。研究证实了他的观点 乔布斯还说过：最优秀的员工通常也是最难管理的。 1979年，史蒂夫·乔布斯和一批苹果的工程师及高层访问了 Xerox PARC（帕洛阿尔托研究中心），这是一个致力...","link":"","photos":[],"count_time":{"symbolsCount":"2.4k","symbolsTime":"2 mins."},"categories":[{"name":"classical","slug":"classical","count":6,"path":"api/categories/classical.json"}],"tags":[{"name":"weibo","slug":"weibo","count":62,"path":"api/tags/weibo.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"视频一致性模型（VideoLCM）","uid":"034f4a0d42715b75637c06564678c3f4","slug":"weibo/视频一致性模型（VideoLCM）","date":"2024-03-14T06:15:59.771Z","updated":"2024-03-14T06:15:59.771Z","comments":true,"path":"api/articles/weibo/视频一致性模型（VideoLCM）.json","keywords":"AIGC,LLM,糖果AIGC实验室","cover":[],"text":"第一个视频一致性模型（VideoLCM）也来了！ 我们之前介绍过图像的LCM（访问微博正文，微博正文），现在视频的LCM也开始卷起来了。 它只需 4 个采样步骤即可生成视频：生成 16 帧（分辨率为 256x256）仅需 10 秒！虽然还不是实时的（像图像LCM那样），但已经接近...","link":"","photos":[],"count_time":{"symbolsCount":582,"symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":119,"path":"api/categories/AIGC.json"}],"tags":[{"name":"AIGC","slug":"AIGC","count":6,"path":"api/tags/AIGC.json"},{"name":"LLM","slug":"LLM","count":4,"path":"api/tags/LLM.json"}],"author":{"name":"安全书","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/20210313122054101.png","link":"/","description":"《墨守之道-Web服务安全架构与实践》","socials":{"github":"https://github.com/shengnoah","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/u/3732639263","zhihu":"https://www.zhihu.com/people/openresty","csdn":"","juejin":"","customs":{}}}}}